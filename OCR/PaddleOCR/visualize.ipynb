{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/ngoc/githubs/aux/OCR/PaddleOCR/results/vizwiz_ocr.json\", 'r') as file:\n",
    "    results = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'idx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_60469/3326528492.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'/mnt/datasets/llava_data/llava_second_stage/{results[0][\"texts\"]}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mbboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bboxes\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Example bounding boxes (x, y, width, height)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"idx\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"idx\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mvisualize_image_with_bboxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'idx'"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_image_with_bboxes(image_path, bboxes, labels, scores):\n",
    "    # Load the image\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    # Create a drawing context\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    # Load a font\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 15)\n",
    "    except IOError:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    # Draw bounding boxes and labels\n",
    "    for bbox, label, score in zip(bboxes, labels, scores):\n",
    "        if score >= 0.3:\n",
    "            xmin, ymin, xmax, ymax = bbox\n",
    "            # Draw the bounding box\n",
    "            draw.rectangle([xmin, ymin, xmax, ymax], outline=\"red\", width=2)\n",
    "            # Put the label near the bounding box\n",
    "            text_size = draw.textsize(label, font=font)\n",
    "            draw.rectangle([xmin, ymin - text_size[1], xmin + text_size[0], ymin], fill=\"red\")\n",
    "            draw.text((xmin, ymin - text_size[1]), label, fill=\"white\", font=font)\n",
    "    \n",
    "    # Display the image using Matplotlib\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "idx = 00\n",
    "image_path = f'/mnt/datasets/llava_data/llava_second_stage/{results[0][\"texts\"]}'\n",
    "bboxes = results[idx][\"bboxes\"]  # Example bounding boxes (x, y, width, height)\n",
    "labels = results[idx][\"texts\"]\n",
    "scores = results[0][\"idx\"]\n",
    "visualize_image_with_bboxes(image_path, bboxes, labels, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img': 'vg/VG_100K/2359476.jpg',\n",
       " 'texts': ['DELL'],\n",
       " 'bboxes': [[66.0, 33.0, 102.0, 56.0]],\n",
       " 'scores': [0.9036558866500854]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codetr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
