[{"id": "000000053864", "image": "coco/train2017/000000053864.jpg", "conversations": [{"from": "human", "value": "<image>\nWhere is the cat sitting?"}, {"from": "gpt", "value": "The cat is sitting on top of an open laptop computer."}, {"from": "human", "value": "What is the cat doing while sitting on the laptop?"}, {"from": "gpt", "value": "The cat is playing with a pencil and possibly grooming itself while sitting on the laptop's keyboard."}, {"from": "human", "value": "What color is the cat in the image?"}, {"from": "gpt", "value": "The cat in the image is black."}, {"from": "human", "value": "Is the cat only playing with the pencil or doing anything else?"}, {"from": "gpt", "value": "The primary focus of the cat is playing with the pencil in front of it, but it is possible it could also be grooming itself intermittently as it interacts with the pencil."}, {"from": "human", "value": "What potential problems might arise from a cat sitting on an open laptop?"}, {"from": "gpt", "value": "Several potential problems might arise from a cat sitting on an open laptop:\n\n1. Accidental Input: The cat's weight or movement on the keyboard might cause unintended commands, typing errors or potentially even change settings or interfere with the normal functioning of the laptop.\n\n2. Damage to the Laptop: The cat's claws could scratch the laptop's screen, keyboard, or other surfaces. Additionally, the cat's playfulness with the pencil could accidentally knock it into the screen, damaging it.\n\n3. Overheating: Laptops rely on internal fans and ventilation to dissipate heat produced during normal operation. A cat sitting on the laptop could block these vents, impeding airflow and resulting in overheating. This could potentially cause hardware damage and reduced performance or even a complete shutdown of the laptop.\n\n4. Hair and Dirt: A cat sitting on a laptop could transfer hair, fur, or dirt from its body onto the device. This can not only lead to a dirty laptop but could also result in dirt or fur making its way into the device's internal components, which could cause problems over time.\n\n5. Distraction: The presence of the cat on the laptop could make it difficult for the user to focus on their work or activities, reducing productivity and potentially causing frustration.\n\nIn summary, a cat sitting on an open laptop could lead to various problems, from accidental input and damage to the laptop to overheating and cleanliness issues, as well as posing a distraction for the user."}]}, {"id": "000000031411", "image": "coco/train2017/000000031411.jpg", "conversations": [{"from": "human", "value": "<image>\nAre the giraffes in an open field or an enclosure?"}, {"from": "gpt", "value": "The giraffes are in an enclosure, and there is a fence visible in the image."}, {"from": "human", "value": "Can you describe how the giraffes are interacting with each other?"}, {"from": "gpt", "value": "The giraffes are interacting by showing affection to one another. One giraffe is licking behind the head of the other, and they are cuddling and touching faces in a tender and affectionate manner."}, {"from": "human", "value": "What type of environment are the giraffes in, based on what is visible in the image?"}, {"from": "gpt", "value": "The giraffes are in a heavily wooded area with grass and trees surrounding them, suggesting a natural or semi-natural setting within their enclosure."}, {"from": "human", "value": "Are the giraffes young or mature?"}, {"from": "gpt", "value": "Based on the image, the giraffes are adult, as they have fully developed features and exhibit mature size and proportions."}, {"from": "human", "value": "Why do giraffes display such social behavior?"}, {"from": "gpt", "value": "Giraffes display social behavior as a form of bonding and maintaining relationships within their social group. These connections are important for various reasons, including mutual defense, coordination during feeding and migration, and overall well-being. Affectionate interactions, such as licking, cuddling, and touching faces, can help strengthen the bonds between individuals and foster a sense of trust and unity within the group.\n\nFurthermore, this social behavior can also serve as a method of communication, allowing the giraffes to convey their intentions, emotions, and needs to one another. For instance, licking and touching faces can be perceived as a nurturing and reassuring gesture, signaling care and support within the group.\n\nIn summary, social behavior among giraffes serves multiple purposes, including bonding, communication, and maintaining relationships within their social group, which in turn are crucial for their survival and overall well-being. The affectionate interactions captured in the image exemplify some of these behaviors that foster harmony and cohesion in the giraffe community."}]}, {"id": "000000194722", "image": "coco/train2017/000000194722.jpg", "conversations": [{"from": "human", "value": "What type of airplane is visible in the image?\n<image>"}, {"from": "gpt", "value": "A biplane is visible in the image, flying over the ocean."}, {"from": "human", "value": "What kind of terrain or scenery surrounds the coastline?"}, {"from": "gpt", "value": "The coastline featured in the image consists of a rocky shore line."}, {"from": "human", "value": "What is the color of the ocean in the image?"}, {"from": "gpt", "value": "The ocean in the image appears to be blue."}, {"from": "human", "value": "What are the weather conditions in the image?"}, {"from": "gpt", "value": "The weather conditions in the image are quite favorable, with clear skies indicating a pleasant day for flying."}, {"from": "human", "value": "What might be some reasons a biplane is flying over this coastal area?"}, {"from": "gpt", "value": "There could be several reasons for a biplane flying over the coastal area in the image. Some of these reasons may include:\n\n1. Recreational flight: The biplane's pilot could be enjoying a leisurely flight to appreciate the area's beauty, take in the breathtaking views of the coastline and ocean, and experience the exhilarating feeling of flying in an open cockpit in the clear skies.\n\n2. Sightseeing tours: The biplane could be used for sightseeing tours, where passengers are taken on brief flights along the coastline to experience aerial views of the stunning landscapes and the ocean. Such tours can be thrilling for those looking for unique ways to explore and experience a destination.\n\n3. Aerial photography or videography: The pilot might be capturing photographs or videos of the coastline and surrounding area from an aerial perspective. Aerial photography and videography can provide valuable insights and unique views of landscapes, which can be useful for various purposes such as marketing, research, or personal interest.\n\n4. Air show or exhibition: The biplane could be part of an air show, exhibition, or flying event that takes place along the coastline. These events often showcase historical or unique aircraft and involve aerial demonstrations, dogfights, and acrobatics to entertain audiences and promote aviation.\n\n5. Training or practice: The pilot might be conducting training or practice maneuvers, such as learning to navigate along a coastline or honing their flying skills in different environments and weather conditions.\n\nIn summary, the biplane flying over the coastal area in the image could be due to several reasons ranging from recreational flight, sightseeing tours, aerial photography, participating in an air show, or training and practice."}]}, {"id": "000000082881", "image": "coco/train2017/000000082881.jpg", "conversations": [{"from": "human", "value": "How many people are skiing in the image?\n<image>"}, {"from": "gpt", "value": "There are two people skiing in the image."}, {"from": "human", "value": "Is any person leading in the skiing activity? If so, can you describe their clothing?"}, {"from": "gpt", "value": "Yes, one skier is leading, and they are wearing blue clothing."}, {"from": "human", "value": "What is the perspective from which the image is taken?"}, {"from": "gpt", "value": "The image is taken from a back diagonal view of the girl and a back view of the boy, both on skis and standing in the snow."}, {"from": "human", "value": "What can you see in the background of the image?"}, {"from": "gpt", "value": "In the background of the image, there are a few trees, a shed, and a small building."}, {"from": "human", "value": "What are some suitable safety precautions to take while skiing in such an environment?"}, {"from": "gpt", "value": "When skiing in the environment depicted in the image, it's essential to take the following safety precautions:\n\n1. Wear appropriate clothing: Dress in layers, including thermal or moisture-wicking base layers, insulation layers, and waterproof/windproof outer layers. This will help keep you warm, dry, and comfortable during your skiing session. Don't forget a hat, gloves, and warm socks.\n\n2. Wear proper ski equipment: Ensure that you have the correct ski equipment, such as skis, boots, bindings, and poles that are suitable for your skill level and the type of skiing you will be doing (cross-country or downhill). Skiers should also wear a helmet for head protection.\n\n3. Ski within your skill level: Choose ski trails or slopes that are appropriate for your level of expertise, and avoid skiing on terrain that is too challenging for your ability. Know your limits and progress gradually as you build confidence and skill.\n\n4. Learn skiing techniques and practice: Take skiing lessons from a certified instructor to learn proper techniques and improve your skills. Regular practice will help you become a better and safer skier.\n\n5. Observe ski trail rules and signs: Follow the rules and guidelines set by the ski area or trail system. Pay attention to trail signs and warnings, and respect other skiers and their rights of way.\n\n6. Ski with a buddy: Whenever possible, ski with a friend or in a group. This ensures that you have someone to help you or seek assistance in case of an emergency or injury.\n\n7. Have an emergency plan: Carry a basic first aid kit and a fully charged mobile phone in a waterproof case. Be aware of your location and know the local emergency numbers, so you can call for help in case of an accident or emergency.\n\nBy following these safety precautions, skiers can enjoy their time on the slopes or trails while minimizing the risk of accidents and injuries."}]}, {"id": "000000221696", "image": "coco/train2017/000000221696.jpg", "conversations": [{"from": "human", "value": "What are the main ingredients in the soup?\n<image>"}, {"from": "gpt", "value": "The main ingredients in the soup are noodles, broth, celery, onions, tofu, and broccoli."}, {"from": "human", "value": "What kind of bowl is the soup served in?"}, {"from": "gpt", "value": "The soup is served in a white bowl."}, {"from": "human", "value": "What is next to the bowl of soup on the counter?"}, {"from": "gpt", "value": "On the counter next to the bowl of soup, there is a bottle of sauce and a white spoon."}, {"from": "human", "value": "Could you describe this soup as an Asian noodle soup?"}, {"from": "gpt", "value": "Yes, considering the presence of ingredients like noodles, tofu, and broccoli, this dish can be described as an Asian noodle soup."}, {"from": "human", "value": "What could be some potential sauce options for this Asian noodle soup?"}, {"from": "gpt", "value": "There are several potential sauce options for this Asian noodle soup, which can enhance its flavor and provide a unique taste. Some popular choices include:\n\n1. Soy Sauce: A versatile and widely used condiment in Asian cuisine, soy sauce adds a rich, salty flavor to the soup.\n\n2. Sesame Oil: This aromatic oil has a nutty taste and can add depth to the soup's flavor profile.\n\n3. Chili Sauce: A spicy condiment that will give the soup a kick, chili sauce is ideal for those who prefer heat in their dishes. Options include Sriracha, Sambal Oelek, or other regional chili sauces.\n\n4. Oyster Sauce: A thick, savory sauce made from oyster extracts that can add a rich umami taste to the soup.\n\n5. Hoisin Sauce: A sweet and salty sauce, hoisin can add a complex and distinct flavor to the Asian noodle soup.\n\n6. Fish Sauce: A potent and salty condiment derived from fermented fish, fish sauce can provide an intense umami flavor to the soup. \n\nThese sauce options can be used individually or combined to create a balanced and unique taste. The choice of sauce(s) will depend on personal preferences and the specific flavors one desires in the soup."}]}, {"id": "000000228442", "image": "coco/train2017/000000228442.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the main color of the bathroom in the image?"}, {"from": "gpt", "value": "The main color of the bathroom in the image is white."}, {"from": "human", "value": "What is the color of the tile floor in the bathroom?"}, {"from": "gpt", "value": "The bathroom has a blue tile floor."}, {"from": "human", "value": "Are there windows in the bathroom?"}, {"from": "gpt", "value": "Yes, there are large windows in the bathroom."}, {"from": "human", "value": "What type of bathtub is in the bathroom?"}, {"from": "gpt", "value": "There is a wooden bathtub placed in the middle of the bathroom."}, {"from": "human", "value": "Please provide a short description of the bathroom's overall style and features."}, {"from": "gpt", "value": "The bathroom is a modern, spacious, and well-illuminated space featuring a white color scheme with a blue tile floor. It has large windows that provide natural light and a pleasant view. A luxurious wooden bathtub is the centerpiece of the room, adding a touch of warmth and elegance to the contemporary design. The bathroom is also equipped with all the essential amenities and possibly even some additional high-end features, making it a comfortable and unique space for relaxation and personal care."}]}, {"id": "000000257162", "image": "coco/train2017/000000257162.jpg", "conversations": [{"from": "human", "value": "What is the main subject of the image?\n<image>"}, {"from": "gpt", "value": "The main subject of the image is a truck with Furnari's life-size sculpture \"Lunchtime on a Skyscraper\" displayed on it."}, {"from": "human", "value": "What color is the truck in the image?"}, {"from": "gpt", "value": "The truck in the image is gray."}, {"from": "human", "value": "What do the statues on the truck depict?"}, {"from": "gpt", "value": "The statues on the truck depict several men sitting on a bench, recreating the famous photograph \"Lunch Atop a Skyscraper\" which was taken during the construction of the Rockefeller Center in New York City in 1932. The sculpture captures the iconic scene of these workers taking a break and eating lunch while sitting on a steel beam high above the streets below."}, {"from": "human", "value": "Who is responsible for creating this life-size sculpture?"}, {"from": "gpt", "value": "The life-size sculpture \"Lunchtime on a Skyscraper\" was created by artist Sergio Furnari."}, {"from": "human", "value": "Can you provide more context about the famous photograph that inspired the sculpture?"}, {"from": "gpt", "value": "Certainly! The photograph, \"Lunch Atop a Skyscraper,\" was taken on September 20, 1932, during the construction of the Rockefeller Center in midtown Manhattan, New York City. The image features 11 ironworkers sitting on a steel beam suspended high above the streets below, casually eating lunch while dangling their legs over the edge. Charles C. Ebbets has been credited as the photographer for this iconic image.\n\nThe photograph was published in the New York Herald Tribune on October 2, 1932, and it quickly gained popularity for capturing the spirit of the city and the boldness of the workers who risked their lives daily to build these towering skyscrapers. It has since become an enduring symbol of the industrial age and the spirit of the workers who helped shape modern cities.\n\nSergio Furnari's life-size sculpture, \"Lunchtime on a Skyscraper,\" was inspired by this iconic image, recreating the scene in 3D for viewers to appreciate the incredible feat captured in the original photograph. The sculpture pays homage to the ironworkers and the remarkable achievements of their era. It also demonstrates the lasting impact of this photograph on popular culture and the art world."}]}, {"id": "000000216766", "image": "coco/train2017/000000216766.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the person sitting or laying on the bench?"}, {"from": "gpt", "value": "The person is laying on the bench by the ocean."}, {"from": "human", "value": "What is the weather like at the beach?"}, {"from": "gpt", "value": "The weather at the beach is windy."}, {"from": "human", "value": "What object is parked near the person on the bench?"}, {"from": "gpt", "value": "A bicycle is parked near the person on the bench."}, {"from": "human", "value": "What are some potential reasons for the person to be resting on the bench next to the ocean with their bicycle?"}, {"from": "gpt", "value": "There could be several potential reasons for the person resting on the bench next to the ocean with their bicycle:\n\n1. Relaxation: The person might have been riding their bicycle along the beach for leisure and decided to stop for a break, taking in the beautiful ocean view and the sound of the waves, while laying on the bench.\n\n2. Exercise break: The person could have been cycling as part of their workout routine and chose the scenic beach spot to rest, cool down, and regain their energy before continuing their cycling session.\n\n3. Recovery from fatigue: The person might have ridden a long distance and started feeling tired, so they decided to lay down on the bench to recover their strength and energy.\n\n4. Contemplation or meditation: The beach can provide a tranquil environment conducive to contemplation and introspection. After a cycling session, the person might have decided to stop at the bench to enjoy the calming atmosphere of the ocean while laying down, which can help clear their mind and induce a meditative state.\n\n5. Social or photography opportunities: The beach setting is popular for gatherings or photoshoots, and having a bicycle around can add an interesting element to the shot. The person might have chosen to lay on the bench to pose for a photograph or wait for a friend to join them for a bike ride or social event.\n\nIn conclusion, the image showcases various elements like cycling, ocean view, and relaxation, reflecting diverse possibilities such as taking a break from exercise, leisurely enjoying nature, or seeking meditative tranquility."}]}, {"id": "000000111831", "image": "coco/train2017/000000111831.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat time of day is depicted in the image?"}, {"from": "gpt", "value": "The image is showing a busy city street scene at night."}, {"from": "human", "value": "What can be observed about the traffic in the image?"}, {"from": "gpt", "value": "In the image, there is heavy bus traffic, with buses making their way through the busy intersection."}, {"from": "human", "value": "What are the people doing at the corner of the intersection?"}, {"from": "gpt", "value": "A large crowd of people is standing at the corner of the intersection, waiting to cross the street. It appears to be a busy and bustling city scene with many commuters and pedestrians."}, {"from": "human", "value": "What can you tell me about the lighting in the image?"}, {"from": "gpt", "value": "The image is illuminated by streetlights, which provide light in the night setting. The glow from the streetlights adds to the busy, urban atmosphere of the scene."}, {"from": "human", "value": "What are some implications of such a high level of pedestrian and vehicle traffic in a city?"}, {"from": "gpt", "value": "A high level of pedestrian and vehicle traffic in a city can have various implications:\n\n1. Economic Activity: A bustling city scene usually indicates a thriving economy with a high degree of commerce, tourism, and general activity. Busy streets, full of people and traffic, can help support local businesses, restaurants, and attractions.\n\n2. Transportation System: With heavy traffic and a large number of pedestrians, the city's transportation system must be well-structured to accommodate the demands. This can include public transportation options, such as buses, subways, and taxis, as well as pedestrian-friendly areas with safe crossings and sidewalks.\n\n3. Safety Concerns: The high level of pedestrian and vehicle traffic can also present potential safety hazards, with the risks of accidents, collisions, or pedestrian injuries. Cities must implement strict traffic regulations, signal systems, and public awareness campaigns to ensure everyone's safety.\n\n4. Environmental Impact: The substantial presence of vehicles, particularly buses, can contribute to air pollution, noise pollution, and greenhouse gas emissions. Cities must employ methods to minimize their environmental impact, such as implementing more fuel-efficient public transportation, promoting the use of electric vehicles or bikes, and fostering green spaces within the urban environment.\n\n5. Quality of Life: While a bustling city can be exciting and full of opportunities, it may also bring stress, noise, and a fast-paced lifestyle. For some individuals, this can affect their quality of life and push them to seek more peaceful and calm environments, such as suburban or rural areas.\n\nIn conclusion, a busy city street with a high level of pedestrian and vehicle traffic can be indicative of a thriving, dynamic urban environment. However, it also presents certain challenges and implications, such as safety concerns, environmental impact, and quality of life considerations, which cities must address proactively to ensure a balanced and sustainable urban life."}]}, {"id": "000000013988", "image": "coco/train2017/000000013988.jpg", "conversations": [{"from": "human", "value": "How many horses are visible in the image?\n<image>"}, {"from": "gpt", "value": "There are two white horses visible in the image."}, {"from": "human", "value": "What are the horses doing in the image?"}, {"from": "gpt", "value": "The horses are grazing in the sunny field, eating grass."}, {"from": "human", "value": "What are the surroundings like in the image?"}, {"from": "gpt", "value": "The image shows a grassy field with trees, and it appears to be a sunny day. The field is the horses' pasture where they are grazing."}, {"from": "human", "value": "What color are the horses?"}, {"from": "gpt", "value": "Both of the horses are white."}, {"from": "human", "value": "Are there any other animals or people in the image?"}, {"from": "gpt", "value": "No, there are no other animals or people visible in the image. The focus is on the two white horses grazing in the sunny field."}]}, {"id": "000000389654", "image": "coco/train2017/000000389654.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the main subject of the image?"}, {"from": "gpt", "value": "The main subject of the image is a cheesy pizza sitting on a pizza pan or plate on a table."}, {"from": "human", "value": "Is there any cutlery or utensils visible in the image?"}, {"from": "gpt", "value": "Yes, a fork can be seen on the plate with the pizza."}, {"from": "human", "value": "What is happening to the cheese as a slice is being taken away from the pizza?"}, {"from": "gpt", "value": "As a slice is being taken away from the pizza, the cheese is stretching and becoming gooey."}, {"from": "human", "value": "How would you describe the closeness of the photo?"}, {"from": "gpt", "value": "The photo is a close-up of the pizza pie, providing a detailed view of its toppings and texture. This allows the viewer to appreciate the deliciousness of the pizza."}]}, {"id": "000000545409", "image": "coco/train2017/000000545409.jpg", "conversations": [{"from": "human", "value": "What type of footwear is featured in the image?\n<image>"}, {"from": "gpt", "value": "The image features a pair of black high heels, specifically stiletto heels."}, {"from": "human", "value": "In what situation is the person wearing the black stiletto heels?"}, {"from": "gpt", "value": "The person wearing the black stiletto heels is lying on a bed."}, {"from": "human", "value": "Is it just the high heels visible in the image or the person wearing them as well?"}, {"from": "gpt", "value": "Both the high heels and the partial legs of the person wearing them are visible in the image, as they are lying on the bed."}, {"from": "human", "value": "What are stiletto heels and how do they differ from other types of high heels?"}, {"from": "gpt", "value": "Stiletto heels are a specific type of high heels characterized by their long, thin, and tapered heels, which can reach heights of several inches. They typically have a slim profile and are considered fashionable and elegant, but can be more challenging to walk in compared to other types of high heels due to their narrow heels.\n\nSome key differences between stiletto heels and other types of high heels include:\n\n1. Heel shape and thickness: Stiletto heels are distinguished by their very thin and slender heels, while other high heels may have thicker or chunkier heels, such as block heels or wedge heels.\n\n2. Stability: Due to their narrow heels, stiletto heels tend to be less stable than other types of high heels, which can make walking more difficult and increase the risk of falling or twisting an ankle.\n\n3. Aesthetics: Stiletto heels are often associated with a more sophisticated and glamorous look, whereas other high heels can range from being casual to formal, depending on their design and material.\n\n4. Impact on posture and comfort: Stiletto heels, like other high heels, can cause the wearer's body to tilt forward, placing increased pressure on the balls of the feet and potentially leading to discomfort and long-term health issues if worn frequently. However, the thinness of the stiletto heel may exacerbate these issues due to the decreased surface area for weight distribution.\n\nIn summary, stiletto heels are a distinctive type of high heels known for their long, thin, and tapered heels, which set them apart from other types of high heels in terms of stability, aesthetics, and impact on the wearer's posture and comfort."}]}, {"id": "000000411969", "image": "coco/train2017/000000411969.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the process happening in the image?"}, {"from": "gpt", "value": "The image shows a process where doughnuts are being glazed with icing. The doughnuts are placed on a conveyor belt and pass under a fountain of frosting or a glazing device, which evenly coats them with the glaze."}, {"from": "human", "value": "In what kind of environment does this process likely take place?"}, {"from": "gpt", "value": "This process likely takes place in a large-scale commercial bakery or a doughnut production facility, where doughnuts are manufactured using automated assembly lines and various specialized machines to ensure consistency, efficiency, and high production volume."}, {"from": "human", "value": "What is the role of the conveyor belt in this process?"}, {"from": "gpt", "value": "The conveyor belt plays a crucial role in transporting the doughnuts during the glazing process. It moves the doughnuts in a linear fashion, ensuring that they pass under the glazing device or fountain of frosting at a controlled pace, allowing for a consistent and even coating of icing on each doughnut."}, {"from": "human", "value": "What are the potential benefits of using a machine to glaze doughnuts?"}, {"from": "gpt", "value": "Using a machine to glaze doughnuts offers several potential benefits:\n\n1. Efficiency: Automated glazing machines increase production speed, enabling the facility to produce large quantities of doughnuts in a shorter time compared to manually glazing each doughnut. This is particularly beneficial for commercial bakeries that need to meet high demand.\n\n2. Consistency: The machine applies the glaze uniformly, ensuring that each doughnut receives a similar amount of icing. This contributes to the quality control and consistency of the final product, with each doughnut looking and tasting as expected.\n\n3. Labor Savings: Using a machine for the glazing process reduces the need for manual labor, freeing up human resources for other tasks in the bakery and potentially reducing labor costs.\n\n4. Hygiene: Automated glazing machines minimize human contact with the doughnuts during production, maintaining a more sanitary environment and reducing the risk of contamination.\n\nIn summary, using a machine for doughnut glazing can increase efficiency, ensure product consistency, save on labor costs, and maintain better hygiene during the production process."}]}, {"id": "000000313979", "image": "coco/train2017/000000313979.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of flooring is in the bathroom?"}, {"from": "gpt", "value": "The bathroom has tile flooring, specifically light brown tiles."}, {"from": "human", "value": "What color is the toilet in the image?"}, {"from": "gpt", "value": "The toilet in the image is white."}, {"from": "human", "value": "Is there any ventilation in the bathroom?"}, {"from": "gpt", "value": "Yes, there is an air vent located above the white toilet."}, {"from": "human", "value": "Is the toilet lid open or closed in the bathroom?"}, {"from": "gpt", "value": "The toilet lid is open in the bathroom."}, {"from": "human", "value": "How would you describe the overall appearance of the bathroom?"}, {"from": "gpt", "value": "The bathroom appears to be small, plain, and clean, with a simple half bathroom design. It features light brown tiled floors, a white toilet with its lid open, and an air vent above the toilet. The scene suggests a functional and well-maintained space, without any additional decorative elements or excessive clutter."}]}, {"id": "000000469988", "image": "coco/train2017/000000469988.jpg", "conversations": [{"from": "human", "value": "What is the main feature on the floor of the living room?\n<image>"}, {"from": "gpt", "value": "The main feature on the living room floor is a collection of bags, including backpacks and luggage, which are gathered together on a rug or directly on the wooden floor."}, {"from": "human", "value": "How many bags are there in the living room?"}, {"from": "gpt", "value": "There are many bags piled on the living room floor, but the exact number cannot be determined from the image description."}, {"from": "human", "value": "What might be the reason for having so many bags gathered in the living room?"}, {"from": "gpt", "value": "There could be several reasons for having so many bags gathered in the living room. Some possible scenarios include:\n\n1. Travel preparation: The bags might belong to a family or group of people that are getting ready for a trip. They could be in the process of packing their belongings and have placed all the bags in the living room for better organization and accessibility.\n\n2. Returning from a trip: The bags could be from a recently completed trip. The family or group may have just returned home and placed all their luggage in the living room before unpacking and putting away their belongings.\n\n3. Moving: The bags could be part of the process of moving in or out of the home. The occupants might be organizing their belongings and placing them into bags before transferring them to another location.\n\n4. Storage or decluttering: The bags might be part of a home organization or decluttering project. The occupants could be sorting through their belongings and placing them into various bags for temporary storage, donation, or disposal.\n\nWithout more context or information about the specific situation, it's impossible to pinpoint the exact reason behind the bags' presence in the living room. Nonetheless, these scenarios offer potential explanations for the bags piled on the floor."}]}, {"id": "000000084243", "image": "coco/train2017/000000084243.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat animal is the main subject in the image?"}, {"from": "gpt", "value": "The main subject in the image is a cow."}, {"from": "human", "value": "Where is the cow positioned in relation to the trees?"}, {"from": "gpt", "value": "The cow is positioned between the trees, poking its head out between the skinny tree trunks or young tree limbs."}, {"from": "human", "value": "What is one possible action the cow might be doing just before it peeked between the trees?"}, {"from": "gpt", "value": "One possible action the cow might have been doing just before it peeked between the trees is grazing."}, {"from": "human", "value": "What breed of cow is present in the image?"}, {"from": "gpt", "value": "The breed of cow in the image is a Jersey cow."}, {"from": "human", "value": "Why are Jersey cows distinctive, and what are their characteristics?"}, {"from": "gpt", "value": "Jersey cows are a distinctive and popular breed of dairy cattle due to their unique combination of characteristics, which make them particularly well-suited for milk production.\n\nFirstly, Jersey cows are known for their high-quality milk, which contains higher butterfat and protein content than milk from other dairy breeds. This means that Jersey milk is particularly valuable for making high-quality dairy products, such as butter and cheese, and is often favored for its rich and creamy texture.\n\nSecondly, Jersey cows are relatively small in size compared to other dairy breeds, which can make them easier to manage and more feed-efficient. They generally require less space and less feed per unit of milk produced, which can lead to lower costs for farmers.\n\nIn terms of physical appearance, Jersey cows have a light brown or fawn-colored coat, often with white markings on their face and legs. They have large, expressive eyes, a dished face, and long, straight horns in their natural state. These horns are often removed for safety reasons in commercial dairy settings.\n\nAdditionally, Jersey cows are known for their gentle and docile nature, making them a pleasure to work with for many farmers. They are also naturally curious animals, which may explain why the cow in the image is peering out from between the trees, seemingly intrigued by the camera.\n\nIn summary, Jersey cows are a distinctive dairy breed known for their high-quality milk, manageable size, feed efficiency, and gentle nature. They have a unique appearance, with a light brown or fawn-colored coat, large eyes, and a dished face, which sets them apart from other cattle breeds."}]}, {"id": "000000187280", "image": "coco/train2017/000000187280.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many red double-decker buses are present in the image?"}, {"from": "gpt", "value": "There are two red double-decker buses in the image."}, {"from": "human", "value": "Are the buses parked or in motion?"}, {"from": "gpt", "value": "The buses are in motion, driving down the road, while another red bus is parked on the side of the road."}, {"from": "human", "value": "What type of road are the buses on?"}, {"from": "gpt", "value": "The buses are on a city street, approaching an intersection with a side road and a crosswalk."}, {"from": "human", "value": "Is there any other vehicle besides the two double-decker buses in the image?"}, {"from": "gpt", "value": "Yes, there is a third vehicle pulling up to the crosswalk before the side road in the image, alongside the two double-decker buses."}, {"from": "human", "value": "Can you describe the surrounding environment where the buses are?"}, {"from": "gpt", "value": "The surrounding environment in the image is an urban city street. There is an intersection with a side road and a crosswalk. A building can be seen on one side of the intersection, possibly indicating the presence of shops, offices, or other commercial establishments. The presence of the red double-decker buses and the city street setting suggest that this might be a busy metropolitan area where public transportation plays a significant role in everyday life."}]}, {"id": "000000164146", "image": "coco/train2017/000000164146.jpg", "conversations": [{"from": "human", "value": "<image>\nIs there a ceiling fan in the bedroom?"}, {"from": "gpt", "value": "Yes, there is a ceiling fan in the bedroom."}, {"from": "human", "value": "What is the position of the bed in relation to the window?"}, {"from": "gpt", "value": "The bed is positioned under the window in the room."}, {"from": "human", "value": "Are the curtains in the room fully closed or partially closed?"}, {"from": "gpt", "value": "The curtains in the room are partially closed."}, {"from": "human", "value": "What other items or devices are present in the bedroom besides the bed?"}, {"from": "gpt", "value": "In addition to the bed, there is also a television set, an A/C unit, and a towel hanging in the bedroom."}, {"from": "human", "value": "How would you describe the size of the bedroom?"}, {"from": "gpt", "value": "The bedroom is relatively small in size, as it mainly contains the bed, a television set, and an A/C unit. Its compact size might make it cozy or functional for the occupants, depending on their needs and preferences. Small bedrooms can be advantageous in terms of ease of maintenance and energy consumption, as they typically require less time and effort to clean and can be heated and cooled more efficiently than larger spaces. On the other hand, they might also limit the possibilities for furniture arrangement, storage, and personalization, which could make them less appealing to individuals seeking more spacious or flexible living environments. In any case, the small bedroom in the image seems to accommodate the essentials of a comfortable sleeping space, including a bed, curtains for privacy and light control, and a television for entertainment."}]}, {"id": "000000351480", "image": "coco/train2017/000000351480.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the appearance of the man in the image?"}, {"from": "gpt", "value": "The man in the image is bald with a black beard, wearing a gray suit."}, {"from": "human", "value": "What is the location of the man in the room?"}, {"from": "gpt", "value": "The man is located in the corner of the room, standing next to a white door."}, {"from": "human", "value": "What color is the suit that the man is wearing? Is he also wearing a vest, and if so, what color is it?"}, {"from": "gpt", "value": "The man is wearing a gray suit. He is also wearing a yellow vest to complement his outfit."}]}, {"id": "000000459003", "image": "coco/train2017/000000459003.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat are the people doing in the image?"}, {"from": "gpt", "value": "The people in the image are walking down a city street during a snowy day, braving the wintery snow and blizzard conditions."}, {"from": "human", "value": "How many people are visible in the scene?"}, {"from": "gpt", "value": "The image description does not provide an exact count of people, but it conveys that there is a group of people walking in the snowy weather."}, {"from": "human", "value": "What kind of weather conditions can be seen in the image?"}, {"from": "gpt", "value": "The image shows snowy and blizzard-like weather conditions, suggesting poor visibility, cold temperatures, and challenging walking conditions for the people on the city street."}, {"from": "human", "value": "How might the heavy snowfall affect city life, transportation, and businesses?"}, {"from": "gpt", "value": "Heavy snowfall can have numerous impacts on city life, transportation, and businesses, as it can create difficult and hazardous conditions for residents, commuters, and pedestrians. Some of the possible effects include:\n\n1. Traffic disruptions: Heavy snow can cause slippery and icy road conditions, which can lead to an increased risk of accidents and make driving more challenging. Public transit systems, such as buses and trains, may also face delays or be disrupted by snow-covered tracks or road closures.\n\n2. Pedestrian mobility: Walking down snow-covered sidewalks can be cumbersome and time-consuming, making it more difficult for people to complete everyday tasks such as shopping, commuting to work, or attending school. Elderly individuals or those with mobility issues could face heightened challenges.\n\n3. Business disruptions: Businesses may see a decline in customers because of the difficult weather conditions, potentially leading to decreased revenue. Furthermore, employees may have difficulty reaching their workplace, leading to understaffing or reduced productivity.\n\n4. Infrastructure issues: Heavy snowfall can put extra strain on roofs and other structures, increase the risks of power outages due to the snow's weight on power lines or branches that fall under the burden.\n\n5. Snow removal: Cities need to invest resources and manpower into efficient and timely snow removal in order to keep streets and sidewalks safe and accessible. This can be a challenging and expensive undertaking, especially during periods of extreme weather.\n\nOverall, heavy snowfall can greatly impact city life, transportation, and businesses, causing disruptions and challenges ranging from traffic jams and delays to reduced foot traffic and revenue for businesses."}]}, {"id": "000000218237", "image": "coco/train2017/000000218237.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the position of the two men on the couch?"}, {"from": "gpt", "value": "One shirtless man is straddling the other man on the couch, sitting on the other man's legs and holding his wrist or arm."}, {"from": "human", "value": "Is one of the men wearing a shirt?"}, {"from": "gpt", "value": "No, one of the men is shirtless."}, {"from": "human", "value": "What else is in the room apart from the two men and the couch?"}, {"from": "gpt", "value": "There is a window in the room, indicating that the couch is positioned close to or near a window."}, {"from": "human", "value": "What is the tone or atmosphere of the image between the two men?"}, {"from": "gpt", "value": "It is difficult to determine the exact tone or atmosphere between the two men without additional context or facial expression information. It could range from playful or friendly interaction to a more intense or even aggressive mood. The shirtless man is holding the other man's arm or wrist, but without knowing the expressions on their faces or any further details, it's impossible to provide more insight into their current emotions or the intent behind their actions."}, {"from": "human", "value": "Is it possible to determine the relationship between the two men based on the image?"}, {"from": "gpt", "value": "Given the limited information, it is not possible to definitively determine the relationship between the two men based on the image alone. Their interaction may be friendly, romantic, or aggressive, but without more context and knowledge of their facial expressions or other interactions within the scene, we cannot confidently assess their exact relationship."}]}, {"id": "000000212935", "image": "coco/train2017/000000212935.jpg", "conversations": [{"from": "human", "value": "What is the weather like in the image?\n<image>"}, {"from": "gpt", "value": "In the image, the weather appears to be cloudy."}, {"from": "human", "value": "What is the main focus of the image?"}, {"from": "gpt", "value": "The main focus of the image is the scenic view of a city, a harbor, and a large body of water, which includes a river and a bridge surrounded by green trees and buildings."}, {"from": "human", "value": "Are there any boats visible in the picture? If so, where are they located?"}, {"from": "gpt", "value": "Yes, there are boats visible in the picture, and they are floating in the river along the edge."}, {"from": "human", "value": "What is the condition of the water under the bridge?"}, {"from": "gpt", "value": "The river water under the bridge is calm."}, {"from": "human", "value": "What kind of view does this image envoke?"}, {"from": "gpt", "value": "This image evokes a serene and picturesque view of a city nestled next to a large body of water. The combination of the calm river, the boats floating along the edge, the green trees and surrounding buildings, and the bridge creates a harmonious and pleasant scene. This setting, with its gentle mix of natural and urban elements, might inspire feelings of relaxation and appreciation for the beauty of the landscape. The cloudy day adds a touch of moodiness to the atmosphere, further enhancing the scenic quality of the image. Overall, the view presents a captivating snapshot of life in the city, showcasing both its architectural charm and its close connection to the natural environment."}]}, {"id": "000000039064", "image": "coco/train2017/000000039064.jpg", "conversations": [{"from": "human", "value": "Why are there stuffed animals on the hockey rink?\n<image>"}, {"from": "gpt", "value": "The presence of stuffed animals on the hockey rink is most likely due to a charity event called a \"Teddy Bear Toss.\" In such events, fans bring stuffed animals to the game and throw them onto the ice after the home team scores its first goal. The collected stuffed toys are then donated to local hospitals, charities, and children in need. This tradition is popular in various ice hockey leagues around the world and is a way to give back to the community while also enjoying the sporting event."}]}, {"id": "000000515062", "image": "coco/train2017/000000515062.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many cupcakes are there in the box?"}, {"from": "gpt", "value": "There are twelve cupcakes in the box."}, {"from": "human", "value": "What type of toppings are on the cupcakes?"}, {"from": "gpt", "value": "The cupcakes have candy and marshmallow toppings."}, {"from": "human", "value": "What color is the box containing the cupcakes?"}, {"from": "gpt", "value": "The box containing the cupcakes is white."}, {"from": "human", "value": "Are the cupcakes covered in chocolate?"}, {"from": "gpt", "value": "Yes, the cupcakes are covered in chocolate."}, {"from": "human", "value": "What kind of dessert is featured in the image?"}, {"from": "gpt", "value": "The image features dessert cupcakes with chocolate, candies, and marshmallows as toppings, presented in a white box. These cupcakes are visually appealing and likely have a combination of sweet and rich flavors, with the soft texture of the cupcakes and marshmallows, the crunchiness from the candies, and the smooth creaminess of the chocolate. The presentation in the white box also implies that the cupcakes are professionally made or designed, potentially for an event or as a gift. Offering a delightful dessert experience, these cupcakes can be enjoyed by people of all ages who have a sweet tooth and appreciate the creativity involved in their decoration."}]}, {"id": "000000225060", "image": "coco/train2017/000000225060.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the occupation of the man sitting at the desk?"}, {"from": "gpt", "value": "It's not possible to know the occupation of the man sitting at the desk just from the image. However, we can confirm that he is working in an office cubicle with a desktop computer, which indicates he's engaged in some kind of office work or computer-related tasks."}, {"from": "human", "value": "Are there other people visible in the image?"}, {"from": "gpt", "value": "Yes, there are other people working in cubicles near the Asian man in the image. This suggests a shared office workspace."}, {"from": "human", "value": "What is the man wearing while sitting at the desk?"}, {"from": "gpt", "value": "The man is wearing a sweatshirt while sitting at the desk in his office cubicle."}, {"from": "human", "value": "Is the workspace an open office plan or individual office cubicles?"}, {"from": "gpt", "value": "The workspace consists of individual office cubicles, where people have their own semi-private areas to work on their tasks. The cubicles provide some form of separation from one another, allowing for a degree of privacy while still facilitating communication and collaboration among colleagues."}]}, {"id": "000000447994", "image": "coco/train2017/000000447994.jpg", "conversations": [{"from": "human", "value": "How many wine glasses are there in the image?\n<image>"}, {"from": "gpt", "value": "There are four wine glasses in the image."}, {"from": "human", "value": "What is the condition of the wine glasses?"}, {"from": "gpt", "value": "Each of the four wine glasses is partially filled with wine."}, {"from": "human", "value": "Are there any other objects present in the image besides the wine glasses?"}, {"from": "gpt", "value": "Yes, there are some papers on the counter as well, besides the wine glasses."}, {"from": "human", "value": "What is the setting of the image, where are the wine glasses placed?"}, {"from": "gpt", "value": "The wine glasses are placed either on a table or a counter, depending on the interpretation of the scene."}]}, {"id": "000000418600", "image": "coco/train2017/000000418600.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the woman doing with her cellphone?"}, {"from": "gpt", "value": "The woman is talking on her cellphone with her phone held up to her ear."}, {"from": "human", "value": "What does the woman look like?"}, {"from": "gpt", "value": "The woman appears to be young and athletic, wearing a white shirt, and she seems to have her eyes closed at the moment. Additionally, she's wearing a badge, which signifies she could be part of an organization or event."}, {"from": "human", "value": "What are the visible accessories on the woman?"}, {"from": "gpt", "value": "The visible accessories on the woman are a badge and a cellphone."}, {"from": "human", "value": "What kind of conversation might the woman be having on her cellphone?"}, {"from": "gpt", "value": "It's difficult to determine the exact content of the woman's conversation just by looking at the image. However, the fact that she's wearing a badge suggests she could be involved in a professional or organized setting, and her conversation could potentially be related to her work, an event, or some affiliation. Alternatively, she could be talking to a friend or family member about personal matters - as the image cannot provide enough context to give a definite answer."}]}, {"id": "000000422100", "image": "coco/train2017/000000422100.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat are the skateboarders doing in the image?"}, {"from": "gpt", "value": "In the image, the skateboarders are performing various stunts on a ramp, with one of them balancing on the ramp while others are sliding along a wall or getting ready to go down the ramp."}, {"from": "human", "value": "Is there an audience watching the skateboarders?"}, {"from": "gpt", "value": "Yes, there are people watching the skateboarders as they perform their stunts."}, {"from": "human", "value": "What kind of ramp are the skateboarders using?"}, {"from": "gpt", "value": "The skateboarders are using a stunt ramp, specifically designed for performing tricks and stunts on skateboards. Stunt ramps come in various shapes and sizes, with some of the most common ones being half-pipes, quarter-pipes, and funboxes."}, {"from": "human", "value": "Can you describe some common skateboarding stunts that can be performed on a ramp?"}, {"from": "gpt", "value": "There are several common skateboarding stunts and tricks that can be performed on a ramp, including:\n\n1. Ollie: The ollie is a fundamental skateboarding trick in which the skater jumps into the air, lifting the board off the ground using only their feet. This trick forms the basis for many other skateboard stunts performed on ramps.\n\n2. Kickflip: A kickflip involves flipping the skateboard 360 degrees along its horizontal axis while the skater is in the air. This is achieved by jumping into an ollie and then using the front foot to flick the board, causing it to spin.\n\n3. Grinds and Slides: Grinds and slides involve performing a trick while the skateboard's trucks (the metal part that holds the wheels) or deck (the wooden platform) makes contact with a surface, like the edge of a ramp. There are various types of grinds and slides, such as the 50-50 grind, 5-0 grind, boardslide, and tailslide.\n\n4. Airs: Airs involve performing a trick while the skateboarder is entirely in the air, typically after launching off a ramp. Examples include the backside air, frontside air, and Melon grab.\n\n5. Lip Tricks: Lip tricks are performed at the lip (edge) of a ramp and usually involve stalling or balancing. Examples include the axle stall, rock to fakie, and nose stall.\n\nThese are just a few examples of the numerous stunts and tricks that can be performed on a ramp by skateboarders. The combinations and variations of these stunts are virtually limitless, making skateboarding a diverse and exciting sport."}]}, {"id": "000000230152", "image": "coco/train2017/000000230152.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of fruits can be seen on the plate?"}, {"from": "gpt", "value": "There are oranges, pears, and bananas on the plate."}, {"from": "human", "value": "What type of plate are the fruits sitting on?"}, {"from": "gpt", "value": "The fruits are sitting on a paper plate."}, {"from": "human", "value": "How many bananas can be seen on the plate?"}, {"from": "gpt", "value": "There are two bananas on the plate."}, {"from": "human", "value": "Are there any other fruits besides oranges, pears, and bananas visible in the image?"}, {"from": "gpt", "value": "No, only oranges, pears, and bananas can be seen on the plate in the image."}, {"from": "human", "value": "What are some health benefits of consuming these fruits?"}, {"from": "gpt", "value": "Oranges, pears, and bananas each offer a variety of health benefits which can be attributed to their unique blend of vitamins, minerals, and other nutrients.\n\n1. Oranges:\nOranges are known for their high vitamin C content, which helps support a healthy immune system, acts as an antioxidant, and aids in collagen production for healthy skin, bones, and connective tissues. They are also a good source of fiber, promoting regular bowel movements and a healthy gut. In addition, oranges contain potassium which can help regulate blood pressure and support proper muscle function.\n\n2. Pears:\nPears are an excellent source of dietary fiber, promoting digestive health and potentially aiding in weight management due to their satiating effect. They are also rich in vitamin C and K, as well as containing smaller amounts of B vitamins, potassium, and various micronutrients. Pears provide antioxidants and can help reduce inflammation, which is beneficial for overall health.\n\n3. Bananas:\nBananas are well-known for their potassium content, which plays a crucial role in maintaining proper heart function and regulating blood pressure. They are also a great source of dietary fiber and contain vitamin C, vitamin B6, and essential amino acids. Bananas can provide an instant energy boost, making them a popular choice for a pre- or post-workout snack.\n\nIn conclusion, each of these fruits offers a range of health benefits, contributing to a balanced and nutritious diet. Incorporating oranges, pears, and bananas into one's daily food intake can promote overall health and well-being."}]}, {"id": "000000447049", "image": "coco/train2017/000000447049.jpg", "conversations": [{"from": "human", "value": "What type of train is in the image?\n<image>"}, {"from": "gpt", "value": "The image features a double-decker passenger train at a station."}, {"from": "human", "value": "What colors are visible on the train?"}, {"from": "gpt", "value": "The train appears to have silver and yellow colors."}, {"from": "human", "value": "Is the train in motion or stationary in the image?"}, {"from": "gpt", "value": "The train is stationary, stopped at the train station."}, {"from": "human", "value": "What is the condition of the door on the train?"}, {"from": "gpt", "value": "The door on the train is open."}, {"from": "human", "value": "Can you explain the purpose and advantages of a double-decker passenger train?"}, {"from": "gpt", "value": "Double-decker passenger trains are designed to efficiently transport a large number of passengers while using less space on the rails as compared to single-level trains. These trains have two levels of passenger seating areas stacked vertically, one above the other. The primary advantage of this design is increased passenger capacity, making it an attractive option for high-demand routes with a large volume of travelers.\n\nIn addition to offering greater capacity, other advantages include:\n\n1. Efficient use of space: By utilizing vertical space, double-decker trains can accommodate more passengers within the same length of a train, reducing the need for long trains that occupy more platform space at stations as well as reducing the overall number of trains required on a route.\n2. Cost-effectiveness: Since fewer trains are required to transport the same number of passengers as single-level counterparts, the costs associated with train operation, maintenance, and infrastructure are reduced.\n3. Reduced congestion: Larger passenger capacity can help alleviate overcrowding on busy routes and during peak travel times, resulting in a more comfortable experience for passengers and less strain on transportation systems.\n4. Eco-friendliness: By transporting more passengers per train, double-decker trains can help minimize the need for additional vehicles on the road or more trains on the tracks, thus reducing air pollution and greenhouse gas emissions.\n\nIn summary, double-decker passenger trains are designed to maximize passenger capacity and make efficient use of railway infrastructure. They can effectively address high-demand transportation needs, contributing to a more sustainable and environmentally-friendly transit system."}]}, {"id": "000000532175", "image": "coco/train2017/000000532175.jpg", "conversations": [{"from": "human", "value": "What is the woman wearing in the image?\n<image>"}, {"from": "gpt", "value": "The woman in the image is wearing a dress."}, {"from": "human", "value": "Where is the woman riding her bicycle?"}, {"from": "gpt", "value": "The woman is riding her bicycle through a busy city intersection, on a busy street."}, {"from": "human", "value": "Is there anyone else visible in the image besides the woman on the bike?"}, {"from": "gpt", "value": "Yes, there is a man walking in the image. They are traveling through the busy city intersection together."}, {"from": "human", "value": "What is the traffic situation at the intersection?"}, {"from": "gpt", "value": "The traffic situation at the intersection can be described as busy, with multiple vehicles and pedestrians like the man walking and the woman on the bicycle navigating through it."}, {"from": "human", "value": "Can you discuss the possible challenges and benefits of cycling in busy urban areas?"}, {"from": "gpt", "value": "Cycling in busy urban areas can have both challenges and benefits for those who choose to use bicycles as their mode of transportation.\n\nChallenges:\n1. Traffic congestion: In busy urban areas, cyclists have to navigate through high volumes of vehicular traffic, which can be dangerous and stressful. This might cause delays and make the overall cycling experience less enjoyable.\n\n2. Limited infrastructure: Depending on the city, there may be a lack of proper cycling infrastructure, such as dedicated bike lanes and secure parking facilities. This can make cycling less safe and less accessible to potential riders.\n\n3. Safety concerns: Cycling in busy urban areas poses various safety risks, especially if drivers and pedestrians are not aware of or do not respect the rights of cyclists. Accidents can occur due to reckless driving, poor road conditions, or failure to comply with traffic rules.\n\nBenefits:\n1. Health benefits: Cycling has numerous health benefits, such as improving cardiovascular fitness, building muscle strength, and enhancing overall well-being. Riding a bike through the city can be an effective and enjoyable way to stay fit and active.\n\n2. Environmental benefits: Cycling is an eco-friendly mode of transportation that does not produce harmful emissions. By choosing to cycle in urban areas, individuals can contribute to reducing air pollution, noise pollution, and greenhouse gas emissions.\n\n3. Cost savings: Cycling can be a cost-effective transportation option compared to owning, maintaining, and using a car. Cyclists avoid the expenses associated with fuel, parking, and vehicle maintenance. Additionally, they may save money on public transit fares.\n\n4. Convenience and accessibility: In some cases, cycling can be a faster and more efficient mode of transportation in busy urban areas, as it allows riders to avoid traffic jams, and find shortcuts through parks and residential areas. Bicycles are also more maneuverable in crowded areas, making it easier to navigate tight spaces or congested streets.\n\nIn conclusion, while there are challenges associated with cycling in busy urban areas, many benefits and advantages can outweigh these potential drawbacks. By investing in appropriate infrastructure, promoting a cycling culture, and raising awareness of the advantages of cycling, cities can create a safer, more enjoyable, and sustainable environment for both cyclists and residents."}]}, {"id": "000000122097", "image": "coco/train2017/000000122097.jpg", "conversations": [{"from": "human", "value": "What are the main components of the lunch displayed in the image?\n<image>"}, {"from": "gpt", "value": "The main components of the lunch displayed in the image include a sandwich, a side of coleslaw, and a drink. The sandwich is either a bacon sandwich or a barbecue sandwich."}, {"from": "human", "value": "What is the sandwich served on?"}, {"from": "gpt", "value": "The sandwich is served on a tray along with the side of coleslaw and the drink."}, {"from": "human", "value": "Is the sandwich large or small?"}, {"from": "gpt", "value": "The sandwich in the image is described as being huge, which indicates that it is a large sandwich."}, {"from": "human", "value": "What could be a possible location or setting where this lunch is being served?"}, {"from": "gpt", "value": "Given the simple presentation of the lunch on a tray, it is possible that the lunch is being served in a casual dining establishment, such as a cafeteria, a fast-food restaurant, or a deli. The presence of a barbecue or bacon sandwich along with coleslaw and a drink suggests this may be a place that specializes in sandwiches or barbecue-style meals, which could be popular for quick and satisfying lunches in various settings such as workplace cafeterias, food courts in shopping centers, or standalone restaurants."}]}, {"id": "000000069424", "image": "coco/train2017/000000069424.jpg", "conversations": [{"from": "human", "value": "What color is the horse in the image?\n<image>"}, {"from": "gpt", "value": "The horse in the image is white."}, {"from": "human", "value": "Is the horse wearing a saddle or a pack on its back?"}, {"from": "gpt", "value": "The white horse has a pack on its back."}, {"from": "human", "value": "What is the horse doing in the image?"}, {"from": "gpt", "value": "The horse is walking down a hill across a grassy field."}, {"from": "human", "value": "What kind of grass is the horse walking on\u2014tall or dry grass?"}, {"from": "gpt", "value": "The horse is walking on dry grass."}, {"from": "human", "value": "What are the weather and sky conditions in the image?"}, {"from": "gpt", "value": "The weather in the image appears to be cloudy, with a cloudy sky visible above the horse and the grassy hill."}]}, {"id": "000000057340", "image": "coco/train2017/000000057340.jpg", "conversations": [{"from": "human", "value": "What object is at the top of the clock tower?\n<image>"}, {"from": "gpt", "value": "An American flag is at the top of the clock tower."}, {"from": "human", "value": "Can you describe the building with the clock tower?"}, {"from": "gpt", "value": "The building with the clock tower is a large and tall structure featuring a prominent clock on its side. The clock tower is topped with an American flag, making it a notable and patriotic landmark in the area."}, {"from": "human", "value": "Is the image taken during day or night time?"}, {"from": "gpt", "value": "The image is taken at night, which enhances the visibility of the clock tower and the American flag flying above it."}, {"from": "human", "value": "What is the significance of a clock tower in a building or a public space?"}, {"from": "gpt", "value": "A clock tower holds historical and modern-day significance in a building or a public space. Historically, clock towers served a practical purpose in helping citizens keep track of time as they went about their daily lives. In the era before personal timepieces or smartphones were common, such large public clocks played a vital role in ensuring punctuality and coordination of activities, especially in busy urban centers.\n\nAesthetically, clock towers often represent a focal point in the urban landscape, with their distinctive height, architecture, and design. They contribute to the city's unique identity and charm, making them memorable landmarks, and can influence the overall design concept of nearby buildings or public spaces. Many clock towers are part of municipal or institutional buildings, such as city halls, courthouses, or universities, where they symbolize prestige, stability, and civic pride.\n\nIn modern times, clock towers can also serve a commemorative or emotional role, honoring historical events, people, or cultural heritage. The incorporation of elements like the American flag in the case of this image links the clock tower and the building to national identity and pride in the local community.\n\nIn summary, clock towers have both practical and symbolic significance in a building or public space. They serve as landmarks, contribute to the city's identity, and often hold historical or cultural importance, making them valued and cherished elements of the urban landscape."}]}, {"id": "000000243895", "image": "coco/train2017/000000243895.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat objects are visible in the image?"}, {"from": "gpt", "value": "In the image, an electrical tower (power transformer) and a large airplane flying through a clear blue sky are visible."}, {"from": "human", "value": "What time of day is it in the image?"}, {"from": "gpt", "value": "Based on the clear blue sky, it appears to be daytime in the image."}, {"from": "human", "value": "How close is the airplane to the power transformer or power line?"}, {"from": "gpt", "value": "In the image, the airplane appears close to the power transformer or power line, as it is flying past it. However, this might be due to the perspective of the image, and the actual distance between them could be quite significant in reality, considering the safety regulations around flying near power lines."}, {"from": "human", "value": "Is the airplane flying at a high or low altitude?"}, {"from": "gpt", "value": "As the image shows the airplane flying past a power transformer, it is likely flying at a low altitude. However, it is important to note that the appearance of low altitude might be due to the perspective of the photograph, and we cannot determine the exact altitude based on a single image."}, {"from": "human", "value": "What are some risks and precautions for airplanes flying near power lines?"}, {"from": "gpt", "value": "There are significant risks associated with airplanes flying near power lines, which include electrical hazards, structural damage, and potential accidents. Due to these risks, pilots and airlines must adhere to strict aviation safety regulations and guidelines set by authorities such as the Federal Aviation Administration (FAA) or the International Civil Aviation Organization (ICAO).\n\nSome precautions and safety measures for airplanes flying near power lines include:\n\n1. Maintaining safe distances: Pilots must maintain a safe distance from power lines and other obstacles while flying at low altitudes. This typically involves following designated flight paths and adhering to minimum safe altitude requirements.\n\n2. Thorough pre-flight planning: Pilots should study their intended flight routes and familiarize themselves with the locations of power lines and other potential hazards. This includes reviewing updated aeronautical charts, obstacle databases, and GPS coordinates.\n\n3. Collision avoidance systems: Modern aircraft may be equipped with collision avoidance systems, such as traffic alert and collision avoidance systems (TCAS) or terrain awareness and warning systems (TAWS), which can provide real-time alerts and guidance to avoid potential dangers.\n\n4. Visual markings on power lines: In many countries, power lines and towers are marked with spherical or other shaped visual markers to increase visibility and aid pilots in detecting and avoiding them.\n\n5. Pilot training: Proper and thorough training of pilots is crucial in ensuring their ability to safely navigate around power lines and other obstacles during flight. This includes recurrent training and proficiency checks to maintain their skills and knowledge.\n\nBy following these safety measures and precautions, pilots can significantly reduce the risk of accidents or incidents involving power lines while flying."}]}, {"id": "000000542937", "image": "coco/train2017/000000542937.jpg", "conversations": [{"from": "human", "value": "What type of animals are standing in the grassy field?\n<image>"}, {"from": "gpt", "value": "Two yaks, which are native animals, are standing in the grassy field."}, {"from": "human", "value": "Is it a sunny day in the image?"}, {"from": "gpt", "value": "Yes, it is a sunny day in the image."}, {"from": "human", "value": "What is the size difference between the two yaks in the image?"}, {"from": "gpt", "value": "There is a sizable difference between the two yaks in the image, with one being a large ox and the other being a younger, smaller ox."}, {"from": "human", "value": "Where do yaks typically live, and what kind of climate are they adapted to?"}, {"from": "gpt", "value": "Yaks are native to the mountainous regions of Central Asia, specifically in the countries of Tibet, Nepal, Bhutan, and northern parts of India. Yaks are adapted to live in high elevation environments with cold climates. They have thick, dense fur that insulates them against the harsh temperatures found in those areas. Moreover, they have well-developed lungs, allowing them to thrive in the low-oxygen conditions prevalent at high altitudes.\n\nYaks are quite versatile animals, and they play an important role in the lives of the people living in the mountainous regions. They are typically used for transportation, carrying heavy loads over rough terrain, and providing milk, meat, and wool for their human caretakers. In some cases, yaks are also domesticated to perform agricultural work or various other labor-intensive tasks.\n\nIn conclusion, yaks are well-adapted to thrive in cold, high-altitude environments found in Central Asia, and they play a crucial role in the everyday lives of the people living in those regions. The presence of yaks in a grassy field on a sunny day, as depicted in the image, could perhaps be during the warmer months, but they are still thriving grazers capable of adapting to various conditions within their natural range."}]}, {"id": "000000146841", "image": "coco/train2017/000000146841.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat types of containers are the fruits and vegetables being sold from?"}, {"from": "gpt", "value": "The fruits and vegetables are being sold from wicker baskets."}, {"from": "human", "value": "What are some of the fruits and vegetables displayed at the shop?"}, {"from": "gpt", "value": "Some of the fruits and vegetables on display at the shop include bananas, potatoes, and several other kinds of fruits and vegetables."}, {"from": "human", "value": "In what type of setting is the fruit and vegetable display located?"}, {"from": "gpt", "value": "The fruit and vegetable display is located in a market setting, likely at a fruit and vegetable shop."}, {"from": "human", "value": "How are the prices determined for the fruits and vegetables at this shop?"}, {"from": "gpt", "value": "The prices of the fruits and vegetables at this shop are determined by a fixed rate, meaning they have a set cost that is not subject to change during a specific period of time."}, {"from": "human", "value": "Why is it important to have fresh fruits and vegetables available for consumption?"}, {"from": "gpt", "value": "Having fresh fruits and vegetables available for consumption is important for several reasons, primarily because of their contributions to good health and overall well-being:\n\n1. Nutrition: Fresh fruits and vegetables are rich in essential vitamins, minerals, and other nutrients that support various bodily functions and help maintain optimal health. They are excellent sources of dietary fiber, antioxidants, and phytonutrients, which play a crucial role in disease prevention and strengthening the immune system.\n\n2. Flavor: The fresher the produce, the better their taste, texture, and aroma. Fresh fruits and vegetables have a more vibrant, natural flavor compared to processed or preserved alternatives. Consuming fresh fruits and vegetables makes eating them more enjoyable, which can help increase the consumption of these healthy food options.\n\n3. Reducing food waste: By consuming fresh produce, people can better monitor and control their portion sizes, reducing food waste. When fruits and vegetables are fresh, they are less likely to be thrown away due to spoilage.\n\n4. Environmental benefits: Consuming fresh fruits and vegetables can help reduce the environmental impact of food production, as they typically have a lower carbon footprint compared to heavily processed foods. Additionally, consuming locally sourced fruits and vegetables supports local farmers and reduces the transportation costs and emissions associated with importing produce from distant locations.\n\n5. Economic benefits: Supporting local fruit and vegetable shops contributes to the local economy and can have positive effects on community well-being.\n\nIn summary, providing fresh fruits and vegetables for consumption is beneficial for personal health, satisfaction, environmental sustainability, and economic stability."}]}, {"id": "000000316059", "image": "coco/train2017/000000316059.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is the fire hydrant in the image?"}, {"from": "gpt", "value": "The fire hydrant in the image is red."}, {"from": "human", "value": "Where is the fire hydrant located?"}, {"from": "gpt", "value": "The fire hydrant is located on the side of a road, sitting in the grass near the street curb."}, {"from": "human", "value": "What is the surface around the fire hydrant?"}, {"from": "gpt", "value": "The surface around the fire hydrant is grass."}, {"from": "human", "value": "What is the purpose of a fire hydrant?"}, {"from": "gpt", "value": "A fire hydrant serves as a key component of a city's firefighting infrastructure. Its primary purpose is to provide firefighters with a convenient and accessible source of water in case of fires or other emergencies requiring water. Fire hydrants are connected to the city's water supply system and allow fire personnel to quickly attach hoses, which enables them to pump water and extinguish fires promptly, saving lives and property. The bright red color of the fire hydrant helps to make it highly visible, ensuring that firefighters can easily locate and access it during emergencies or when visibility might be limited due to smoke or low light conditions. Additionally, fire hydrants may also be used to flush the local water system, which helps maintain water quality and remove sediments or debris from the pipes."}]}, {"id": "000000304067", "image": "coco/train2017/000000304067.jpg", "conversations": [{"from": "human", "value": "How many motorcyclists are in the image?\n<image>"}, {"from": "gpt", "value": "There are three motorcyclists in the image."}, {"from": "human", "value": "What is the formation of the bikers on the road?"}, {"from": "gpt", "value": "The bikers are in a staggered formation, with one biker slightly falling behind the other two as they ride down the road."}, {"from": "human", "value": "Is the road straight or curvy in the image?"}, {"from": "gpt", "value": "The road in the image is curvy."}, {"from": "human", "value": "What is one distinctive feature or landmark near the road?"}, {"from": "gpt", "value": "A notable landmark near the road is a house."}, {"from": "human", "value": "What are the motorcyclists doing as they go around the curve?"}, {"from": "gpt", "value": "As the motorcyclists go around the curve, they are navigating the turn carefully, maintaining balance and control to ensure their safety. This involves leaning into the turn, adjusting their body positions, and managing their speed and braking accordingly. It is an essential skill for motorcyclists to master, as it helps reduce the risk of accidents and enables smoother and more efficient maneuvering on curvy roads."}]}, {"id": "000000556162", "image": "coco/train2017/000000556162.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many young boys are in the image?"}, {"from": "gpt", "value": "There are two young boys in the image."}, {"from": "human", "value": "Are the boys sitting or standing?"}, {"from": "gpt", "value": "The boys are sitting on a bed."}, {"from": "human", "value": "How many teddy bears are in the image with the boys?"}, {"from": "gpt", "value": "There are three teddy bears with the boys in the image."}, {"from": "human", "value": "What is the unique detail about the sign the boys have in the image?"}, {"from": "gpt", "value": "The sign that the boys have in the image has the number 20 crossed out."}, {"from": "human", "value": "Can you speculate on the possible meaning or context of the sign with the number 20 crossed out?"}, {"from": "gpt", "value": "While the exact meaning behind the sign with the number 20 crossed out is not explicitly clear in the image, we can venture several possible explanations.\n\n1. Achievement milestone: The crossed-out number 20 might represent a goal, target, or accomplishment that the boys have achieved or surpassed. For example, they might have been working on a personal or educational project, and reaching 20 successful repetitions or steps in the process was their target.\n\n2. Countdown or celebration: The boys could be marking a countdown to a special event, such as a birthday, holiday, or vacation. Crossing out the number 20 might indicate that the event is getting closer, and they are excited about its approach.\n\n3. Game or challenge: The image could be capturing a moment during a game or challenge that involves teddy bears and the number 20. Crossing out the number might represent a step in the game or an indication that a certain challenge has been completed.\n\nIn any case, the presence of the sign with the crossed-out number, combined with the boys and the teddy bears, suggests that they might be engaged in a playful activity, celebration, or achievement. However, without additional context or information, it is difficult to determine the exact meaning or purpose behind the sign."}]}, {"id": "000000513888", "image": "coco/train2017/000000513888.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the color of the dog in the image?"}, {"from": "gpt", "value": "The dog in the image is white."}, {"from": "human", "value": "What is the dog doing on the beach?"}, {"from": "gpt", "value": "The dog is walking or running through the water on the beach, stepping into the ocean."}, {"from": "human", "value": "Is the beach wet in the picture? If yes, where do you see this?"}, {"from": "gpt", "value": "Yes, the beach is wet in the picture. This can be observed where the dog is walking across the beach and through the water."}, {"from": "human", "value": "Describe the actual location of the dog on the beach."}, {"from": "gpt", "value": "The dog is located near the water's edge, at the end of the ocean, where the waves meet the shoreline. The dog is walking or running through the water in this area."}, {"from": "human", "value": "What activities might the dog be engaged in or enjoying while at the beach?"}, {"from": "gpt", "value": "While at the beach, the dog might be engaged in various activities such as playing in the water, fetching objects thrown by its owner, or simply enjoying the sensation of the waves and water on its paws. Additionally, the dog might be exploring the surroundings, including the sand, seaweed, and other debris found on the beach. Dogs are typically curious animals and enjoy investigating new environments. Being at the beach provides ample opportunities for the dog to exercise, play, and socialize with other dogs or humans present. Overall, the image of the white dog walking or running through the water on the beach gives the impression of a happy, engaged, and active dog making the most of its time in a dynamic and refreshing environment."}]}, {"id": "000000007567", "image": "coco/train2017/000000007567.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of aircraft is visible in the image?"}, {"from": "gpt", "value": "A large commercial passenger jet airplane is visible in the image."}, {"from": "human", "value": "What is the color of the sky in the image?"}, {"from": "gpt", "value": "The sky in the image is a clear blue color."}, {"from": "human", "value": "What stage of flight is the airplane in?"}, {"from": "gpt", "value": "It is not possible to definitively determine the stage of flight from the image alone, as the airplane could be in various stages, such as ascending, cruising, or descending. However, the airplane is in mid-air, flying through the clear blue sky."}, {"from": "human", "value": "What are some possible destinations or origins for a large commercial passenger jet?"}, {"from": "gpt", "value": "Large commercial passenger jets operate on various routes, connecting major cities and countries worldwide. Possible destinations or origins for a commercial passenger jet could include major business hubs, such as New York, London, Tokyo, Hong Kong, and Singapore; popular tourist spots like Paris, Rome, Sydney, and Bangkok; as well as international airports in other large metropolitan areas, smaller cities or island destinations.\n\nAirlines often operate scheduled flights linking major domestic and international destinations, catering to both business travelers and tourists. The specific destinations and origins of a commercial passenger jet would depend on the airline's route network, the type and size of the aircraft, and the commercial demand for flights between different destinations.\n\nFor instance, a large passenger jet, such as a Boeing 747 or an Airbus A380, is built to carry hundreds of passengers on long-distance routes, spanning several hours or even continents. Such planes commonly operate on highly frequented routes, such as transatlantic flights between the United States and Europe, long-haul flights across the Pacific Ocean to Asia, or connecting flights between major airports across the globe.\n\nIn conclusion, the possible destinations or origins for a large commercial passenger jet would cover a diverse range of locations worldwide, from major cities and business centers to tourist hotspots and international airports, depending on the airline's route network, the aircraft's capacity, and passenger demand for flights between specific destinations."}]}, {"id": "000000254779", "image": "coco/train2017/000000254779.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the person likely doing in the bathroom?"}, {"from": "gpt", "value": "The person is likely making repairs or installing a new toilet in the bathroom, as they are holding a pair of pliers and potentially other tools near the toilet."}, {"from": "human", "value": "What kind of bathroom is it: public or private?"}, {"from": "gpt", "value": "Based on the image alone, we cannot definitively determine if it is a public or private bathroom. However, the image can suggest it is likely a private bathroom, as the presence of a single toilet and a person holding tools near it is more typical of residential settings for repair or installation purposes. Public restrooms tend to have multiple stalls and a more commercial setting."}, {"from": "human", "value": "What are some examples of tools one might use when repairing or installing a toilet?"}, {"from": "gpt", "value": "Some common tools that might be used when repairing or installing a toilet include:\n\n1. Plunger: To unclog any blockages in the toilet.\n2. Adjustable wrench: For tightening or loosening bolts and nuts.\n3. Pipe wrench: Useful for gripping pipes and turning them during a repair or installation.\n4. Teflon tape: To ensure threaded connections have a leak-proof seal.\n5. Plumber's putty: To seal gaps around the toilet flange and wax ring.\n6. Screwdriver: For attaching and removing various parts, such as the tank and seat.\n7. Hacksaw: For cutting piping or any other components to fit during installation.\n8. Measuring tape: To ensure the correct clearances and dimensions are available for the toilet to fit properly.\n\nThese tools are typically used in combination throughout the repair or installation process. It is important to have the right tools and knowledge when working on plumbing projects to ensure a successful outcome and prevent damage to the bathroom and plumbing system."}, {"from": "human", "value": "What are some common issues that can lead to repairing or replacing a toilet?"}, {"from": "gpt", "value": "There are several common issues that can lead to repairing or replacing a toilet. These include:\n\n1. Constant clogging: If a toilet frequently clogs despite normal usage and regular attempts to clean and unclog it, it may be indicative of a deeper issue that requires repair or replacement.\n2. Cracks or leaks: Over time, toilets can develop cracks or leaks in either the tank or the bowl. These can lead to significant water damage if not addressed promptly.\n3. Inefficient flushing: Older toilets might not have efficient flushing mechanisms, resulting in wasting more water than necessary. Replacing the toilet with a newer, more water-efficient model can reduce water consumption and save money on utility bills.\n4. Damage to internal components: A toilet's internal components, such as the flush valve, fill valve, or flapper, can wear out or break over time, requiring repair or replacement.\n5. Cosmetic upgrades: In some cases, homeowners may want to replace a toilet to update the look of their bathroom or change the color or style of their fixtures.\n\nPersonal preferences and specific toilet conditions will determine whether a repair or complete replacement is necessary. Hiring a professional plumber or acquiring reliable knowledge about toilet repairs can help make informed decisions about the best course of action."}]}, {"id": "000000292177", "image": "coco/train2017/000000292177.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of animal is featured in the image?"}, {"from": "gpt", "value": "A giraffe is featured in the image."}, {"from": "human", "value": "What type of terrain is the giraffe standing on?"}, {"from": "gpt", "value": "The giraffe is standing on a grass-covered field."}, {"from": "human", "value": "What is the weather like in the image?"}, {"from": "gpt", "value": "The weather in the image is sunny."}, {"from": "human", "value": "Is there any other vegetation visible around the giraffe?"}, {"from": "gpt", "value": "Yes, there is a bush near the giraffe in the field."}, {"from": "human", "value": "How would you describe the appearance of the giraffe's spots?"}, {"from": "gpt", "value": "The giraffe's spots are very dark."}]}, {"id": "000000198936", "image": "coco/train2017/000000198936.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the woman sitting or laying down on the couch?"}, {"from": "gpt", "value": "The woman is sitting on the couch next to her Boston terrier."}, {"from": "human", "value": "What is the color of the couch?"}, {"from": "gpt", "value": "The color of the couch is red."}, {"from": "human", "value": "What is the woman holding in her hand?"}, {"from": "gpt", "value": "The woman is holding a remote control in her hand."}, {"from": "human", "value": "What type of dog is sitting next to the woman on the couch?"}, {"from": "gpt", "value": "The dog sitting next to the woman is a Boston terrier."}, {"from": "human", "value": "What is the color of the woman's shirt?"}, {"from": "gpt", "value": "The woman is wearing a green shirt."}]}, {"id": "000000417230", "image": "coco/train2017/000000417230.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many police officers and horses are there in the image?"}, {"from": "gpt", "value": "There are two police officers, and they are each riding one horse, making a total of two brown horses."}, {"from": "human", "value": "What is the environment like where the officers are riding the horses?"}, {"from": "gpt", "value": "The officers are riding their horses near a body of water, specifically near the ocean. They are on a beach, which is an open sandy area adjacent to the water."}, {"from": "human", "value": "Are the officers interacting or talking to each other while riding the horses?"}, {"from": "gpt", "value": "Yes, the two officers appear to be talking to each other while riding their horses on the beach."}, {"from": "human", "value": "What is the purpose of police officers patrolling on horseback in this environment?"}, {"from": "gpt", "value": "Patrolling on horseback contributes several advantages for police officers, particularly in locations like beaches where the terrain may be difficult for vehicles to traverse or when maintaining visibility is crucial. Horses can maneuver easily on sandy beaches and navigate more challenging areas than traditional patrol vehicles. \n\nWhen officers patrol on horseback, they have the benefit of an elevated vantage point, which allows them to oversee wider areas and spot potential issues or disturbances earlier. Additionally, the presence of officers on horses can act as a significant deterrent factor for any potential criminal activity or unruly behavior.\n\nPublic relations and approachability are also enhanced when officers patrol on horseback. People, especially tourists and children, may feel more comfortable approaching officers on horseback because of the novelty and more friendly appearance. This aspect can help build a stronger rapport between the police and the community.\n\nOverall, police officers patrolling on horseback near a body of water, like the ocean or beaches, provide various advantages related to terrain navigability, visibility, crime deterrence, and positive community interactions."}]}, {"id": "000000012283", "image": "coco/train2017/000000012283.jpg", "conversations": [{"from": "human", "value": "Are there people walking across a street in the image?\n<image>"}, {"from": "gpt", "value": "Yes, there is a crowd of people walking across the street in the image."}, {"from": "human", "value": "Is there a horse present in the scene?"}, {"from": "gpt", "value": "Yes, there is a horse present in the scene. It is crossing the street and stepping up onto a sidewalk near a group of people."}, {"from": "human", "value": "What are the people doing in the image besides walking across the street?"}, {"from": "gpt", "value": "Besides walking across the street, the townspeople are taking a stroll down the sidewalk, and some of them are near the horse that is crossing the street."}, {"from": "human", "value": "Is there any indication of a restaurant or similar establishment in the image?"}, {"from": "gpt", "value": "Yes, there is a restaurant in the image. The horse is crossing the street next to this restaurant."}, {"from": "human", "value": "What type of setting does this scene take place in - urban or rural?"}, {"from": "gpt", "value": "Based on the presence of a crowd of people, a street corner, a restaurant, and a horse, it appears that the scene takes place in an urban setting with a touch of a rural or historical atmosphere due to the presence of the horse. The image might be depicting a town or city center where various activities, such as walking, shopping, dining, and even horse-related events, can take place."}]}, {"id": "000000279648", "image": "coco/train2017/000000279648.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the main activity taking place in the image?"}, {"from": "gpt", "value": "In the image, the main activity is a girl riding a wave in the ocean using a surfboard."}, {"from": "human", "value": "What type of board is the girl using in the water?"}, {"from": "gpt", "value": "The girl is using a surfboard to ride the wave in the ocean."}, {"from": "human", "value": "Is the person riding the wave in a standing or lying down position?"}, {"from": "gpt", "value": "The person is riding the wave in a standing position on the surfboard."}, {"from": "human", "value": "Can you provide a brief explanation of surfing and its popularity?"}, {"from": "gpt", "value": "Surfing is a water sport in which an individual, known as a surfer, rides the face of a wave in a standing position on a surfboard. The objective is to balance on the surfboard while harnessing the wave's energy to propel oneself forward, navigating the constantly changing conditions of the water. Surfing can be practiced in various types of waves, from gently rolling small waves to large swells that are several feet high.\n\nThe sport has origins dating back thousands of years, with the earliest records originating from ancient Polynesians. Over time, surfing gained popularity and spread to other cultures across the globe. Today, it is a popular recreational activity and competitive sport, attracting millions of participants and spectators worldwide.\n\nSurfing's widespread appeal can be attributed to several factors, including its unique connection with nature, the physical and mental challenges it presents, and the thrill of riding waves at high speeds. The sport offers a mixture of excitement, relaxation, and adventure, which has helped it maintain its status as a popular pastime for people of all ages and skill levels.\n\nIn addition to being a compelling individual pursuit, surfing has also fostered a tight-knit global community of enthusiasts who share a common passion for the sport and the ocean environment. This camaraderie enhances the appeal of surfing and encourages the growth of the sport as more people immerse themselves in the surfing lifestyle.\n\nIn conclusion, surfing is a thrilling water sport that has inspired a global following due to its deep roots in history, unique relationship with nature, and its ability to challenge both the body and mind, while also fostering a strong sense of community among its practitioners."}]}, {"id": "000000139571", "image": "coco/train2017/000000139571.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat are the people doing with the cake?"}, {"from": "gpt", "value": "The people are cutting the cake using a sword as part of a ceremony. They are standing around the cake and participating in the event together."}, {"from": "human", "value": "Are there different nationalities present among the people cutting the cake?"}, {"from": "gpt", "value": "Yes, there are people of two different nationalities cutting the cake together."}, {"from": "human", "value": "What are the people wearing while cutting the cake?"}, {"from": "gpt", "value": "The people cutting the cake are wearing white uniforms, while other uniformed individuals watch the ceremony."}, {"from": "human", "value": "Is this event casual or formal?"}, {"from": "gpt", "value": "Given that the people attending the event are wearing uniforms and using a sword to cut the cake as part of a ceremony, the event appears to be formal in nature."}, {"from": "human", "value": "What are some possible reasons for cutting a cake with a sword in a formal ceremony?"}, {"from": "gpt", "value": "Cutting a cake with a sword in a formal ceremony can hold various symbolic meanings, often representing unity, strength, or honor. Here are a few possible reasons for cutting a cake with a sword:\n\n1. Military or naval traditions: In some military or naval celebrations, such as weddings, retirements, or anniversaries, cutting a cake with a sword represents loyalty, strength, and commitment to one's duties. It also reflects the honor and respect for the traditions and values upheld by the armed forces.\n\n2. Cultural customs: In certain cultural traditions, cutting a cake with a sword can symbolize the bond between two families or communities, particularly at weddings. This emphasizes the joining of two separate entities, coming together as one with strength and unity.\n\n3. Historic significance: Using a sword to cut a cake at a formal event can pay tribute to historical customs or traditions, adding a touch of elegance and significance to the ceremony.\n\nIn the image, since the people cutting the cake are wearing white uniforms and are of two different nationalities, the event might symbolize unity and collaboration between these two groups, reinforcing the importance of cooperation and mutual respect."}]}, {"id": "000000129071", "image": "coco/train2017/000000129071.jpg", "conversations": [{"from": "human", "value": "How many people are there in the image with skis?\n<image>"}, {"from": "gpt", "value": "There are two people in the image with skis."}, {"from": "human", "value": "Are the skiers moving or standing still?"}, {"from": "gpt", "value": "The skiers are standing still at the top of a snow-covered slope, looking over their shoulders at the camera."}, {"from": "human", "value": "Are the skiers on top of a hill or further down the slope?"}, {"from": "gpt", "value": "The skiers are standing on top of a hill, ready to start their descent down the snow-covered slope."}, {"from": "human", "value": "Can you see their facial expressions or are they facing away from the camera?"}, {"from": "gpt", "value": "The skiers are looking over their shoulders at the camera, so we can see their facial expressions."}, {"from": "human", "value": "What should skiers consider before starting their descent down a slope?"}, {"from": "gpt", "value": "Before starting their descent down a slope, skiers should take several factors into consideration to ensure their safety and enjoyment on the mountain. These factors include:\n\n1. Skill level: Skiers should evaluate their abilities and choose slopes that match their skill level. Attempting a run that is too difficult for one's abilities can lead to accidents, injuries, and a less enjoyable experience.\n\n2. Snow conditions: Weather conditions and recent snowfalls can affect the quality of the snow. Skiers should consider if the snow is packed, powdery, icy, or slushy and plan their skiing techniques accordingly to stay safe and maintain control on the slopes.\n\n3. Slope conditions: Skiers should assess the steepness, width, and grooming of a slope, as well as any potential obstacles such as trees, rocks, or natural features. They should also observe any signs or markings that indicate the difficulty of the run, which usually follow a color-coded system (green for beginner, blue for intermediate, and black for advanced).\n\n4. Visibility: Skiers should ensure that they have clear visibility on the slope, taking into account weather conditions such as fog, snowfall, or blinding sunlight. Wearing appropriate goggles or sunglasses can help improve visibility.\n\n5. Avalanche risk: Before starting their descent, skiers should be aware of any potential avalanche risks in the area. They can check with local authorities or ski patrol for the latest avalanche forecasts and follow any safety guidelines provided.\n\n6. Safety equipment: Skiers should ensure that they are wearing appropriate safety gear, such as helmets, gloves, and protective padding, and have functioning bindings on their skis.\n\n7. Familiarity with the slope: If possible, skiers should familiarize themselves with the layout of the slope and any key landmarks, such as lift stations or trail junctions, to prevent becoming disoriented or lost on the mountain.\n\nBy taking these factors into consideration, skiers can make informed decisions about their descent, ensuring they have an enjoyable and safe skiing experience."}]}, {"id": "000000455744", "image": "coco/train2017/000000455744.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is the cat in the image?"}, {"from": "gpt", "value": "The cat in the image is black."}, {"from": "human", "value": "Where is the cat walking?"}, {"from": "gpt", "value": "The black cat is walking out of a partially opened bathroom door."}, {"from": "human", "value": "What items are hanging on the back of the bathroom door?"}, {"from": "gpt", "value": "A robe and a towel are hanging on the back of the bathroom door."}, {"from": "human", "value": "Is the bathroom door fully open, closed, or somewhere in between?"}, {"from": "gpt", "value": "The bathroom door is partially open, halfway ajar."}, {"from": "human", "value": "What is the black cat doing as it goes behind the door?"}, {"from": "gpt", "value": "As the black cat goes behind the door, it is walking through the bathroom entrance, making its way out of the bathroom."}]}, {"id": "000000347248", "image": "coco/train2017/000000347248.jpg", "conversations": [{"from": "human", "value": "What color is the container holding the food in the image?\n<image>"}, {"from": "gpt", "value": "The container holding the food in the image is green."}, {"from": "human", "value": "What types of food can be seen on the green container?"}, {"from": "gpt", "value": "On the green container, you can see a variety of foods, including carrots, cheese, pasta (specifically pasta shells), beans, corn, and green beans. The cheese appears to be shredded."}, {"from": "human", "value": "Is the food in the container suited for a vegetarian diet?"}, {"from": "gpt", "value": "Yes, based on the visible contents in the green container, the food is suited for a vegetarian diet. The food items include pasta, beans, corn, carrots, green beans, and cheese, which are all vegetarian-friendly ingredients."}, {"from": "human", "value": "How can the food in the container be appropriate for a balanced meal?"}, {"from": "gpt", "value": "The food in the container can be appropriate for a balanced meal, as it includes a variety of food groups that contribute to a nutritious diet. \n\n1. Carbohydrates: The pasta shells serve as a source of carbohydrates, which provide energy for the body.\n2. Protein: The beans contribute to the meal's protein content, which is essential for cells' growth, repair, and maintenance.\n3. Vegetables: Carrots, corn, and green beans add valuable vitamins, minerals, and dietary fiber to support overall health.\n4. Dairy: The shredded cheese contains calcium for strong bones and teeth, while also adding protein and some fat to the meal.\n\nBy incorporating ingredients from different food groups, the container's contents can support a balanced meal that meets a person's nutritional needs. Additionally, the variety of colors and textures in the dish add to its visual appeal, potentially making the meal more enjoyable and satisfying.\n\nTo enhance the meal's balance further, the addition of a healthy source of fat (such as olive oil drizzled over the pasta) and a side dish containing whole grains (like a slice of whole-grain bread) could be considered. This would ensure that the meal caters to all essential macronutrients while providing a diverse range of micronutrients."}]}, {"id": "000000276739", "image": "coco/train2017/000000276739.jpg", "conversations": [{"from": "human", "value": "How many seats does the modified motorcycle have?\n<image>"}, {"from": "gpt", "value": "The modified motorcycle on display has four seats."}, {"from": "human", "value": "Is the unique motorcycle displayed indoors or outdoors?"}, {"from": "gpt", "value": "The unique, multiple-seat motorcycle is displayed indoors, as described by the image."}, {"from": "human", "value": "Are there other motorcycles displayed along with the unique motorcycle?"}, {"from": "gpt", "value": "Yes, there is a line of motorcycles parked in a row as part of an indoor display. The modified motorcycle with four seats is among them."}, {"from": "human", "value": "What is unusual about the design of the modified motorcycle in the image?"}, {"from": "gpt", "value": "The unusual aspect of the modified motorcycle's design is its capacity to accommodate multiple passengers with its four seats. Motorcycles typically have one or two seats, so a four-seat motorcycle is unique and not commonly seen."}, {"from": "human", "value": "Are there any events or gatherings where modified motorcycles like this one might be displayed?"}, {"from": "gpt", "value": "Yes, modified motorcycles like the one in the image might be displayed at various events or gatherings, such as motorcycle shows, expos, and conventions. These events often showcase unique and customized motorcycles, featuring innovative designs, advanced technologies, and creative modifications. At such gatherings, enthusiasts and industry professionals come together to admire the craftsmanship, share ideas, and celebrate the art of motorcycle modification. In addition, bike shows may include contests, judging panels, or awards for different categories, such as Best Custom Bike, Most Innovative Design, or Best Paint Job. By participating in or attending these events, motorcycle enthusiasts can stay informed about the latest trends and developments in the industry, while also networking with like-minded individuals and possibly drawing inspiration for their own projects."}]}, {"id": "000000374174", "image": "coco/train2017/000000374174.jpg", "conversations": [{"from": "human", "value": "What type of truck is seen in the image?\n<image>"}, {"from": "gpt", "value": "The image features a tow truck."}, {"from": "human", "value": "What is the tow truck carrying?"}, {"from": "gpt", "value": "The tow truck is carrying a nice sedan on its back."}, {"from": "human", "value": "Where is the tow truck located?"}, {"from": "gpt", "value": "The tow truck is located on a city street, driving near a traffic light."}, {"from": "human", "value": "What is a tow truck typically used for?"}, {"from": "gpt", "value": "A tow truck is typically used to transport vehicles that are unable to be driven or need to be removed from the road due to various reasons. These reasons might include accidents, breakdowns, repairs, illegal parking, or impoundment. The tow truck driver usually loads the disabled, damaged, or unallowed vehicles onto the truck's platform before transporting them to a designated location, such as a repair shop, impound lot, or the vehicle owner's home.\n\nThere are different types of tow trucks, such as flatbed trucks (which have a large, flat platform for the vehicle to be loaded onto), wheel-lift trucks (which lift the vehicle by attaching underneath its wheels), hook-and-chain trucks (which use chains to secure the vehicle), and integrated trucks (commonly used for heavy-duty towing).\n\nIn the context of the image, the tow truck carrying a nice sedan could be providing various services, such as assisting the owner whose car has broken down, transporting a newly repaired or purchased vehicle, or removing a vehicle from the road due to parking or traffic violations."}]}, {"id": "000000167505", "image": "coco/train2017/000000167505.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is the tour bus in the image?"}, {"from": "gpt", "value": "The tour bus in the image is blue."}, {"from": "human", "value": "What type of bus is featured in the image?"}, {"from": "gpt", "value": "The image features a two-tiered or double-decker British tour bus."}, {"from": "human", "value": "What is the bus doing in the image?"}, {"from": "gpt", "value": "The bus is making a turn and driving down a residential street with several cars behind it."}, {"from": "human", "value": "What might the passengers on the bus experience during the tour?"}, {"from": "gpt", "value": "Passengers on the blue double-decker tour bus would likely be enjoying the sights of the city and its residential neighborhoods the bus is driving through. Being on a two-tiered bus enables passengers, particularly those seated on the upper deck, to have a vantage point that allows for better views of the cityscape and architecture. \n\nAs the bus drives around corners and along the streets, the passengers would be able to observe various aspects of local life, such as homes, parks, shops, and other landmarks. Depending on the specific tour, there may be a knowledgeable tour guide providing interesting information and historical facts about the city and the areas being visited, which can engage and educate the passengers. \n\nThe tour may also include designated stops at popular landmarks, giving passengers the opportunity to disembark and explore more closely before returning to the bus and continuing the journey. Overall, the passengers on the blue double-decker bus would likely have a unique and engaging experience, allowing them to gain insights and appreciate the beautiful and diverse aspects of the city they're touring."}]}, {"id": "000000258611", "image": "coco/train2017/000000258611.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is the couch the man is sitting on?"}, {"from": "gpt", "value": "The man is sitting on a red couch."}, {"from": "human", "value": "Is there anything next to the man on the couch?"}, {"from": "gpt", "value": "Yes, there is a suitcase next to the man on the couch."}, {"from": "human", "value": "What type of room is the man sitting in?"}, {"from": "gpt", "value": "The man is sitting in a large room, possibly a living room near the windows, or a loft apartment."}, {"from": "human", "value": "What can you tell about the interior design of the room?"}, {"from": "gpt", "value": "From the image, I can see that the room has a chandelier, which suggests a stylish and upscale interior design. The presence of windows indicates that the room is well-lit and likely offers a view. The red couch adds a pop of color to the space, and the overall room appears spacious and comfortable. The specific design style cannot be precisely determined from the limited information provided; however, it seems to be an inviting and aesthetically pleasing environment."}, {"from": "human", "value": "Can we infer anything about the man's situation or his plans from the image?"}, {"from": "gpt", "value": "We cannot definitively determine the man's situation or plans from the image, but we can make some speculations based on what we can see:\n\n1. Presence of a suitcase: This may suggest either the man has recently returned from a trip or is preparing to leave for one. His relaxed position on the couch could indicate that he is taking a break from packing or unwinding after a journey.\n\n2. Sitting alone on a red couch: This might imply that the man is enjoying a moment of solitude and reflective thought in the comfort of his home. Perhaps he is contemplating his plans, experiences, or simply appreciating the interior design and atmosphere of the room.\n\nHowever, these assumptions are merely speculative and cannot be confirmed solely based on the image."}]}, {"id": "000000520769", "image": "coco/train2017/000000520769.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the main activity taking place in the image?"}, {"from": "gpt", "value": "The main activity in the image is a young girl in a dark blue uniform pitching a softball underhanded during a game."}, {"from": "human", "value": "What type of ball is being used in the image?"}, {"from": "gpt", "value": "A softball is being used in the image."}, {"from": "human", "value": "How is the girl throwing the ball? Underhanded or overhanded?"}, {"from": "gpt", "value": "The girl is throwing the ball underhanded."}, {"from": "human", "value": "Is the girl wearing a uniform?"}, {"from": "gpt", "value": "Yes, the girl is wearing a dark blue uniform."}, {"from": "human", "value": "What are some basic rules and elements of a softball game?"}, {"from": "gpt", "value": "Softball is a team sport that consists of two teams facing off to score runs by hitting a ball and advancing around bases. The game is played on a diamond-shaped field, with four bases (first, second, third, and home plate) and a pitching mound in the center. Here are some basic rules and elements of a softball game:\n\n1. Teams: Each team has nine players on the field at a time, including a pitcher, catcher, four infielders, and three outfielders.\n\n2. Innings: A game is usually composed of seven innings, but in case of a tie, extra innings can be played. Each inning consists of two halves, with one team batting and the other team fielding in each half.\n\n3. Pitching: The pitcher throws the ball underhanded towards the batter, who tries to hit it with a bat. The catcher, positioned behind the batter, catches any missed pitches.\n\n4. Batting: Each batter gets up to three strikes (swinging and missing or hitting a foul ball) before they are called out. If the batter hits a fair ball, they attempt to run to first base, while the fielding team tries to get the batter out by throwing the ball to the base before the batter arrives.\n\n5. Outs: The fielding team can get batters out in several ways, such as catching a fly ball, tagging a base while holding the ball before the batter reaches it, or tagging a runner with the ball as they try to advance to another base.\n\n6. Scoring: A team earns a run when a player advances around all the bases (first, second, third, and back to home plate) without being put out. The team with the most runs at the end of the game wins.\n\nThese are just a few of the basic rules and elements of softball. The sport offers various positions, strategies, and skills for players to develop and enjoy, making it a popular and engaging activity for people of all ages."}]}, {"id": "000000092585", "image": "coco/train2017/000000092585.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the color of the boat in the image?"}, {"from": "gpt", "value": "The color of the boat in the image is white."}, {"from": "human", "value": "What type of boat is depicted in the image?"}, {"from": "gpt", "value": "The image depicts a fishing boat, which is typically used for commercial fishing purposes."}, {"from": "human", "value": "Is the boat full of items or empty?"}, {"from": "gpt", "value": "The boat is full of various items, indicating that it might be carrying equipment for fishing or supplies for a journey."}, {"from": "human", "value": "Can a crew be seen on the boat in the image?"}, {"from": "gpt", "value": "Yes, a crew can be seen on the boat, which suggests that they might be managing the equipment or navigating the vessel."}, {"from": "human", "value": "What is the setting of the image in terms of the boat's location and the surrounding environment?"}, {"from": "gpt", "value": "The boat is floating on a large body of water, likely an ocean or a sea, as suggested by the blue color of the water."}]}, {"id": "000000047328", "image": "coco/train2017/000000047328.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of pizza is shown in the image?"}, {"from": "gpt", "value": "The image shows a thin-crust pizza with various vegetable toppings on it."}, {"from": "human", "value": "How is the pizza presented in the image?"}, {"from": "gpt", "value": "The pizza is sitting on a pizza pan, which is placed on top of a wooden table."}, {"from": "human", "value": "What is the appearance of the pizza like?"}, {"from": "gpt", "value": "The pizza looks very tasty and is loaded with various toppings, making it a visually appealing meal."}, {"from": "human", "value": "What kind of plate is nearby the pizza?"}, {"from": "gpt", "value": "There is a large white plate of food on the table near the pizza."}, {"from": "human", "value": "Is the meal in the image ready to be consumed?"}, {"from": "gpt", "value": "Yes, the meal is ready on the table and can be eaten."}]}, {"id": "000000167330", "image": "coco/train2017/000000167330.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the condition of the stop sign in the image?"}, {"from": "gpt", "value": "The stop sign in the image is vandalized, with an \"ALL WAR\" sign added beneath it."}, {"from": "human", "value": "What type of tree is near the stop sign?"}, {"from": "gpt", "value": "The tree near the stop sign is a palm tree."}, {"from": "human", "value": "What street is the stop sign located on?"}, {"from": "gpt", "value": "The stop sign is located on Electric Avenue."}, {"from": "human", "value": "Is there a street sign in the image?"}, {"from": "gpt", "value": "Yes, there is a street sign in the image, which is positioned next to the vandalized stop sign at an intersection."}, {"from": "human", "value": "What can you tell me about the act of vandalism on the stop sign?"}, {"from": "gpt", "value": "The act of vandalism on the stop sign can be seen as a form of street art or a form of protest, depending on the intention behind it. In this case, the vandal has added an \"ALL WAR\" sign beneath the stop sign, which might be interpreted as a statement against war or a call for peace. \n\nVandalism like this can be controversial, as some people believe it adds character or conveys important messages, while others see it as a criminal act that causes damage to public property. Ultimately, the interpretation and impact of such an act depend on the context and the reactions from the surrounding community.\n\nWhile it is essential to acknowledge the creative aspects and potential message behind this specific act of vandalism, it is also crucial to consider the implications of it on public property and the potential confusion it may cause at an intersection. Public authorities often discourage such activities, as they can lead to additional expenses and complications in maintaining traffic signs and other public properties."}]}, {"id": "000000114879", "image": "coco/train2017/000000114879.jpg", "conversations": [{"from": "human", "value": "What is the main focus of this image?\n<image>"}, {"from": "gpt", "value": "The main focus of the image is a man sitting in a colorful beach chair, relaxing by the ocean."}, {"from": "human", "value": "Are there other people on the beach in the image?"}, {"from": "gpt", "value": "Yes, there are other people on the beach, walking around and enjoying the beach as well."}, {"from": "human", "value": "What are some of the activities depicted in the image?"}, {"from": "gpt", "value": "The image depicts a man relaxing in a lounge chair on the beach, and other people walking nearby, enjoying the seaside atmosphere. The scene suggests leisure time, relaxation, and a casual beach environment."}, {"from": "human", "value": "Can you describe the setting and the surroundings in the image?"}, {"from": "gpt", "value": "The image showcases a picturesque beach setting, with the vast ocean extending into the horizon, soft sand underfoot, and the sound of waves crashing gently against the shore. The man sitting in the colorful beach chair is positioned near the water's edge, allowing him to fully appreciate the tranquility and beauty of the ocean. The people walking nearby are presumably enjoying the warm sunshine, the fresh sea breeze, and the calming ambiance of the beach. The overall mood of the image feels peaceful and inviting, making it an ideal representation of a relaxing beach day."}]}, {"id": "000000170832", "image": "coco/train2017/000000170832.jpg", "conversations": [{"from": "human", "value": "What type of building is the clock located on?\n<image>"}, {"from": "gpt", "value": "The clock is located on a tall brick building, which is a clock tower."}, {"from": "human", "value": "What type of roof does the clock tower have?"}, {"from": "gpt", "value": "The clock tower has a pointy, blue roof that is quite tall and with an ornate design."}, {"from": "human", "value": "How would you describe the design of the clock tower?"}, {"from": "gpt", "value": "The clock tower features an ornate design with a tall steeple, a pointy blue roof, and a brick structure. It stands out against the sky background, showcasing its impressive height and intricate architectural details."}, {"from": "human", "value": "What type of background is behind the clock tower?"}, {"from": "gpt", "value": "The background behind the clock tower is the sky, which helps to emphasize the tower's height and distinctive design."}, {"from": "human", "value": "What purpose does a clock tower serve?"}, {"from": "gpt", "value": "A clock tower generally serves multiple purposes. Firstly, it acts as a prominent timekeeping device, allowing people in the surrounding area to easily see the time displayed on its large clock face. This was particularly useful in the past when personal timekeeping devices such as wristwatches and mobile phones were not as common or accessible.\n\nSecondly, clock towers often hold historical and cultural significance. Many clock towers are attached to or part of important landmarks, such as town halls, churches, or other public buildings. They were sometimes built to commemorate specific events or historical figures or simply as symbols of a city or institution.\n\nLastly, clock towers often have architectural and aesthetic functions. Their unique designs can enhance the beauty and identity of the surrounding cityscape, making them popular tourist attractions and points of interest for both local residents and visitors. Their impressive height allows them to dominate the skyline, offering spectacular views from a distance and acting as easily recognizable focal points.\n\nIn conclusion, a clock tower serves not only as a practical means of displaying the time but also as a culturally significant, aesthetically pleasing, and iconic focal point within a community."}]}, {"id": "000000190798", "image": "coco/train2017/000000190798.jpg", "conversations": [{"from": "human", "value": "What color is the cat in the image?\n<image>"}, {"from": "gpt", "value": "The cat in the image is black."}, {"from": "human", "value": "What is the cat doing in the image?"}, {"from": "gpt", "value": "The black cat is balancing on the rim of the toilet seat with its head inside the toilet bowl, drinking the toilet water."}, {"from": "human", "value": "Is the toilet in the image white?"}, {"from": "gpt", "value": "Yes, the toilet in the image is white."}, {"from": "human", "value": "Why might a cat drink water from a toilet bowl?"}, {"from": "gpt", "value": "There could be several reasons why a cat might choose to drink water from a toilet bowl. Some possible explanations include:\n\n1. The cat may be thirsty and, for some reason, finds the toilet water more accessible or attractive as a source of water. This could be due to the water remaining fresh and cooler in the toilet bowl. \n2. The cat's water bowl may be empty or contaminated, making the toilet water more appealing.\n3. Some cats might be attracted to the running water from a toilet flush, as they prefer flowing water rather than still water. \n4. It could also simply be due to curiosity or mischievous behavior on the part of the cat, as they are known to be curious creatures and often explore their surroundings to satisfy their curiosity.\n\nTo discourage cats from drinking toilet water, owners should ensure they have a clean and easily accessible water source. Additionally, it's essential to keep the toilet lid closed when not in use to prevent pets from accessing it."}]}, {"id": "000000059351", "image": "coco/train2017/000000059351.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat kind of animal is the woman walking with?"}, {"from": "gpt", "value": "The woman is walking with a horse."}, {"from": "human", "value": "Is the horse carrying anything on its back?"}, {"from": "gpt", "value": "Yes, the horse is carrying a pack on its back."}, {"from": "human", "value": "How many horses are visible in the image?"}, {"from": "gpt", "value": "There is only one horse visible in the image."}, {"from": "human", "value": "What is the setting of the image?"}, {"from": "gpt", "value": "The setting of the image is an outdoor dirt path or trail, where the woman is walking with the horse."}, {"from": "human", "value": "What can you tell me about the relationship between horses and humans based on the image and in general?"}, {"from": "gpt", "value": "Based on the image of a woman walking a horse down a trail, it is evident that there is a cooperative relationship between horses and humans in this particular scenario. In general, this relationship dates back thousands of years and has evolved from primarily functional roles to include recreational and competitive activities.\n\nHorses have served various roles in human societies, including transportation, agriculture, and warfare. They have been instrumental in aiding the development, expansion, and sustenance of numerous civilizations throughout history. In the image, the horse is carrying a pack on its back, illustrating its utility and willingness to work alongside humans.\n\nThe bond between humans and horses can also extend beyond their functional roles. Today, horses are often used in sports such as racing, equestrian events, and rodeos, exemplifying their athletic abilities and grace. Leisure activities such as horseback riding and trail riding have also become popular amongst people of all ages, demonstrating the emotional connection and therapeutic benefits of interacting with these majestic animals.\n\nThrough proper training and care, horses can develop trusting relationships with their human handlers or riders, evident by the respectful and calm behavior displayed in the image. This relationship showcases not only the practical aspects of human-horse interactions but also the emotional bond that can form between the two species. In conclusion, the image of the woman walking the horse down the trail represents just one example of the multifaceted and enduring relationship between humans and horses in both functional and recreational aspects."}]}, {"id": "000000155505", "image": "coco/train2017/000000155505.jpg", "conversations": [{"from": "human", "value": "How many tractors are being hauled by the truck?\n<image>"}, {"from": "gpt", "value": "The truck is hauling three tractors on its trailer."}, {"from": "human", "value": "What type of truck is being used to haul the tractors?"}, {"from": "gpt", "value": "A semi-truck is being used to haul the tractors."}, {"from": "human", "value": "What is the setting of the image? Is it on a road or a parking lot?"}, {"from": "gpt", "value": "The setting of the image is on a road, where a semi-truck is hauling three large tractors down the street."}, {"from": "human", "value": "What can be inferred from the image about the purpose of transporting these tractors?"}, {"from": "gpt", "value": "From the image, we can infer that the tractors are being transported for various reasons, such as being delivered to a construction site, an agricultural field, or even a dealership for sale. It's important to note that the tractors are hauled on a large trailer by a semi-truck, which suggests that this is a professional operation, rather than a casual transportation choice. This can indicate that the tractors are valuable, or may be required to perform heavy-duty tasks in their destination. The image doesn't provide further details on the specific purpose, but it does reveal that the transportation process is purposeful and organized."}]}, {"id": "000000030805", "image": "coco/train2017/000000030805.jpg", "conversations": [{"from": "human", "value": "What color is the liquid inside the blender?\n<image>"}, {"from": "gpt", "value": "The liquid inside the blender is a white-beige color."}, {"from": "human", "value": "Is there any other container holding liquid in the image?"}, {"from": "gpt", "value": "Yes, there is a glass measuring cup with yellow liquid in it."}, {"from": "human", "value": "What can you deduce from the image about the blender's activity?"}, {"from": "gpt", "value": "Based on the image, it appears that the blender has been recently used to mix or blend some ingredients, resulting in the white-beige liquid inside the blender. The presence of the freshly blended beverage and the view looking down into the blender filled with liquid indicate that it has completed its blending process, and the contents are ready for consumption or further use."}, {"from": "human", "value": "What could be some possible ingredients or types of beverages that the white-beige liquid might be?"}, {"from": "gpt", "value": "The white-beige liquid inside the blender could be a variety of smoothie, milkshake, or some other blended drink or concoction. Some specific possibilities include:\n\n1. Smoothie: The liquid could be a fruit or vegetable-based smoothie containing ingredients like bananas, yogurt, milk, or almond milk. These ingredients would give the blended drink a white or beige color. It could also include other ingredients like fruits or greens blended in, creating a more heterogeneous texture.\n\n2. Milkshake: The white-beige liquid could be a milkshake made with ice cream, milk, or a dairy-free alternative. It might be a vanilla, coffee, or caramel flavored milkshake, as these flavors typically have a lighter color.\n\n3. Protein shake: The liquid could be a protein shake made with protein powder, milk, or another type of liquid. The particular color could result from a specific flavor of protein powder, such as vanilla or peanut butter, mixed with the chosen liquid.\n\n4. Nut butter: The white-beige liquid could be a nut or seed butter, like almond butter or tahini, which has been blended with a liquid to make a sauce, smoothie, or other culinary creation.\n\nIt is difficult to pinpoint the exact ingredients or beverage type without additional information, but these are a few possible ideas based on the color and texture of the liquid observed in the blender."}]}, {"id": "000000475316", "image": "coco/train2017/000000475316.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of flooring does the kitchen have?"}, {"from": "gpt", "value": "The kitchen has a nice wood floor."}, {"from": "human", "value": "How many chairs are there in the dining area?"}, {"from": "gpt", "value": "There are four chairs in the dining area."}, {"from": "human", "value": "Does the kitchen have any separating wall between the cooking area and the dining area?"}, {"from": "gpt", "value": "No, there is no separating wall between the kitchen and dining area. The two areas are adjoined."}, {"from": "human", "value": "What are some of the features of the kitchen?"}, {"from": "gpt", "value": "The kitchen features wood floors, wood cabinets, a table with four chairs, and a refrigerator. The attractive wood colors give the space a warm and inviting ambiance. The absence of a separating wall between the kitchen and dining area creates an open feel to the space, making it an ideal candidate for a breakfast nook. The nicely appointed kitchen and breakfast nook area showcases a thoughtful design and a strong emphasis on aesthetics, functionality, and modern living."}]}, {"id": "000000033332", "image": "coco/train2017/000000033332.jpg", "conversations": [{"from": "human", "value": "What color is the vanity in the bathroom?\n<image>"}, {"from": "gpt", "value": "The vanity in the bathroom is black."}, {"from": "human", "value": "What colors are the sink and toilet in the bathroom?"}, {"from": "gpt", "value": "Both the sink and the toilet in the bathroom are white."}, {"from": "human", "value": "Is there a mirror in the bathroom? If so, what is its location?"}, {"from": "gpt", "value": "Yes, there is a mirror in the bathroom. It is located in front of the toilet and above the sink."}, {"from": "human", "value": "Can you describe the color scheme of the bathroom?"}, {"from": "gpt", "value": "The bathroom features a black, teal, and gold color scheme with white tile floors. The vanity is black, while the sink and toilet are both white, which contributes to the overall color palette. The teal and gold elements in the bathroom likely come from decorative items or fixtures, creating a harmonious and stylish appearance."}]}, {"id": "000000280132", "image": "coco/train2017/000000280132.jpg", "conversations": [{"from": "human", "value": "What color is the sheep in the image?\n<image>"}, {"from": "gpt", "value": "The sheep in the image is pink."}, {"from": "human", "value": "What is the sheep doing in the image?"}, {"from": "gpt", "value": "The sheep is grazing on grass near a river."}, {"from": "human", "value": "Where is the large group of people located in relation to the sheep?"}, {"from": "gpt", "value": "The large group of people is located on a bridge in the background, across from the sheep."}, {"from": "human", "value": "Is the pink coloration of the sheep natural or artificial?"}, {"from": "gpt", "value": "The pink coloration of the sheep is most likely artificial, as sheep are not naturally pink in color. This unusual color may result from the use of dyes or other colorants applied to the sheep's wool."}, {"from": "human", "value": "Why might someone color a sheep pink?"}, {"from": "gpt", "value": "There could be several reasons for coloring a sheep pink, but it's important to note that this is not a common practice. Some possible reasons include:\n\n1. Artistic expression or a publicity stunt: An artist or someone seeking attention might dye a sheep pink to create a unique and eye-catching spectacle, drawing attention and sparking curiosity.\n\n2. Raising awareness for a cause: Pink is often associated with breast cancer awareness campaigns, and a pink sheep might serve as a mascot to raise awareness for this cause or another health issue.\n\n3. Marking ownership or distinction: Sheep farmers might dye their sheep in distinct colors to differentiate their flock from others or to mark ownership.\n\n4. Festive events or celebrations: A pink sheep could be part of a themed event, festival, or celebration, serving as an interesting attraction or conversation starter.\n\nIt's essential to ensure that any dyes or colorants used on animals are non-toxic and safe for the animals, and that the process is carried out with care and respect for the animal's well-being."}]}, {"id": "000000425576", "image": "coco/train2017/000000425576.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color are the eyes of the woman in the image?"}, {"from": "gpt", "value": "The woman in the image has beautiful blue eyes."}, {"from": "human", "value": "What is the woman doing in the image?"}, {"from": "gpt", "value": "The woman is eating a small, sugary mini donut."}, {"from": "human", "value": "What color is the woman's hair?"}, {"from": "gpt", "value": "The woman's hair is red."}, {"from": "human", "value": "Does the woman wear glasses? If so, what color are the glasses?"}, {"from": "gpt", "value": "Yes, the woman is wearing glasses, and they are red in color."}, {"from": "human", "value": "Is the woman taking a bite of the donut or just holding it?"}, {"from": "gpt", "value": "The woman is getting ready to take a bite out of the mini donut."}]}, {"id": "000000397513", "image": "coco/train2017/000000397513.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat sport is being played in the image?"}, {"from": "gpt", "value": "The sport being played in the image is baseball."}, {"from": "human", "value": "What is the person in the image doing?"}, {"from": "gpt", "value": "The person in the image is a baseball pitcher, and he is in the middle of pitching a baseball from the mound."}, {"from": "human", "value": "What piece of equipment is the man wearing on his hand?"}, {"from": "gpt", "value": "The man is wearing a glove on his hand, which is commonly used by baseball players for catching the ball."}, {"from": "human", "value": "Can you explain the role of a pitcher in a baseball game?"}, {"from": "gpt", "value": "In a baseball game, the pitcher plays a crucial role as a member of the defensive team. Their primary responsibility is to pitch or throw the baseball towards home plate, where the batter from the opposing team stands ready to hit the ball. The objective of the pitcher is to deliver the ball in a manner that makes it difficult for the batter to hit it, either by throwing the ball with great speed, accuracy, or using various pitching techniques that cause the ball to move unpredictably.\n\nPitchers are typically skilled in throwing different types of pitches, such as fastballs, curveballs, sliders, and changeups, each with its unique characteristics and movement patterns. These pitches are designed to deceive the batter and make it challenging to anticipate the ball's trajectory, ultimately leading to a missed swing (strike) or a poorly hit ball that can be easily fielded by the defensive team.\n\nA successful pitcher must possess a combination of physical and mental skills, such as strength, control, endurance, strategic thinking, and the ability to read the opposing batters' tendencies. They also need to work closely with their catcher, who calls the pitches and gives signals for the desired location of each pitch.\n\nIn short, the pitcher's role in a baseball game is to challenge the opposing batters by throwing the ball in a way that makes it difficult to hit, ultimately leading to outs and preventing the other team from scoring runs."}]}, {"id": "000000421542", "image": "coco/train2017/000000421542.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the primary activity of the man in the image?"}, {"from": "gpt", "value": "The primary activity of the man in the image is cooking, as he is standing in front of a stove, stirring a pot, and preparing food in a kitchen."}, {"from": "human", "value": "What type of stove is the man using?"}, {"from": "gpt", "value": "The man is using an electric stove in the image."}, {"from": "human", "value": "How big is the kitchen where the man is cooking?"}, {"from": "gpt", "value": "The kitchen where the man is cooking is relatively small."}, {"from": "human", "value": "Is the man actively cooking?"}, {"from": "gpt", "value": "Yes, the man is actively cooking, as he is shown stirring a pot on top of the stove."}, {"from": "human", "value": "What can you infer about the man's cooking skills or familiarity with the kitchen based on the image?"}, {"from": "gpt", "value": "While one cannot definitively determine the extent of the man's cooking skills or familiarity with the kitchen based solely on the image, some safe inferences can be made. The fact that he is actively engaged in the cooking process, stirring a pot on an electric stove, implies that he possesses at least a basic level of cooking proficiency and is acquainted with using stovetop appliances. Furthermore, his presence in the small kitchen indicates that he is comfortable navigating and preparing food within limited spaces, which may also suggest some level of experience and familiarity with cooking in confined environments."}]}, {"id": "000000094179", "image": "coco/train2017/000000094179.jpg", "conversations": [{"from": "human", "value": "What are the two men wearing while sitting on the bench?\n<image>"}, {"from": "gpt", "value": "The two men are wearing white shirts and ties while sitting on the bench."}, {"from": "human", "value": "What are the two men doing with a laptop?"}, {"from": "gpt", "value": "The two men are sitting on a bench and looking at a laptop, possibly working, studying, or discussing something relevant to the content displayed on the computer screen."}, {"from": "human", "value": "Are the two men dressed identically?"}, {"from": "gpt", "value": "Yes, the two men are dressed identically with white shirts and ties."}, {"from": "human", "value": "Where are the two men located while using the laptop?"}, {"from": "gpt", "value": "The two men are located outdoors, sitting on a park bench while using the laptop."}, {"from": "human", "value": "Is there any indication of the men's professional background or occupation based on their attire and activity?"}, {"from": "gpt", "value": "Based on their attire (white shirts and ties) and the fact that they are using a laptop, it can be inferred that the two men might be professionals, such as office workers or businessmen. However, it is not possible to determine their exact occupation or professional background solely from the image."}]}, {"id": "000000083079", "image": "coco/train2017/000000083079.jpg", "conversations": [{"from": "human", "value": "What color is the bus in the image?\n<image>"}, {"from": "gpt", "value": "The bus in the image is green."}, {"from": "human", "value": "What is the bus doing in the image?"}, {"from": "gpt", "value": "The bus is stopped at a corner near a large building."}, {"from": "human", "value": "Describe the large building in the background."}, {"from": "gpt", "value": "The large building in the background is a fancy and impressive structure, which appears to be either a castle or a large church. The specific details of the architecture and design are not provided, but it can be inferred that the building is a notable landmark in the area."}, {"from": "human", "value": "What is near the bus besides the large building?"}, {"from": "gpt", "value": "A stop sign is also near the bus, specifically at the backside of the sign."}, {"from": "human", "value": "Is the bus in a city or a rural area?"}, {"from": "gpt", "value": "The bus can be described as a big city bus, so it is likely in an urban setting. This is further supported by the presence of a large, fancy building and a stop sign nearby."}]}, {"id": "000000043383", "image": "coco/train2017/000000043383.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many sheep are present in the image?"}, {"from": "gpt", "value": "As the image shows a herd or group of sheep, it is difficult to give an exact number, but there are multiple sheep present in the grassy field."}, {"from": "human", "value": "What is the overall landscape in the image?"}, {"from": "gpt", "value": "The landscape in the image consists of a lush, green hillside or a large field of grass where the sheep are grazing."}, {"from": "human", "value": "What are the sheep doing in the image?"}, {"from": "gpt", "value": "The sheep are grazing on the green grass in the field, likely feeding on it as a source of nourishment."}, {"from": "human", "value": "What type of environment is the field or hillside in which the sheep are grazing?"}, {"from": "gpt", "value": "Based on the image, the environment can be described as a rural, natural setting with lush green vegetation, which serves as an ideal grazing area for the sheep. The presence of a green hillside or field suggests that the area might be part of a pastoral landscape, which is typically used for farming or raising livestock, such as sheep."}]}, {"id": "000000362067", "image": "coco/train2017/000000362067.jpg", "conversations": [{"from": "human", "value": "What type of vehicle is depicted in the image?\n<image>"}, {"from": "gpt", "value": "The image shows a large bus, specifically a Gibson Guitar bus, parked in a parking lot."}, {"from": "human", "value": "What kind of decor or design is featured on the side of the bus?"}, {"from": "gpt", "value": "There is a guitar design on the side of the Gibson Guitar bus."}, {"from": "human", "value": "What is the surrounding area like where the bus is parked?"}, {"from": "gpt", "value": "The bus is parked in a paved parking lot, and there are a lot of trees surrounding the area."}, {"from": "human", "value": "What is the purpose of the Gibson Guitar bus?"}, {"from": "gpt", "value": "While the exact purpose of the Gibson Guitar bus cannot be determined just by looking at the image, it can be inferred that it serves as a promotional or touring vehicle for Gibson guitars. Given the brand's prominence in the music industry, it could be transporting instruments, equipment, or artists to and from events, concerts, or music festivals. Additionally, the bus might also serve as a mobile advertisement or a means for Gibson to interact with fans and customers.\n\nGibson is a well-known American musical instrument manufacturer, particularly famous for its iconic guitars. Founded in 1902, the company has established itself as one of the leading brands in the music industry, offering a wide range of electric and acoustic guitars, as well as other stringed instruments like mandolins and banjos.\n\nThroughout the years, some of the most celebrated musicians and artists have used Gibson guitars, solidifying the brand's iconic status. Consequently, the Gibson Guitar bus could be employed in various settings, showcasing the latest product releases or promoting upcoming events while also serving as a music and entertainment hub for fans and enthusiasts of the brand."}]}, {"id": "000000393924", "image": "coco/train2017/000000393924.jpg", "conversations": [{"from": "human", "value": "What are the man and woman doing in the image?\n<image>"}, {"from": "gpt", "value": "The man and woman in the image are posing for a picture while hugging each other."}, {"from": "human", "value": "What are the man and woman wearing in the image?"}, {"from": "gpt", "value": "The woman is wearing a pink dress, and the man is wearing a suit with a purple tie."}, {"from": "human", "value": "What type of event are the man and woman attending?"}, {"from": "gpt", "value": "The man and woman are attending a wedding, as suggested by their attire and the context of posing for a picture."}, {"from": "human", "value": "What are some possible scenarios or relationships between the man and woman in the picture?"}, {"from": "gpt", "value": "There are several possible scenarios or relationships between the man and woman in the picture. Some possibilities include:\n\n1. They could be the bride and groom, dressed up for their own wedding and posing for pictures to capture their special day.\n2. They might be attendees at the wedding, such as close friends or family members of the bride and groom, who are dressed up to celebrate the occasion and want to capture some beautiful memories.\n3. The man and woman might be part of the wedding party, like the best man and bridesmaid, who traditionally pose together for photographs at a wedding.\n4. They could be a couple attending the wedding, celebrating the love and commitment of the bride and groom while also enjoying each other's company.\n\nWithout more context, it's difficult to know the exact relationship between the man and woman. However, given their attire, affectionate pose, and the wedding event setting, it's clear that they share a close bond and are enjoying themselves at the celebration."}]}, {"id": "000000405959", "image": "coco/train2017/000000405959.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of sign is the teddy bear sitting on?"}, {"from": "gpt", "value": "The teddy bear is sitting on top of a sandwich board, which is an outdoor menu sign typically used by cafes or restaurants to display their offerings to passing pedestrians."}, {"from": "human", "value": "What is the color of the teddy bear?"}, {"from": "gpt", "value": "The color of the teddy bear is brown."}, {"from": "human", "value": "What is the purpose of the teddy bear sitting on the menu sign?"}, {"from": "gpt", "value": "The purpose of the teddy bear sitting on the menu sign is likely to attract the attention of passersby and create a welcoming atmosphere for the cafe or restaurant that the sign belongs to. It serves as a playful, eye-catching element that can make the establishment stand out from its surroundings or competitors and encourage people to stop and explore the menu offerings or take a seat at the outdoor seating area."}, {"from": "human", "value": "Can you elaborate on the use of sandwich boards for businesses like cafes and restaurants?"}, {"from": "gpt", "value": "Sandwich boards, also known as A-frame signs, are a popular form of outdoor signage used by businesses like cafes, restaurants, and shops to advertise their products, services, or promotions to potential customers passing by. They are typically made of durable materials, such as wood, metal, or plastic, and can be placed on the sidewalk or other high-traffic areas outside the establishment to draw attention.\n\nThe use of sandwich boards offers several benefits for businesses:\n\n1. Visibility: A well-designed, strategically placed sandwich board helps to enhance the visibility of the business by capturing the attention of pedestrians and increasing brand awareness. It also helps to differentiate the establishment from competitors and encourages people to explore what the business has to offer.\n\n2. Flexibility: Sandwich boards can be easily updated with new menu items, promotions, or event announcements, allowing businesses to keep their messaging fresh and relevant. They can also be moved or stored effortlessly, making them a convenient and adaptable form of signage.\n\n3. Cost-effective advertising: Compared to other forms of advertising, sandwich boards are relatively inexpensive and offer a good return on investment. They can be used to promote a business on an ongoing basis or tailored to specific events or promotions, providing businesses with a versatile and affordable advertising solution.\n\nIn conclusion, sandwich boards, like the one with the brown teddy bear sitting on top in the image, are an effective and adaptable form of outdoor signage that can help businesses like cafes and restaurants attract customers, increase brand awareness, and promote their offerings in an appealing and cost-efficient manner."}]}, {"id": "000000545538", "image": "coco/train2017/000000545538.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat are the people in the image doing?"}, {"from": "gpt", "value": "The people in the image are standing together, watching a group of elephants in the area."}, {"from": "human", "value": "How many elephants are in the image?"}, {"from": "gpt", "value": "There are a couple of elephants in the image."}, {"from": "human", "value": "Are the people and elephants in a natural or urban environment?"}, {"from": "gpt", "value": "The people and elephants are in a park, which suggests a more natural environment."}, {"from": "human", "value": "Could you elaborate on the importance of such parks or wildlife reserves for elephants and people?"}, {"from": "gpt", "value": "Parks or wildlife reserves that house elephants and other species play a crucial role in conservation, education, and fostering a greater appreciation for the natural world among people. \n\nFor elephants, parks and wildlife reserves provide a protected habitat where they can thrive without the threats that they often face in the wild, such as poaching, habitat loss, and human-animal conflicts. These reserves help ensure the long-term survival of these magnificent creatures by providing them with ample space, food, and water resources, as well as opportunities to socialize with other elephants, which is essential to their well-being. The efforts of park rangers and conservation teams contribute significantly to the monitoring, tracking, and protection of these animals within the reserve's boundaries.\n\nFor people, parks and wildlife reserves serve as valuable educational and recreational resources. Observing wild animals like elephants up close allows individuals to learn more about the animals' behaviors, social structures, and the importance of their role in the ecosystem. This knowledge not only helps engender a sense of appreciation and empathy for these animals but also raises awareness about the broader issues of conservation and habitat preservation. \n\nMoreover, these parks and reserves also offer socio-economic benefits in the form of ecotourism, which can contribute to local economies by generating income and providing employment opportunities for nearby communities. This, in turn, encourages the sustainable use of natural resources and positively impacts the way local communities interact with their environment.\n\nIn conclusion, parks and wildlife reserves that protect elephants and other species are indispensable for the animals' long-term survival and well-being. At the same time, they also serve as important educational, recreational, and socio-economic resources for people, fostering a deep appreciation for the natural world and promoting sustainable practices in the communities that coexist with these magnificent animals."}]}, {"id": "000000034261", "image": "coco/train2017/000000034261.jpg", "conversations": [{"from": "human", "value": "What is the main subject of the image?\n<image>"}, {"from": "gpt", "value": "The main subject of the image is a giraffe standing outside a brick building."}, {"from": "human", "value": "Is it a real giraffe or a statue of a giraffe?"}, {"from": "gpt", "value": "The image does not provide enough information to definitively determine whether the giraffe is real or a statue. However, giraffes are not commonly found in urban environments near brick buildings, so it is more likely to be a statue of a giraffe."}, {"from": "human", "value": "What type of door is near the giraffe?"}, {"from": "gpt", "value": "There is a round, metal door near the giraffe in front of the brick building."}, {"from": "human", "value": "Can you describe the brick wall that the giraffe is standing next to?"}, {"from": "gpt", "value": "The brick wall, which is part of the brick building, features a distinct reddish color and displays a traditional, rectangular brick pattern. The wall serves as a backdrop for the giraffe, highlighting its presence and contrasting with its natural appearance. The juxtaposition of the giraffe alongside the brick wall creates an interesting visual composition that draws attention to the uniqueness of the scene."}, {"from": "human", "value": "What kind of setting does this image depict?"}, {"from": "gpt", "value": "The image depicts an urban setting, as evidenced by the presence of a brick building and round metal door. It possibly represents a city street, courtyard, or plaza scene where the giraffe, likely a statue, serves as an eye-catching focal point or an artistic installation. The combination of the urban environment with the unexpected presence of a giraffe\u2014whether real or a statue\u2014creates a striking and interesting visual experience for viewers, inviting them to ponder the relationship between nature and the built environment."}]}, {"id": "000000350810", "image": "coco/train2017/000000350810.jpg", "conversations": [{"from": "human", "value": "What is the cat doing in the image?\n<image>"}, {"from": "gpt", "value": "The cat is laying down and sleeping on top of a computer keyboard near a monitor."}, {"from": "human", "value": "What kind of keyboard is the cat sleeping on?"}, {"from": "gpt", "value": "The cat is sleeping on a white computer keyboard."}, {"from": "human", "value": "What color is the cat, and does it have a collar?"}, {"from": "gpt", "value": "The cat is a brown tabby with a blue collar."}, {"from": "human", "value": "What is the cat's position relative to the keyboard and monitor?"}, {"from": "gpt", "value": "The cat is curled up sleeping on the keyboard, which is close to the monitor. The cat is positioned against the keyboard, making it difficult to use without disturbing the sleeping cat."}]}, {"id": "000000476188", "image": "coco/train2017/000000476188.jpg", "conversations": [{"from": "human", "value": "What is the person in the image doing, in relation to the oven?\n<image>"}, {"from": "gpt", "value": "The person in the image, a woman, is checking on her food in the oven. She is either bending over and looking at the food, or stirring something in the oven."}, {"from": "human", "value": "What type of clothing is the woman wearing?"}, {"from": "gpt", "value": "The woman is wearing a striped sweater."}, {"from": "human", "value": "Does the image depict any specific cooking action, such as poking or stirring?"}, {"from": "gpt", "value": "Yes, the image shows that the woman is engaged in a specific cooking action. She is either stirring something in the oven or looking closely at the food while it cooks."}, {"from": "human", "value": "What can you infer about the woman's cooking expertise or experience from the image?"}, {"from": "gpt", "value": "Although it is difficult to definitively determine the woman's cooking expertise or experience from the image alone, we can make a few assumptions based on her actions. The fact that she is carefully checking on her food in the oven suggests that she is attentive and diligent in her cooking efforts, which may indicate a level of experience or at least a serious interest in ensuring that her dish comes out well.\n\nThe act of stirring something in the oven also shows that she is actively engaged in the cooking process and possibly familiar with the necessary steps involved in preparing her dish. While we cannot conclude that she is an expert chef, her actions do seem to portray a level of competence and familiarity with the cooking process.\n\nIn summary, the image of the woman in the striped sweater checking her food in the oven and stirring it suggests that she is attentive and experienced to a certain extent when it comes to cooking. While her exact level of expertise cannot be firmly established without further information, her actions certainly imply a level of skill and understanding of the culinary process."}]}, {"id": "000000481209", "image": "coco/train2017/000000481209.jpg", "conversations": [{"from": "human", "value": "What color is the fire hydrant in the image?\n<image>"}, {"from": "gpt", "value": "The fire hydrant in the image is black and silver in color, with a silver top."}, {"from": "human", "value": "Where is the fire hydrant located in the image?"}, {"from": "gpt", "value": "The fire hydrant is located on the side of a street in a city."}, {"from": "human", "value": "Are there any vehicles on the street in the image?"}, {"from": "gpt", "value": "Yes, there are cars both parked along the street and driving down it."}, {"from": "human", "value": "Describe the overall scene of the image."}, {"from": "gpt", "value": "The image depicts a typical city street scene, with a black and silver fire hydrant positioned on the side of the street. There are cars parked along the street, as well as vehicles driving down the road. The presence of the fire hydrant indicates that the city takes safety measures to provide fire protection for its residents, while the cars signal an active and bustling urban environment. The picture provides a glimpse into everyday life in a metropolitan area, with its mix of static elements, like the fire hydrant and parked cars, and dynamic elements, such as the vehicles moving down the street."}]}, {"id": "000000543201", "image": "coco/train2017/000000543201.jpg", "conversations": [{"from": "human", "value": "What color is the girl's hair in the image?\n<image>"}, {"from": "gpt", "value": "The girl's hair in the image is red."}, {"from": "human", "value": "What is the girl holding?"}, {"from": "gpt", "value": "The girl is holding an umbrella."}, {"from": "human", "value": "What color is the umbrella the girl is holding?"}, {"from": "gpt", "value": "The umbrella the girl is holding is green according to one sentence, and yellow according to the other sentence. Based on what I can see in the image, I cannot definitively confirm the color of the umbrella as it seems ambiguous."}, {"from": "human", "value": "Where is the girl standing?"}, {"from": "gpt", "value": "The girl is standing on a porch or patio."}, {"from": "human", "value": "Are there any flowers in the image? If so, where are they located?"}, {"from": "gpt", "value": "Yes, there are flowers in the image. They are located in pots next to the little girl, who is standing on a porch with the umbrella."}]}, {"id": "000000502894", "image": "coco/train2017/000000502894.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the person in the image walking or riding a bike?"}, {"from": "gpt", "value": "The person in the image is walking next to a bike, not riding it."}, {"from": "human", "value": "Is there a dog accompanying the person in the image?"}, {"from": "gpt", "value": "Yes, there is a dog accompanying the person in the image, and it is on a leash."}, {"from": "human", "value": "What is the gender of the person in the image?"}, {"from": "gpt", "value": "The person in the image is a woman."}, {"from": "human", "value": "Is the bicycle equipped with a basket?"}, {"from": "gpt", "value": "Yes, the bicycle has a basket."}, {"from": "human", "value": "What is the main activity shown in the image?"}, {"from": "gpt", "value": "The main activity shown in the image is the woman walking beside a bicycle while also walking her dog on a leash. This might suggest that she has taken a break from riding her bike to walk her dog, or perhaps she prefers to walk alongside her bike for a more relaxed and leisurely experience. It could also indicate that the area might not be suitable for riding at the moment, or she might need to navigate a crowded or challenging path. Overall, the image portrays a casual, everyday scene of a woman spending time outdoors with her dog and her bicycle."}]}, {"id": "000000056065", "image": "coco/train2017/000000056065.jpg", "conversations": [{"from": "human", "value": "What airline does the airplane belong to?\n<image>"}, {"from": "gpt", "value": "The airplane in the image belongs to Air Canada."}, {"from": "human", "value": "What is the weather like in the image?"}, {"from": "gpt", "value": "The weather in the image is cloudy."}, {"from": "human", "value": "Where is the airplane located?"}, {"from": "gpt", "value": "The airplane is located at the airport, sitting on the tarmac or runway."}, {"from": "human", "value": "Is there any vehicle present around the airplane?"}, {"from": "gpt", "value": "Yes, there is a truck sitting on the runway near the airplane."}, {"from": "human", "value": "What might be happening at the airport with the airplane and truck?"}, {"from": "gpt", "value": "Based on the image, it appears that the Air Canada airplane and the truck sitting on the runway are part of the airport's ground operations. The airplane might be getting ready for takeoff or has recently landed, and the truck is likely supporting the aircraft's pre-flight or post-flight processes. \n\nGround operations at airports involve various tasks and activities that ensure the smooth functioning of airline services, such as refueling, baggage handling, de-icing, and cabin cleaning. The truck seen in the image could be responsible for one or several of these tasks, assisting in the orderly and efficient boarding, disembarking, and preparation of the airplane for its next flight. \n\nDuring these ground operations, airport personnel work in coordination with pilots, flight attendants, and air traffic controllers to ensure that all aspects of the flight process, from arrival to departure, are handled safely and efficiently. Proper communication and adherence to guidelines and procedures are crucial during these ground activities to minimize any potential risks or delays.\n\nIn summary, the presence of an Air Canada airplane and a truck sitting on the runway at an airport on a cloudy day suggests that the aircraft is either preparing for takeoff or has recently landed, and the truck is involved in the various ground operations necessary to support the airplane's pre-flight or post-flight processes."}]}, {"id": "000000246160", "image": "coco/train2017/000000246160.jpg", "conversations": [{"from": "human", "value": "How many layers does the dessert have in the image?\n<image>"}, {"from": "gpt", "value": "The dessert in the image has three layers."}, {"from": "human", "value": "What type of dessert is shown in the image?"}, {"from": "gpt", "value": "The image shows a dessert tart or a small pastry with three layers, garnished with a raspberry on top."}, {"from": "human", "value": "What is the main color of the dessert?"}, {"from": "gpt", "value": "The main color of the dessert is pink."}, {"from": "human", "value": "Are there other desserts present in the image?"}, {"from": "gpt", "value": "Yes, there are other desserts visible around the three-layer pastry in the image."}, {"from": "human", "value": "What is the garnish on top of the dessert?"}, {"from": "gpt", "value": "The garnish on top of the dessert is a raspberry."}]}, {"id": "000000567803", "image": "coco/train2017/000000567803.jpg", "conversations": [{"from": "human", "value": "What type of plant is visible in the image?\n<image>"}, {"from": "gpt", "value": "In the image, a broccoli plant is visible."}, {"from": "human", "value": "What does the broccoli plant look like in detail?"}, {"from": "gpt", "value": "The broccoli plant has a small head surrounded by several large green leaves. The image provides a close-up view of the broccoli and the leaves around it, showcasing the details of the plant's growth on the stem."}, {"from": "human", "value": "How is the broccoli plant growing?"}, {"from": "gpt", "value": "The broccoli plant is growing on a stem, with the clump of fresh broccoli emerging from it. The plant shows a healthy growth pattern with lots of green leaves surrounding the small broccoli head for support and energy production."}, {"from": "human", "value": "What are some ways to cook or prepare broccoli?"}, {"from": "gpt", "value": "Broccoli is a versatile and nutritious vegetable that can be cooked and prepared in various ways to create tasty and healthy dishes. Some popular methods to cook or prepare broccoli include:\n\n1. Steaming: Steaming broccoli is a gentle way to cook it without losing much of its nutrients. You can use a steamer basket to hold the broccoli florets over boiling water for a few minutes until it becomes tender but still firm.\n\n2. Boiling: Although not the most preferred method since it can lead to nutrient loss, boiling is a fast way to cook broccoli. Just be careful not to overcook it, as it can become mushy and lose its bright green color.\n\n3. Stir-frying: An excellent way to cook broccoli quickly while retaining its nutrients, stir-frying involves tossing the florets with a small amount of oil in a heated wok or frying pan over high heat.\n\n4. Roasting: Roasting broccoli in an oven creates a delicious caramelized flavor and crisp texture. Toss the florets with olive oil, salt, and pepper, then spread them evenly on a baking sheet and bake at a high temperature until they become tender and slightly charred.\n\n5. Grilling: Grilled broccoli brings out a smoky and charred flavor. Simply skewer the florets or use a grilling basket, brush with some oil or marinade, and cook on a grill over medium heat.\n\n6. Eating raw: Broccoli can also be enjoyed raw, eaten alone or as part of a salad. To make it more palatable, you can cut it into smaller florets and mix it with other ingredients, such as fruits or nuts, and add salad dressing.\n\nThese methods offer a variety of flavors and textures, making broccoli an enjoyable and healthy addition to your meals."}]}, {"id": "000000189912", "image": "coco/train2017/000000189912.jpg", "conversations": [{"from": "human", "value": "<image>\nWhere are the people and their luggage in the image?"}, {"from": "gpt", "value": "The people are in an airport, standing around a luggage carousel, waiting for their bags and suitcases to arrive on the conveyor belt."}, {"from": "human", "value": "How many people are in the group?"}, {"from": "gpt", "value": "As an AI, I am unable to accurately count the number of people in a group without an exact number given. However, I can confirm that there is a group of people in the image."}, {"from": "human", "value": "What are the people doing in the airport?"}, {"from": "gpt", "value": "The people are waiting and milling around the luggage carousel to collect their luggage as it arrives on the conveyor belt."}, {"from": "human", "value": "What is a luggage carousel and why is it important in an airport?"}, {"from": "gpt", "value": "A luggage carousel, also known as a baggage carousel or baggage reclaim area, is a rotating conveyor system that is used in airports to deliver checked-in baggage to passengers upon arrival at their destination. It plays a crucial role in facilitating the smooth flow of people and luggage in an airport, ensuring passengers can retrieve their belongings efficiently after a flight.\n\nThe importance of a luggage carousel in an airport can be attributed to several factors:\n\n1. Organization and Efficiency: Luggage carousels enable airports to systematically unload baggage from the aircraft, sort it by flight and route it to the designated carousel for collection by passengers. This optimizes the baggage handling process, allowing passengers to quickly locate and retrieve their luggage.\n\n2. Time Management: As passengers wait for their baggage, they stay in the baggage claim area, preventing overcrowding at the airport's exit points or in other areas of the terminal. Once their luggage is retrieved, they can then proceed to clear customs and exit the airport without causing congestion and delays.\n\n3. Security: Luggage carousels help maintain security within the airport by ensuring that only authorized passengers have access to their luggage. Most airports require passengers to go through a security checkpoint to enter the baggage claim area, reducing the risk of theft or tampering with belongings by unauthorized individuals.\n\n4. Passenger Satisfaction: Being able to quickly and easily retrieve luggage contributes to a positive travel experience for passengers. Efficient baggage handling and the presence of a luggage carousel contribute to minimizing delays and inconvenience, which helps maintain passenger satisfaction.\n\nIn summary, luggage carousels serve a crucial role in airport operations, providing a convenient and efficient means for passengers to retrieve their checked-in baggage, ensuring proper organization and security, and aiding in maintaining passenger satisfaction."}]}, {"id": "000000458505", "image": "coco/train2017/000000458505.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many motorcycles are visible in the image?"}, {"from": "gpt", "value": "There are two motorcycles visible in the image."}, {"from": "human", "value": "What are the colors of the motorcycles in the image?"}, {"from": "gpt", "value": "One motorcycle is black and silver, while the other motorcycle is also black."}, {"from": "human", "value": "What additional feature does one of the motorcycles have?"}, {"from": "gpt", "value": "One of the motorcycles has a black bag attached to it."}, {"from": "human", "value": "Where are the motorcycles parked?"}, {"from": "gpt", "value": "The motorcycles are parked on the asphalt road or pavement, near some bushes, trees, and shrubs, in a shaded section of a parking lot."}, {"from": "human", "value": "What type of exhaust system does one of the motorcycles have?"}, {"from": "gpt", "value": "One of the motorcycles has a dual exhaust engine system."}]}, {"id": "000000561590", "image": "coco/train2017/000000561590.jpg", "conversations": [{"from": "human", "value": "What color is the horse's harness?\n<image>"}, {"from": "gpt", "value": "The horse's harness is pink and black."}, {"from": "human", "value": "What is the horse doing in the image?"}, {"from": "gpt", "value": "The horse is being led by a trainer or handler, probably during an event or being walked down the street in front of onlookers."}, {"from": "human", "value": "What type of setting is the horse in?"}, {"from": "gpt", "value": "The horse is standing in front of a business with a short white fence, indicating an urban or semi-urban setting where people are present."}, {"from": "human", "value": "Are there any observers nearby?"}, {"from": "gpt", "value": "Yes, there are onlookers or observers nearby, who are likely watching the horse being led by the trainer or handler."}, {"from": "human", "value": "Can you describe the horse in more detail?"}, {"from": "gpt", "value": "The horse is brown and is wearing a pink and black harness on its head. It is likely a well-groomed and cared-for animal, as the colorful harness suggests that it may be used for events or special occasions. The horse appears to be obedient, following the trainer's guidance while being led by the jaw, which indicates proper training and handling. The onlookers' presence also suggests the horse is accustomed to being around people, making it a suitable and safe animal for public appearances and events in populated areas."}]}, {"id": "000000521437", "image": "coco/train2017/000000521437.jpg", "conversations": [{"from": "human", "value": "What object is the woman holding while playing the video game?\n<image>"}, {"from": "gpt", "value": "The woman is holding a Wii remote as she plays the video game."}, {"from": "human", "value": "Is the woman wearing any notable accessories while playing the video game?"}, {"from": "gpt", "value": "Yes, the woman is wearing sunglasses or shades while playing the video game."}, {"from": "human", "value": "Is the woman alone, or is there someone else in the image with her?"}, {"from": "gpt", "value": "There is a man next to the woman in the image, watching her play the video game."}, {"from": "human", "value": "What is the woman wearing on her upper body?"}, {"from": "gpt", "value": "The woman is wearing a black top on her upper body."}, {"from": "human", "value": "What can you tell about the situation based on the presence of sunglasses on the woman and the man watching her play?"}, {"from": "gpt", "value": "The situation seems to be a casual and fun gaming atmosphere. The woman wearing sunglasses while playing the video game indicates that she might be trying to create a playful or cool vibe. It also suggests that the players are not engaged in a competitive, high-stakes environment but are instead enjoying a more relaxed and entertaining gaming experience. The presence of the man watching her play further supports the idea that they are likely friends or acquaintances spending time together and bonding over the shared activity."}]}, {"id": "000000374520", "image": "coco/train2017/000000374520.jpg", "conversations": [{"from": "human", "value": "What airline does the airplane in the image belong to?\n<image>"}, {"from": "gpt", "value": "The airplane in the image belongs to Austrian Airlines."}, {"from": "human", "value": "What are the main colors of the airplane?"}, {"from": "gpt", "value": "The main colors of the airplane are red and white."}, {"from": "human", "value": "Is the airplane on a runway or a field?"}, {"from": "gpt", "value": "The airplane is on a runway, specifically on the tarmac of an airport."}, {"from": "human", "value": "What type of aircraft is shown in the image?"}, {"from": "gpt", "value": "The image shows a large jumbo jet plane belonging to Austrian Airlines."}, {"from": "human", "value": "What kind of activities might be happening at the airport related to the airplane?"}, {"from": "gpt", "value": "There could be various activities happening at the airport related to the Austrian Airlines airplane. Some possibilities include:\n\n1. Preparing for departure: The airplane could be undergoing pre-flight checks, refueling, and having its cargo and luggage loaded before its next flight. The crew might be boarding and conducting safety checks, while passengers are waiting at the gate to board the plane.\n\n2. Arriving from a flight: The airplane may have recently landed, and passengers could be disembarking from the aircraft. Baggage handlers would be unloading luggage and cargo, while the ground crew inspects the airplane for any issues that may have occurred during the flight.\n\n3. Maintenance and cleaning: The airplane might be going through routine maintenance or required repairs to ensure its safety and performance. Cleaning crews could be tidying up the aircraft's interior and exterior, preparing it for the next group of passengers.\n\n4. Waiting for the next assignment: The airplane could be parked on the tarmac, waiting for its next flight assignment or for a gate to become available.\n\n5. Taxiing: The airplane might be taxiing to or from the runway, either preparing for takeoff or returning to the gate after landing.\n\nThese activities are typical of what happens at an airport, ensuring that the airplane is safe, functional, and prepared for its upcoming flight or for resting between flights."}]}, {"id": "000000003008", "image": "coco/train2017/000000003008.jpg", "conversations": [{"from": "human", "value": "What is the woman doing while sitting at her desk?\n<image>"}, {"from": "gpt", "value": "The woman is clapping her hands while sitting at her desk."}, {"from": "human", "value": "Are there any objects on the desk?"}, {"from": "gpt", "value": "Yes, there are many books on the desk."}, {"from": "human", "value": "Does the image feature a girl or a woman at the desk?"}, {"from": "gpt", "value": "The image features a woman sitting at the desk."}, {"from": "human", "value": "What might be the reason for the woman clapping her hands at her desk?"}, {"from": "gpt", "value": "While I cannot definitively determine the specific reason for the woman clapping her hands at her desk from the image alone, there could be several possible reasons. For instance, she might be celebrating a recent achievement, providing applause during a virtual meeting or online presentation, or engaging in energizing hand-clapping exercises to increase blood circulation and maintain focus during a break from her work or studies. The presence of many books on her desk indicates that the woman might be in a work or study environment, making these scenarios plausible."}]}, {"id": "000000025421", "image": "coco/train2017/000000025421.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the cat doing on the TV stand?"}, {"from": "gpt", "value": "The cat is standing on its hind legs and pawing at the large flat screen TV, which is displaying an image of another cat."}, {"from": "human", "value": "Is the cat touching the TV screen with its paws?"}, {"from": "gpt", "value": "Yes, the cat is touching the TV screen with its paws, as if it is trying to interact with the cat displayed on the screen."}, {"from": "human", "value": "What is the cat's posture while interacting with the TV screen?"}, {"from": "gpt", "value": "The cat's posture is unusual for a cat, as it is standing on its hind legs and extending its front paws towards the screen, as if trying to reach the cat shown on the TV."}, {"from": "human", "value": "What could be a possible explanation for the cat's behavior towards the TV screen?"}, {"from": "gpt", "value": "A possible explanation for the cat's behavior towards the TV screen is that it is intrigued or curious about the cat displayed on the screen. The cat might not understand the concept of a screen or that the image is not an actual cat but is instead just a representation. This confusion might lead the cat to attempt to interact with, touch, or even play with the cat on the screen. This type of behavior is not uncommon among cats and other animals, as they may react to moving images or scenes on screens, particularly when the content is of interest or resembles something familiar to them, such as another cat or prey animals."}]}, {"id": "000000272899", "image": "coco/train2017/000000272899.jpg", "conversations": [{"from": "human", "value": "Is the little boy sitting alone or with any other creatures?\n<image>"}, {"from": "gpt", "value": "The little boy is not sitting alone; he is sitting near two birds."}, {"from": "human", "value": "What is the boy sitting on?"}, {"from": "gpt", "value": "The little boy is sitting on a rock."}, {"from": "human", "value": "How many birds are present in the image with the little boy?"}, {"from": "gpt", "value": "There are two birds in the image with the little boy."}, {"from": "human", "value": "What could be the possible relationship or interaction between the boy and the birds?"}, {"from": "gpt", "value": "As the little boy is sitting near the two birds, it is possible that he is observing, admiring, or simply enjoying their company. The scenario suggests that the boy is connecting with nature, and the peaceful presence of the birds could provide a sense of companionship or curiosity for the child. \n\nThis moment captures the beauty of a shared experience between the boy and the birds, as they are in close proximity, allowing for an interesting and potentially educational interaction. The boy may have a keen interest in birds or wildlife, or he could simply appreciate the serenity provided by their presence. Being in such close contact with the natural world can have a profound impact on a child's development, fostering a sense of wonder, appreciation, and respect for the environment and the creatures that inhabit it.\n\nThe birds, on the other hand, may view the boy as an opportunity to obtain food, a familiar presence if they are used to people around their location, or just a harmless coexisting being. Overall, this scene conveys a sense of harmony and connection between the young boy and the birds, creating a unique and memorable experience for both parties involved."}]}, {"id": "000000273119", "image": "coco/train2017/000000273119.jpg", "conversations": [{"from": "human", "value": "How many people are there in the image?\n<image>"}, {"from": "gpt", "value": "There are a couple of people in the image, i.e., two people."}, {"from": "human", "value": "What kind of boat is visible in the image?"}, {"from": "gpt", "value": "The boat visible in the image is a canoe."}, {"from": "human", "value": "What are the people doing in the water?"}, {"from": "gpt", "value": "The two people are swimming, wading, or walking in the water next to the canoe, holding onto it."}, {"from": "human", "value": "Is there anyone inside the boat or is it empty?"}, {"from": "gpt", "value": "The boat in the image is empty, with no one inside it."}, {"from": "human", "value": "What kind of body of water are the people and boat in? A lake or a river?"}, {"from": "gpt", "value": "It is not possible to definitively determine whether the body of water is a lake or a river based solely on the image description. However, since the people are wading or walking in the water, it implies that the water might be shallow, which may suggest that they are in a river. Regardless, the exact type of water body cannot be confirmed with certainty."}]}, {"id": "000000292053", "image": "coco/train2017/000000292053.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat are the two people on the motorcycle wearing?"}, {"from": "gpt", "value": "The two people on the motorcycle are wearing bear costumes."}, {"from": "human", "value": "What is located in the side car of the motorcycle?"}, {"from": "gpt", "value": "There is a stuffed bear in the side car of the motorcycle."}, {"from": "human", "value": "What message is being displayed on the signs?"}, {"from": "gpt", "value": "The signs say, \"No to the bike parking tax.\""}, {"from": "human", "value": "Do the motorcyclists seem to be part of a larger group or event?"}, {"from": "gpt", "value": "Yes, the motorcyclists, including the couple in bear costumes, appear to be part of a larger group of people gathered on the street with motorbikes, suggesting that they are participating in an event or demonstration."}, {"from": "human", "value": "Is this gathering taking place in a rural or urban setting?"}, {"from": "gpt", "value": "The gathering is taking place in an urban setting, as evidenced by the city street filled with motorcycles and people."}]}, {"id": "000000116123", "image": "coco/train2017/000000116123.jpg", "conversations": [{"from": "human", "value": "What type of birds can be seen in the water?\n<image>"}, {"from": "gpt", "value": "Swans and ducks can be seen swimming in the water in the image. There may also be other small birds present."}, {"from": "human", "value": "Where are the birds located in the image?"}, {"from": "gpt", "value": "The birds are located in the water near a marina and dockside, likely in a waterway with access to boats and other watercraft."}, {"from": "human", "value": "Are the birds sitting or swimming in the water?"}, {"from": "gpt", "value": "The birds (swans and ducks) can be seen swimming in the water."}, {"from": "human", "value": "What is the significance of the birds' presence at the marina?"}, {"from": "gpt", "value": "The presence of birds, such as swans and ducks, at the marina indicates a healthy ecosystem in the area. It is common for birds to congregate near water bodies, as they provide a source of food, a suitable habitat, and a place to rest during migration periods.\n\nBirds' presence can also have other implications. For boaters, bird droppings can be a nuisance and can potentially damage boat surfaces if not cleaned regularly. Additionally, the presence of birds can be an aesthetically pleasing feature for visitors to the marina, as people generally appreciate the beauty and tranquility that these creatures bring to the environment. \n\nFurthermore, bird-watching can be a popular recreational activity for visitors and locals alike. Observing various bird species and their behaviors can be both a relaxing and educational experience for people of all ages.\n\nIn summary, the presence of swans and ducks swimming in the water near the marina demonstrates the area's ecological importance, provides opportunities for recreational and educational activities, and enhances the overall ambiance of the marina."}]}, {"id": "000000215242", "image": "coco/train2017/000000215242.jpg", "conversations": [{"from": "human", "value": "<image>\nWhere is the toilet located in the bathroom?"}, {"from": "gpt", "value": "The toilet is located under a window in the bathroom."}, {"from": "human", "value": "Can you see a view of the city from the bathroom window?"}, {"from": "gpt", "value": "Yes, you can see a view of the city when looking out of the bathroom window."}, {"from": "human", "value": "Is the window in the bathroom open or closed?"}, {"from": "gpt", "value": "The window in the bathroom is wide open."}, {"from": "human", "value": "Why might someone consider the toilet's location strange?"}, {"from": "gpt", "value": "The toilet's location might be considered strange because it is situated directly under a window, which could potentially compromise privacy. Additionally, having a wide-open window in the bathroom might give direct exposure to the outside environment, which could lead to uncomfortable temperatures, as well as make the toilet user more conscious of their activities and surroundings. Some people might prefer a more enclosed, private space for their toilets, rather than one that showcases a view of the city through an open window."}]}, {"id": "000000443857", "image": "coco/train2017/000000443857.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the main color theme of the bedding?"}, {"from": "gpt", "value": "The main color theme of the bedding is blue, with a blue blanket, comforter, and pillow."}, {"from": "human", "value": "Can you describe the position of the lamp in relation to the bed?"}, {"from": "gpt", "value": "The lamp is situated next to the bed, providing light and enhancing the room's decor."}, {"from": "human", "value": "What can you tell me about the wall near the bed?"}, {"from": "gpt", "value": "The wall near the bed features a picture hanging in the middle, which adds a decorative touch to the room. The picture is of a bird, giving the space a nature-inspired feel and complementing the overall aesthetic."}, {"from": "human", "value": "What is the overall impression of the room based on the image?"}, {"from": "gpt", "value": "The image suggests that the room is well-maintained and cozy, with a neatly made bed and a coordinated color theme of brown and blue. The blue accents on the bedding, lamp, and wall decor create a harmonious and visually appealing environment, while the bird picture adds a unique and artistic touch. The attention to detail and thoughtfully arranged elements in the space indicate that the room is designed for comfort and relaxation, creating a welcoming atmosphere for its occupants."}]}, {"id": "000000304889", "image": "coco/train2017/000000304889.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the man holding in his hand?"}, {"from": "gpt", "value": "The man is holding a wine glass filled with a red liquid, likely wine or a similar bright-colored beverage."}, {"from": "human", "value": "What is the man wearing?"}, {"from": "gpt", "value": "The man is wearing a black hat and a black shirt."}, {"from": "human", "value": "What kind of expression is the man displaying?"}, {"from": "gpt", "value": "The man is making a shocked face, indicating that he might be surprised or reacting to something unexpected."}, {"from": "human", "value": "Based on the image alone, can we tell if the man is enjoying the wine or not?"}, {"from": "gpt", "value": "Based on the image alone, it is difficult to determine if the man is enjoying the wine or not. His shocked expression could be related to the taste of the wine, or it could be a reaction to something unrelated to the beverage. Without more context, we cannot confidently conclude whether or not he is enjoying the wine."}]}, {"id": "000000427283", "image": "coco/train2017/000000427283.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is the train in the image?"}, {"from": "gpt", "value": "The train in the image is purple."}, {"from": "human", "value": "What is the primary function of the location where the train is stopped?"}, {"from": "gpt", "value": "The primary function of the location where the train is stopped is to serve as a train station, where people can board and unboard passenger trains."}, {"from": "human", "value": "What type of train is pictured in the scene?"}, {"from": "gpt", "value": "The train pictured in the scene is a commuter (passenger) train."}, {"from": "human", "value": "What is the train doing at the train station platform?"}, {"from": "gpt", "value": "The train is stopped at the train station platform, allowing passengers to board and unboard the train."}, {"from": "human", "value": "What is the purpose of a commuter train, and how does it benefit the community?"}, {"from": "gpt", "value": "A commuter train, also known as a passenger train, is a mode of public transportation designed to transport passengers from one location to another, primarily along urban-suburban routes or across regions. Their primary purpose is to provide a reliable and efficient means for people to travel between their homes and workplaces, as well as to other important destinations such as schools, shopping centers, or recreational areas.\n\nCommuter trains offer several benefits to the communities they serve, including:\n\n1. Reduced traffic congestion: By providing a convenient alternative to driving, commuter trains can help reduce the number of vehicles on the roads, leading to less traffic congestion and shorter commute times.\n\n2. Improved air quality: Fewer cars on the roads also result in reduced emissions and improved air quality. Trains, especially those powered by electricity or low-emission fuels, typically produce fewer emissions per passenger compared to automobiles.\n\n3. Increased accessibility: Commuter trains can make it easier for people to access job opportunities, education, healthcare, and other essential services, especially in densely populated areas or those with limited road infrastructure.\n\n4. Cost savings: Commuter trains can offer a more affordable means of transportation compared to owning and maintaining a personal vehicle, particularly in areas with high costs of living or insufficient parking facilities.\n\n5. Increased productivity: By providing a comfortable and often faster means of transportation, commuter trains can enable passengers to spend time working, reading, or engaging in other productive activities during their daily commute, leading to a better work-life balance.\n\n6. Land use efficiency: Train stations and surrounding developments tend to encourage higher-density, mixed-use developments, promoting more efficient land use and reducing urban sprawl.\n\n7. Promote sustainable urban development: Commuter trains support the concept of sustainable urban development by encouraging public transportation use, reducing car dependency, and promoting land use efficiency.\n\nIn conclusion, commuter trains serve as a vital transportation option for many communities, providing numerous benefits, such as reduced traffic congestion, improved air quality, increased accessibility, cost savings, better productivity, efficient land use, and promoting sustainable urban development."}]}, {"id": "000000520321", "image": "coco/train2017/000000520321.jpg", "conversations": [{"from": "human", "value": "How many vases are visible in the image?\n<image>"}, {"from": "gpt", "value": "There are four beautiful Chinese vases visible in the image."}, {"from": "human", "value": "What do these vases appear to be lined up in front of?"}, {"from": "gpt", "value": "The vases are lined up in front of a beautiful temple or building."}, {"from": "human", "value": "Are there any plants or trees in the image? If yes, what type?"}, {"from": "gpt", "value": "Yes, there are bonsai trees and plants in the image. They are sitting outside and standing next to the vases."}, {"from": "human", "value": "Can you explain what bonsai trees are and their significance?"}, {"from": "gpt", "value": "Bonsai trees are miniature trees or shrubs grown in small containers or pots, which have their roots pruned and branches trimmed to maintain a compact, aesthetically pleasing appearance. The art of growing bonsai trees originated in China over a thousand years ago and later gained popularity in Japan. It has since become a widely-practiced horticultural art form across the globe.\n\nThe term \"bonsai\" is a combination of two Japanese words: \"bon,\" meaning tray, and \"sai,\" meaning plant. Bonsai is more than just a decorative plant; it is a living art that symbolizes the harmony between nature, growth, and change. Bonsai practitioners invest time and effort into nurturing and caring for their trees, shaping them through skilled pruning and wiring techniques to create the desired artistic effect.\n\nBonsai trees are valued for their unique beauty and their ability to evoke a sense of calm and connection to nature. They are often used as decorative elements in homes, offices, and public spaces. Many people also find the process of growing and caring for bonsai trees to be therapeutic and meditative, as it requires patience, dedication, and attention to detail. Additionally, bonsai trees can serve as symbols of cultural heritage, as different species and styles of bonsai may be associated with specific regions or traditions.\n\nIn the context of the image, the presence of bonsai trees alongside the large Chinese vases and the temple suggest a setting that appreciates and showcases traditional art, craftsmanship, and horticultural practices. The bonsai trees and vases together create a harmonious, visually appealing atmosphere, reflecting the cultural and artistic values associated with the art of bonsai and fine pottery."}]}, {"id": "000000331824", "image": "coco/train2017/000000331824.jpg", "conversations": [{"from": "human", "value": "Does the building have a clock on it?\n<image>"}, {"from": "gpt", "value": "Yes, the building has a clock on top of it."}, {"from": "human", "value": "What color is the large building in the image?"}, {"from": "gpt", "value": "The large building in the image is white."}, {"from": "human", "value": "How many stories does the building have?"}, {"from": "gpt", "value": "The building is a large, multistoried structure. However, the exact number of stories cannot be determined from the image."}, {"from": "human", "value": "What is noteworthy about the windows and the clock on the building?"}, {"from": "gpt", "value": "Some windows and the clock on the building are lit up with lights, giving the facade an appealing appearance and drawing attention to these architectural features."}, {"from": "human", "value": "What type of building might this be, considering its size and features?"}, {"from": "gpt", "value": "While we cannot determine the exact purpose of the building from the image alone, the combination of its large size, multiple stories, and clock at the top could suggest that it is a significant public or commercial building, such as a city hall, courthouse, or office building. These types of structures often have grand facades and clocks to symbolize their prominence and importance within the community. However, without more context or distinct identifying features, we cannot be certain about the specific type of building."}]}, {"id": "000000008309", "image": "coco/train2017/000000008309.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the woman doing in the image?"}, {"from": "gpt", "value": "The woman in the image is sitting on the grass, cross-legged, talking on her cellphone and smiling."}, {"from": "human", "value": "What is the setting or location of the image?"}, {"from": "gpt", "value": "The setting of the image appears to be an outdoor field, possibly associated with a soccer pitch, as there is a soccer net in the background."}, {"from": "human", "value": "How is the woman's body positioned while she is talking on the phone?"}, {"from": "gpt", "value": "The woman is sitting cross-legged on the grass while talking on her cellphone."}, {"from": "human", "value": "What is the woman's facial expression while talking on the phone?"}, {"from": "gpt", "value": "The woman has a smiling facial expression, indicating that she is in a positive or pleasant mood during her phone conversation."}, {"from": "human", "value": "Can the image provide any information about the conversation the woman is having on the phone?"}, {"from": "gpt", "value": "While we can see that the woman is smiling during her phone conversation, the image does not provide specific details about the content of her conversation. It could range from catching up with a friend, discussing a pleasant topic, or sharing good news, but there are no definitive clues in the image that allows us to determine the exact nature of the discussion."}]}, {"id": "000000420859", "image": "coco/train2017/000000420859.jpg", "conversations": [{"from": "human", "value": "What is the primary action happening in the image?\n<image>"}, {"from": "gpt", "value": "The primary action in the image is a man riding a bike on the beach."}, {"from": "human", "value": "What color is the bike the man is riding?"}, {"from": "gpt", "value": "The bike the man is riding is blue."}, {"from": "human", "value": "What is the attire of the person riding the bike?"}, {"from": "gpt", "value": "The person riding the bike is wearing plaid attire."}, {"from": "human", "value": "How close is the person on the bike to the water on the beach?"}, {"from": "gpt", "value": "The person riding the bike is near the water on the beach, but the exact distance cannot be determined from the image."}, {"from": "human", "value": "What are some potential challenges or benefits of riding a bike on the beach?"}, {"from": "gpt", "value": "Riding a bike on the beach presents several unique challenges and benefits compared to riding on regular paved surfaces. Here's a brief overview of these aspects:\n\nChallenges:\n1. Soft sand: The soft and uneven nature of sand on the beach can make it difficult to maintain balance and control of the bike. It can also be more physically demanding to pedal through compared to paved surfaces.\n2. Corrosion and wear: The salty air and potential exposure to seawater can cause corrosion and wear on the bike components, requiring more frequent maintenance and cleaning.\n3. Tire pressure and traction: Choosing the right tire pressure and type is crucial for improved traction on sandy surfaces. Too high tire pressure can make it difficult to grip the sand, whereas too low pressure can lead to a \"sinking\" effect.\n\nBenefits:\n1. Scenic views: Riding a bike on the beach offers the opportunity to enjoy beautiful coastal views and a more relaxed atmosphere that is conducive to leisurely cycling.\n2. Low-impact exercise: The softer surface of sand provides a low-impact workout for cyclists, reducing stress on joints and muscles compared to harder surfaces.\n3. Variety: Incorporating beach cycling into a regular routine can add variety to workouts and help improve overall fitness and endurance levels, as the added resistance from sand can increase the physical demands of cycling.\n\nIn summary, while riding a bike on the beach presents some unique challenges, such as dealing with soft sand and corrosion, it also offers benefits like scenic views, a low-impact exercise environment, and added variety to one's cycling routine."}]}, {"id": "000000258110", "image": "coco/train2017/000000258110.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the person in the image doing with their surfboard?"}, {"from": "gpt", "value": "The person in the image, a surfer, is carrying their surfboard as they walk into the water through shallow water on the beach."}, {"from": "human", "value": "What is the surfer intending to do?"}, {"from": "gpt", "value": "The surfer is intending to surf on the waves in the water, which is why they are carrying their surfboard and walking into the water."}, {"from": "human", "value": "Can you describe the appearance of the water at the beach?"}, {"from": "gpt", "value": "The water at the beach is shallow, which allows the surfer to walk comfortably while carrying the surfboard. This suggests the water is calm and clear, gradually deepening as it goes further from the shore. The actual appearance of the water (in terms of color or clarity) is not described, but you can imagine a typical beach scene with waves gently crashing on the shoreline."}, {"from": "human", "value": "What challenges might surfers face and how can they stay safe?"}, {"from": "gpt", "value": "Surfers face various challenges that can impact their safety and enjoyment of the sport. By being aware of potential hazards and taking appropriate precautions, surfers can minimize risks and improve their surfing experience. Some challenges and safety tips include:\n\n1. Strong currents and rip currents: Powerful water currents can carry surfers away from their intended position or to unsafe areas. To stay safe, surfers should learn how to identify and avoid rip currents, swim parallel to the beach if caught in one, and never panic or exhaust themselves trying to swim against the current.\n\n2. Collisions: Surfers can collide with other surfers, their own or others' surfboards, or structures (such as piers or rocky outcroppings) in the water. To prevent collisions, surfers should be mindful of their surroundings and maintain a safe distance from other surfers, especially when catching a wave.\n\n3. Drowning and accidents: Accidents can happen while surfing, so it's crucial for surfers to know their swimming abilities and wear proper safety gear, such as a leash to attach the surfboard to their ankle, a life vest, or a wetsuit (which can provide some buoyancy).\n\n4. Weather and water conditions: It's essential for surfers to stay informed about local weather forecasts and ocean conditions, including water temperature, wave height, and tidal information. Surfers should avoid surfing during storms or when conditions are too challenging for their skill level.\n\n5. Marine life: Encounters with marine life, such as sharks, jellyfish, or sea urchins, can pose a risk to surfers. Wearing appropriate protective gear, following local guidelines, and staying informed about any reported marine life threats or sightings can help minimize risks.\n\n6. Over-exhaustion and dehydration: Surfing can be a physically demanding sport, so it's essential for surfers to stay hydrated, take breaks, and not push themselves beyond their limits.\n\nBy following these safety tips, surfers can overcome challenges and have a more enjoyable and safer time in the water."}]}, {"id": "000000199619", "image": "coco/train2017/000000199619.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat fruits are in the metal dish on the wooden table?"}, {"from": "gpt", "value": "The metal dish contains four mangoes and three bananas."}, {"from": "human", "value": "How many fruits are there in total in the dish?"}, {"from": "gpt", "value": "There are a total of seven fruits in the dish - four mangoes and three bananas."}, {"from": "human", "value": "What is the dish made of?"}, {"from": "gpt", "value": "The dish is made of metal."}, {"from": "human", "value": "Is the dish on a surface and, if so, what kind of surface is it on?"}, {"from": "gpt", "value": "Yes, the dish is on a surface. It is sitting on top of a wooden table."}, {"from": "human", "value": "Can you elaborate on the health benefits of mangoes and bananas as part of a balanced diet?"}, {"from": "gpt", "value": "Mangoes and bananas are both nutritious and delicious fruits that offer numerous health benefits as part of a balanced diet. \n\n1. Mangoes:\nMangoes are rich in vitamins and minerals, including vitamin C, vitamin A, vitamin E, potassium, and various B vitamins. They are high in fiber and low in calories, which makes them beneficial for digestive health, weight management, and overall well-being.\n\nSome health benefits of mangoes include:\n- Boosts immune system: High vitamin C content in mangoes helps support a healthy immune system.\n- Promotes eye health: Mangoes are a good source of vitamin A, which is essential for maintaining and improving eye health.\n- Supports heart health: The potassium and magnesium content in mangoes can help regulate blood pressure, protect against heart disease, and improve overall cardiovascular health.\n- Improves digestion: The dietary fibers in mangoes promote a healthy digestive system and prevent constipation.\n\n2. Bananas:\nBananas are an excellent source of energy, as they are rich in carbohydrates, vitamins, and minerals such as potassium, vitamin C, vitamin B6, and magnesium. They are also low in fat and cholesterol, making them an ideal snack or addition to meals.\n\nSome health benefits of bananas include:\n- Provides instant energy: The natural sugars present in bananas provide a quick energy boost, making them a perfect snack for athletes or busy individuals.\n- Regulates blood pressure: The potassium content in bananas helps maintain proper electrolyte balance, regulate blood pressure, and support overall heart health.\n- Improves digestion: Bananas are a good source of dietary fiber, which aids in digestion and helps prevent constipation.\n- Supports brain health: The vitamin B6 in bananas plays a vital role in maintaining brain function and cognitive health.\n\nIn conclusion, incorporating mangoes and bananas into your diet can provide you with essential nutrients, support various bodily functions, and contribute to overall health and wellness. Not only are they delicious and versatile, but they also offer numerous health benefits that make them a great addition to anyone\u2019s daily diet."}]}, {"id": "000000074403", "image": "coco/train2017/000000074403.jpg", "conversations": [{"from": "human", "value": "What are the main ingredients of the dish on the plate?\n<image>"}, {"from": "gpt", "value": "The main ingredients of the dish on the plate are broccoli, meat, and vegetables, all covered by a sauce."}, {"from": "human", "value": "What is the color of the plate?"}, {"from": "gpt", "value": "The color of the plate is white."}, {"from": "human", "value": "Does the dish appear to be a main course or a side dish?"}, {"from": "gpt", "value": "Given the presence of both meat and vegetables, along with a sauce, the dish appears to be a main course rather than a side dish."}, {"from": "human", "value": "Can you suggest any potential sources of protein in this dish?"}, {"from": "gpt", "value": "In this dish, the primary source of protein comes from the meat present in the meal. The meat could be derived from various sources such as chicken, beef, pork or fish. The vegetables, including the broccoli, may also contribute some plant-based protein to the dish but to a lesser extent compared to the meat."}, {"from": "human", "value": "How can someone prepare a similar dish at home?"}, {"from": "gpt", "value": "To prepare a similar dish at home, follow these general steps:\n\n1. Choose and prepare the meat:\n\nSelect the type of meat you'd like to use, such as chicken, beef, pork, or fish. Cut the meat into bite-sized pieces, and season it with your preferred spices, herbs, or marinades to enhance the flavor.\n\n2. Prepare the vegetables:\n\nChoose a variety of vegetables to accompany the meat, including broccoli and other vegetables that complement the flavors in the dish. Wash and chop the vegetables into bite-sized pieces.\n\n3. Cook the meat and vegetables:\n\nHeat some oil or butter in a frying pan or wok over medium heat. Cook the meat evenly until it is almost fully cooked, then remove it from the pan and set aside. In the same pan, saut\u00e9 the vegetables until they are tender-crisp, making sure not to overcook them.\n\n4. Prepare the sauce:\n\nCreate a sauce that pairs well with the meat and vegetables. This could be a simple stir-fry sauce, a tomato-based sauce, a cream sauce, or any other type of sauce that aligns with your taste preferences. You can start by experimenting with ingredients like soy sauce, garlic, ginger, lemon juice, or various herbs and spices.\n\n5. Combine everything:\n\nAdd the cooked meat back into the pan with the vegetables, and then pour the sauce over the top. Stir to thoroughly coat the meat and vegetables in the sauce, and allow everything to simmer for a few minutes. This will allow the flavors from the sauce to penetrate the dish.\n\n6. Serve:\n\nPlace the cooked dish on a white plate or any other preferred serving dish. If desired, you can serve the meal with a side of rice, noodles, or another grain. Enjoy your homemade meat and vegetable dish with sauce!"}]}, {"id": "000000408266", "image": "coco/train2017/000000408266.jpg", "conversations": [{"from": "human", "value": "What is the boy doing in the image?\n<image>"}, {"from": "gpt", "value": "The boy in the image is sitting at a table, holding and eating a slice of pizza."}, {"from": "human", "value": "What is the boy's facial expression or mood in the image?"}, {"from": "gpt", "value": "The boy appears to be sullen or sad-looking as he eats his pizza."}, {"from": "human", "value": "Is the pizza slice being held flat or folded in the boy's hands?"}, {"from": "gpt", "value": "The boy is holding the pizza slice in a folded manner in his hands."}, {"from": "human", "value": "What are some possible reasons for the boy's sad expression while eating pizza?"}, {"from": "gpt", "value": "There can be numerous reasons for the boy's sad expression while eating pizza. Some possible scenarios include:\n\n1. Disappointment: The boy might be disappointed with the taste or quality of the pizza, or he could be eating a type of pizza that is not his favorite.\n\n2. External factors: The boy's sadness could be unrelated to the pizza itself. He might be going through a difficult situation or dealing with some personal issues that are causing his sullen expression.\n\n3. Lack of company: The boy may feel lonely at the dining table, perhaps because he was expecting to share the pizza and the experience with friends or family members who did not show up or had to leave early.\n\n4. Loss of appetite: The boy may have a decreased appetite or may not be feeling well, but he's trying to eat the pizza anyway. This could lead to a displeased or sad facial expression.\n\n5. Context: The setting of the image or other circumstances surrounding the situation could be affecting the boy's mood. For instance, he could be sad if he was forced to attend an event he didn't want to or if he's missing an important occasion to be at the current location.\n\nIt is essential to keep in mind that these are merely hypothetical reasons and should not be taken as the definite cause of the boy's sadness in the image."}]}, {"id": "000000003915", "image": "coco/train2017/000000003915.jpg", "conversations": [{"from": "human", "value": "What is the woman doing in the image?\n<image>"}, {"from": "gpt", "value": "The woman in the image is standing in a kitchen, preparing food and inspecting the white plates stacked before her. She is wearing an apron and getting ready to serve a large meal."}, {"from": "human", "value": "What is the woman's attire as she prepares the food?"}, {"from": "gpt", "value": "The woman is wearing an apron while preparing food in the kitchen, which is a practical garment to protect her clothing from spills and stains during cooking and serving."}, {"from": "human", "value": "What is the condition of the kitchen counter?"}, {"from": "gpt", "value": "The kitchen counter is full of dishes, including white plates that the woman is inspecting. The large number of dishes indicates that she is preparing a considerable meal, possibly to serve many individuals."}, {"from": "human", "value": "How many plates are visible on the counter?"}, {"from": "gpt", "value": "I'm sorry, but I cannot provide an exact number of plates on the counter as I am only able to visually process single images as a whole. However, it is clear that there are several plates stacked on the counter, indicating the woman's intention to serve a large meal."}, {"from": "human", "value": "What can be deduced from the woman's actions in the image?"}, {"from": "gpt", "value": "From the image, it can be deduced that the woman is in the midst of preparing a large meal, possibly for a gathering, family dinner, or an event. The presence of several white dishes and plates on the counter suggests the scale of the meal she is going to serve.\n\nThe fact that the woman is wearing an apron indicates that she is actively engaged in the kitchen and taking care of the preparation work that goes into serving a large meal. This could involve tasks like chopping, mixing, and stirring various ingredients, as well as plating and presenting the food on the white plates. \n\nIt also suggests that she is attentive to details, as she inspects the plates before using them. This demonstrates her desire to make sure everything is clean and perfect for the meal she is about to serve.\n\nOverall, the image depicts a woman who is dedicated to her task of preparing and serving a substantial meal, ensuring that her guests or family members enjoy a well-presented and delicious dining experience."}]}, {"id": "000000241667", "image": "coco/train2017/000000241667.jpg", "conversations": [{"from": "human", "value": "What type of clock is in the image?\n<image>"}, {"from": "gpt", "value": "The image features a grandfather clock."}, {"from": "human", "value": "How is the design of the clock described in the image?"}, {"from": "gpt", "value": "The grandfather clock in the image is described as rich-looking and decorated with engravings of flowers. It is placed against a nicely paneled wall."}, {"from": "human", "value": "What is the time displayed on the clock face?"}, {"from": "gpt", "value": "The time displayed on the clock face is 3."}, {"from": "human", "value": "Can you provide more information on the history and features of grandfather clocks?"}, {"from": "gpt", "value": "Grandfather clocks, also known as longcase clocks or floor clocks, have a rich history dating back to the late 17th century. They were invented by English clockmaker William Clement in 1670, who realized that adding a longer pendulum to a clock mechanism improved its accuracy. Back then, these clocks were called \"long pendulum clocks\" or \"longcase clocks.\" It wasn't until the 1880s that they became popularly known as \"grandfather clocks,\" thanks to the popular song \"My Grandfather's Clock\" written by Henry Clay Work.\n\nGrandfather clocks are characterized by their tall, freestanding wooden cases that house the clock's mechanics and a swinging pendulum. The cases are often intricately carved and decorated, showcasing the craftsmanship of the clockmaker. The clock face usually features Roman or Arabic numerals and has an hour, minute, and sometimes a second hand.\n\nA key feature of grandfather clocks is the chiming mechanism, which strikes hourly and sometimes quarterly, playing melodies such as Westminster, Whittington, or St. Michael's chimes. These chimes originated from famous clock towers, churches, and mechanisms throughout Europe.\n\nHistorically, grandfather clocks had an important role as timekeepers in households, as they were regarded as status symbols due to their expense and ornate designs. Today, they remain prized possessions and functional pieces of art, gracing the homes of antique collectors and enthusiasts. Although modern timekeeping devices have surpassed their original purpose, the charm and elegance of grandfather clocks continue to be celebrated and admired."}]}, {"id": "000000191350", "image": "coco/train2017/000000191350.jpg", "conversations": [{"from": "human", "value": "What is the woman wearing in the image?\n<image>"}, {"from": "gpt", "value": "The woman in the image is wearing a bikini or swimsuit while engaging in the sport of surfing."}, {"from": "human", "value": "What is the activity the woman is engaged in?"}, {"from": "gpt", "value": "The woman is engaged in surfing, where she is riding a surfboard on a wave in the ocean."}, {"from": "human", "value": "What type of water body is the woman surfing in?"}, {"from": "gpt", "value": "The woman is surfing in the ocean, as indicated by the presence of waves, which are typical in ocean environments."}, {"from": "human", "value": "Can you describe the woman's position or stance on the surfboard?"}, {"from": "gpt", "value": "The woman is standing on the surfboard, maintaining her balance and control while riding the wave. This stance is often referred to as the surfer's stance, which allows the surfer to steer and maneuver the board effectively as well as respond to the changing wave conditions."}, {"from": "human", "value": "What are some essential skills and techniques needed in surfing?"}, {"from": "gpt", "value": "Surfing requires a combination of physical strength, balance, and coordination, as well as the ability to read and understand ocean conditions. Key skills and techniques in surfing include:\n\n1. Paddling: The ability to paddle efficiently and powerfully is crucial for catching waves. Paddling involves using one's arms to propel the surfboard through the water while lying flat on the board.\n\n2. Pop-up technique: This is the action of quickly transitioning from a prone position (lying on the surfboard) to standing up on the surfboard, which is required to ride a wave. The pop-up must be fast and fluid, helping the surfer maintain balance and control during the process.\n\n3. Balance and stance: A proper surfer's stance involves having slightly bent knees, a wide stance, and looking in the direction of the wave. Maintaining good balance and control is essential to navigate the wave and execute various maneuvers.\n\n4. Wave selection and reading: Understanding and predicting wave behavior is a vital skill in surfing. Being able to select the right waves to catch and knowing when to start paddling is crucial for a successful surf session.\n\n5. Maneuvering: Surfing also involves various maneuvers such as turns, cutbacks, and snaps. These movements require good technique, speed, and timing to perform successfully.\n\n6. Etiquette and safety: Surfing, like any other sport, has rules and etiquette that must be followed to ensure a safe and enjoyable experience. This includes respecting other surfers' right of way, not dropping in on others' waves, and being aware of the surroundings.\n\nBy mastering these skills and techniques, surfers can have a better experience in the water, progress their surfing abilities, and potentially perform more advanced maneuvers and ride larger waves."}]}, {"id": "000000507928", "image": "coco/train2017/000000507928.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat kind of vehicle is the person riding on in the image?"}, {"from": "gpt", "value": "The person in the image is riding a dirt bike or motorbike."}, {"from": "human", "value": "What are the conditions of the trail or track where the person is riding?"}, {"from": "gpt", "value": "The person is riding on a muddy trail or track, with the surrounding area full of mud."}, {"from": "human", "value": "Is the dirt bike rider moving at a slow or fast pace?"}, {"from": "gpt", "value": "The dirt bike rider is moving at a fast pace, as they ride around a curve on the muddy trail."}, {"from": "human", "value": "What is the appearance of the person riding the dirt bike?"}, {"from": "gpt", "value": "The person riding the dirt bike is full of mud, which indicates that they have been riding through the muddy conditions for some time."}, {"from": "human", "value": "How does riding a dirt bike in muddy conditions affect the rider's performance and experience?"}, {"from": "gpt", "value": "Riding a dirt bike in muddy conditions presents unique challenges and experiences for the rider. Here are some ways mud impacts the rider's performance and experience:\n\n1. Handling and control: Muddy trails can be slippery and unpredictable, requiring the rider to exhibit increased finesse and skill to maintain control over their dirt bike. Riding around curves or navigating through obstacles may become more difficult in these conditions.\n\n2. Traction: Mud can reduce tire traction, making it harder for the rider to maintain their preferred speed, especially when accelerating or taking turns at a high pace. Riders may need to adjust their riding techniques to compensate for the decreased traction and avoid sliding or losing control.\n\n3. Visibility: Mud splatters and accumulates on the riding gear, including goggles and helmet visors, hampering the rider's visibility on the track. Regularly cleaning the goggles or visor becomes essential to maintain clear visibility.\n\n4. Cleaning and maintenance: Riding in muddy conditions will require thorough cleaning and maintenance of the bike afterwards. Accumulated mud and dirt can potentially clog or damage essential components such as the engine, air filters, and chain. Frequent inspections and cleaning can prevent issues in the long run.\n\n5. Riding gear: Mud can weigh down the rider's gear, making it more challenging to move freely during the ride. Adequate cleaning and drying of the gear are necessary to maintain its functionality and protect it from damage.\n\nOverall, riding a dirt bike in muddy conditions requires the rider to adapt their techniques, gear, and expectations to fully enjoy the sport and ensure their bike's longevity. It can be a thrilling experience for those who enjoy pushing their limits and conquering challenging terrain."}]}, {"id": "000000053840", "image": "coco/train2017/000000053840.jpg", "conversations": [{"from": "human", "value": "What color is the sailboat in the image?\n<image>"}, {"from": "gpt", "value": "The sailboat in the image is white."}, {"from": "human", "value": "Is the sailboat docked or sailing in the water?"}, {"from": "gpt", "value": "The sailboat is docked, sitting in the ocean next to a pier."}, {"from": "human", "value": "What are the conditions of the sky in the image?"}, {"from": "gpt", "value": "The sky in the image is pink, likely indicating that it is during sunset."}, {"from": "human", "value": "What is the setting of the image?"}, {"from": "gpt", "value": "The setting of the image is a harbor, with the sailboat docked on a pier in a bay area. This calm and picturesque scene features a beautiful sunset, casting a warm, pink glow over the water and the boat."}, {"from": "human", "value": "Can you describe the overall atmosphere and mood of the image?"}, {"from": "gpt", "value": "The overall atmosphere and mood of the image are serene and peaceful. The white sailboat is gently docked at the pier, resting in the calm waters of the bay. The pink sky from the sunset adds a touch of warmth and tranquility to the scene, creating a sense of stillness and reflection.\n\nThis picture may evoke feelings of relaxation and contentment, as it showcases the natural beauty of the harbor and the simple pleasure of spending time by the water during the golden hours of the day. The docked sailboat could also represent a moment of pause or rest after a day of sailing and exploration, inspiring thoughts of pleasant memories, and anticipation for new adventures to come."}]}, {"id": "000000437889", "image": "coco/train2017/000000437889.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat can be seen through the window in the image?"}, {"from": "gpt", "value": "Through the window in the image, there is a view of trees, hills, and land with some vegetation."}, {"from": "human", "value": "What type of window is seen in the image?"}, {"from": "gpt", "value": "The image features a small, rough window, which appears to be on the side of an airplane."}, {"from": "human", "value": "What is the overall scenery visible through the window?"}, {"from": "gpt", "value": "The overall scenery visible through the window consists of land, trees, hills, and vegetation. It's a natural landscape that one might see when looking out of an airplane window while flying at a lower altitude. The presence of dirt indicates a more rustic, untouched environment, possibly a rural or remote area."}, {"from": "human", "value": "In the context of the image, what does the term \"rough window\" mean?"}, {"from": "gpt", "value": "In the context of the image, the term \"rough window\" describes the appearance and quality of the window itself. It may refer to the window being small, having an uneven or irregular shape, scratches, or not being entirely clear. Since it's on the side of an airplane, it could also suggest that the window is not as polished and well-maintained as a standard commercial airplane window. This could be due to the aircraft's age, or it could be a small private or vintage airplane where the windows might not have the same smooth finish as modern commercial planes."}]}, {"id": "000000565600", "image": "coco/train2017/000000565600.jpg", "conversations": [{"from": "human", "value": "How many people are on the tennis court in the image?\n<image>"}, {"from": "gpt", "value": "There are two men on the tennis court in the image."}, {"from": "human", "value": "What are the men doing on the tennis court?"}, {"from": "gpt", "value": "The men are playing a game of tennis on the court, with one man holding a tennis racquet watching the other hit the ball. They are both actively engaged in the game and holding tennis racquets."}, {"from": "human", "value": "Can you describe the facial expression of the tennis player swinging for a shot?"}, {"from": "gpt", "value": "The tennis player swinging for a shot has a grimacing facial expression, which indicates they are putting in considerable effort and concentration into hitting the ball."}, {"from": "human", "value": "What is the typical layout of a tennis court?"}, {"from": "gpt", "value": "A tennis court is a rectangular playing surface with specific dimensions and layout, which includes lines and markings for the game. A standard tennis court measures 78 feet (23.77 meters) in length and 27 feet (8.23 meters) in width for singles matches or 36 feet (10.97 meters) for doubles matches.\n\nThe court is divided into two equal halves by a net, which stands at 3.5 feet (1.07 meters) high at the sides and 3 feet (0.914 meters) high at the center. The net is supported by two net posts positioned 3 feet (0.914 meters) outside the doubles court on each side.\n\nThe main lines and markings on a tennis court include the baseline, singles and doubles sidelines, service boxes, and the center mark on the baseline. The service boxes are created by dividing the area between the net and the baseline into quarters using the service lines, which run parallel to the net, and the center service line, which runs perpendicular to the net.\n\nBesides, there are alley markings for doubles play, known as tramlines, which extend the width of the court on either side.\n\nOverall, the tennis court layout is designed to facilitate organized play and scoring within the rules of tennis. With its marked boundaries, a tennis court allows players to engage in challenging rallies and aim for strategic shots with precise control."}]}, {"id": "000000446670", "image": "coco/train2017/000000446670.jpg", "conversations": [{"from": "human", "value": "How many chairs are surrounding the wooden table?\n<image>"}, {"from": "gpt", "value": "There are four chairs surrounding the wooden table."}, {"from": "human", "value": "What type of furniture is the table meant for?"}, {"from": "gpt", "value": "The table is meant for dining, as suggested by the chairs that accompany it."}, {"from": "human", "value": "What kind of fruit is in the bowl on the table?"}, {"from": "gpt", "value": "There is a bowl of bananas on the table."}, {"from": "human", "value": "What is the overall impression of the dining table and chairs?"}, {"from": "gpt", "value": "The overall impression of the dining table and chairs is that they are pretty and nice, which suggests a visually pleasing and inviting setup for dining and socializing."}, {"from": "human", "value": "What can be inferred about the owner's taste in furniture from this image?"}, {"from": "gpt", "value": "The image of the wooden dining table with four nice chairs and a bowl of bananas in the middle suggests that the owner has an appreciation for classic and elegant furniture. The wooden material of the table and chairs indicates a preference for natural materials and a timeless design, which often lends itself to versatility and longevity. The decision to use four different chairs around the table might suggest that the owner values creativity and uniqueness, which may be a reflection of their personal style or a desire to make their dining area stand out. \n\nFurthermore, the presence of the bowl of bananas implies that the owner values aspects of practicality and hospitality. The fruit not only serves as a useful and healthy snack option for the residents and guests, but it also adds a touch of color and freshness to the dining setup, making the space more visually appealing and inviting. \n\nIn conclusion, the image of the pretty wooden dining table with four nice chairs and a bowl of bananas in the middle suggests that the owner has a preference for classic, elegant, and unique furniture styles, while also considering practicality and hospitality elements in their choices. This could indicate a well-rounded approach to decorating their living space, balancing aesthetics and function to create a welcoming and pleasant dining area."}]}, {"id": "000000036373", "image": "coco/train2017/000000036373.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the boy doing in the image?"}, {"from": "gpt", "value": "The boy in the image is playing baseball, focusing on catching an incoming ball with his baseball mitt."}, {"from": "human", "value": "What color is the boy's hat?"}, {"from": "gpt", "value": "The boy's hat is red."}, {"from": "human", "value": "Is the boy standing or in a different position while trying to catch the ball?"}, {"from": "gpt", "value": "The boy is crouching or squatting over while lowering his mitt towards the ball that hovers in the air, preparing to catch the baseball in motion."}, {"from": "human", "value": "What type of baseball glove is the boy using?"}, {"from": "gpt", "value": "The boy is using a catcher's mitt to catch the baseball. A catcher's mitt is a specialized type of baseball glove designed to provide extra padding and a unique shape to facilitate the catching of fastpitched balls, often used by the catcher positioned behind the batter."}]}, {"id": "000000301558", "image": "coco/train2017/000000301558.jpg", "conversations": [{"from": "human", "value": "How many people are in the image?\n<image>"}, {"from": "gpt", "value": "There are three people in the image."}, {"from": "human", "value": "What are the people doing in the image?"}, {"from": "gpt", "value": "The three people are posing for a picture on their snow skis on a mountain slope."}, {"from": "human", "value": "Are the people in the image male or female?"}, {"from": "gpt", "value": "The people in the image are three men."}, {"from": "human", "value": "What is the background of the image?"}, {"from": "gpt", "value": "The background of the image is a picturesque mountain slope, providing a beautiful setting for the group of skiers as they pose for their photo."}, {"from": "human", "value": "Can you explain the risks associated with skiing and how one can minimize those risks?"}, {"from": "gpt", "value": "Skiing is a popular and exhilarating winter sport, but it also carries some inherent risks due to the nature of the activity and the challenging environment in which it takes place. Some potential risks include falls, collisions, avalanches, frostbite, and getting lost or stranded in remote areas. However, by being aware of these dangers and following certain safety guidelines, skiers can significantly reduce their risk and enjoy a safer, more enjoyable experience on the slopes.\n\n1. Wear appropriate gear: Skiers should wear proper skiing equipment, including ski boots, bindings, skis, poles, a helmet, goggles, and suitable clothing that provides protection against the cold and wet conditions. This gear will help prevent injuries during falls, maintain body temperature, and improve overall performance and control on the slopes.\n\n2. Know your skill level: Skiers should be aware of their abilities and limitations, and choose ski runs and terrain that are suitable for their skill level. Overestimating one's expertise can lead to accidents and injuries. Beginners should take lessons from certified instructors to learn the basics and progress at their own pace.\n\n3. Be aware of the environment: Skiers should familiarize themselves with the ski area, including its marked trails, warning signs, and any potential hazards such as cliffs, rocks, or tree wells. Checking weather forecasts and avalanche reports before skiing can help one anticipate changes in conditions and make informed decisions about when and where to ski.\n\n4. Follow ski area rules: Staying on marked trails, obeying posted signs, and not venturing into closed or out-of-bounds areas can reduce the risk of accidents and ensure the safety of both the individual skier and others on the mountain. Yielding to skiers ahead or below and maintaining a safe distance from others can help prevent collisions.\n\n5. Stay in control and ski defensively: Skiers should monitor their speed and always remain aware of their surroundings, adjusting their skiing style to accommodate changing conditions, terrain, and the presence of other skiers. Practicing control and awareness will minimize the risk of accidents.\n\n6. Buddy system: Skiing with a partner or a group provides not only companionship but also a safety net in case of emergencies. A buddy can provide assistance, alert ski patrol, or locate help if needed.\n\nIn conclusion, while there are inherent risks in skiing, being aware of these dangers, wearing appropriate gear, knowing one's skill level, staying informed about the environment and following ski area rules can help minimize those risks and promote a safer and more enjoyable experience on the slopes."}]}, {"id": "000000160573", "image": "coco/train2017/000000160573.jpg", "conversations": [{"from": "human", "value": "How many people are visible in the image?\n<image>"}, {"from": "gpt", "value": "There are two people visible in the image."}, {"from": "human", "value": "What are the two people doing in the image?"}, {"from": "gpt", "value": "The two people, both women, are sitting at a table and holding donuts while showing off their choices. They are inside a donut shop."}, {"from": "human", "value": "How would you describe the shape of the donuts the women are holding?"}, {"from": "gpt", "value": "The donuts held by the women are funny or uniquely shaped, making them interesting and eye-catching."}, {"from": "human", "value": "What is the setting of the image, and what kind of establishment are they in?"}, {"from": "gpt", "value": "The image is set inside a donut or doughnut shop, where the women are enjoying their time and showcasing their selected donuts."}, {"from": "human", "value": "What are some factors that contribute to a pleasant experience at a donut shop?"}, {"from": "gpt", "value": "Several factors contribute to a pleasant experience at a donut shop. These include:\n\n1. Variety and creativity: Having a wide selection of donut flavors and styles, including distinct, funny, or uniquely shaped designs as seen in the image, can attract customers and enhance their overall experience.\n \n2. Taste and quality: Ensuring that the donuts are fresh and made with high-quality ingredients is essential for customer satisfaction. Donuts that taste good and meet customer expectations will keep them coming back for more.\n\n3. Ambiance: Comfortable seating, well-lit spaces, clean interiors, and pleasant music or background noise all contribute to a welcoming atmosphere where customers can enjoy their treats and spend time with friends or family.\n\n4. Friendly staff: Having attentive, courteous, and knowledgeable staff can significantly improve a customer's experience. Staff members who are genuinely helpful and enthusiastic about the products being sold can make a difference in a customer's perception of the establishment.\n\n5. Additional offerings: Some donut shops may also serve coffee, tea, or other beverages that complement their donuts, providing a more complete experience for the customers. Offering various options can cater to individual preferences and make the experience more enjoyable.\n\nIn conclusion, various factors like variety, taste, ambiance, friendly staff, and additional offerings play a vital role in creating a pleasant experience at a donut shop for customers."}]}, {"id": "000000401822", "image": "coco/train2017/000000401822.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the overall color scheme of the kitchen?"}, {"from": "gpt", "value": "The kitchen has white painted walls, blue tiles, and wooden floors."}, {"from": "human", "value": "What type of oven is present in the kitchen?"}, {"from": "gpt", "value": "There is a stove top oven in the kitchen."}, {"from": "human", "value": "What type of flooring does the kitchen have?"}, {"from": "gpt", "value": "The kitchen has wooden flooring."}, {"from": "human", "value": "Does the kitchen have any ventilation system for the stove?"}, {"from": "gpt", "value": "Yes, the kitchen features outside ventilation for the stove, indicating that it is a well-designed and luxury kitchen."}, {"from": "human", "value": "Describe the size of the kitchen."}, {"from": "gpt", "value": "The kitchen is described as small, containing a sink and stove as its primary features. Although it is a smaller space, it has been designed thoughtfully with outside ventilation and a harmonious color scheme consisting of white, blue, and wood elements."}]}, {"id": "000000313007", "image": "coco/train2017/000000313007.jpg", "conversations": [{"from": "human", "value": "<image>\nIs there a handicap sign visible on the train in the image?"}, {"from": "gpt", "value": "Yes, there is a handicap sign visible on the side of the silver train in the image."}, {"from": "human", "value": "Apart from the handicapped sign, what other sign is visible in the image?"}, {"from": "gpt", "value": "Aside from the handicapped sign, there is also a \"Training Train\" sign on the silver door of the train."}, {"from": "human", "value": "What color is the train in the image?"}, {"from": "gpt", "value": "The train in the image is silver or stainless steel in color."}, {"from": "human", "value": "What part of the train is the image focused on?"}, {"from": "gpt", "value": "The image is focused on a close-up view of the train door, where the handicapped sign and \"Training Train\" sign are visible."}, {"from": "human", "value": "What might the \"Training Train\" sign suggest about the train's purpose?"}, {"from": "gpt", "value": "The \"Training Train\" sign indicates that this particular train is likely used for training purposes, such as teaching train operators and conductors about train functions, safety protocols, or maintenance procedures in a controlled environment. It might also be used for training staff on how to assist passengers with disabilities, given the presence of the handicapped sign on the train. The training train ensures that the staff are well-prepared and knowledgeable about train operations, safety, and customer service before working on actual trains in service."}]}, {"id": "000000210187", "image": "coco/train2017/000000210187.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the child in the image doing?"}, {"from": "gpt", "value": "The child in the image, a young girl, is sitting at a table and eating a doughnut."}, {"from": "human", "value": "What kind of furniture can be seen in the background?"}, {"from": "gpt", "value": "In the background, there are tables and chairs, indicating that the girl is in a restaurant or cafe setting."}, {"from": "human", "value": "What material is the table made of?"}, {"from": "gpt", "value": "The table the young girl is eating at is made of wood."}, {"from": "human", "value": "What can you tell me about the restaurant or cafe setting based on the image?"}, {"from": "gpt", "value": "Based on the image, the restaurant or cafe setting appears to be relatively casual and comfortable, as demonstrated by the wooden table and chairs. The young girl is enjoying her doughnut in a relaxed environment, which suggests that the establishment may be family-friendly or cater to an informal, laid-back dining experience. Unfortunately, without more details or a broader view of the interior, it's difficult to provide further insights into the restaurant or cafe, such as its size, style, or decor."}]}, {"id": "000000457618", "image": "coco/train2017/000000457618.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the man wearing in the image?"}, {"from": "gpt", "value": "The man in the image is wearing a white shirt and a red tie."}, {"from": "human", "value": "What is the man's facial expression or demeanor in the image?"}, {"from": "gpt", "value": "The man looks puzzled and is looking sideways or to his left."}, {"from": "human", "value": "Is the man in an indoor or outdoor setting?"}, {"from": "gpt", "value": "The man is in an indoor setting, possibly in an office environment."}, {"from": "human", "value": "How would you interpret the man's puzzled expression in the context of an office setting?"}, {"from": "gpt", "value": "In the context of an office setting, the man's puzzled expression could be attributed to several factors. The man could be facing a challenging task or problem that requires critical thinking, or he might have encountered an unexpected issue or obstacle delaying his work progress. \n\nHis sideways glance implies that he might be seeking solutions or assistance from surrounding resources or colleagues. Alternatively, he may have heard or seen something unusual that has momentarily caught his attention or caused confusion. \n\nThe man's puzzled expression suggests that there may be a level of uncertainty or complexity in the situation he is dealing with, and it requires his attention, problem-solving skills, and collaborative efforts to address the issue. In an office setting, such situations are common, as they can arise from various daily work-related challenges or even interpersonal interactions that demand effective communication and cooperation between team members."}]}, {"id": "000000011713", "image": "coco/train2017/000000011713.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many skiers are performing stunts in the air?"}, {"from": "gpt", "value": "There are two skiers performing stunts in the air."}, {"from": "human", "value": "What are the skiers doing as part of their stunt?"}, {"from": "gpt", "value": "The skiers are jumping and flying through the air while riding their skis, likely after going off a jump or a ramp. They might be doing tricks as part of their stunt."}, {"from": "human", "value": "What is the terrain like where the skiers are performing the stunts?"}, {"from": "gpt", "value": "The terrain where the skiers are performing the stunts is snowy, which is ideal for skiing and performing ski-related stunts."}, {"from": "human", "value": "What type of skiing would you categorize these stunts as?"}, {"from": "gpt", "value": "These stunts can be categorized as part of freestyle skiing, which is a type of downhill skiing focused on performing aerial tricks and jumps. In freestyle skiing, skiers often go off jumps, halfpipes, or other features that allow them to get air and execute various acrobatic maneuvers. The main disciplines within freestyle skiing include slopestyle, halfpipe, aerials, moguls, ski cross, and big air competitions. In this case, since the skiers are performing aerial tricks, it suggests they are participating in a slopestyle or big air event, both of which emphasize the execution of jumps and stunts in the air."}]}, {"id": "000000341741", "image": "coco/train2017/000000341741.jpg", "conversations": [{"from": "human", "value": "What size is the bed in the bedroom?\n<image>"}, {"from": "gpt", "value": "The bed in the bedroom is a twin bed."}, {"from": "human", "value": "What kind of furniture is beside the bed?"}, {"from": "gpt", "value": "There is a small wooden table beside the bed."}, {"from": "human", "value": "What is placed on the small table next to the bed?"}, {"from": "gpt", "value": "An open laptop computer is placed on the small table next to the bed."}, {"from": "human", "value": "What color is the bed?"}, {"from": "gpt", "value": "The bed is blue."}, {"from": "human", "value": "Is the bedroom also used as a workspace?"}, {"from": "gpt", "value": "Yes, the bedroom is used as a workspace with a computer, as evidenced by the presence of the laptop on the small table next to the bed. This setup allows the occupant to easily access the computer for work or leisure purposes while remaining comfortable in the bedroom. Working from home is becoming more common, and having a designated workspace in the bedroom can facilitate productivity and create a space where one can focus on tasks or rest."}]}, {"id": "000000342294", "image": "coco/train2017/000000342294.jpg", "conversations": [{"from": "human", "value": "What type of plate is the cake on?\n<image>"}, {"from": "gpt", "value": "The cake is placed on a white plate with multi-colored polka dots."}, {"from": "human", "value": "What is on top of the dessert?"}, {"from": "gpt", "value": "The dessert, which is a slice of cake, is covered in dark syrup."}, {"from": "human", "value": "Is there any utensil visible in the image?"}, {"from": "gpt", "value": "Yes, there is a fork visible on the plate."}, {"from": "human", "value": "Does the cake look appetizing?"}, {"from": "gpt", "value": "Yes, the cake looks very tasty and appetizing with its syrup topping."}, {"from": "human", "value": "Can you describe the overall presentation and appearance of the dessert in the image?"}, {"from": "gpt", "value": "In the image, a delicious-looking piece of cake is served on a white plate adorned with multi-colored polka dots, which adds a playful and fun element to the presentation. The cake itself is topped with a generous amount of dark syrup, giving it a rich and decadent appearance that entices the viewer. The fork placed on the plate suggests that it is ready to be enjoyed. Overall, the presentation of the dessert is visually appealing and appetizing, making the viewer eager to taste it."}]}, {"id": "000000387368", "image": "coco/train2017/000000387368.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the main focus of the living room in the image?"}, {"from": "gpt", "value": "The main focus of the living room in the image is the lavishly decorated interior that showcases art treasures, along with beautiful flower arrangements and a clock mounted on a yellow wall."}, {"from": "human", "value": "How many people can be seen in the living room?"}, {"from": "gpt", "value": "There are two people in the living room: a man who is bent down attending to a woman sitting in the room."}, {"from": "human", "value": "What is the man doing in the living room?"}, {"from": "gpt", "value": "The man is bent down attending to the woman sitting in the living room. It seems like he is engaged in a conversation with her or offering assistance."}, {"from": "human", "value": "What are some of the decorations in this living room?"}, {"from": "gpt", "value": "Some of the decorations in this living room include art treasures, which could be paintings, sculptures, or other decorative objects, a clock mounted on a yellow wall, and beautiful flower arrangements placed in strategic locations to enhance the overall aesthetics of the space."}, {"from": "human", "value": "Can you discuss the potential purposes of having art treasures in a living room?"}, {"from": "gpt", "value": "Having art treasures in a living room serves various purposes, ranging from aesthetics and personal preferences to status symbols and conversation starters:\n\n1. Aesthetics: Art treasures add an element of visual appeal and elegance to a living room. They come in many different forms and styles, making it possible to find the perfect pieces that resonate with the homeowner's tastes and preferences. Incorporating art into living spaces can improve the overall ambiance and establish a specific mood within the room.\n\n2. Personal Expression: Art can be a reflection of a person's personality, interests, and experiences. Displaying art treasures in a living room allows the homeowner to express their unique style and create a space that feels truly their own. Moreover, collecting and displaying art creates a sense of ownership and pride in the curated collection.\n\n3. Status Symbol: Owning and displaying art treasures can be considered a sign of wealth, culture, and taste. This could be especially true if the art pieces are rare, valuable, or created by well-known artists. In this sense, art serves as a symbol of social status and accomplishment.\n\n4. Conversation Starter: Art in a living room can spark conversations between guests, inviting them to share their thoughts or learn more about the pieces on display. This can lead to engaging discussions about the art, the artists, and the stories behind the pieces, fostering social interactions and connections between people.\n\nThus, displaying art treasures in a living room not only enhances the room's aesthetic appeal, but also allows for personal expression, serves as a status symbol, and inspires conversation among guests, creating a unique and inviting atmosphere for all who enter the space."}]}, {"id": "000000497746", "image": "coco/train2017/000000497746.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of garden is in the image?"}, {"from": "gpt", "value": "The image features a small backyard garden with a planter box containing various plants, including freshly grown vegetables. The garden is in the yard of a house."}, {"from": "human", "value": "What do the stakes in the garden indicate?"}, {"from": "gpt", "value": "The stakes in the garden are typically used to support the plants as they grow, ensuring they grow upright and maintain their structure. They are particularly helpful for plants with tall stems or those prone to drooping under their own weight or external factors like wind."}, {"from": "human", "value": "What time of the day is the photo taken?"}, {"from": "gpt", "value": "The photo is taken during the day, as indicated by the presence of sunlight."}, {"from": "human", "value": "Is the garden located in the front yard or the backyard?"}, {"from": "gpt", "value": "The garden is located in the backyard of the house."}, {"from": "human", "value": "Can you name some benefits of having a backyard garden like this one?"}, {"from": "gpt", "value": "There are several benefits of having a backyard garden like the one in the image, which include:\n\n1. Fresh Produce: Homegrown vegetables and fruits are often fresher and more flavorful than those found in supermarkets, as they can be harvested when they are fully ripe and consumed shortly after.\n\n2. Healthier Options: Growing your own produce allows you to take full control of the growing process, ensuring that no harmful chemicals or pesticides are used, resulting in healthier food.\n\n3. Environmental Benefits: Backyard gardens contribute to sustainable living by reducing the need for transportation and packaging of produce, thereby reducing the carbon footprint and minimizing waste.\n\n4. Stress Relief: Gardening is considered a therapeutic activity that can provide stress relief and help foster mental well-being. Tending to plants and watching them grow can bring a sense of accomplishment and satisfaction to the gardener.\n\n5. Physical Activity: Gardening also serves as a form of low-impact exercise that helps maintain physical fitness, as it involves tasks such as digging, planting, watering, and weeding.\n\n6. Educational Opportunities: If you have children or other family members, a backyard garden can be an excellent opportunity to teach them about plant growth, nutrition, and the importance of sustainable living practices.\n\n7. Cost Savings: Growing your own produce can be more cost-effective in the long run, as you save on grocery expenses and potentially reduce the need for packaged or processed food.\n\n8. Landscape Design: A well-maintained backyard garden can add visual appeal and enhance the aesthetics of your property, potentially increasing its value.\n\nIn summary, having a backyard garden like the one in the image can provide various benefits, such as access to fresh and healthy produce, enhanced well-being through stress relief, and opportunities for physical activity, education, and environmental conservation."}]}, {"id": "000000235987", "image": "coco/train2017/000000235987.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the person doing in the image?"}, {"from": "gpt", "value": "The person in the image is standing on a tennis court, holding a tennis racket, and appears to be ready for a match of tennis."}, {"from": "human", "value": "What is the gender of the person on the tennis court?"}, {"from": "gpt", "value": "The person on the tennis court is a woman."}, {"from": "human", "value": "What color is the shirt the person is wearing in the image?"}, {"from": "gpt", "value": "The person on the tennis court is wearing a blue shirt."}, {"from": "human", "value": "Is the woman alone on the tennis court or are there others visible in the image?"}, {"from": "gpt", "value": "The woman is standing alone on the tennis court."}, {"from": "human", "value": "What are some basic rules and gameplay aspects of tennis?"}, {"from": "gpt", "value": "Tennis is a popular racquet sport played between two players (singles) or between two teams of two players each (doubles). The objective of the game is to hit the tennis ball with a racquet over a net and into the opponent's court, ensuring that the opponent is unable to return the ball legally. Here are some basic rules and gameplay aspects:\n\n1. The Court: A tennis court is a flat, rectangular surface, typically made of grass, clay, or a hard surface like concrete or asphalt. The court has specific boundary lines marking the singles and doubles playing areas. A net runs across the middle of the court, dividing it into two equal halves.\n\n2. Scoring: Tennis uses a unique scoring system, with points progressing from love (0), 15, 30, to 40. If both players reach 40 (called deuce), one player must win two consecutive points to win the game. A match is divided into sets, with each set requiring a player to win a predetermined number of games (usually six games) with a margin of at least two games.\n\n3. Serving: At the beginning of each point, a player serves the ball by standing behind the baseline and hitting the ball diagonally across the net into the opponent's service box. A serve must be done legally, or the server will receive a fault. If a player commits two faults in a row, it results in a double fault, awarding a point to the opponent.\n\n4. Ball in Play: After a legal serve, the players must hit the ball back and forth, making sure it lands within the designated boundary lines. Players must avoid letting the ball bounce more than once on their side of the court before hitting it back.\n\n5. Winning Points: Points can be won by various means, including hitting the ball into the opponent's court so that they cannot return it, the opponent committing a double fault, or the opponent hitting the ball out of the court or into the net.\n\nThese are just a few of the basic rules and gameplay aspects of tennis. There are many other nuances and strategies involved in the sport, making it a complex and engaging game for both casual players and professional athletes."}]}, {"id": "000000082858", "image": "coco/train2017/000000082858.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many pieces of meat are on the plate?"}, {"from": "gpt", "value": "There are two pieces of meat on the plate."}, {"from": "human", "value": "What type of plate is the food served on?"}, {"from": "gpt", "value": "The food is served on a white dining plate."}, {"from": "human", "value": "Are the meat pieces covered in sauce?"}, {"from": "gpt", "value": "Yes, the two pieces of meat are covered in sauce."}, {"from": "human", "value": "Is the food on the plate considered to be fine dining or casual cuisine?"}, {"from": "gpt", "value": "The food on the plate is presented as fine dining, as it is well-prepared and served with a sauce on a white plate for an appealing presentation."}, {"from": "human", "value": "What else could be on the plate other than meat? Any dessert items?"}, {"from": "gpt", "value": "The image also suggests that there could be two small pastries on the plate. However, it is not certain whether both meat and pastries are on the same plate or if the pastries are on a separate plate by themselves."}]}, {"id": "000000066828", "image": "coco/train2017/000000066828.jpg", "conversations": [{"from": "human", "value": "What are the people doing in the image?\n<image>"}, {"from": "gpt", "value": "The people in the image are riding elephants as they cross a river."}, {"from": "human", "value": "How would you describe the surroundings of the river?"}, {"from": "gpt", "value": "The surroundings of the river include mud and grass nearby, providing a natural and somewhat muddy environment."}, {"from": "human", "value": "What is the purpose of people riding elephants to cross the river?"}, {"from": "gpt", "value": "Though I can't determine their exact purpose from the image, people are likely riding elephants to cross the river as a form of transportation or as part of a travel adventure or tourist activity. Elephants are capable of navigating through deep water and rough terrain, making them suitable for such river crossings. Riding elephants can also provide an exciting and unique experience, particularly for tourists looking to interact with these majestic creatures."}, {"from": "human", "value": "Are the people by themselves on the elephants, or are there any local guides or caretakers accompanying them?"}, {"from": "gpt", "value": "Based on the image, it is impossible to definitively determine whether local guides or caretakers are accompanying the people riding the elephants. However, it is common in elephant riding activities, particularly in tourism, to have experienced caretakers or guides present to ensure the safety of both the riders and the elephants."}]}, {"id": "000000025461", "image": "coco/train2017/000000025461.jpg", "conversations": [{"from": "human", "value": "<image>\nWhere is the group of people gathered?"}, {"from": "gpt", "value": "The group of people is gathered in a grass-covered field or park, standing together in a clearing."}, {"from": "human", "value": "What is the activity of the group of people?"}, {"from": "gpt", "value": "The group of people appears to be involved in a musical activity, possibly as part of an oriental musical group. Some members of the group are holding onto drums, which suggests that they are playing musical instruments or preparing to perform."}, {"from": "human", "value": "Are the people in the group young or old?"}, {"from": "gpt", "value": "The people in the group are described as young, although exact ages cannot be determined from the image."}, {"from": "human", "value": "What are the people in the group doing or focusing on?"}, {"from": "gpt", "value": "The people in the group are standing together, looking up, and seem to be engaged in a shared activity or experience, possibly related to their musical performance."}, {"from": "human", "value": "Can you provide some background on oriental musical groups and the use of drums in their performances?"}, {"from": "gpt", "value": "Oriental musical groups often feature traditional instruments and styles from countries in Asia, particularly East Asia. The term \"oriental\" serves as a broad category encompassing various cultures, traditions, and instruments. However, it's essential to note that the use of the term \"oriental\" can be considered outdated and inappropriate in some contexts due to its association with Eurocentric views and stereotypes of the East.\n\nTraditional oriental music might include instruments such as drums, stringed instruments like the erhu, guzheng, or koto, as well as woodwind instruments like the dizi or shakuhachi. The use of drums in these musical groups varies depending on the specific region, culture, and style. Drums are often featured in traditional music for their rhythmic qualities, and they can play a central role in setting the tempo or creating a percussive backdrop for other instruments.\n\nDrums can be found in numerous different shapes and sizes, ranging from small hand drums to larger, more resonant drums. Some traditional Asian drums include the Japanese taiko, the Chinese paigu, and the Korean buk. These drums often hold cultural significance and may be used for ceremonial, celebratory, or entertainment purposes in various settings, such as festivals, religious events, or cultural performances.\n\nIn summary, oriental musical groups focus on traditional instruments and styles from Asia, with drums being a common feature in their performances. The specific role and type of drums used in a performance depend on the region's culture and musical tradition, but they generally contribute to the rhythmic foundation of the music."}]}, {"id": "000000257951", "image": "coco/train2017/000000257951.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat activity is the man engaging in together with his dog?"}, {"from": "gpt", "value": "The man is engaging in surfing with his dog, both standing on a surfboard in the ocean."}, {"from": "human", "value": "Is the surfer and dog duo close to the shore, or are they farther out in the ocean?"}, {"from": "gpt", "value": "The surfer and his dog are relatively near the beach area, not too far out in the ocean."}, {"from": "human", "value": "What is the surfer waiting for?"}, {"from": "gpt", "value": "The surfer is waiting with his dog for the next wave to ride."}, {"from": "human", "value": "Can you explain the concept of tandem surfing and its popularity?"}, {"from": "gpt", "value": "Tandem surfing refers to the practice of two or more individuals sharing a surfboard and riding a wave together. It can involve various combinations of people \u2013 such as two adults, an adult and a child, or even an adult and a pet, as seen in the image. The concept allows surfers to experience the thrill of surfing in a cooperative and synchronized manner, requiring good communication and trust between riders.\n\nTandem surfing gained popularity in the mid-20th century, especially during the 1960s, when surfers would showcase their skills by performing acrobatic and synchronized maneuvers on long surfboards. While the sport witnessed a dip in popularity with the advent of shorter boards, it has seen a resurgence in recent years, owing to its social bonding aspect and unique challenges.\n\nOne of the key reasons tandem surfing attracts enthusiasts is the need for teamwork and coordination between riders, which adds an exciting element to the sport. Additionally, tandem surfing serves as an opportunity for beginners to learn from experienced surfers by directly experiencing wave-riding techniques and movements. Lastly, tandem surfing is also popular for its \"wow factor\" - the impressive visual of two or more riders gliding and performing stunts on a single wave is undoubtedly eye-catching and entertaining. In the case of a man and his dog, tandem surfing highlights the bond between a pet and its owner and their shared enjoyment of the ocean and the sport."}]}, {"id": "000000464965", "image": "coco/train2017/000000464965.jpg", "conversations": [{"from": "human", "value": "What is the man holding in the image?\n<image>"}, {"from": "gpt", "value": "The man is holding a foil-wrapped sandwich or hotdog in the image."}, {"from": "human", "value": "What is the man wearing in the image?"}, {"from": "gpt", "value": "The man is wearing a blue shirt in the image."}, {"from": "human", "value": "Where is the man located while holding the sandwich or hotdog?"}, {"from": "gpt", "value": "The man is located either in an office or a hotel setting, sitting next to a computer or a laptop while holding the sandwich or hotdog."}, {"from": "human", "value": "Is the man standing or sitting in the image?"}, {"from": "gpt", "value": "The man is sitting in the image, either at a desk in an office or in a hotel room."}, {"from": "human", "value": "Why might a person eat a meal while working on a computer or laptop?"}, {"from": "gpt", "value": "A person might eat a meal while working on a computer or laptop for several reasons:\n\n1. Time management: With busy schedules and multiple tasks to complete, eating while working allows a person to save time by multitasking. Combining work and mealtime can help the individual maintain productivity and stay on track with their work.\n\n2. Short breaks: In some cases, eating while working can serve as a short break from a more focused or intense work session. This brief interruption may help someone recharge and refocus, increasing their overall productivity.\n\n3. Work-based deadlines or priorities: Jobs with tight deadlines or workloads may require employees to eat their meals while still working to maintain their work pace and satisfy their goals.\n\n4. Remote work: With the rise of remote work, many employees are working from home, where access to food and personal kitchens is readily available. This dynamic can make it more convenient for workers to have meals at their workspaces rather than taking separate breaks for mealtime.\n\nIn conclusion, eating a meal while working on a computer or laptop can be a practical choice for individuals attempting to optimize their time, manage their workloads, and adapt to a remote work setting. However, it is essential to balance work and mealtime, as taking proper breaks and focusing on self-care ensures productivity and overall wellbeing in the long run."}]}, {"id": "000000550532", "image": "coco/train2017/000000550532.jpg", "conversations": [{"from": "human", "value": "How many parking meters are visible in the image?\n<image>"}, {"from": "gpt", "value": "There are two parking meters visible in the image."}, {"from": "human", "value": "What color are the parking meters?"}, {"from": "gpt", "value": "The parking meters are green in color."}, {"from": "human", "value": "What material are the parking meters made of?"}, {"from": "gpt", "value": "The parking meters are made of metal."}, {"from": "human", "value": "Where are the parking meters located?"}, {"from": "gpt", "value": "The parking meters are located on the street, outside of a shop or a business building."}, {"from": "human", "value": "Are the parking meters still in use or are they old and out of service?"}, {"from": "gpt", "value": "While it's not possible to definitively determine whether the parking meters are in service or out of service based on the image alone, their old metal appearance might suggest that they might be out of service or at least have been in use for quite some time. Newer parking meters typically feature a digital display and allow for various payment methods, while older meters, like the ones in the image, often only accept coins."}]}, {"id": "000000251360", "image": "coco/train2017/000000251360.jpg", "conversations": [{"from": "human", "value": "What is the main subject in the image?\n<image>"}, {"from": "gpt", "value": "The main subject in the image is a cat sitting underneath a plaid umbrella."}, {"from": "human", "value": "What pattern does the umbrella in the image have?"}, {"from": "gpt", "value": "The umbrella in the image has a plaid and striped pattern."}, {"from": "human", "value": "What is the cat doing under the umbrella?"}, {"from": "gpt", "value": "The cat is sitting under the umbrella and looking at the camera."}, {"from": "human", "value": "Where is the umbrella located, indoors or outdoors?"}, {"from": "gpt", "value": "The umbrella with the cat under it is located indoors, as suggested by the phrase \"inside\" in the last sentence."}, {"from": "human", "value": "How would you describe the appearance of the cat in the image?"}, {"from": "gpt", "value": "The cat appears to be rather chunky and has stripes on its fur."}]}, {"id": "000000578775", "image": "coco/train2017/000000578775.jpg", "conversations": [{"from": "human", "value": "Is there a laptop on the table?\n<image>"}, {"from": "gpt", "value": "Yes, there is a laptop on the table."}, {"from": "human", "value": "What is the design on the table?"}, {"from": "gpt", "value": "The table is decorated with a design that resembles railroad tracks."}, {"from": "human", "value": "Are there any other objects on the table besides the laptop?"}, {"from": "gpt", "value": "Yes, there is a mouse on the table as well."}, {"from": "human", "value": "What type of table is the laptop and mouse on?"}, {"from": "gpt", "value": "The laptop and mouse are on a long table."}, {"from": "human", "value": "Do the railroad tracks on the table appear to be real or part of the table's design?"}, {"from": "gpt", "value": "The railroad tracks are part of the table's design and not real tracks."}]}, {"id": "000000128561", "image": "coco/train2017/000000128561.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many children are playing in the image?"}, {"from": "gpt", "value": "There are three kids playing in the image."}, {"from": "human", "value": "What are the children doing in the grassy area?"}, {"from": "gpt", "value": "The children are playing with a flying disc, engaging in a game of catch in the large grassy area."}, {"from": "human", "value": "Is there any body of water visible near the grassy area where the children are playing?"}, {"from": "gpt", "value": "Yes, there is a lake near the field where the children are playing catch."}, {"from": "human", "value": "What is the overall atmosphere of the scene depicted in the image?"}, {"from": "gpt", "value": "The overall atmosphere of the scene depicted in the image is one of joy, fun, and playfulness. With children actively engaged in a game of catch with a flying disc, the image conveys a sense of camaraderie and lighthearted competition. The lush green field and the presence of the nearby lake add to the idyllic setting, creating a sense of openness and a connection with nature. This image captures a moment of youthful enjoyment as the children bond with one another while participating in outdoor physical activity, reminding us of the simple pleasures of childhood play."}]}, {"id": "000000099316", "image": "coco/train2017/000000099316.jpg", "conversations": [{"from": "human", "value": "Is there a person in the image or is the beach empty?\n<image>"}, {"from": "gpt", "value": "The beach is empty except for an umbrella and an empty bench. There isn't any person visible in the image."}, {"from": "human", "value": "What are the main objects near the bench on the beach?"}, {"from": "gpt", "value": "The main objects near the bench on the beach are an umbrella and a fence."}, {"from": "human", "value": "Is the beach sandy or rocky?"}, {"from": "gpt", "value": "The beach in the image is described as a rocky beach."}, {"from": "human", "value": "Where is the umbrella in relation to the bench?"}, {"from": "gpt", "value": "The umbrella is sitting on the corner of the bench, near the water."}]}, {"id": "000000488547", "image": "coco/train2017/000000488547.jpg", "conversations": [{"from": "human", "value": "What is the weather like in the image?\n<image>"}, {"from": "gpt", "value": "The weather in the image seems to be rainy, as the flight of stairs is soaked with rain."}, {"from": "human", "value": "Can you describe the appearance of the man in the image?"}, {"from": "gpt", "value": "The man in the image is wearing a plaid jacket and is walking up the stairs."}, {"from": "human", "value": "What is the man doing on the stairs in terms of his actions?"}, {"from": "gpt", "value": "The man is imitating a STAIRS sign above him while standing on the stairs, presumably in a playful manner."}, {"from": "human", "value": "Where does the staircase lead to?"}, {"from": "gpt", "value": "The staircase leads underground, likely to a subway or similar urban transit system, as there are buildings visible in the background."}, {"from": "human", "value": "Is the man walking up or down the stairs?"}, {"from": "gpt", "value": "The man is walking up the stairs."}]}, {"id": "000000249132", "image": "coco/train2017/000000249132.jpg", "conversations": [{"from": "human", "value": "What color is the bus in the image?\n<image>"}, {"from": "gpt", "value": "The bus in the image is red."}, {"from": "human", "value": "What type of road is the bus traveling on?"}, {"from": "gpt", "value": "The bus is traveling on a country lane or tree-lined street, which indicates a more rural or suburban setting as opposed to an urban environment."}, {"from": "human", "value": "What is the bus passing by as it drives down the street?"}, {"from": "gpt", "value": "The bus is passing by a forest and hedgerows, creating a scenic and green environment along its route."}, {"from": "human", "value": "What is the primary purpose of the bus?"}, {"from": "gpt", "value": "The primary purpose of the bus in the image is to serve as a passenger vehicle, transporting people from one location to another along its route."}, {"from": "human", "value": "What can you infer about the transportation system in this location based on the image?"}, {"from": "gpt", "value": "Based on the image, one can infer that the transportation system in this location includes public transit options like buses that cater to the needs of residents or tourists in the area. The presence of a red passenger bus on a country lane or tree-lined street suggests that public transit is accessible in both rural and suburban settings, not just urban areas. \n\nThis availability of public transportation could potentially help reduce individual car usage and traffic congestion on the roads, as well as contribute to a decreased carbon footprint in the form of lower greenhouse gas emissions. In addition, the presence of the bus in a scenic, green environment could demonstrate that the local government or transit authorities are committed to ensuring the accessibility of public transit options for people living or traveling in these areas, making it easier for them to commute to work, school, or other destinations without relying solely on private vehicles."}]}, {"id": "000000036282", "image": "coco/train2017/000000036282.jpg", "conversations": [{"from": "human", "value": "What is the color of the umbrella the woman is holding?\n<image>"}, {"from": "gpt", "value": "The color of the umbrella the woman is holding is blue."}, {"from": "human", "value": "What is the woman wearing when walking along the beach with the umbrella?"}, {"from": "gpt", "value": "The woman is wearing a short skirt while walking along the beach with the umbrella."}, {"from": "human", "value": "What is the landscape like where the woman is walking with the umbrella?"}, {"from": "gpt", "value": "The woman is walking along a rocky shore or beach, near a body of water which could possibly be a creek or the ocean."}, {"from": "human", "value": "What is the mood or atmosphere of the image with the woman and the blue umbrella?"}, {"from": "gpt", "value": "The mood or atmosphere of the image is contemplative and serene, as the woman is walking along the rocky shore taking in the scenic surroundings. The presence of the umbrella and the landscape evoke a sense of tranquility, solitude, and a connection with nature. The woman appears to be in deep thought, perhaps reflecting on her life or simply enjoying the moment, as she gracefully strolls along the water's edge. The blue umbrella adds a touch of color and a visual point of interest, further enhancing the overall atmosphere of the scene."}]}, {"id": "000000471839", "image": "coco/train2017/000000471839.jpg", "conversations": [{"from": "human", "value": "What type of pizza is shown in the image?\n<image>"}, {"from": "gpt", "value": "The image shows an uncooked pizza with sausage and whole slices of cheese on top, prepared and ready to be cooked."}, {"from": "human", "value": "What is the pizza resting on?"}, {"from": "gpt", "value": "The pizza is resting on a wooden cutting board, or it can also be referred to as a wooden peel."}, {"from": "human", "value": "What is the state of the pizza in the image?"}, {"from": "gpt", "value": "The pizza is in an uncooked state, with the ingredients assembled on the crust and ready to go into the pizza oven for cooking."}, {"from": "human", "value": "What are the visible toppings on the pizza?"}, {"from": "gpt", "value": "The visible toppings on the pizza are sausage and whole slices of cheese."}]}, {"id": "000000190241", "image": "coco/train2017/000000190241.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich part of the zebra is visible in the image?"}, {"from": "gpt", "value": "In the image, the tail end of the zebra is visible, with the zebra facing away from the camera."}, {"from": "human", "value": "What is the zebra standing on?"}, {"from": "gpt", "value": "The zebra is standing on a field covered in grass, but there is also some rocky ground."}, {"from": "human", "value": "Is the zebra fully visible or partially visible?"}, {"from": "gpt", "value": "The zebra is partially visible in the image, as only the back end of it is shown from a diagonal view."}, {"from": "human", "value": "Please describe the surroundings of the zebra in the image."}, {"from": "gpt", "value": "The zebra is standing in an open field covered with grass, and there is some rocky ground present as well. There are no other animals or objects visible in the image, and the environment appears to be natural and outdoors, likely a typical habitat for zebras. In the absence of any stressors, the zebra seems to be relaxed and calmly enjoying its surroundings."}, {"from": "human", "value": "In which type of habitat do zebras typically live?"}, {"from": "gpt", "value": "Zebras typically live in a variety of grassland habitats, including savannas and plains. These habitats provide zebras with an abundance of grazing opportunities, as they mainly feed on grasses. Additionally, these open environments offer sufficient space for zebras to move around and make it easier for them to spot potential predators from a distance. They usually prefer areas with a mix of grasses and small shrubs, allowing them to have not only enough food but also suitable cover.\n\nZebras are mostly found in Africa, with three species known: the plains zebra (Equus quagga), the mountain zebra (Equus zebra), and the Grevy's zebra (Equus grevyi). Each species has its specific habitat preferences. For instance, the plains zebra is commonly found in grasslands and savannas throughout Eastern and Southern Africa, while the mountain zebra prefers the rocky mountain slopes and plateaus in Southern Africa. On the other hand, Grevy's zebras are usually found in semi-arid grasslands in Northern Kenya and parts of Ethiopia. \n\nIn the image, the zebra is shown standing in a grassy field with some rocky ground, which aligns well with the natural habitats typically inhabited by zebras."}]}, {"id": "000000512325", "image": "coco/train2017/000000512325.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the main subject of the image?"}, {"from": "gpt", "value": "The main subject of the image is a woman sitting on a bench."}, {"from": "human", "value": "What is the woman doing while sitting on the bench?"}, {"from": "gpt", "value": "The woman is talking on her phone while sitting on the bench."}, {"from": "human", "value": "What is the location of the bench?"}, {"from": "gpt", "value": "The bench is located in a garden, surrounded by many flowers and bushes."}, {"from": "human", "value": "What kind of bench is the woman sitting on?"}, {"from": "gpt", "value": "The woman is sitting on a wooden bench."}, {"from": "human", "value": "Can you describe the overall atmosphere of the scene depicted in the image?"}, {"from": "gpt", "value": "The image portrays a peaceful and pleasant atmosphere. The scene showcases the woman sitting on a wooden bench surrounded by lush flowers and bushes, suggesting that she is in a beautiful and well-maintained garden. This setting evokes a sense of serenity, relaxation, and connection with nature.\n\nAs the woman is talking on her phone, it indicates that she may be engaging in a casual conversation, catching up with friends or family, or even taking a break from her busy day to enjoy the tranquility of the garden. The vibrant colors and lush greenery further enhance the calming and picturesque environment, making it an ideal spot for the woman to sit and relax while making her phone call. Overall, the image captures a serene moment in the woman's day, surrounded by the beauty of nature in the garden."}]}, {"id": "000000286877", "image": "coco/train2017/000000286877.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat colors are the seats in the subway car?"}, {"from": "gpt", "value": "The seats in the subway car are yellow and blue."}, {"from": "human", "value": "Are there any passengers visible in the subway car?"}, {"from": "gpt", "value": "No, the subway car is completely empty of passengers."}, {"from": "human", "value": "Is the lighting inside the subway car turned on or off?"}, {"from": "gpt", "value": "The lights inside the subway car are turned on."}, {"from": "human", "value": "What could be some reasons for the empty train car?"}, {"from": "gpt", "value": "There could be several reasons for the empty train car:\n\n1. Off-peak hours: The subway car might be empty because it is traveling during off-peak hours when there's less demand for public transportation. During early mornings, late nights, or midday, fewer people are likely to be commuting, so subway cars might be less crowded or even empty.\n\n2. In-between stations: The train might be in between stations, and passengers may have disembarked at the previous stop. If the train has not yet reached the next station to pick up additional passengers, the car might be momentarily empty.\n\n3. Service disruptions or delays: If there has been a service disruption, such as a technical issue or an accident on the line, passengers might have been directed to use alternative forms of transportation, leaving the subway car empty.\n\n4. Maintenance or cleaning: The train car might be empty if it's temporarily taken out of service for maintenance or cleaning. In such cases, the train car might be empty even if its lights are still on.\n\n5. Special event or situation: There could be a special event or situation in the city that has caused a significant shift in the normal patterns of public transportation use, leading to an unusually empty subway car. For example, a major sports event, festival, or extreme weather conditions might influence the number of passengers using public transportation at a specific time.\n\nIn conclusion, while it's impossible to definitively determine the exact reason for the emptiness of the subway car based on the image alone, there are various potential explanations for this observation."}]}, {"id": "000000139389", "image": "coco/train2017/000000139389.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is the car parked in the parking lot?"}, {"from": "gpt", "value": "The car parked in the parking lot is blue."}, {"from": "human", "value": "What is on top of the car?"}, {"from": "gpt", "value": "There is a surfboard strapped to the top of the car on a surfboard rack."}, {"from": "human", "value": "Where is the blue car parked?"}, {"from": "gpt", "value": "The blue car is parked in a parking lot outside of a large building or shopping center."}, {"from": "human", "value": "Is there any indication of the weather in the image?"}, {"from": "gpt", "value": "Yes, the image suggests that it is a rainy day, as the blue car is parked in the shopping center lot during a rainy day."}, {"from": "human", "value": "What kind of building or establishment is the car parked near?"}, {"from": "gpt", "value": "The car is parked near a sub shop in the shopping center, indicating that the area is likely a commercial area with various businesses for visitors to patronize."}]}, {"id": "000000270269", "image": "coco/train2017/000000270269.jpg", "conversations": [{"from": "human", "value": "What color is the traffic light in the image?\n<image>"}, {"from": "gpt", "value": "The traffic light in the image is green."}, {"from": "human", "value": "What type of sign is visible in the image, aside from the green traffic light?"}, {"from": "gpt", "value": "There is a street sign visible that instructs pedestrians and bicyclists to stop."}, {"from": "human", "value": "What time of day does the image appear to be taken?"}, {"from": "gpt", "value": "The image appears to be taken during the evening, as evidenced by the presence of street lights and the overall ambiance."}, {"from": "human", "value": "How would you describe the overall atmosphere in the city based on the image?"}, {"from": "gpt", "value": "Based on the image, the city seems to be busy, with many street and traffic signs catering to varied transportation modes such as cars, pedestrians, and cyclists. The green traffic light and the stop sign indicate an active traffic management system that facilitates smooth traffic flow in the city. The presence of street lights further emphasizes that the city is well-lit, ensuring safety and visibility for commuters even during the evening hours. These elements together create an atmosphere of an organized and bustling urban environment."}]}, {"id": "000000573453", "image": "coco/train2017/000000573453.jpg", "conversations": [{"from": "human", "value": "What is the person doing in the image?\n<image>"}, {"from": "gpt", "value": "The person in the image is riding a snowboard down a snow-covered slope."}, {"from": "human", "value": "Is the person on a snowboard or skis?"}, {"from": "gpt", "value": "The person is on a snowboard, not skis."}, {"from": "human", "value": "Is the person snowboarding on a hill or a mountain?"}, {"from": "gpt", "value": "The person is snowboarding down the side of a mountain, but it could also be described as a snowy hill."}, {"from": "human", "value": "Can you see any mountains in the background of the image?"}, {"from": "gpt", "value": "Yes, there is a mountain visible in the background of the image."}, {"from": "human", "value": "What are the main differences between snowboarding and skiing?"}, {"from": "gpt", "value": "Snowboarding and skiing are both popular winter sports that involve sliding down snow-covered slopes. However, there are several key differences between the two:\n\n1. Equipment: In skiing, participants wear a pair of skis \u2013 one on each foot \u2013 that are attached to ski boots with bindings. Ski poles are also used for balance and propulsion. On the other hand, snowboarding involves the use of a single snowboard that both feet are attached to with bindings, while no poles are used.\n\n2. Technique: Skiing and snowboarding require different techniques for movement and balance. In skiing, the legs remain parallel, and skiers shift their weight and use carving turns to navigate the slope. Snowboarders, however, have their feet positioned sideways on the board and use their upper body and legs to lean, twist, and shift their weight to control their movement.\n\n3. Body Position: The body position in skiing is typically more upright and facing forward, whereas, in snowboarding, the body is often positioned more sideways, with the snowboarder looking over their shoulder in the direction they are going.\n\n4. Terrain: Both skiers and snowboarders can enjoy various terrains, including groomed runs, moguls, snow parks, and backcountry. However, due to the differences in technique, snowboarders may find flat terrain or very narrow, steep slopes more challenging than skiers.\n\n5. Learning Curve: While individual experiences may vary, skiing is often considered easier to learn initially, as the independent movement of each leg can provide more stability. Snowboarding, on the other hand, may require more practice to master the balance and control needed for successful turns and stops.\n\nIn summary, the main differences between snowboarding and skiing lie in the equipment used, techniques for movement and balance, body positioning, preferred terrain, and learning curve. Each sport has its unique challenges and thrills for participants to enjoy."}]}, {"id": "000000521176", "image": "coco/train2017/000000521176.jpg", "conversations": [{"from": "human", "value": "Is the person holding the umbrella a man or a woman?\n<image>"}, {"from": "gpt", "value": "The person holding the umbrella in the image is a man."}, {"from": "human", "value": "What is the purpose of the umbrella being held by the man?"}, {"from": "gpt", "value": "The umbrella is being used to protect the man or his artwork from the elements, such as sunlight or potential rain, while he is painting the scenic view."}, {"from": "human", "value": "What can the man see in the distance as he looks over the flowery hill?"}, {"from": "gpt", "value": "The man can see the sea beyond the flowery hill, offering a panoramic view of nature that is serving as the subject of his artwork."}, {"from": "human", "value": "Is the person focused on his artwork or simply admiring the view?"}, {"from": "gpt", "value": "The man appears to be focused on his artwork, as he has set up his easel on the hill to capture the scenery below. This indicates that he is using the breathtaking view as inspiration for his painting."}, {"from": "human", "value": "What is the significance of incorporating nature as the subject of artwork?"}, {"from": "gpt", "value": "Incorporating nature as the subject of artwork holds significant importance for many artists due to several reasons. Firstly, artists are often inspired by the beauty, variety, and the vivid color palette that nature effortlessly offers, enabling them to express their creativity and emotions through the portrayal of the natural world. This distinctive representation of nature also resonates with the viewer's own emotional and aesthetic experiences, allowing them to connect with the artwork on a deeper level.\n\nSecondly, the depiction of nature in art often serves as a visual commentary on contemporary issues, such as environmental protection and climate change. By highlighting the inherent beauty and fragility of the natural world, artists aim to remind viewers of the need to preserve the environment and respect its delicate balance. In some instances, artists also use their work to communicate the personal or cultural significance of particular landscapes or natural elements, fostering a sense of belonging and reverence for their surroundings.\n\nLastly, turning to nature as the subject of artwork provides a unique challenge for artists, as it tests their ability to accurately capture the complex interplay of light, color, texture, and form found within the natural world. This challenge often serves as a means for artists to push their creative boundaries, experiment with new techniques, and ultimately grow as professionals.\n\nIn conclusion, the significance of incorporating nature as the subject of artwork lies in its ability to inspire creativity, evoke emotion, promote environmental awareness, and facilitate artistic growth. For the man in the image, the picturesque scene of the flowery hill and the sea beyond likely holds a unique personal significance, as well as offering him the opportunity to challenge and expand his artistic skills."}]}, {"id": "000000098162", "image": "coco/train2017/000000098162.jpg", "conversations": [{"from": "human", "value": "How many people are playing in the pool in the image?\n<image>"}, {"from": "gpt", "value": "There are three people playing in the pool in the image."}, {"from": "human", "value": "What are they doing in the pool?"}, {"from": "gpt", "value": "The three people are playing with a frisbee in the pool."}, {"from": "human", "value": "What is the gender composition of the group playing in the pool?"}, {"from": "gpt", "value": "The group playing in the pool consists of two women and one man."}, {"from": "human", "value": "What type of pool are they playing in?"}, {"from": "gpt", "value": "They are playing in an in-ground pool."}, {"from": "human", "value": "What is the color of the pool?"}, {"from": "gpt", "value": "The color of the pool is blue."}, {"from": "human", "value": "Can you describe a few benefits of engaging in physical activities like playing with a frisbee in a pool?"}, {"from": "gpt", "value": "Engaging in physical activities like playing with a frisbee in a pool offers several benefits, not only for physical health but also for mental well-being and social interaction. Here are a few benefits:\n\n1. Improved cardiovascular fitness: Playing with a frisbee in a pool requires constant movement, which increases the heart rate, enhances blood circulation, and strengthens the cardiovascular system.\n\n2. Muscle strength and flexibility: Swimming and moving in the water provide resistance that works and tones muscles throughout the body. The buoyancy of water also supports flexibility, reducing the chances of injuries while promoting a greater range of motion.\n\n3. Low-impact exercise: Water activities are gentle on the joints, making them ideal for people with joint-related issues or those recovering from injuries. The water provides support to the body and minimizes the impact experienced during land-based activities.\n\n4. Mental well-being: Engaging in physical activities like playing with a frisbee in a pool can help reduce stress and anxiety and promote relaxation. Water activities can have a calming effect, improving overall mood and mental health.\n\n5. Social interaction: Playing pool games with friends or family members provides an opportunity for bonding and socialization. Group activities can foster a sense of belonging and improve communication skills.\n\n6. Cooling effect: Playing in a pool on a hot day can help regulate body temperature, providing relief from the heat while still allowing for physical activity and enjoyment.\n\nSo, engaging in activities like playing with a frisbee in a pool can have numerous positive effects on both physical and mental health, while also providing fun opportunities for social interaction and enjoying the outdoors during hot weather."}]}, {"id": "000000577484", "image": "coco/train2017/000000577484.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color are the walls and towels in the bathroom?"}, {"from": "gpt", "value": "The walls and towels in the bathroom are white."}, {"from": "human", "value": "What type of room is the bathroom situated in?"}, {"from": "gpt", "value": "The bathroom is situated in a hotel room."}, {"from": "human", "value": "How many mirrors are in the bathroom?"}, {"from": "gpt", "value": "There is one huge mirror in the bathroom."}, {"from": "human", "value": "How many sinks are present in the bathroom?"}, {"from": "gpt", "value": "There is a single sink in the bathroom."}, {"from": "human", "value": "Are there any towels in the bathroom? If so, where are they located?"}, {"from": "gpt", "value": "Yes, there are towels in the bathroom. A couple of them are located on a rack."}]}, {"id": "000000201706", "image": "coco/train2017/000000201706.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is the double decker bus in the image?"}, {"from": "gpt", "value": "The double decker bus in the image is red."}, {"from": "human", "value": "Is the bus moving or has it stopped?"}, {"from": "gpt", "value": "The double decker bus in London has stopped to pick up and drop off people."}, {"from": "human", "value": "What are the people with matching backpacks doing near the double decker bus?"}, {"from": "gpt", "value": "The people with matching backpacks are standing outside the double decker bus, likely waiting to either board the bus or continuing to gather around as a group."}, {"from": "human", "value": "What color are the matching backpacks worn by the group of people?"}, {"from": "gpt", "value": "The matching backpacks worn by the group of people are red."}, {"from": "human", "value": "What can we infer about this group of people with matching backpacks?"}, {"from": "gpt", "value": "Based on the image, we can infer that the group of people with matching red backpacks might be part of a tour or an organized event. The matching backpacks could serve as a way for the group members to easily identify each other and stay together amidst the bustling city environment. \n\nIt is also possible that they are tourists or travelers exploring the city of London, considering the presence of the iconic red double decker bus. The fact that they are gathered near the bus could indicate that they have either just arrived at a popular sightseeing spot, or they are preparing to continue their journey and explore the city further. \n\nOverall, the image presents a lively atmosphere with people enjoying their time and the convenience of public transportation, such as the red double decker bus, in a vibrant city like London."}]}, {"id": "000000005260", "image": "coco/train2017/000000005260.jpg", "conversations": [{"from": "human", "value": "What kind of baseball game is shown in the image?\n<image>"}, {"from": "gpt", "value": "The image shows a Little League baseball game in progress."}, {"from": "human", "value": "Who are the main participants visible in the image?"}, {"from": "gpt", "value": "The main participants visible in the image are the hitter (a young boy holding a bat and preparing to swing), the catcher (another young boy in a catching position), and the umpire."}, {"from": "human", "value": "What is the hitter doing in the image?"}, {"from": "gpt", "value": "The hitter is in the ready position, standing at home plate and preparing to swing his bat in an attempt to hit the incoming baseball."}, {"from": "human", "value": "What is the role of the catcher and the umpire in a baseball game?"}, {"from": "gpt", "value": "In a baseball game, the catcher and the umpire play crucial roles in overseeing and managing the game's progress.\n\nThe catcher is a defensive player positioned behind the home plate. They have several responsibilities, including receiving pitches thrown by their team's pitcher, attempting to prevent the other team's runners from advancing to the next base, and relaying pitch calls and signals to their pitcher. The catcher must have good reflexes, agility, and hand-eye coordination, as they need to catch the incoming baseballs and be able to throw them accurately to different bases.\n\nThe umpire is an official responsible for enforcing the rules of the game while ensuring fair play and safety for all participants. Their primary role is to make judgment calls on various aspects of the game, such as whether a pitch was a ball or a strike, determining safe or out calls when a player attempts to reach a base, and monitoring the legality of the pitcher's actions. Umpires also have the authority to eject players, coaches, or managers from the game if they display unsportsmanlike behavior or violate the rules.\n\nIn summary, the catcher is an essential defensive player in a baseball game, responsible for receiving pitches and preventing runners from advancing, while the umpire is an official who oversees the game and enforces its rules to maintain its integrity and ensure fair play for all involved."}]}, {"id": "000000209745", "image": "coco/train2017/000000209745.jpg", "conversations": [{"from": "human", "value": "How many pizzas are on the table in the image?\n<image>"}, {"from": "gpt", "value": "There are two pizzas on the table in the image."}, {"from": "human", "value": "What is the man in the image doing?"}, {"from": "gpt", "value": "The man in the image is eating, and he is taking a bite while sitting at the table with the pizzas."}, {"from": "human", "value": "What type of crust do the pizzas have?"}, {"from": "gpt", "value": "The pizzas have thick crusts."}, {"from": "human", "value": "What is the setting of the image?"}, {"from": "gpt", "value": "The setting of the image is a restaurant, where the man is enjoying his meal with two pizzas in front of him."}, {"from": "human", "value": "What type of table are the pizzas placed on?"}, {"from": "gpt", "value": "The pizzas are placed on a wood table."}]}, {"id": "000000575305", "image": "coco/train2017/000000575305.jpg", "conversations": [{"from": "human", "value": "What action is the baseball player performing in the image?\n<image>"}, {"from": "gpt", "value": "The baseball player in the image is swinging his bat attempting to hit the ball during a baseball game."}, {"from": "human", "value": "Is the player using a particular technique while hitting the ball, like bunting?"}, {"from": "gpt", "value": "There is no clear indication as to whether the player is bunting the ball or just attempting a regular hit. However, it is apparent that the player is actively swinging the bat toward the ball during the game."}, {"from": "human", "value": "Are there any spectators in the image?"}, {"from": "gpt", "value": "Yes, there are people watching the baseball game as the player swings his bat at the baseball."}, {"from": "human", "value": "Can you give a brief explanation of the roles of a batter and a pitcher in a baseball game?"}, {"from": "gpt", "value": "In a baseball game, the main roles of a batter and a pitcher are as follows:\n\n1. Batter:\nThe batter stands in the batter's box and attempts to hit the baseball thrown by the pitcher. The batter's primary objective is to hit the ball in such a way that they can safely run around the bases and eventually score runs for their team. Batters need excellent hand-eye coordination, quick reflexes, and strategic thinking to successfully hit various types of pitches thrown by the pitcher. They may employ different techniques during their at-bat, such as bunting, hitting for contact, or trying to hit for power.\n\n2. Pitcher:\nThe pitcher's role is to throw the baseball towards the batter with the intent of preventing the batter from hitting the ball successfully. This can be achieved by pitching the ball with a combination of speed, movement, and location, making it difficult for the batter to predict and hit. The pitcher follows the signals given by the catcher, who directs which type of pitch to throw and where to locate it. The pitcher aims to either strike out the batter (getting three strikes) or induce a weak hit that can be easily fielded by the defensive players on their team.\n\nIn short, the batter and pitcher engage in a continuous strategic battle during a baseball game. Their individual skills, as well as their ability to anticipate and adjust to each other's moves, significantly impact the game's outcome."}]}, {"id": "000000400710", "image": "coco/train2017/000000400710.jpg", "conversations": [{"from": "human", "value": "<image>\nWhere is the skateboarder located?"}, {"from": "gpt", "value": "The skateboarder is located at a skate park."}, {"from": "human", "value": "What is the skateboarder preparing to do?"}, {"from": "gpt", "value": "The skateboarder is getting ready to ride his skateboard, possibly on the edge of a ramp."}, {"from": "human", "value": "Is the skate park decorated with any artwork?"}, {"from": "gpt", "value": "Yes, the skate park is decorated with graffiti murals, which adds an artistic and colorful ambiance to the environment."}, {"from": "human", "value": "What type of skateboard is the person using?"}, {"from": "gpt", "value": "I cannot determine the specific type of skateboard the person is using from the image, but it is most likely a standard skateboard, which is commonly used in skate parks for performing tricks and maneuvers on ramps and other features."}, {"from": "human", "value": "Can you tell us more about skateboarding and its relation to skate parks and graffiti culture?"}, {"from": "gpt", "value": "Skateboarding is an action sport and a form of creative expression that involves riding and performing tricks on a skateboard. It has its roots in the 1950s when surfers in California sought an alternative to surfing when the waves were not optimal. Since then, skateboarding has evolved into a worldwide phenomenon, with millions of people participating in the sport and a thriving subculture that values individuality, creativity, and personal style.\n\nSkate parks are purpose-built areas designed for skateboarding and other action sports, such as BMX biking and inline skating. They typically feature a variety of ramps, ledges, rails, bowls, and other obstacles that allow skaters to perform a wide range of tricks and maneuvers. Skate parks serve as gathering places for skaters to practice, improve their skills, and socialize with others who share their passion for the sport.\n\nGraffiti culture is closely associated with the skateboarding community because both activities are rooted in artistic expression, creativity, and a desire for self-expression. Graffiti, as an art form, emerged from the urban street culture of the 1970s and 1980s and has since become a global artistic movement. Many skate parks incorporate graffiti murals as a way to showcase local artists' talents and create a vibrant, artistic atmosphere that reflects the skateboarding community's values.\n\nThe connection between skateboarding and graffiti culture can also be seen in the sport's influence on streetwear, fashion, and music. Skateboarding has inspired numerous clothing brands, such as Vans, Supreme, and Thrasher, which often feature graffiti-style artwork and designs. Similarly, the punk rock and hip-hop music genres have resonated with the skateboarding community due to their shared emphasis on self-expression, nonconformity, and pushing boundaries.\n\nIn conclusion, skateboarding and graffiti are closely connected through their shared emphasis on creativity, individuality, and artistic expression. Both activities emerged from urban street culture and have since influenced fashion, music, and other aspects of popular culture. Skate parks often showcase graffiti murals to create an environment that celebrates and supports the artistic nature of the sport and its subculture."}]}, {"id": "000000345590", "image": "coco/train2017/000000345590.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many sheep are in the image?"}, {"from": "gpt", "value": "There are two sheep in the image, one adult sheep (possibly a ram) and a lamb."}, {"from": "human", "value": "What is the condition of the field in the image?"}, {"from": "gpt", "value": "The field in the image is covered with tall grass and is surrounded by a layer of fog or mist."}, {"from": "human", "value": "What kind of atmosphere does the image of the sheep in the foggy field create?"}, {"from": "gpt", "value": "The image of the sheep in the foggy field creates a serene and peaceful atmosphere. The combination of the misty surroundings, the presence of the sheep and lamb, and the tall grassy field contributes to a sense of calmness and tranquillity, portraying a natural and idyllic rural setting."}, {"from": "human", "value": "Can you identify any specific breeds of sheep in the image?"}, {"from": "gpt", "value": "It is difficult to confidently identify specific sheep breeds in the image without clearer details about their physical appearance and characteristics. Sheep breeds can be quite varied, with differences in size, shape, color, wool type, and other features, but these distinctions can be challenging to discern in a foggy scene like the one depicted in the image."}]}, {"id": "000000203673", "image": "coco/train2017/000000203673.jpg", "conversations": [{"from": "human", "value": "What type of fruit is sitting on the laptop computer?\n<image>"}, {"from": "gpt", "value": "There is an apple sitting on the laptop computer."}, {"from": "human", "value": "Can you describe the type of laptop the apple is on?"}, {"from": "gpt", "value": "The apple is sitting on an Apple MacBook Pro laptop computer."}, {"from": "human", "value": "Which specific part of the laptop is the apple resting on?"}, {"from": "gpt", "value": "The apple is resting on the keyboard of the laptop computer."}, {"from": "human", "value": "What does placing an apple on a MacBook Pro laptop symbolize?"}, {"from": "gpt", "value": "Placing an apple on a MacBook Pro laptop can symbolize several things, depending on the context.\n\n1. A visual pun or wordplay: The image can represent a play on words, as the Apple brand logo is an apple with a bite taken out of it. By placing an actual apple on an Apple laptop, the image may intentionally create a humorous or clever connection between the two.\n\n2. Representing knowledge and technology: The apple is often associated with knowledge and learning, stemming from the biblical story of Adam and Eve in the Garden of Eden, where the apple represents the fruit from the Tree of Knowledge. In this context, placing an apple on a MacBook Pro laptop may symbolize the marriage of traditional knowledge and modern technology, highlighting how technology can be a powerful tool for acquiring and disseminating information in today's digital age.\n\n3. Emphasizing the concept of health and wellness: Apples are also commonly associated with health and well-being due to the famous saying, \"an apple a day keeps the doctor away.\" In the context of the image, placing an apple on a laptop keyboard might serve as a reminder to maintain a balance between work or screen time and adopting healthier habits, such as proper nutrition or taking breaks to go for a walk or exercise.\n\nIn summary, placing an apple on a MacBook Pro laptop can symbolize various ideas, including a visual pun, the connection between knowledge and technology, or as a reminder to maintain a healthy work-life balance. The specific meaning may vary depending on the context in which the image is presented or the message it aims to convey."}]}, {"id": "000000426976", "image": "coco/train2017/000000426976.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the main object in the image?"}, {"from": "gpt", "value": "The main object in the image is a red stop sign."}, {"from": "human", "value": "Does the stop sign have anything on its surface?"}, {"from": "gpt", "value": "Yes, the stop sign is covered with tagging, graffiti, and stickers."}, {"from": "human", "value": "What is the purpose of a stop sign?"}, {"from": "gpt", "value": "The purpose of a stop sign is to regulate traffic at intersections or junctions, ensuring that vehicles come to a complete stop before proceeding. This helps prevent collisions, maintain traffic flow, and improve road safety for drivers, pedestrians, and cyclists."}, {"from": "human", "value": "Is the visibility of the stop sign affected by the graffiti and stickers?"}, {"from": "gpt", "value": "While it is still possible to recognize the stop sign as a traffic control sign, the presence of graffiti and stickers could negatively affect its visibility and clarity. This may lead to confusion, misinterpretation, or even dangerous situations where drivers might not promptly recognize and obey the stop sign. To maintain a safe driving environment, it is essential that traffic signs are kept clear of any obstructions or defacements that may impair their purpose and functionality."}, {"from": "human", "value": "What can be done to restore the stop sign or address the issue of graffiti and stickers on traffic signs?"}, {"from": "gpt", "value": "To restore and maintain traffic signs, local authorities can adopt several measures to address the issue of graffiti and stickers:\n\n1. Removal and cleaning: Regular inspection and cleaning of traffic signs can ensure that tagging, graffiti, or stickers are promptly removed, preserving the sign's visibility and effectiveness. This may involve using cleaning solutions or specialized equipment designed to remove paint and adhesive materials without damaging the sign's surface. In severe cases of defacement, the sign may need to be replaced entirely.\n\n2. Prevention and enforcement: Local authorities can work to prevent vandalism and illegal activities by implementing stricter penalties or fines for those caught defacing or placing stickers on traffic signs. Public awareness campaigns can also help educate the community about the hazards and consequences of vandalizing traffic signs.\n\n3. Community involvement: Engaging the community in traffic sign maintenance and reporting vandalism can foster a sense of responsibility and civic pride among residents. Initiatives such as neighborhood watch programs and partnerships with local businesses, schools, and organizations can encourage individuals to take an active role in preserving their community's safety and appearance.\n\n4. Aesthetic alternatives: Encouraging artists to create public art projects in designated spaces can provide a legal and welcomed outlet for creative expression, potentially reducing the temptation to vandalize traffic signs.\n\nThrough a combination of regular maintenance, enforcement, community involvement, and supporting artistic endeavors, it is possible to effectively address the issue of graffiti and stickers on traffic signs, ensuring that they remain visible, functional, and safe for all road users."}]}, {"id": "000000103355", "image": "coco/train2017/000000103355.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of tools and supplies can be seen in the image?"}, {"from": "gpt", "value": "The image features a variety of crafting and sewing tools and supplies, including scissors, needle, yarn, paper guide, pattern, wires, zip ties, and a cutting mat. These items are laid out on a table, indicating that someone is likely preparing to work on a project."}, {"from": "human", "value": "What sort of project does it seem like the person is about to embark on?"}, {"from": "gpt", "value": "Based on the tools and supplies visible in the image, it seems that the person is preparing to work on a sewing or crafting project that involves cutting, stitching, and possibly assembling different materials. This could involve creating a garment, an accessory, or another type of handmade item, using a combination of sewing techniques and other crafting skills."}, {"from": "human", "value": "What is the purpose of a cutting mat in sewing and crafting projects?"}, {"from": "gpt", "value": "A cutting mat serves as a protective surface for cutting materials and helps to ensure the accuracy and precision of the cuts being made. It is designed to withstand the pressure from sharp blades, such as scissors or rotary cutters, without being easily damaged. Cutting mats often feature grid lines, measurements, and angle guides to assist with accurate cutting and aligning of materials. Using a cutting mat not only protects the table or working surface from scratches and damage caused by cutting tools but also helps to prolong the life of the tools themselves, as the mat provides a suitable surface for the blades to work against without dulling them too quickly. Overall, a cutting mat is an essential tool in sewing and crafting projects for both practical and safety reasons."}]}, {"id": "000000465353", "image": "coco/train2017/000000465353.jpg", "conversations": [{"from": "human", "value": "What color are the umbrellas outside the building?\n<image>"}, {"from": "gpt", "value": "The umbrellas outside the building are green."}, {"from": "human", "value": "What are the people doing outside the building?"}, {"from": "gpt", "value": "The people are walking outside the building, likely patronizing the establishment, which could be a restaurant or a caf\u00e9."}, {"from": "human", "value": "Is there a vehicle parked near the building, and if so, what is in the background?"}, {"from": "gpt", "value": "Yes, there is a four-wheeler parked near the building with a mountain in the background."}, {"from": "human", "value": "How is the weather in the image, considering the presence of umbrellas?"}, {"from": "gpt", "value": "The presence of green umbrellas suggests that the weather is sunny or warm. These umbrellas are likely providing shade for customers outside the restaurant or caf\u00e9, allowing them to enjoy the outdoors comfortably."}]}, {"id": "000000250380", "image": "coco/train2017/000000250380.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many people are there in the image?"}, {"from": "gpt", "value": "There are two people in the image."}, {"from": "human", "value": "What is the dog's color?"}, {"from": "gpt", "value": "The dog is black."}, {"from": "human", "value": "What are the people doing with the dog?"}, {"from": "gpt", "value": "The two people are running and playing with the dog, trying to get it to release the frisbee in its mouth."}, {"from": "human", "value": "What is the setting of this image?"}, {"from": "gpt", "value": "The setting of the image is a park-like area with green and flowering trees on a bright, clear day."}, {"from": "human", "value": "What kind of activity is suitable in this park-like area?"}, {"from": "gpt", "value": "In this park-like area, various outdoor activities are suitable, such as walking, jogging, playing with pets, family picnics, playing games like frisbee or catch, and enjoying nature. The open green space and pleasing environment make it perfect for socializing, exercise, and leisure activities. The presence of flowering trees also provides aesthetic appeal and offers excellent opportunities for photography or relaxation under the shade. People of all ages can take advantage of the park-like setting to embrace the outdoors and engage in different forms of recreation."}]}, {"id": "000000170235", "image": "coco/train2017/000000170235.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the baseball player swinging at a ball during a game or taking practice swings?"}, {"from": "gpt", "value": "The baseball player is swinging at a ball during a game. They have taken a swing at a pitch at home plate with the umpire and catcher present."}, {"from": "human", "value": "What is the position and role of the batter in this image?"}, {"from": "gpt", "value": "The batter's role in this image is to hit the baseball thrown by the opposing team's pitcher. They are positioned at home plate and have just swung at the pitch."}, {"from": "human", "value": "What are the umpire and catcher doing during this moment?"}, {"from": "gpt", "value": "During this moment, the umpire is standing behind the catcher observing the pitch and determining whether it is a strike or a ball. The catcher is squatting behind home plate, wearing protective gear, and is ready to catch the pitch if it is not hit by the batter."}, {"from": "human", "value": "Can you provide a brief explanation of the basic rules of swinging in baseball?"}, {"from": "gpt", "value": "In baseball, a batter's primary objective is to hit the ball thrown by the opposing team's pitcher. Swinging in baseball involves following specific guidelines and strategies to maximize the chances of successful contact between the bat and the ball. Here are some basic rules and concepts related to swinging in baseball:\n\n1. The Strike Zone: The strike zone is an imaginary box that extends from the batter's knees to the midpoint between their shoulders and the top of their pants, and it spans the width of home plate. The umpire uses the strike zone to determine if a pitch is a strike or a ball. If the pitch is within the strike zone and the batter does not swing, the pitch is called a strike. If it is outside the strike zone and the batter does not swing, the pitch is called a ball. Batters must be selective in their swings, aiming to hit pitches within the strike zone while laying off pitches outside the zone.\n\n2. Strikes, Balls, and Foul Balls: A strike occurs when a batter swings and misses the ball, when the ball is hit into foul territory without being caught, or when the batter does not swing at a pitch that passes through the strike zone. A ball is called when the batter does not swing at a pitch outside the strike zone. If a batter accumulates three strikes, they are out. If they get four balls, they are awarded a walk to first base. Foul balls can count as strikes, but a batter cannot be struck out on a foul ball unless it is caught in the air.\n\n3. Timing and Mechanics: Timing and proper mechanics are essential for successful swinging in baseball. Batters must time their swings to make solid contact with the ball and utilize good body mechanics to generate power and accuracy. The swing should be smooth, fluid, and well-coordinated, with the batter transferring their weight from the back foot to the front foot, rotating their hips, and extending their arms to make contact with the ball. A well-timed and well-executed swing can result in hits, ranging from singles to home runs, depending on the ball's trajectory and distance traveled.\n\nIn summary, swinging in baseball involves decision-making, adherence to the rules related to the strike zone and pitch counts, and mastering proper timing and mechanics to maximize the chances of successful contact between the bat and the ball."}]}, {"id": "000000382890", "image": "coco/train2017/000000382890.jpg", "conversations": [{"from": "human", "value": "What type of buses are seen in the image?\n<image>"}, {"from": "gpt", "value": "There are two red double-decker buses in the image."}, {"from": "human", "value": "Where are the double-decker buses located?"}, {"from": "gpt", "value": "The double-decker buses are located on the side of the street or road."}, {"from": "human", "value": "Are the buses next to each other or parked separately?"}, {"from": "gpt", "value": "The two double-decker buses are next to each other on the street."}, {"from": "human", "value": "What might be the purpose of these double-decker buses in the context where they are located?"}, {"from": "gpt", "value": "The presence of two red double-decker buses in the image suggests that they serve as a form of public transportation, which is particularly common in some regions and cities, such as London in the United Kingdom. These buses are designed to accommodate a larger number of passengers due to their two-level structure, making them an efficient and iconic mode of transport for urban areas with high passenger density.\n\nDouble-decker buses play an essential role in keeping the cities more easily navigable and less reliant on private cars, contributing to reducing road traffic congestion and air pollution. Furthermore, these distinctive buses also act as a tourist attraction in some cities, where sightseeing tours are conducted using open-top or specially-designed double-decker buses to provide panoramic views of popular landmarks and points of interest.\n\nIn the context of the image, the two red double-decker buses parked on the side of the street could be waiting for passengers, taking a break between shifts, or be temporarily out of service for maintenance or operational reasons."}]}, {"id": "000000011065", "image": "coco/train2017/000000011065.jpg", "conversations": [{"from": "human", "value": "What are the two people doing near the horse?\n<image>"}, {"from": "gpt", "value": "The two people are interacting with the horse - a man is reaching down to touch the horse's hoof, while a woman is holding the bridle."}, {"from": "human", "value": "What color is the horse in the image?"}, {"from": "gpt", "value": "The horse in the image is brown."}, {"from": "human", "value": "Where is the horse standing?"}, {"from": "gpt", "value": "The horse is standing on the grass."}, {"from": "human", "value": "Are the two people in the image male or female?"}, {"from": "gpt", "value": "In the image, there is one man and one woman interacting with the horse. The man is touching the horse's hoof, and the woman is holding the bridle."}, {"from": "human", "value": "What might be the purpose of the man touching the horse's hoof?"}, {"from": "gpt", "value": "The man might be touching the horse's hoof for a variety of reasons, such as checking for any signs of injury, discomfort, or ensuring that the hooves are well-maintained. Proper hoof care is essential for a horse's health and well-being, as it can prevent various issues like lameness or infection. \n\nThe man could also be a farrier or a veterinarian, conducting a professional examination to assess the horse's hoof condition and provide necessary care like shoeing, trimming, or treatment. Another possibility is that the man could be a horse owner, trainer, or a casual observer, demonstrating his fondness or curiosity for the horse by gently exploring its hooves. \n\nIn any case, the man's action of touching the horse's hoof indicates a level of familiarity, trust, and interest in the animal's welfare. It also suggests that the horse is comfortable and well-behaved around people, allowing them to safely approach and interact with it."}]}, {"id": "000000043383", "image": "coco/train2017/000000043383.jpg", "conversations": [{"from": "human", "value": "Explain the visual content of the image in great detail.\n<image>"}, {"from": "gpt", "value": "The scene features a lush green grassy hillside that is occupied by a herd of sheep. There are at least 13 sheep distributed across the field, with some grazing on the grass and others standing peacefully. The sheep are scattered in various positions, some closer to the foreground and others further away on the hillside. The verdant landscape provides a peaceful and serene environment for the animals to graze and wander."}]}, {"id": "000000116123", "image": "coco/train2017/000000116123.jpg", "conversations": [{"from": "human", "value": "<image>\nExplain the visual content of the image in great detail."}, {"from": "gpt", "value": "The image shows a calm waterway near a marina, with several birds enjoying the water. A variety of swans, ducks, and smaller birds can be seen swimming and sitting in the water. Among the birds, there are 14 prominent individuals visible, scattered across the waterway.\n\nThe marina features numerous boats docked nearby, with a total of 13 boats of various sizes and shapes in the background. The boats and birds create a serene, bustling scene typically found at a marina."}]}, {"id": "000000003915", "image": "coco/train2017/000000003915.jpg", "conversations": [{"from": "human", "value": "Can you elaborate on the elements of the picture provided?\n<image>"}, {"from": "gpt", "value": "In this image, a woman wearing an apron is standing in a kitchen, preparing food for a large meal. She is surrounded by various kitchen tools and appliances, such as a refrigerator, an oven, a sink, and a microwave. The counter in front of the woman is full of dishes, including several white plates, bowls, and a vase. \n\nNumerous utensils, like knives and spoons, are also scattered across the counter, indicating that they are being used during the food preparation process. Furthermore, the kitchen features some decorative elements, such as potted plants adorning the space, and a chair can be seen near the edge of the room."}]}, {"id": "000000575305", "image": "coco/train2017/000000575305.jpg", "conversations": [{"from": "human", "value": "What do you see happening in this image?\n<image>"}, {"from": "gpt", "value": "The image presents a baseball game with multiple players and spectators. The central focus is a baseball player swinging his bat at a ball, attempting to hit it skillfully. The ball is floating in the air, relatively close to the batter. The pitcher and other players are also visible in the scene, some wearing baseball gloves and ready to react to the play.\n\nAround the field, there are people seated in various chairs, watching the game intently. One person is even holding a book, which might indicate they're reading during breaks in the action. Overall, the atmosphere seems exciting and competitive, as everyone appears to be engrossed in the game."}]}, {"id": "000000005260", "image": "coco/train2017/000000005260.jpg", "conversations": [{"from": "human", "value": "Can you elaborate on the elements of the picture provided?\n<image>"}, {"from": "gpt", "value": "The image depicts a Little League baseball game in progress, with several players and an umpire on the field. A young boy is at home plate, standing in a ready position, holding a baseball bat, and preparing to swing. Behind him is the catcher, wearing a baseball glove, and the umpire closely monitoring the game.\n\nThere are many other players on the field, distributed across various positions. Some are closer to the foreground near home plate, while others are farther away and playing in the outfield. The scene offers a lively atmosphere typical of a spirited youth baseball game."}]}, {"id": "000000083738", "image": "coco/train2017/000000083738.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat are the key elements in this picture?"}, {"from": "gpt", "value": "The image features a white tiled bathroom with a clean and minimalist design. There is a toilet placed against the wall, accompanied by a sink on its left side. Above the sink, there is a mirror reflecting the bathroom interior.\n\nSeveral cups and toothbrushes can be observed. On the right side of the sink, two cups and a toothbrush seem to be placed beside each other, whereas on the left side, one more cup and toothbrush can be spotted. Another cup is resting near the middle of the sink. Overall, the bathroom is organized and has all the necessary essentials one would expect."}]}, {"id": "000000160573", "image": "coco/train2017/000000160573.jpg", "conversations": [{"from": "human", "value": "What do you think is going on in this snapshot?\n<image>"}, {"from": "gpt", "value": "The image features two women sitting at a table inside a donut shop, enjoying their time together. They are proudly showing off their funny shaped donuts, each holding one in their hands. The women are seated across from each other at the dining table, with one woman positioned more toward the left side of the table and the other woman on the right side.\n\nAdditional people can be seen at the other dining tables in the background\u2014one on the left and another on the far right. A few cups and bowls are visible close to the edge of the scene at the right side, likely used for drinks or condiments in the shop."}]}, {"id": "000000039064", "image": "coco/train2017/000000039064.jpg", "conversations": [{"from": "human", "value": "Describe the following image.\n<image>"}, {"from": "gpt", "value": "The image depicts a hockey player standing on the ice, surrounded by numerous stuffed animals. It seems that these toys have been tossed into the rink, creating an unusual scene. In addition to the main hockey player, several other people can be seen around the area, though they appear smaller and farther from the focal point. \n\nThere are at least eight teddy bears scattered across the ice, varying in size and position. Some of the toys are close together, while others are spread out. The hockey player appears to be observing the situation with interest, likely wondering about the unexpected presence of the stuffed animals on the ice."}]}, {"id": "000000520769", "image": "coco/train2017/000000520769.jpg", "conversations": [{"from": "human", "value": "Can you elaborate on the elements of the picture provided?\n<image>"}, {"from": "gpt", "value": "The image features a young girl in a dark blue uniform standing on a sports field. She is in the middle of pitching a softball, throwing it underhanded during a game. Another person can be seen on the field, likely a teammate or an opponent. Two baseball gloves are visible, one near the girl and the other further to the left on the field.\n\nThe field is surrounded by a parking area with numerous cars and two trucks parked, indicating that it might be a local community sports event or a recreational match. The vehicles are positioned on the top and left sides of the field, with different models and sizes being present."}]}, {"id": "000000216766", "image": "coco/train2017/000000216766.jpg", "conversations": [{"from": "human", "value": "Describe the following image.\n<image>"}, {"from": "gpt", "value": "The image captures a serene scene by the ocean, where a person is resting on a bench with their bicycle parked nearby. It appears to be a windy day at the beach, as several birds are flying around at various distances in the scene. The bench is located close to the water, offering a picturesque view.\n\nSome of the person's belongings, such as a backpack and a handbag, can be seen placed close to the bench. The backpack is resting on the ground, while the handbag is placed slightly above it. In the distance, a boat is visible on the water, adding to the overall coastal atmosphere."}]}, {"id": "000000469988", "image": "coco/train2017/000000469988.jpg", "conversations": [{"from": "human", "value": "<image>\nDescribe the following image."}, {"from": "gpt", "value": "The image portrays a living room with wooden floors and various pieces of furniture. There is a couch near the middle of the room and two chairs, one on the left side and the other closer to the lower left corner. \n\nThe focal point of the scene is a cluster of bags on the floor in the middle of the room. It includes several backpacks, a handbag, and a suitcase. The bags are piled on top of each other and placed on a rug. This accumulation of luggage makes the room appear to be used for storage or packing for a trip."}]}, {"id": "000000261381", "image": "coco/train2017/000000261381.jpg", "conversations": [{"from": "human", "value": "<image>\nExplain the visual content of the image in great detail."}, {"from": "gpt", "value": "It is an old black and white photograph displaying a group of four men sitting next to each other on a bench outdoors. Each of the men is wearing a tie, with the first man on the left having his tie visible between the first man and the second man, the second man's tie can be seen below his neck, the third man's tie can be observed between the third and fourth man, and the tie of the fourth man on the right is visible below his neck.\n\nIn the background, two vintage cars are parked, one behind the first two men on the left side of the photo and another behind the last two men on the right side of the photo. The presence of these cars adds to the nostalgic atmosphere of the photograph."}]}, {"id": "000000111831", "image": "coco/train2017/000000111831.jpg", "conversations": [{"from": "human", "value": "<image>\nCan you describe the main features of this image for me?"}, {"from": "gpt", "value": "The image captures a bustling scene of a busy city street at night. The street is packed with a large number of people standing at a corner, waiting to cross the intersection. There are at least 11 pedestrians visible in the scene, some of them wearing backpacks. The crowd adds to the vibrant atmosphere of the urban environment.\n\nIn addition to the heavy foot traffic, there are several vehicles on the street, including three buses and two cars, contributing to the busy atmosphere. Assisting the flow of traffic are traffic lights; four traffic lights can be spotted in this scene.\n\nThe intersection is well-lit, with street lights illuminating the area and providing a sense of security for the pedestrians and commuters alike. Overall, the image portrays the energy and liveliness of the city at night."}]}, {"id": "000000465196", "image": "coco/train2017/000000465196.jpg", "conversations": [{"from": "human", "value": "What is this photo about'?\n<image>"}, {"from": "gpt", "value": "A woman wearing a bright red jacket is standing on skis in the snow under a cloudy sky, smiling at the camera. She appears to be the main subject of the photo as she takes up a significant portion of the image. Surrounding her, there are several other people visible at various distances, seemingly also enjoying their time in the snowy environment. Some of these people are closer to the background, while others are scattered around the area.\n\nIn addition to the main woman, there is another pair of skis seen further back on the right side of the image. Interestingly, there is also a bus depicted in the scene, probably used for transportation to and from the skiing area."}]}, {"id": "000000286877", "image": "coco/train2017/000000286877.jpg", "conversations": [{"from": "human", "value": "What are the key elements in this picture?\n<image>"}, {"from": "gpt", "value": "The image captures an empty subway train car with its lights on. Numerous yellow and blue seats are laid out, offering plenty of seating options for passengers. The seats are arranged in the form of benches and individual chairs, with some lined along the car's walls and others in rows, facing each other. \n\nThe subway car seems well-lit, with no passengers currently occupying any of the seats, creating a spacious and vacant atmosphere."}]}, {"id": "000000408266", "image": "coco/train2017/000000408266.jpg", "conversations": [{"from": "human", "value": "<image>\nCan you elaborate on the elements of the picture provided?"}, {"from": "gpt", "value": "The image features a young boy sitting at a dining table, holding a slice of pizza in his hands. He appears a bit sullen or sad while eating the pizza. There are multiple chairs surrounding the table, and a bowl can be seen placed on the table as well.\n\nThere are several other people in various parts of the scene, though their involvement or interactions with the main subject are not clear. The dining area seems to be the primary focus of the picture, and the boy with the pizza is the main subject of interest."}]}, {"id": "000000532175", "image": "coco/train2017/000000532175.jpg", "conversations": [{"from": "human", "value": "Write a detailed description of the given image.\n<image>"}, {"from": "gpt", "value": "The scene takes place in a busy city intersection with cars and people moving about. A woman wearing a white dress is riding a bicycle, making her way through the bustling street alongside other cyclists. There are multiple people walking and crossing the intersection, as well as a man walking close to the woman on the bicycle. \n\nSeveral cars are present in the streets around the cyclists and pedestrians, coming from various directions. Traffic lights can be seen placed on different corners and locations throughout the intersection, helping control the flow of traffic in the busy area. Additionally, there are a couple of handbags seen around the commuters \u2013 one closer to the center of the intersection and another below the person walking in the scene."}]}, {"id": "000000258611", "image": "coco/train2017/000000258611.jpg", "conversations": [{"from": "human", "value": "What are the key elements in this picture?\n<image>"}, {"from": "gpt", "value": "The image shows a man sitting alone on a red couch, relaxing in a spacious living room near some windows. A suitcase is placed next to him on the floor, suggesting that he may have recently arrived or is preparing to leave. A backpack can also be seen close to the couch. \n\nIn the room, there is a dining table positioned further back and several chairs are scattered around the area. On the table, there are two books placed close to each other and a bowl located at the far end. The space has a loft apartment vibe, adding a warm and cozy ambiance to the scene."}]}, {"id": "000000447994", "image": "coco/train2017/000000447994.jpg", "conversations": [{"from": "human", "value": "Can you describe the main features of this image for me?\n<image>"}, {"from": "gpt", "value": "There is a dining table in the scene where four wine glasses are sitting, each one partially filled with wine. The glasses are spread out across the table, with some placed closer to other objects on the table. \n\nIn addition to the wine glasses, there are several books and a bowl on the table. The books appear to be stacked, with one placed further up on the table and the others just below it. The bowl is located near the left side of the table, closer to the middle. Overall, the scene depicts a casual and relaxed environment, perhaps an intimate gathering or a quiet evening at home."}]}, {"id": "000000543201", "image": "coco/train2017/000000543201.jpg", "conversations": [{"from": "human", "value": "<image>\nDescribe the following image."}, {"from": "gpt", "value": "The image portrays a young red-haired girl standing on a patio and holding a green umbrella. She is surrounded by various potted plants and flowers, with some placed close to her and others further away. \n\nOne potted plant is located to the left of the girl, while another can be seen above her on the porch. More potted plants are situated at different points around the scene. A chair is also present near the patio, resting above the little girl's head. The charming scene creates a sense of youthful playfulness and an appreciation for nature."}]}, {"id": "000000025461", "image": "coco/train2017/000000025461.jpg", "conversations": [{"from": "human", "value": "Write a detailed description of the given image.\n<image>"}, {"from": "gpt", "value": "In the image, a group of people is gathered on a grass-covered field, possibly forming an oriental musical group as some are holding drums. They are standing in a clearing with a festive and engaging atmosphere. \n\nThere are a total of ten people in the group, with some looking up, possibly at kites flying above them as two kites are visible in the sky. A few people are holding their belongings nearby, with a backpack and a handbag spotted on the grass.\n\nIn the background, there are two trucks and a bus parked, indicating that they might have arrived at the field in those vehicles. The scene appears to be taking place at a park, with people enjoying each other's company and engaging in various activities."}]}, {"id": "000000292053", "image": "coco/train2017/000000292053.jpg", "conversations": [{"from": "human", "value": "What do you see happening in this image?\n<image>"}, {"from": "gpt", "value": "The scene depicts a large group of people on motorcycles gathered on a city street. There are several motorcycles scattered throughout the image. Among the motorcyclists, two people are dressed in bear costumes, riding on a black motorcycle. The motorcycle is equipped with a sidecar, which has a stuffed teddy bear seated in it. The couple wearing bear costumes appear to be making a statement as they have signs saying \"No to the bike parking tax.\"\n\nIn addition to the couple in bear costumes and the stuffed teddy bear, there are many other people visible in the scene, both on and off motorcycles, making it a lively gathering on the city street."}]}, {"id": "000000012283", "image": "coco/train2017/000000012283.jpg", "conversations": [{"from": "human", "value": "What is this photo about'?\n<image>"}, {"from": "gpt", "value": "The image depicts a vibrant street corner bustling with activity. A crowd of people, including more than ten pedestrians, can be seen walking across the street and down the sidewalk. They appear to be townspeople taking a leisurely stroll. \n\nIn the midst of this urban scene, there is a horse crossing the street and stepping up onto a sidewalk near a group of people. The area also features multiple cars parked along the curbside or moving on the road, as well as a bicycle in the background. \n\nA stop sign is visible in the corner, indicating that the area is regulated for safety and order amidst the busy conditions. The overall atmosphere suggests a lively and engaging environment where people and a horse are sharing the public space."}]}, {"id": "000000114879", "image": "coco/train2017/000000114879.jpg", "conversations": [{"from": "human", "value": "What do you see happening in this image?\n<image>"}, {"from": "gpt", "value": "The image captures a lively beach scene, with a group of people enjoying their time both walking and sitting on the coast. There is a man sitting in a colorful lounge chair close to the water, taking in the atmosphere and relaxing.\n\nIn the company of this man, there are several other people leisurely walking along the shore. Some are closer to him while others are positioned farther away, all contributing to the vibrant, bustling vibe of the beach. Additionally, there is another chair located near the sitting man, showing that this beach is an inviting spot for visitors to take a break.\n\nIn the background, a boat can be spotted floating on the ocean, further enhancing the scenic view of the coast."}]}, {"id": "000000422170", "image": "coco/train2017/000000422170.jpg", "conversations": [{"from": "human", "value": "<image>\nWrite a detailed description of the given image."}, {"from": "gpt", "value": "The image features a group of people sitting on outdoor bleachers, enjoying the sun. There is a lady prominently seated on the bleachers, using her cellphone. Other people are scattered around her, either chatting or enjoying the surroundings.\n\nThere is a bottle placed on the bleachers, likely belonging to someone in the group. A handbag can also be seen towards the bottom of the bleachers, and a book is placed nearby, possibly for someone to read during their leisure time."}]}, {"id": "000000501565", "image": "coco/train2017/000000501565.jpg", "conversations": [{"from": "human", "value": "Can you elaborate on the elements of the picture provided?\n<image>"}, {"from": "gpt", "value": "The scene features a group of excited children gathered around a dining table with a cake positioned in the center. Many of the children are wearing party hats, indicating a festive occasion. A woman is standing near the table, possibly overseeing the cake cutting process and keeping the children engaged. The children appear to be eagerly waiting for their share of the cake. \n\nA couple of chairs can be spotted around the table, and a book is placed on the surface of the table alongside various spoons arranged in different sections on the table. There is also a knife close to the cake, which will likely be used for cutting it. A cup is placed near the table, ready to be used during the celebration."}]}, {"id": "000000463464", "image": "coco/train2017/000000463464.jpg", "conversations": [{"from": "human", "value": "<image>\nExplain the visual content of the image in great detail."}, {"from": "gpt", "value": "In the image, there is a large kitchen grill with a variety of food being cooked on top. There are three slices of French toast and hash browns sizzling on the surface, along with a few grilled cheese sandwiches. \r\n\r\nThe kitchen environment features an oven situated on the left side and various utensils, such as knives and a spoon, placed around. Some of these utensils are resting near the grill while others are positioned elsewhere in the room. There is also a bowl visible in the kitchen, likely containing ingredients or additional food items."}]}, {"id": "000000189912", "image": "coco/train2017/000000189912.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat's happening in the scene?"}, {"from": "gpt", "value": "The image shows a group of people gathered in an airport, waiting for their luggage. In total, there are about 13 people visible in the scene, each positioned at various points around a busy luggage carousel. Some people are lined up, while others are standing individually, focusing on their bags arriving on the conveyor belt.\n\nSeveral suitcases can be seen on the conveyor belt, with one large suitcase towards the right side and another closer to the center. A handbag is also visible on the belt, positioned near the left part of the scene. One person in the scene is wearing a tie, which indicates a level of formality in their attire. In general, the passengers are all waiting patiently, milling around as they anticipate the retrieval of their luggage."}]}, {"id": "000000167505", "image": "coco/train2017/000000167505.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat are the key elements in this picture?"}, {"from": "gpt", "value": "The image depicts a street scene with a blue, two-tiered British tour bus taking a turn on a residential street. The double-decker bus is the central focus of the picture and is surrounded by several smaller cars driving behind it.\n\nIn addition to the vehicles, there are many people on the sidewalks of the street. Some are near the bus and others are dispersed along the street, likely engaging in various activities such as walking, waiting for the bus, or observing the traffic.\n\nOverall, the scene showcases a busy street with a mix of cars, a bus, and pedestrians, creating a lively urban atmosphere."}]}, {"id": "000000421542", "image": "coco/train2017/000000421542.jpg", "conversations": [{"from": "human", "value": "Write a detailed description of the given image.\n<image>"}, {"from": "gpt", "value": "In the image, a man is standing in a small kitchen, preparing food on an electric stove. He is focused on the task, stirring a pot placed on top of the stove. There are a total of four ovens present in the kitchen area, with one of them right next to the man.\n\nThe kitchen is equipped with a refrigerator which is located on the left side of the man. Additionally, there are two bowls placed on the countertop and a spoon can be seen nearby, possibly used for cooking. A sink is also present in the kitchen, situated below the countertop. On the side, a laptop is found, perhaps being used to follow a recipe or for entertainment while cooking."}]}, {"id": "000000515062", "image": "coco/train2017/000000515062.jpg", "conversations": [{"from": "human", "value": "Write a detailed description of the given image.\n<image>"}, {"from": "gpt", "value": "The image displays a white box containing twelve delicious cupcakes arranged in a neat pattern. Each of these cupcakes is topped with sweet treats such as chocolates and marshmallows, adding an extra touch of indulgence. The cupcakes are evenly distributed within the box, showcasing a full view of their appetizing dessert creations for everyone to admire. The assortment of toppings and decorations makes the cupcakes look tempting and ready to be enjoyed."}]}, {"id": "000000092585", "image": "coco/train2017/000000092585.jpg", "conversations": [{"from": "human", "value": "<image>\nAnalyze the image in a comprehensive and detailed manner."}, {"from": "gpt", "value": "The image features a white boat floating on a large body of blue ocean water. The boat seems to be a fishing boat, carrying a lot of stuff within it, which may include fishing equipment or various items for the crew aboard.\n\nIn addition to the boat, there are several birds scattered throughout the sky, some flying closer to the water, while others are placed higher up in the sky. These birds may be drawn to the boat's activities or simply enjoying the ocean breeze."}]}, {"id": "000000459003", "image": "coco/train2017/000000459003.jpg", "conversations": [{"from": "human", "value": "<image>\nCan you describe the main features of this image for me?"}, {"from": "gpt", "value": "The image shows a group of people walking down a city street during a snowstorm. The weather is quite wintery, and the snow is creating a blizzard-like scene. The pedestrians appear to be braving the cold as they make their way through the snowy environment.\n\nThere are several handbags visible among the people, indicating that this might be a busy city setting despite the harsh weather conditions. A clock can be seen in the upper area of the image, indicating the time for passersby in the city. Overall, the scene demonstrates the resilience of people navigating through a snowy, urban landscape."}]}, {"id": "000000436073", "image": "coco/train2017/000000436073.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat do you see happening in this image?"}, {"from": "gpt", "value": "The image features a young child wrapped in a towel, standing in a bathroom. The child is getting their teeth brushed with a pink toothbrush. A second person is visible in the scene, likely assisting the child with brushing their teeth. \n\nSurrounding them are numerous bottles on various surfaces, possibly containing toiletries or bathroom essentials. In the background, there is a toilet visible to the left of the scene. The focus of the scene remains on the child's dental hygiene routine."}]}, {"id": "000000139571", "image": "coco/train2017/000000139571.jpg", "conversations": [{"from": "human", "value": "Write a detailed description of the given image.\n<image>"}, {"from": "gpt", "value": "A group of people are gathered around a dining table in a celebratory mood. At the center of the gathering, a cake is being cut using a sword-like knife. Two men in white uniforms are actively cutting the cake while other uniformed individuals watch intently. It appears that the people in the room might belong to two different nationalities, as they join in this joyous ceremony together."}]}, {"id": "000000187280", "image": "coco/train2017/000000187280.jpg", "conversations": [{"from": "human", "value": "<image>\nDescribe the following image."}, {"from": "gpt", "value": "The image showcases a city street with two red double-decker buses driving down the road. One of the buses is closer to the foreground, while the other can be seen further down the street. There is a third vehicle, a car, parked on the side of the road. The buses and the car are approaching an intersection with a crosswalk and a side road.\n\nSeveral people can be seen around the street, with one person standing near the car, two people closer to the center of the scene, and another near the edge of the image, possibly waiting to cross the road. Two handbags are also visible in the scene - one near the middle and the other on the right side.\n\nThe presence of traffic lights at the intersection helps to regulate the flow of vehicles, with one traffic light visible on the left side and another on the right side of the street. A building can also be observed on one side of the intersection, contributing to the urban landscape."}]}, {"id": "000000545538", "image": "coco/train2017/000000545538.jpg", "conversations": [{"from": "human", "value": "<image>\nDescribe the following image."}, {"from": "gpt", "value": "The image features a group of people gathered around a dirt field, watching a herd of elephants in a park-like setting. There are several people in the scene, with some clustered on the left side and others spread out across the rest of the field. Among them, at least eleven people can be seen clearly watching the elephants. \n\nThree elephants are visible in the field. One elephant is quite large and located near the right edge of the frame, while another elephant, slightly smaller, can be seen closer to the middle of the image. The third elephant is found in the upper right portion of the scene.\n\nLastly, there is a handbag placed on the ground on the left side of the image, possibly belonging to one of the people observing the elephants."}]}, {"id": "000000210187", "image": "coco/train2017/000000210187.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is this photo about'?"}, {"from": "gpt", "value": "In the image, a young girl is sitting at a wooden dining table, enjoying a doughnut. She is surrounded by various chairs, with some situated around the table where she is eating, and others placed near additional dining tables in the background. \n\nThe restaurant has a mix of different-sized chairs, placed in different arrangements. A bottle can also be seen on one of the tables, adding to the casual dining atmosphere. The overall scene has a comfortable and inviting feel, with the young girl happily indulging in her treat."}]}, {"id": "000000387368", "image": "coco/train2017/000000387368.jpg", "conversations": [{"from": "human", "value": "<image>\nCan you elaborate on the elements of the picture provided?"}, {"from": "gpt", "value": "The image displays a lavishly decorated living room with various art treasures and flower arrangements. Two people are present in the room, with a man bending down attending to a woman who is sitting. The furniture in the room includes a couch on the left side and two chairs, one towards the right side and another in the middle of the room. \n\nThe living space is adorned with several potted plants, vases, and a clock mounted on the yellow wall. There are three vases located in the center area, two more towards the right, and one near the right edge of the room. A total of four potted plants are dispersed around the room, adding to the ambiance. A handbag is also visible near the people, placed on the floor. The room showcases a cozy waiting area with sophisticated decor."}]}, {"id": "000000276739", "image": "coco/train2017/000000276739.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat do you see happening in this image?"}, {"from": "gpt", "value": "The image showcases an indoor display featuring a collection of motorcycles. These motorcycles are parked in a row next to one another, creating an impressive lineup. A uniquely modified motorcycle with four seats stands out among the display, drawing attention with its design that accommodates multiple passengers.\n\nIn addition to the motorcycles, two people can be observed in the scene, possibly admiring the vehicles on display or discussing their features. There are also a couple of chairs in the room, placed near the front of the display area."}]}, {"id": "000000488547", "image": "coco/train2017/000000488547.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat do you think is going on in this snapshot?"}, {"from": "gpt", "value": "The image features a man in a plaid jacket walking up a wet flight of stairs that leads underground, with buildings visible in the background. The staircase likely soaks with rain, giving a sense of a rainy day in the city. Another person can be seen standing not too far away from the man on the stairs. \n\nAround the scene, several chairs are scattered throughout the area. The chairs are positioned in various arrangements, suggesting that they may be part of an outdoor seating area, possibly associated with a nearby building or a public space. A car is also visible in the background, blending into the urban landscape."}]}, {"id": "000000427283", "image": "coco/train2017/000000427283.jpg", "conversations": [{"from": "human", "value": "Explain the visual content of the image in great detail.\n<image>"}, {"from": "gpt", "value": "The image features a train station where a purple-pink passenger train is stopped at the platform. The train occupies most of the image, stretching from the middle of the platform to the far end.\n\nNumerous people are present at the platform, with some boarding and unboarding the train. There are people standing near the back, middle, and front sections of the train. Additionally, there are individuals scattered across the platform, some of which are carrying handbags and backpacks.\n\nA second, smaller train can be seen in the background, positioned further away, indicating a busy train station with multiple tracks for passengers."}]}, {"id": "000000411969", "image": "coco/train2017/000000411969.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat are the key elements in this picture?"}, {"from": "gpt", "value": "The scene showcases an industrial setting where a large number of doughnuts are being glazed with icing. The doughnuts are arranged in rows and are moving along an assembly line. As they pass under a glazing device, they are coated with a waterfall of glaze, giving them a delicious and appetizing appearance. The assembly line ensures that each doughnut receives an even layer of icing, resulting in a uniform and visually appealing product."}]}, {"id": "000000422100", "image": "coco/train2017/000000422100.jpg", "conversations": [{"from": "human", "value": "Can you describe the main features of this image for me?\n<image>"}, {"from": "gpt", "value": "The image features a group of skateboarders, each in different positions, around a stunt ramp. One skateboarder is balancing on a ramp, while another appears to be sliding along a wall with people watching. Another skateboarder seems to be preparing to go down the ramp, while a fourth skateboarder is leaning on a board over the ramp.\n\nIn addition to the skateboarders, there are several skateboards scattered around the scene. Some skateboards can be seen on the ramp, while others are resting near their owners. The atmosphere seems to be full of energy and excitement as the skateboarders perform various stunts and enjoy their time together."}]}, {"id": "000000329766", "image": "coco/train2017/000000329766.jpg", "conversations": [{"from": "human", "value": "Explain the visual content of the image in great detail.\n<image>"}, {"from": "gpt", "value": "The image features a man standing next to a subway train parked at a railway station. He appears to be either approaching the train as it arrives at the station or may have just gotten off the train before it leaves. The train is large and takes up a significant portion of the image.\n\nThe platform is equipped with several red chairs, scattered throughout the scene, and two benches placed nearby. Numerous bicycles can be seen parked alongside the platform, varying in size and orientation. Some vehicles, including a car and a truck, are visible in the background, adding to the bustling atmosphere of the railway station."}]}, {"id": "000000201706", "image": "coco/train2017/000000201706.jpg", "conversations": [{"from": "human", "value": "<image>\nCan you elaborate on the elements of the picture provided?"}, {"from": "gpt", "value": "The scene features a street with a red double-decker bus making its way down the road. There is a group of people standing near the bus, possibly waiting to board or disembark. All of these people are wearing red backpacks, giving them the appearance of being a coordinated group. \n\nOther vehicles are present on the street, including cars parked on the side and other buses in the background. There are also a few trucks visible near the front of the scene. Traffic lights are dispersed throughout the street, ensuring organized traffic flow.\n\nThe street appears to be a lively and bustling environment, and the main focus remains on the double-decker bus and the group of people with matching backpacks."}]}, {"id": "000000247700", "image": "coco/train2017/000000247700.jpg", "conversations": [{"from": "human", "value": "What is this photo about'?\n<image>"}, {"from": "gpt", "value": "The image depicts a busy street in China with a variety of signs in both Asian and English writing, showcasing the bustling shopping area. The street is filled with traffic and includes multiple cars, such as a truck in the center of the scene, a car closer to the left side, and another car on the right side. \n\nThere are numerous people walking along the sidewalks and crossing the street, indicating the liveliness of the area. Some people can be seen near the front of the scene, while others are spotted further in the background. This diverse, busy environment highlights the captivating atmosphere of a shopping area in a Chinese city."}]}, {"id": "000000475316", "image": "coco/train2017/000000475316.jpg", "conversations": [{"from": "human", "value": "What do you see happening in this image?\n<image>"}, {"from": "gpt", "value": "The image displays a beautifully appointed kitchen and breakfast nook area with attractive wood colors. The kitchen has a wooden floor, a sink, a refrigerator, and an oven. On the counter, there are several cups, knives, and bottles. The dining area features a table and four main chairs, with additional chairs in the room. The table is adorned with books, cups, and a backpack.\n\nThe design of this space showcases an open concept, with no separating walls between the kitchen and dining area. The room feels inviting and comfortable, perfect for enjoying meals or spending time with family and friends."}]}, {"id": "000000301558", "image": "coco/train2017/000000301558.jpg", "conversations": [{"from": "human", "value": "What do you think is going on in this snapshot?\n<image>"}, {"from": "gpt", "value": "The image captures a picturesque mountain slope where three friends have stopped to pose for a picture. They are standing close together and all wearing snow skis. The vibrant scene also features several other people in the background, some on skis and others on snowboards. The background is filled with various skis and snowboards positioned near their owners. The individuals in the image seem to be enjoying their time skiing and snowboarding on the stunning mountain slope."}]}, {"id": "000000359363", "image": "coco/train2017/000000359363.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is this photo about'?"}, {"from": "gpt", "value": "In this scene, a woman is interacting with an oven in the kitchen, either putting something in or taking food out. A dog, presumably her pet, is attentively watching the woman, standing nearby on the right side of her. A pizza can be seen, possibly being the food item the woman is handling.\n\nThere are several bottles located around the kitchen, with one placed closer to the front, another positioned towards the right side, and a third one further back. In addition to the oven, a microwave is also visible in the kitchen area, situated on the right side of the scene."}]}, {"id": "000000521176", "image": "coco/train2017/000000521176.jpg", "conversations": [{"from": "human", "value": "Write a detailed description of the given image.\n<image>"}, {"from": "gpt", "value": "The image features a man holding an umbrella and standing on a flowery hill with an easel set up, capturing the stunning scenery below. He appears to be creating artwork inspired by the surrounding nature and the vast view of the sea beyond. \n\nIn the distance, boats of different sizes are scattered across the sea, possibly enhancing the landscape that the man is attempting to paint. The man is positioned near the center of the frame, with the umbrella above him, protecting him from the sun or possibly any light rain."}]}, {"id": "000000295655", "image": "coco/train2017/000000295655.jpg", "conversations": [{"from": "human", "value": "<image>\nDescribe the following image."}, {"from": "gpt", "value": "The image shows a young woman standing on a sidewalk near a fence and a flower garden, looking down at her cell phone. She is engrossed in her phone while being outdoors. A handbag can be seen hanging by her side.\n\nIn the vicinity, there are several bicycles parked in a bike rack close to her, as well as a few cars parked nearby. Some other people are also present in the background, possibly enjoying the day or attending to their own activities."}]}, {"id": "000000446670", "image": "coco/train2017/000000446670.jpg", "conversations": [{"from": "human", "value": "<image>\nAnalyze the image in a comprehensive and detailed manner."}, {"from": "gpt", "value": "The image features a beautiful wooden dining table surrounded by four different chairs. The chairs are arranged neatly around the table, creating a cozy dining atmosphere. In the center of the table, there is a bowl filled with bananas, serving as the centerpiece of the dining setup. \n\nThere are several books scattered around the table and more adjacent to the chairs. The presence of books suggests that the space might be used not only for dining purposes but also for reading or other activities. The combination of the pretty wooden dining table, fruit centerpiece, and the books create a welcoming and comfortable environment."}]}, {"id": "000000520321", "image": "coco/train2017/000000520321.jpg", "conversations": [{"from": "human", "value": "What do you think is going on in this snapshot?\n<image>"}, {"from": "gpt", "value": "The scene features an outdoor display with several large, beautiful Chinese vases and various bonsai trees. There are five tall vases lined up, with some placed in front of a building. The vases are positioned at different heights, adding visual interest to the arrangement.\n\nIn addition to the vases, there are six potted plants, including the bonsai trees, dispersed throughout the scene. Some of the potted plants are situated close to the vases, while others are placed further away. The combination of vases and plants creates a harmonious and eye-catching display."}]}, {"id": "000000127296", "image": "coco/train2017/000000127296.jpg", "conversations": [{"from": "human", "value": "Analyze the image in a comprehensive and detailed manner.\n<image>"}, {"from": "gpt", "value": "The scene shows a group of people standing on a street corner near a building. Among the crowd, several well-dressed business men can be seen conversing, possibly with a police officer. Some individuals in the crowd appear to be wearing backpacks and a tie is visible on one of the individuals.\n\nAround them, various modes of transportation can be observed. On the sidewalk, there is a bicycle parked, while a car and a motorcycle are parked further down the street. Traffic lights are also present in the scene, indicating an urban setting with organized traffic regulations."}]}, {"id": "000000225060", "image": "coco/train2017/000000225060.jpg", "conversations": [{"from": "human", "value": "Describe the following image.\n<image>"}, {"from": "gpt", "value": "The image depicts a busy office environment with multiple people working in their respective cubicles. In the foreground, there is a young Asian man sitting at a desk with a desktop computer in his cubicle. The man is wearing a sweatshirt and appears to be focused on his work. \n\nAround him, there are four other people working in nearby cubicles. Each person can be seen at varying distances from the main subject.\n\nIn the workspace, various items can be identified, including a mouse, a keyboard, a cell phone, two books, and three smaller TVs, one of which is positioned above the young man's desk. There is also a sports ball, possibly representing an element of recreation within the office."}]}, {"id": "000000465353", "image": "coco/train2017/000000465353.jpg", "conversations": [{"from": "human", "value": "<image>\nAnalyze the image in a comprehensive and detailed manner."}, {"from": "gpt", "value": "The image depicts a lively outdoor scene with a building surrounded by numerous green umbrellas providing shade to the area. There are several people walking and interacting outside the building. One of the individuals appears to be a heavy-set man without a shirt on.\n\nA variety of seating is available, with multiple benches spread across the vicinity. Some people are carrying handbags while they walk. There is a four-wheeler, also known as an ATV, parked with a mountain in the background, adding to the picturesque atmosphere. \n\nApart from the main building, there is also a restaurant on-site, with its customers enjoying the outdoor experience under the umbrella shades. In addition, a motorcycle can be seen parked further away from the main activities."}]}, {"id": "000000280132", "image": "coco/train2017/000000280132.jpg", "conversations": [{"from": "human", "value": "<image>\nCan you elaborate on the elements of the picture provided?"}, {"from": "gpt", "value": "The image depicts a unique scene of a pink sheared sheep grazing on grass near a river. In the background, a large group of people is standing on a bridge across the water. The people appear to be engrossed in their activities and might be admiring the view or engaging in conversation.\n\nThe sheep is situated in the foreground, more to the right side of the image. The crowd of people stretches from the left edge to the right edge of the bridge, with individuals clearly visible throughout the scene."}]}, {"id": "000000056065", "image": "coco/train2017/000000056065.jpg", "conversations": [{"from": "human", "value": "Describe the following image.\n<image>"}, {"from": "gpt", "value": "The image shows an airport during the day with overcast skies. There are multiple airplanes in the scene, including an Air Canada airplane prominently visible on the tarmac, possibly getting ready to take off. Another airplane is sitting nearby, with additional aircraft dispersed throughout the airport.\n\nAround the tarmac, several vehicles are present, including cars and various trucks of different sizes. Some trucks are parked close to the airplanes, possibly for service or cargo handling, while others are scattered around the airport's vicinity. Furthermore, a few people can be seen around the airport, likely taking care of their duties to support the take-off and landing operations."}]}, {"id": "000000389159", "image": "coco/train2017/000000389159.jpg", "conversations": [{"from": "human", "value": "What is this photo about'?\n<image>"}, {"from": "gpt", "value": "The image showcases a unique scene inside a subway car filled with people and an abundance of potted plants. The plants are diverse in size and spread throughout the interior, giving the subway car a tropical and green ambiance. Some plants are placed next to the seats, while others are found higher up, as if they are growing from the floor or walls.\n\nPeople can be seen trying to navigate their way around the plants, either looking for a seat or simply standing among the greenery. There are at least ten people visible in the car, occupying various positions, and some are engaged with their cell phones. A handbag can also be spotted in the scene, adding to the sense of a busy commuting environment.\n\nOverall, it is an unusual yet intriguing sight, with passengers riding a subway train amidst an indoor garden-like atmosphere."}]}, {"id": "000000381758", "image": "coco/train2017/000000381758.jpg", "conversations": [{"from": "human", "value": "<image>\nAnalyze the image in a comprehensive and detailed manner."}, {"from": "gpt", "value": "The image depicts a busy city intersection with vehicular traffic, pedestrians, and a crosswalk. Numerous people are visible throughout the scene, some carrying handbags and backpacks, and others crossing the street or walking alongside it. There is a mix of cars, buses, and bicycles navigating the street, all obeying the traffic signals, of which several can be seen in the image.\n\nThe intersection is bustling with activity and there are a few people holding umbrellas. The combination of these elements highlights the lively atmosphere of the city as people go about their day."}]}, {"id": "000000481209", "image": "coco/train2017/000000481209.jpg", "conversations": [{"from": "human", "value": "<image>\nExplain the visual content of the image in great detail."}, {"from": "gpt", "value": "The image showcases a city street with a black and silver fire hydrant on the side of the road. There is another fire hydrant further down the street. Several cars are parked along the street, and a few are driving down it. \n\nIn addition to the cars and fire hydrants, there are numerous people walking around the area, making for a lively city atmosphere. This lively scene depicts a typical day in an urban environment, highlighting the street corner, pedestrians, and parked cars, as well as the cars passing by."}]}, {"id": "000000218237", "image": "coco/train2017/000000218237.jpg", "conversations": [{"from": "human", "value": "What could be a reason for the interaction between the two men on the couch?\n<image>"}, {"from": "gpt", "value": "One possible reason for the interaction between the two men on the couch, with the shirtless man straddling the other guy while holding his arm, could be that they are engaged in a playful wrestling or grappling match. This activity is often seen among close friends or relatives who are enjoying a moment of bonding and entertainment. It could be a friendly competition or an exhibition of physical strength and skill. It is important to note that such activities should always be practiced with caution, and participants should be mindful of safety measures to avoid any injuries."}]}, {"id": "000000241836", "image": "coco/train2017/000000241836.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat might the owner of the cell phone be planning to do with the sandwich?"}, {"from": "gpt", "value": "The owner of the cell phone might be planning to enjoy the meat and cheese sandwich, as it is presented on a dining table, ready to be consumed. The long submarine sandwich is already taken out of its packaging and placed on top of a brown bag, signifying that it is prepared for eating. They might be using their cell phone to take a photo of the sandwich, to share with friends or on social media, or simply browsing the phone while enjoying their meal."}]}, {"id": "000000545409", "image": "coco/train2017/000000545409.jpg", "conversations": [{"from": "human", "value": "What are the potential consequences of wearing high heels frequently?\n<image>"}, {"from": "gpt", "value": "Wearing high heels frequently, such as the black stiletto heels seen on the person lying on the bed in the image, can have several negative impacts on one's health and overall well-being. Some of these potential consequences include:\n\n1. Foot pain and deformities: High heels can cause discomfort, pain, and pressure on the toes and other areas of the foot. Prolonged use can lead to issues like bunions, hammer toes, and ingrown toenails.\n\n2. Increased risk of injury: High heels can affect balance, making it more difficult to walk and increasing the likelihood of trips, falls, and sprains or strains.\n\n3. Joint and muscle issues: Wearing high heels regularly can alter the alignment of your body, affecting your posture and exerting pressure on your ankle, knee, hip, and lower back joints. This may contribute to muscle imbalances, chronic pain, and long-term joint problems.\n\n4. Tightened and shortened calf muscles: Prolonged use of high heels may cause the calf muscles to tighten and shorten, as the foot is in a raised position. This can contribute to discomfort, stiffness, and an increased risk of conditions like plantar fasciitis.\n\nTaking breaks from wearing high heels, stretching, and investing in supportive and comfortable footwear can help mitigate these potential issues. It is essential to prioritize one's health and well-being over fashion whenever possible."}]}, {"id": "000000003008", "image": "coco/train2017/000000003008.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat could be a reason for the woman's gesture at her desk?"}, {"from": "gpt", "value": "The woman sitting at her desk surrounded by books might be clapping her hands to celebrate a recent achievement or a breakthrough in her work or studies. It is evident from the presence of several books on and around her desk that she is engaged in a task that involves research or learning. Her gesture of raising and clapping her hands could signal her satisfaction, excitement, or relief after accomplishing a challenging objective or solving a problem that required her attention and dedication."}]}, {"id": "000000254779", "image": "coco/train2017/000000254779.jpg", "conversations": [{"from": "human", "value": "What task might the person be performing in the bathroom?\n<image>"}, {"from": "gpt", "value": "In the image, the person is holding a pair of pliers near a white toilet in the bathroom and appears to have other tools nearby. It is plausible that they may be installing, repairing, or maintaining the toilet. The presence of the tools suggests that they are likely performing some plumbing work, which might involve replacing components, fixing leaks, or adjusting the toilet's functional mechanisms."}]}, {"id": "000000034261", "image": "coco/train2017/000000034261.jpg", "conversations": [{"from": "human", "value": "What could be the purpose of having a giraffe statue near a brick building?\n<image>"}, {"from": "gpt", "value": "The purpose of having a giraffe statue near a brick building could be for various reasons like artistic expression, thematic decoration, or even as a symbol or landmark for the establishment. For example, the giraffe statue might represent a unique theme for the building, such as a wildlife or nature-inspired establishment, drawing attention and curiosity from passersby. Alternatively, the statue could be a part of an outdoor art installation or exhibition to add visual interest to the public space surrounding the building. In either case, the presence of the giraffe statue contributes to the aesthetic appeal and identity of the location, piquing interest and potentially attracting more visitors or customers."}]}, {"id": "000000011713", "image": "coco/train2017/000000011713.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat risks are associated with performing this stunt?"}, {"from": "gpt", "value": "Performing a ski stunt like the one depicted in the image, where two skiers are jumping and catching air, carries several risks. These risks include injuries such as sprains, fractures, or dislocations due to incorrect landings, collisions with other skiers, or losing control in the air. Additionally, there's a risk of falling with great impact which could potentially result in head or spinal injuries. To mitigate these risks, skiers should be appropriately trained, wear proper protective gear such as helmets and padding, and perform stunts only in designated areas with appropriate safety measures in place. Maintaining awareness of their surroundings and other skiers will also contribute to minimizing accidents or collisions during such stunts."}]}, {"id": "000000447049", "image": "coco/train2017/000000447049.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat can be inferred about the capacity of this train, and why might it be beneficial for public transportation?"}, {"from": "gpt", "value": "The train in the image is a double-decker passenger train, which suggests that it has a relatively high capacity to accommodate passengers as it has two levels of seating. Such trains are beneficial for public transportation systems, particularly in busy urban areas or popular train routes, because their increased capacity can accommodate more passengers during peak times and help reduce congestion in trains. Additionally, the larger capacity may also enable cost-efficient operations by allowing a greater number of passengers to be transported with fewer train cars or fewer trips, thus reducing operational costs and potentially leading to lower fares for the passenger. Overall, double-decker trains can improve the experience for both the public transportation service and the passengers using it."}]}, {"id": "000000497746", "image": "coco/train2017/000000497746.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat benefits does having a garden at home provide?"}, {"from": "gpt", "value": "Having a garden at home provides various benefits for the homeowner and the environment. In the image, the garden contains a planter box with different plants growing in it, possibly including vegetables. Home gardening can supply fresh, organic, and locally-grown produce, contributing to a healthy diet and lifestyle. It also promotes physical activity, as gardening involves various tasks, such as planting, watering, weeding, and harvesting.\n\nAdditionally, gardens can serve as an effective stress-relief tool and boost mental well-being by offering a calming, natural environment for relaxation and reflection. The increased greenery also has potential environmental benefits, such as providing habitats for local wildlife, improving air quality, and reducing air temperature around the house, which helps mitigate the heat island effect in urban areas.\n\nMoreover, home gardening fosters a sense of accomplishment and satisfaction in growing and nurturing plants from seeds to maturity. It can also be a rewarding hobby and a way to engage with nature and learn more about the life cycles and growth of various plant species."}]}, {"id": "000000209745", "image": "coco/train2017/000000209745.jpg", "conversations": [{"from": "human", "value": "Why might the man have ordered two large pizzas for himself?\n<image>"}, {"from": "gpt", "value": "There could be several reasons why the man has ordered two large pizzas for himself while sitting in the restaurant. One possibility is that he has a large appetite and enjoys indulging in multiple pizzas. Another explanation could be that he plans to share the pizzas with someone else who might be joining him later, or he might be taking the leftovers home for a later meal. Additionally, it is possible that the man wanted to try different flavors and decided to order two different kinds of pizzas. Lastly, there could be a promotion or deal at the restaurant that encouraged him to order more than one pizza. These scenarios illustrate various motivations for the man's decision to have two large pizzas in front of him."}]}, {"id": "000000025421", "image": "coco/train2017/000000025421.jpg", "conversations": [{"from": "human", "value": "<image>\nWhy might the cat be interacting with the TV screen in this way?"}, {"from": "gpt", "value": "The cat is likely interacting with the TV screen this way because it sees the image of another cat on the screen, and its natural instincts are triggered. Cats often respond to the movement, size, and appearance of objects they see, so it may be compelled to investigate, chase, or paw at the image of the cat on the TV. The cat may not understand that the image on the screen is not a real cat, so it's simply behaving in accordance with its typical reactions when it sees another feline."}]}, {"id": "000000158821", "image": "coco/train2017/000000158821.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat qualities could help the young tennis player improve and succeed in his game?"}, {"from": "gpt", "value": "To improve and succeed in his game, the young tennis player could focus on several key qualities, including:\n\n1. Technique: Developing a strong foundation in the various strokes, such as forehands, backhands, serves, and volleys, is crucial. This requires consistent practice and refining his skills alongside a professional coach if possible.\n\n2. Footwork: Good footwork enables the player to quickly and efficiently reach the ball, allowing them to be in the ideal position to execute shots. Agility drills and footwork exercises can help him enhance his movement on the court.\n\n3. Physical fitness: Building strength, stamina, and flexibility are all vital aspects of a tennis player's success. A dedicated fitness regimen including cardiovascular, strength, and flexibility exercises will help him improve his overall performance on the court.\n\n4. Mental fortitude: Tennis is as much a mental game as it is a physical one. Cultivating a strong mindset, focusing on staying present and composed during matches, and practicing mental toughness skills can significantly impact his performance.\n\n5. Strategy: Understanding tactics and developing a game plan will help the young player exploit his opponent's weaknesses and capitalize on his strengths. Studying players' patterns, seeking feedback from coaches or peers, and employing smart tactics during matches will give him a competitive edge.\n\n6. Consistency: Constant practice and dedication are imperative to improving one's game. The young player should be committed to his practice sessions, learn from his mistakes, and continuously strive for improvement."}]}, {"id": "000000169607", "image": "coco/train2017/000000169607.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat factors might influence the person's decision to venture out in the boat, given the cold climate?"}, {"from": "gpt", "value": "Several factors might influence the person's decision to venture out in the boat despite the cold climate. The person's level of experience in navigating boats in cold conditions could play a part, as more experienced individuals might feel confident handling potential challenges. The type and condition of the boat, as well as the safety and navigational equipment on board, can also affect their decision. Access to appropriate clothing and gear for cold weather is another important factor, as it would provide protection against the elements and make the journey more comfortable. Finally, the purpose of the boat trip (for example, if it is work-related or for recreational purposes) and the weather forecast for the duration of the trip might weigh on their decision, as they might only choose to venture out if they believe the conditions will be safe and manageable."}]}, {"id": "000000033332", "image": "coco/train2017/000000033332.jpg", "conversations": [{"from": "human", "value": "What design elements distinguish this bathroom from a typical bathroom?\n<image>"}, {"from": "gpt", "value": "This bathroom stands out due to its unique color scheme and design elements. It features a black vanity with a white sink, white toilet, and white tile floors. The color scheme, which includes black, teal, and gold elements, creates contrast and adds visual interest. Additionally, the presence of a large mirror enhances the sense of space in the bathroom. These distinctive design elements make this bathroom different from a standard bathroom, giving it a more sophisticated and stylish appearance."}]}, {"id": "000000031411", "image": "coco/train2017/000000031411.jpg", "conversations": [{"from": "human", "value": "What kind of interaction is taking place between the giraffes and why?\n<image>"}, {"from": "gpt", "value": "The giraffes in the image are interacting in a gentle and affectionate way, with one of them licking the area behind the other's head. This type of interaction could potentially be a social bonding behavior, a display of affection, or grooming. Giraffes are social animals, and such behaviors help them establish and maintain connections within their group, reassuring each other, and strengthening their relationships. It is also possible that the grooming behavior serves to remove parasites or irritants from the other giraffe's skin, ensuring their well-being and comfort. Overall, the interaction showcases their complex social behaviors and need for companionship."}]}, {"id": "000000427283", "image": "coco/train2017/000000427283.jpg", "conversations": [{"from": "human", "value": "How might the variety of passenger belongings affect the boarding process at the train station?\n<image>"}, {"from": "gpt", "value": "At the train station, passengers come with different types of belongings, such as handbags and backpacks. The variety of passenger belongings can affect the boarding process in several ways:\n\n1. Space management: Passengers have to find suitable storage spaces for their belongings, either in overhead compartments, under seats, or designated luggage storage areas. This process may take time, and passengers may struggle to find appropriate space or face difficulties managing their luggage within the train, which could potentially delay the boarding process.\n\n2. Movement within the train: As passengers board the train and try to find their seats, the presence of bulky luggage such as backpacks and handbags may make it harder for other passengers to move through the narrow aisles. This can further slow down the boarding process and create congestion in the train's walkways.\n\n3. Passenger safety and comfort: The presence of multiple bags and personal belongings may lead to safety concerns if they are not placed securely, as they can become obstacles during emergencies or sudden movements. Furthermore, passengers may experience discomfort if they have to travel with their belongings occupying limited legroom or seat space.\n\nTrain operators and passengers need to cooperate to ensure an efficient boarding process and minimize delays caused by the handling and placement of various types of personal belongings."}]}, {"id": "000000235987", "image": "coco/train2017/000000235987.jpg", "conversations": [{"from": "human", "value": "What challenges might this mature lady face during her tennis match?\n<image>"}, {"from": "gpt", "value": "In the image, the mature lady is holding a tennis racket and standing on a tennis court, ready to play a match. Some potential challenges she might face during the game could include physical stamina, agility, reflexes, and keeping up with a potentially faster or more experienced opponent. As an older individual, she may need to adopt different strategies and techniques to compensate for any age-related decline in physical abilities. This might involve relying on her experience, precisely placing her shots, and conserving energy by moving efficiently around the court. By remaining focused, adaptive, and persistent, she could successfully enjoy her tennis match and overcome the challenges presented."}]}, {"id": "000000286877", "image": "coco/train2017/000000286877.jpg", "conversations": [{"from": "human", "value": "<image>\nWhy might an empty train car be beneficial or undesirable during different times?"}, {"from": "gpt", "value": "An empty train car can be both beneficial or undesirable depending on the peculiar context and time.\n\nIt can be beneficial for a few reasons:\n1. Passengers seeking a quiet and less crowded environment can enjoy more personal space on an empty train. This can lead to a more comfortable and stress-free commuting experience.\n2. During a pandemic or a health crisis, an empty train car minimizes the risks of transmission and contagion, as people can maintain social distance more efficiently.\n\nOn the other hand, an empty train car can be undesirable in these scenarios:\n1. An empty train during peak hours could indicate operational issues or delays that affect a significant number of commuters, leading to inconvenience and dissatisfaction.\n2. From an eco-friendly and sustainability perspective, empty train cars consume energy without maximizing passenger capacity. This results in higher energy consumption per passenger, which is economically and environmentally inefficient.\n3. Finally, for public transportation providers, empty train cars can mean unmet expectations about ridership or suboptimal scheduling, indicating a need for better management and route planning."}]}, {"id": "000000003915", "image": "coco/train2017/000000003915.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat can be inferred about the woman in the scene?"}, {"from": "gpt", "value": "In the scene, a woman is observed wearing an apron and standing in a kitchen with counter full of dishes, including bowls, plates, and various utensils such as knives and spoons. We can infer that she is preparing to serve a large meal and is possibly the host or cook for the gathering. She might be in the process of inspecting the plates and ensuring everything is in order for the meal. Her apron suggests that she is taking care to not get her clothes dirty while preparing and serving the food. The presence of several kitchen appliances and items, such as a refrigerator, oven, microwave, and potted plants, indicates a well-equipped and possibly well-organized kitchen, suggesting that the woman is accustomed to cooking meals and hosting gatherings."}]}, {"id": "000000279648", "image": "coco/train2017/000000279648.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat are some benefits of engaging in this water activity?"}, {"from": "gpt", "value": "Engaging in the water activity of surfing or riding a boogie board on ocean waves provides various physical, mental, and social benefits. Some of these benefits include:\n\n1. Improved cardiovascular fitness: Paddling, catching waves, and maintaining balance on the surfboard exercise the heart and help improve overall cardiovascular health.\n\n2. Increased strength: Surfing requires the use of various muscle groups, such as upper body muscles (arms and shoulders) for paddling, and leg and core muscles for maintaining balance on the board. This results in increased overall strength.\n\n3. Enhanced balance and flexibility: Controlling and maneuvering a surfboard on an unpredictable wave improves balance and flexibility over time, as the body adapts to the different movements required while surfing.\n\n4. Mental health benefits: Surfing and other water sports can provide an opportunity to connect with nature, promoting relaxation and stress reduction. The sport often leads to the release of endorphins, which contribute to a sense of happiness and well-being.\n\n5. Social connections: Surfing can be a shared activity, allowing individuals to connect with and form bonds with like-minded people, exchanging experiences and knowledge about the sport."}]}, {"id": "000000521176", "image": "coco/train2017/000000521176.jpg", "conversations": [{"from": "human", "value": "What could be the inspiration behind the person's artwork in this scene?\n<image>"}, {"from": "gpt", "value": "The person's artwork might be inspired by the breathtaking view of nature encompassing both the flowery hill and the sea. The setting offers a vibrant balance between the lush, colorful hillside filled with flowers and the calm, sprawling sea dotted with boats. The person, holding an umbrella while setting up an easel, seeks to capture the essence of the picturesque scenery below. The diverse elements in the scene, such as the various boats on the sea and the contrasting land and water, provide a rich source of inspiration for the artist to create a captivating piece of art."}]}, {"id": "000000369859", "image": "coco/train2017/000000369859.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat can be a possible concern regarding the skier's choice of outfit?"}, {"from": "gpt", "value": "A possible concern regarding the skier's choice of outfit is the white jacket, which might affect visibility in the snowy environment. Since the skier is wearing a white coat, they may blend in with the snow-covered hill, making it difficult for other skiers or snowboarders to see them. This can potentially increase the risk of collisions, accidents, or injuries on the slopes. To mitigate this concern, the skier could opt for bright, distinct colors for their outfit, improving visibility and ensuring a safer skiing experience."}]}, {"id": "000000036373", "image": "coco/train2017/000000036373.jpg", "conversations": [{"from": "human", "value": "What skills are essential for the young boy to successfully catch the baseball?\n<image>"}, {"from": "gpt", "value": "To successfully catch the baseball, the young boy needs to have good hand-eye coordination to track the ball accurately as it approaches. He also requires proper body positioning, including maintaining a balanced and low crouching position, ensuring his glove is facing the incoming ball and at the correct height. Additionally, the boy must be attentive, focused on the ball's motion, and be able to react rapidly to any changes in its trajectory. Lastly, having a strong foundation in baseball fundamentals, including understanding proper catching techniques with a baseball mitt, will help increase his likelihood of success in catching the ball."}]}, {"id": "000000542937", "image": "coco/train2017/000000542937.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat factors might be contributing to the well-being of these animals?"}, {"from": "gpt", "value": "The image shows two cows (or native animals) standing in a grassy field on a sunny day, which contributes to their well-being in various ways. Firstly, they have abundant access to fresh grass to graze on, ensuring a healthy and natural source of nutrition. Furthermore, the animals appear to be in an open and spacious environment, which allows them to freely roam and engage in natural behaviors. The sunny weather also provides warmth and a pleasant atmosphere, which could result in reduced stress levels and increased comfort for the animals. Additionally, the presence of different aged cows, such as a larger, older ox and a younger, smaller ox, can be indicative of a diverse and thriving population, allowing the animals to socialize and interact with each other, further contributing to their well-being."}]}, {"id": "000000567803", "image": "coco/train2017/000000567803.jpg", "conversations": [{"from": "human", "value": "Why is it important for the broccoli plant to have large leaves and how does it relate to broccoli growth?\n<image>"}, {"from": "gpt", "value": "Large leaves are crucial for a broccoli plant's health and growth because they are responsible for carrying out photosynthesis, the process through which plants convert sunlight, carbon dioxide, and water into energy and nutrients necessary for growth. The larger the leaf area, the more sunlight the plant can harvest and convert into energy. This energy is then used by the plant to grow and produce the broccoli head, which is the part commonly consumed. In essence, large leaves provide the plant with an increased capacity for photosynthesis, supporting the development and growth of both the leaves and the head of the broccoli plant. As a result, proper leaf growth contributes to the overall quality and yield of the broccoli."}]}, {"id": "000000345590", "image": "coco/train2017/000000345590.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat factors could affect these animals' visibility in the field?"}, {"from": "gpt", "value": "The main factor affecting the visibility of the sheep and ram in the field is the presence of fog, which can considerably reduce visibility by spreading a dense layer of water droplets in the air. This makes it challenging to see objects from a distance, including the sheep that are dispersed among the tall grasses in the field. Both the fog and the tall grass contribute to the obscured view of the animals and affect their overall visibility within the scene."}]}, {"id": "000000411969", "image": "coco/train2017/000000411969.jpg", "conversations": [{"from": "human", "value": "What potential concerns might a bakery face in automating the glazing process using a large machine?\n<image>"}, {"from": "gpt", "value": "Automating the glazing process using a large machine might pose several potential concerns for a bakery, such as:\n\n1. Consistency and Quality: Ensuring that the glazing machine evenly coats the doughnuts with the desired thickness of icing without causing drips, spills, or excess waste.\n\n2. Sanitation and Cleanliness: Keeping the glazing machine clean and well-maintained to adhere to food safety regulations and prevent cross-contamination.\n\n3. Production Speed: The machine speed should be adjusted to match the production pace, preventing bottlenecks or delays in the overall doughnut manufacturing process.\n\n4. Efficiency and Energy Consumption: The operation of the machine should be energy-efficient, as higher energy consumption could lead to increased overhead costs.\n\n5. Adaptability: The machine should be adaptable to handle different doughnut sizes, shapes, and types of glazing or icing, offering flexibility in the manufacture of a diverse range of doughnut products.\n\n6. Maintenance and Repair: Regular preventive maintenance should be scheduled to reduce unexpected breakdowns or malfunctions, and the availability of spare parts should be considered to minimize downtime.\n\n7. Cost of Automation: The initial cost of purchasing, installing, and setting up the glazing machine might be substantial, and the bakery would need to ensure that the potential long-term benefits, such as improved efficiency, consistency, and quality control, outweigh this initial investment."}]}, {"id": "000000047328", "image": "coco/train2017/000000047328.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat factors might influence the choice of pizza toppings?"}, {"from": "gpt", "value": "The choice of pizza toppings can be influenced by several factors, such as personal preferences, dietary restrictions, cultural influences, and the availability of various ingredients. In the image, there is a thin crust pizza loaded with various veggie toppings, served on a wooden table. Personal preferences play a significant role in the selection of toppings, as different people may have different tastes and cravings. Additionally, dietary restrictions or choices, such as being vegetarian, vegan, or following a specific diet, can also determine the selection of toppings. Cultural influences, regional cuisine, and specialty dishes can also contribute to the choice of topping combinations. Finally, the availability and seasonality of ingredients may have an impact on the choice of toppings, as restaurants and individuals might prefer to use fresh, in-season, and locally sourced ingredients for the pizza."}]}, {"id": "000000292177", "image": "coco/train2017/000000292177.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat factors might contribute to the giraffe's well-being in this environment?"}, {"from": "gpt", "value": "In the image, the giraffe is standing in a grassy field on a sunny day, which seems to be a suitable environment for its well-being. Factors that might contribute to the giraffe's well-being in this environment include:\n\n1. Abundant food supply: Since giraffes primarily feed on leaves, twigs, and flowers, the presence of a grassy field and bushes nearby suggests that the giraffe has access to sufficient food sources.\n\n2. Open space: Giraffes need a wide-open space to roam, and the grassy field in the image offers plenty of room for the giraffe to move around and explore.\n\n3. Sunshine: The presence of sunlight in the environment is essential for the giraffe's physiological health. Sunlight offers warmth and promotes the synthesis of essential vitamins such as Vitamin D, crucial for bone health.\n\n4. Social Interaction: Although the image does not show other giraffes, the presence of these animals in the same area would contribute to the well-being of the giraffe by providing social interaction, which is important for the cognitive and emotional health of these social animals.\n\nOverall, the combination of food sources, open space, sunshine, and potentially social interaction would contribute to the giraffe's well-being in this environment."}]}, {"id": "000000069826", "image": "coco/train2017/000000069826.jpg", "conversations": [{"from": "human", "value": "What unique feature does the toothbrush holder have?\n<image>"}, {"from": "gpt", "value": "The toothbrush holder in the image has a unique feature: it is decorated like a skull. This skull cup adds an unconventional and creative touch to the bathroom setting and acts as a conversation starter due to its distinct design. The toothbrush holder is placed on top of the bathroom sink counter, holding the toothbrush securely."}]}, {"id": "000000063626", "image": "coco/train2017/000000063626.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat benefits does a public transit bus with a bicycle rack offer?"}, {"from": "gpt", "value": "A public transit bus equipped with a bicycle rack offers numerous benefits to both individuals and the community. Firstly, it promotes a multimodal approach to transportation, allowing people to use a combination of cycling and public transit for their daily commute, which can alleviate traffic congestion and parking issues. Additionally, this encourages a more active and environmentally-friendly lifestyle by supporting the integration of cycling into daily routines. It also makes public transportation more accessible to those who rely on bicycles for short-distance travel, enhancing the overall efficiency and convenience of the transportation system. Finally, by catering to cyclists, public transit agencies can attract more riders, further reducing the number of private vehicles on the road and contributing to the reduction of greenhouse gas emissions and air pollution."}]}, {"id": "000000053864", "image": "coco/train2017/000000053864.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat could be the possible consequences of the cat's actions?"}, {"from": "gpt", "value": "The cat's actions of sitting on the open laptop and playing with a pencil can cause various consequences. First, its weight and movement on the laptop's keyboard may accidentally press keys and potentially result in unintended actions, such as deleting files or sending undesired emails. Additionally, the cat playing with a pencil may accidentally scratch the laptop's screen, keyboard, or other components, which would lead to cosmetic or functional damage to the device. Furthermore, the fur and dirt from the cat's body can cause dust and debris to collect on the laptop, which might negatively affect the device's cooling system over time or impact its overall performance. In some cases, the cat's presence on the laptop may distract or obstruct the user from performing tasks efficiently."}]}, {"id": "000000561590", "image": "coco/train2017/000000561590.jpg", "conversations": [{"from": "human", "value": "What is the purpose of the harness worn by the horse?\n<image>"}, {"from": "gpt", "value": "The pink harness worn by the horse serves multiple purposes. It is designed to provide some level of control and guidance for the person leading the horse. Additionally, the harness ensures the horse's comfort and safety while being walked or ridden, and it is also used for attaching reins, which provide further control during riding or training sessions. In this image, the horse is in a public setting, with several onlookers and other people nearby, indicating that the horse is likely being led to or participating in an event. In such contexts, the harness is vital for managing the horse's movement and behavior and ensuring the safety of both the horse and the people around it."}]}, {"id": "000000331824", "image": "coco/train2017/000000331824.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat can you infer about the building's purpose based on the clock tower feature?"}, {"from": "gpt", "value": "As the large clock is prominently displayed on top of the building, one can infer that the building might hold some significance or serve an essential function in the city. Buildings with clock towers often symbolize a central gathering place, such as a city hall, a public transportation hub, or an important institution like a university or library. The clock tower can serve as a landmark or a point of reference for residents and visitors, as well as providing the essential service of displaying the time to the public in a convenient and visible manner."}]}, {"id": "000000575305", "image": "coco/train2017/000000575305.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat might be the general mood among the spectators during the game?"}, {"from": "gpt", "value": "Given the image of a baseball game showing the batter actively hitting or attempting to hit the ball, it is likely that the general mood among the spectators is excitement and anticipation. In a baseball game, moments of action like a batter swinging the bat towards the ball usually create an electric atmosphere among fans. They watch intently, waiting for the outcome of each play and cheering for their favorite team or player. The high level of engagement among the spectators during such events typically results in an energetic and passionate mood."}]}, {"id": "000000313979", "image": "coco/train2017/000000313979.jpg", "conversations": [{"from": "human", "value": "What improvements can be suggested for this bathroom?\n<image>"}, {"from": "gpt", "value": "The image shows a small, plain, and clean half bathroom with light brown tiled flooring and a white toilet. Some possible improvements to enhance the user experience and aesthetics in this bathroom could include:\n\n1. Adding decorative elements: Incorporate artwork, peel-and-stick wall decals, or a stylish mirror to add visual interest and make the space more inviting.\n2. Installing storage options: Add a small shelf or cabinet to store bathroom essentials such as toilet paper, cleaning supplies, and toiletries.\n3. Enhancing the lighting: Upgrading the lighting fixtures or adding additional light sources can make the space feel brighter and more welcoming.\n4. Upgrading the toilet seat: A high-quality, comfortable toilet seat can improve user comfort.\n5. Introducing plants: Incorporating small, low maintenance plants that thrive in bathrooms can add a touch of freshness and pop of color.\n\nThese suggestions can help make the bathroom more functional and visually appealing while catering to the users' needs."}]}, {"id": "000000066828", "image": "coco/train2017/000000066828.jpg", "conversations": [{"from": "human", "value": "Why are people using elephants to cross the river instead of other means?\n<image>"}, {"from": "gpt", "value": "People are using elephants to cross the river in this scenario because elephants are well-suited for traversing the potentially challenging terrain, such as muddy or grassy areas near the riverbank. Elephants are large, sturdy animals with strong bodies that can carry people and heavy loads across bodies of water with relative ease. Furthermore, elephants have the ability to wade through deep water due to their height, which may not be possible for smaller animals or vehicles. By riding elephants, these people can safely and efficiently cross the river, regardless of the water depth or the conditions of the surrounding terrain."}]}, {"id": "000000273119", "image": "coco/train2017/000000273119.jpg", "conversations": [{"from": "human", "value": "<image>\nWhy might the people in the image be in the water rather than using the boat?"}, {"from": "gpt", "value": "There could be several reasons why the people in the image are in the water next to the boat instead of using it. They might be taking a break from rowing or navigating the boat and decided to enjoy a swim or cool off in the water. Another possibility is that they could be guiding the boat through shallow areas or avoiding obstacles, rocks, or debris in the water that might be dangerous to the boat's hull. Alternatively, if they are learning how to control and maneuver the boat, being in the water could allow them a hands-on experience with better control in challenging situations. Overall, there might be various reasons, including relaxation, safety, learning, or navigating difficult sections of the river."}]}, {"id": "000000427692", "image": "coco/train2017/000000427692.jpg", "conversations": [{"from": "human", "value": "What can someone possibly notice about the architecture of the building?\n<image>"}, {"from": "gpt", "value": "One noticeable architectural feature of the building is the presence of a clock tower at the top. It appears to be a large and prominent four-sided clock, making it easily visible from various angles. The clock tower's design adds a classic touch to the building's overall appearance. Furthermore, the gray and white color scheme of the structure contrasts with the surrounding palm trees, creating an interesting blend of modern and traditional elements."}]}, {"id": "000000422100", "image": "coco/train2017/000000422100.jpg", "conversations": [{"from": "human", "value": "What skills are necessary for these skateboarders to successfully perform their stunts?\n<image>"}, {"from": "gpt", "value": "To successfully perform stunts on the ramp, these skateboarders need a combination of skills, including balance, coordination, strength, and agility. They also require good body control and spatial awareness, as they need to maintain their position on the skateboard while navigating the ramp and performing various tricks. Additionally, experience and practice are crucial for mastering these stunts, as skateboarding involves fine-tuning muscle memory, timing, and technique. Moreover, the skateboarders must possess mental resilience, perseverance, and the ability to adapt and learn from mistakes, as skateboarding stunts can be difficult to master and may involve falls and failures along the way. It is important for them to maintain a positive attitude, dedication, and patience as they progress and develop their skills."}]}, {"id": "000000167330", "image": "coco/train2017/000000167330.jpg", "conversations": [{"from": "human", "value": "What issue does the neighborhood face?\n<image>"}, {"from": "gpt", "value": "The neighborhood faces an issue due to vandalism. In the image, a stop sign, located at an intersection and next to a palm tree, has been vandalized with the phrase \"ALL WAR\" beneath it. This graffiti on the stop sign reflects a disregard for public property and can create an unwelcoming or unsafe atmosphere for residents and visitors, affecting the neighborhood's overall image. To address this issue, measures such as increasing the police presence, installing security cameras, and encouraging community involvement in keeping the neighborhood clean might be helpful to prevent further acts of vandalism."}]}, {"id": "000000381758", "image": "coco/train2017/000000381758.jpg", "conversations": [{"from": "human", "value": "What are some ways the city in the image could improve for pedestrian safety and reduce traffic congestion?\n<image>"}, {"from": "gpt", "value": "The city in the image could improve pedestrian safety and reduce traffic congestion in a number of ways. Some possible solutions:\n\n1. Install more traffic signals and pedestrian crossing lights at busy intersections. This will improve traffic flow and ensure that pedestrians can safely cross the street without confusion or danger.\n\n2. Widen sidewalks and create more pedestrian-friendly zones, such as pedestrian plazas or parks where motor vehicles are not allowed or have limited access. This can reduce congestion by encouraging more people to walk.\n\n3. Implement a well-developed public transportation system, such as buses, trams, and metros, to encourage people to use public transportation instead of personal vehicles. This can ease traffic and reduce the number of cars on the streets, thereby minimizing congestion.\n\n4. Create dedicated bike lanes that provide a safe space for cyclists, away from traffic. This can encourage more people to choose cycling as an alternative transportation mode, reducing the number of vehicles on the roads.\n\n5. Implement traffic calming measures, such as speed reductions, speed humps, and traffic circles. These measures can slow down vehicular traffic and improve safety for pedestrians and cyclists.\n\nOverall, implementing these changes can contribute to a safer and more efficient transportation environment in the city, promoting a more sustainable and inclusive urban landscape for all its inhabitants."}]}, {"id": "000000190241", "image": "coco/train2017/000000190241.jpg", "conversations": [{"from": "human", "value": "How can we interpret the zebra's behavior in this image?\n<image>"}, {"from": "gpt", "value": "Based on the image, we can see a zebra standing in a field with rocky ground and grass. The zebra's body is facing away from the camera, and we are observing it from a diagonal angle. Its behavior in this scene could be interpreted as being on alert, grazing, or simply resting. As zebras are prey animals, they need to be aware of their surroundings for any potential danger or predators. We cannot determine the exact details of what the zebra is doing without more information or a clearer view of its head, but it is likely engaging in one or more of these typical activities within its natural habitat."}]}, {"id": "000000258110", "image": "coco/train2017/000000258110.jpg", "conversations": [{"from": "human", "value": "What might the surfer be thinking or preparing for?\n<image>"}, {"from": "gpt", "value": "As the surfer walks into the water while carrying his surfboard, he might be thinking about or preparing for several things. Firstly, he could be observing the waves, assessing their size, and timing in order to identify the best opportunities to catch a wave. Secondly, he might be mentally preparing himself for the physical demands of surfing, strategizing over techniques to maintain balance on the board, and anticipating potential wipeouts. Lastly, the surfer might also be considering safety aspects, such as avoiding other surfers or swimmers in the area and being aware of any hazards like rocks, reefs, or strong currents. Overall, the surfer is likely evaluating the conditions and planning his approach to make the most of his surfing experience."}]}, {"id": "000000241667", "image": "coco/train2017/000000241667.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat impact does the grandfather clock's appearance have on the room's aesthetic?"}, {"from": "gpt", "value": "The grandfather clock, decorated with engravings of flowers and placed against a nicely paneled wall, adds a sense of elegance and sophistication to the room's aesthetic. The rich and classic design of the clock enhances the overall atmosphere and creates a focal point, making it an interesting and appealing addition to the space. The floral engravings and the clock's detailed craftsmanship contribute to the room's atmosphere, showcasing a combination of history, art, and functionality. Such an ornate piece can serve as a conversation starter and an anchor for the overall design theme of the room."}]}, {"id": "000000347248", "image": "coco/train2017/000000347248.jpg", "conversations": [{"from": "human", "value": "What health benefits can one expect from eating the food on this tray?\n<image>"}, {"from": "gpt", "value": "The tray contains a variety of nutritious foods, including pasta, beans, corn, carrots, green beans, and cheese. The combination of these ingredients can offer several health benefits. \n\nCarrots and green beans are rich in vitamins and minerals and are a great source of dietary fiber, which supports digestion and can help maintain a healthy weight. Beans and corn provide an excellent source of plant-based protein and essential micronutrients, such as iron, magnesium, and folic acid. These nutrients can help build and repair tissues and support overall body functions. Cheese provides calcium, which is essential for strong bones and teeth, along with other vitamins and minerals, like vitamin B12 and zinc. The pasta shells provide energy in the form of carbohydrates that help fuel daily activities and maintain proper brain function. \n\nBy consuming a diverse and balanced meal like the one in the tray, one can support their overall well-being and invest in their long-term health."}]}, {"id": "000000573453", "image": "coco/train2017/000000573453.jpg", "conversations": [{"from": "human", "value": "What safety precautions should be taken by the man while snowboarding down the slope?\n<image>"}, {"from": "gpt", "value": "When snowboarding down a snow-covered slope, the man should take several safety precautions to minimize the risk of injury and accidents:\n\n1. Wearing appropriate protective gear: This includes a helmet to protect the head from impact during falls, goggles to protect the eyes and improve visibility, wrist guards to prevent wrist injuries, and padded clothing to protect the body.\n\n2. Ensuring the snowboard is properly maintained and adjusted: The bindings should be secure, and the board should be in good condition, free from any damage that might affect its performance.\n\n3. Checking weather and snow conditions: Before heading down the slope, the man should be aware of the current weather and snow conditions to avoid any unexpected hazards such as ice patches or snowstorms.\n\n4. Riding within skill level: The man should select a slope that suits his proficiency and avoid attempting any tricks or techniques beyond his ability.\n\n5. Maintaining safe speeds and controlling the snowboard: Maintaining a safe and appropriate speed, as well as being able to control the snowboard, is crucial to preventing collisions and falls.\n\n6. Being aware of surroundings: The man should stay vigilant and aware of other riders and obstacles, such as trees or rocks, in his path to avoid collisions.\n\nBy taking these precautions, the snowboarder can enjoy a safer experience while navigating the snow-covered slope."}]}, {"id": "000000426976", "image": "coco/train2017/000000426976.jpg", "conversations": [{"from": "human", "value": "What issues might arise from the defacement of this stop sign?\n<image>"}, {"from": "gpt", "value": "The defacement of the stop sign, which is covered in graffiti, tagging, and stickers, can pose several issues. Firstly, it can hinder the visibility and legibility of the sign, leading to potential confusion for drivers and increased risk of traffic accidents. Secondly, the defaced stop sign can give the impression of poor maintenance and lack of order in the area, contributing to an overall negative public image. Lastly, if incidents like this become widespread within the community, it can encourage further vandalism and create an atmosphere of disorder, potentially leading to an increase in crime or reduced property values in the surrounding neighborhood. It is essential to address such issues through regular maintenance, cleanup efforts, and effective law enforcement to uphold the safety and aesthetic quality of the community."}]}, {"id": "000000198240", "image": "coco/train2017/000000198240.jpg", "conversations": [{"from": "human", "value": "What could be the reason for the child eating the cake with his hands?\n<image>"}, {"from": "gpt", "value": "It is likely that the little boy is eating the cake with his hands due to his young age, which is a common behavior among toddlers. At this stage in their development, children may not have fully developed fine motor skills or coordinated enough to use utensils like forks effectively. Eating with their hands allows them to explore the food's texture and have a more engaging and sensory experience. In addition, since the image shows that the child seems to be celebrating his first birthday in an outdoor setting, the informal environment could also contribute to the child's decision to enjoy the cake with his hands."}]}, {"id": "000000187368", "image": "coco/train2017/000000187368.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat design issue can be identified from the image?"}, {"from": "gpt", "value": "The design issue in the image is the placement of the toilet directly inside the glass-enclosed walk-in shower. This is problematic because it doesn't follow the standard layout for restrooms where the shower and toilet are usually separated. The combined setup can lead to water splashing from the shower onto the toilet, potentially causing an uncomfortable experience and raised hygiene concerns. This bathroom layout might require a redesign or repair to address the issue of having the toilet and shower too closely integrated."}]}, {"id": "000000545538", "image": "coco/train2017/000000545538.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat potential risks or safety concerns does this group of people need to consider while watching the elephants?"}, {"from": "gpt", "value": "While the group of people is watching the elephants in the park, there are potential risks and safety concerns they need to consider. First, the group should maintain a safe distance from the elephants to avoid provoking or startling them. As wild animals, elephants can exhibit unpredictable behavior, and they possess great strength, which can result in injuries or damage if a person is too close. Secondly, the people should avoid feeding the elephants, as it can disrupt their natural habitat and diet, and can lead to unintentional aggression. Additionally, the group should pay close attention to the body language of the elephants as well as environmental circumstances that might make the situation less predictable. By doing so, they can anticipate any sudden movements or changes in the elephants' behavior, ensuring their own safety and well-being during this wildlife encounter."}]}, {"id": "000000083079", "image": "coco/train2017/000000083079.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat challenges might someone approaching the bus stop face?"}, {"from": "gpt", "value": "As someone approaches the bus stop where a big green city bus is waiting, they might face challenges due to the presence of other objects and individuals in the area. In the image, there is a bicycle and two people near the bus stop. The pedestrian may need to navigate around these objects and individuals, ensuring they maintain a safe distance, especially if the space is limited. Additionally, there are two stop signs in the scene, with one being close to the bus. The person approaching the bus stop must be aware of their surroundings and pay attention to any potential traffic or proximity to these signs to ensure they safely reach the bus without any issues."}]}, {"id": "000000520769", "image": "coco/train2017/000000520769.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat can be deduced about the environment surrounding this softball game?"}, {"from": "gpt", "value": "Based on the image, the softball game is being played in an urban setting with various vehicles parked in the vicinity of the field. There are cars and trucks visible around the playing area, which indicates that the game is likely being played in a location near streets or parking lots rather than a more isolated or dedicated sports facility. Consequently, this environment may present challenges for the players, such as limited space or distractions from traffic, but it also speaks to the adaptability and love for the sport since the game is being played despite the non-traditional setting."}]}, {"id": "000000365536", "image": "coco/train2017/000000365536.jpg", "conversations": [{"from": "human", "value": "<image>\nConsidering the horse's surroundings, what factors may contribute to its good health?"}, {"from": "gpt", "value": "The horse's good health may be influenced by several factors based on its surroundings in the image. First, there is an abundance of grass for the horse to graze on, providing it with a natural and nutritious food source. This contributes to its dietary well-being. Second, the proximity to the water source, such as a river, ensures that the horse has easy access to freshwater for hydration, which is essential for maintaining overall health. Lastly, the presence of open fields and a hill allows the horse to move around freely and engage in physical activity, promoting regular exercise and muscle development."}]}, {"id": "000000228442", "image": "coco/train2017/000000228442.jpg", "conversations": [{"from": "human", "value": "What are some factors to consider when choosing suitable furnishings and amenities for a bathroom?\n<image>"}, {"from": "gpt", "value": "When selecting suitable furnishings and amenities for a bathroom, several factors should be considered. These include functionality, comfort, available space, style, and overall aesthetic. For example, the bathroom in the image has a wooden tub, large windows, a sink with a box under the faucet, and two chairs. The wooden tub adds to the aesthetic of the room while also providing a comfortable bathing experience. Large windows let in natural light and might offer scenic views, while the blue-tiled floor contributes to the modern design. The box under the faucet and the chairs offer practical storage and seating options. When making such choices, it is essential to strike a balance between practicality and visual appeal, as well as to consider the user's needs and preferences. Additionally, the materials used should be durable and easy to clean, considering the moist environment of a bathroom."}]}, {"id": "000000389654", "image": "coco/train2017/000000389654.jpg", "conversations": [{"from": "human", "value": "<image>\nCan you describe a characteristic of this pizza that makes it enticing?"}, {"from": "gpt", "value": "In the image, the pizza has gooey, melted cheese that stretches as a slice is being taken away from it. This visual characteristic makes the pizza appear enticing and appetizing, as people often find the sight of melted cheese on a pizza quite alluring. Additionally, the close-up shot of the pizza on the table adds to the appeal by showcasing the delicious ingredients and rich textures, creating a mouthwatering experience for the viewer."}]}, {"id": "000000114879", "image": "coco/train2017/000000114879.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat factors could be contributing to the man's relaxing experience at the beach?"}, {"from": "gpt", "value": "There are several factors contributing to the man's relaxing experience at the beach. Firstly, the man is sitting in a colorful beach chair, which allows him to sit comfortably and enjoy the ocean view. The environment also plays a crucial role in his relaxation, as the beach, combined with the sound of ocean waves, creates a calming atmosphere. Additionally, the presence of other people walking by and engaging in various beach activities adds to the overall pleasant ambiance. These factors work together to provide the man with an enjoyable and relaxing beach experience."}]}, {"id": "000000053840", "image": "coco/train2017/000000053840.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat factors might affect the sailboat's departure or arrival at the dock?"}, {"from": "gpt", "value": "Several factors could affect the sailboat's departure or arrival at the dock, including weather conditions, tides, wind speed and direction, and available daylight. In the image, the sailboat is docked at a pier in a bay under a pink sky, which suggests that it might be during a sunset or sunrise. Departing or arriving during daylight hours is generally safer and more convenient for navigation. Additionally, stable weather conditions\u2014such as clear skies, calm seas, and moderate winds\u2014are preferable for smooth sailing. Tides can also play a critical role, as they affect water levels and currents, which may impact the sailboat's ability to safely maneuver near the dock. Sailing experience, as well as the overall condition and maintenance of the sailboat, will also have an impact on the ease or difficulty of departing or arriving at the dock."}]}, {"id": "000000421542", "image": "coco/train2017/000000421542.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat additional information or resources can help the man in the kitchen while cooking?"}, {"from": "gpt", "value": "In the kitchen, the man is standing next to a stove, preparing food in a pot while cooking on an electric stove. To enhance his cooking experience and access additional resources, he could make use of the laptop that is currently placed nearby. The laptop can provide him with online recipes, cooking videos, or even help in setting timers, so he can follow the instructions and prepare the meal more effectively. Additionally, he can also use the refrigerator to store ingredients or access any required ingredients during the cooking process. Bowls and a sink are also available in the kitchen, which can be helpful for washing ingredients, prepping food, or cleaning up during or after cooking."}]}, {"id": "000000455744", "image": "coco/train2017/000000455744.jpg", "conversations": [{"from": "human", "value": "What kind of situation could have led to this scene?\n<image>"}, {"from": "gpt", "value": "A possible situation that could have led to this scene is that the black cat, being naturally curious, decided to explore the bathroom while it was empty. Cats tend to wander around and check different spaces in their environment. The bathroom door being partially open allowed the cat to easily enter and explore the room. As the cat finishes its exploration, it walks out of the bathroom, leading to the captured scene of the cat exiting through the partially opened door. The robe and towel hanging on the back of the door indicate that the bathroom is used, but at this moment, no one else is inside."}]}, {"id": "000000426778", "image": "coco/train2017/000000426778.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat might be the reason for the cat to choose this unusual place to rest?"}, {"from": "gpt", "value": "The cat might have chosen to rest in the dish tray in the sink for various reasons. Cats are known for their curious and playful nature, so the cat may have been exploring its environment and found the dish tray in the sink as an interesting and comfortable spot to lay. The sink's enclosed and elevated space creates a sense of security for the cat, similar to how it would feel inside a basket or a cage. Additionally, the dish tray might provide a cool, solid surface to rest on, which can be appealing to cats, particularly during warm weather or when seeking relief from heat. It's also possible that the cat has simply found the location appealing and interesting, ultimately deciding to rest there for a change in routine or surroundings."}]}, {"id": "000000316059", "image": "coco/train2017/000000316059.jpg", "conversations": [{"from": "human", "value": "<image>\nWhy is it important for fire hydrants to be easily visible like the one in the image?"}, {"from": "gpt", "value": "It is crucial for fire hydrants to be easily visible for the purpose of efficient and effective emergency response. The bright red color of the fire hydrant in the image helps it stand out against the surrounding grass and road, making it quickly identifiable for firefighters in case of an emergency. This enables them to locate and access the hydrant with minimal delay, which is essential for saving lives and minimizing property damage during a fire. Furthermore, a clearly visible fire hydrant also ensures that residents and drivers in the area are aware of its presence, thereby reducing the likelihood of obstructions or accidents related to the hydrant. Overall, easy visibility of fire hydrants plays a significant role in ensuring public safety and seamless emergency response."}]}, {"id": "000000084243", "image": "coco/train2017/000000084243.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat environmental benefits might this grazing cow provide?"}, {"from": "gpt", "value": "Grazing cows, like the one in the image peeking between young trees, can provide several environmental benefits. First, they can contribute to the maintenance of grasslands and meadows, as their grazing action helps to control plant growth and prevent overcrowding or overgrowth of certain species. This can promote biodiversity and create habitats for various wildlife species. Second, cows' natural fertilization through their manure adds nutrients back into the soil, promoting the soil's fertility and productivity. Additionally, well-managed grazing practices can improve water infiltration into the soil, which helps reduce soil erosion and runoff. However, it is important to practice responsible and sustainable grazing to ensure that these benefits are realized without causing harm to the environment, such as overgrazing or soil degradation."}]}, {"id": "000000210187", "image": "coco/train2017/000000210187.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat are some potential concerns for a parent when having a young child eat a doughnut in this setting?"}, {"from": "gpt", "value": "In this setting, where a young girl is eating a doughnut at a wooden table with several chairs around, a parent might have a few concerns:\n\n1. Hygiene and cleanliness: As doughnuts can be sticky and messy, the surfaces and the child's hands may become dirty. Parents should ensure their kids have napkins or wet wipes to clean their hands and avoid touching other surfaces, especially during a pandemic context.\n\n2. Dietary concerns: Doughnuts are high in sugar and calories, and some parents may be concerned about their child's nutritional intake. A doughnut as an occasional treat is acceptable, but moderation is essential for maintaining a balanced diet.\n\n3. Allergies: Many doughnuts contain allergens, such as gluten, dairy, and nuts. Parents should be aware of any allergies their child might have and inquire about the doughnut's ingredients before letting their child consume it.\n\n4. Choking hazard: Doughnuts can have a dense texture, which may pose a choking risk for young children. Parents should monitor their children while eating doughnuts to ensure they chew their food properly and do not choke.\n\n5. Uncontrolled environment: Restaurants and cafe settings are public spaces where accidents can happen or other patrons may be nearby. Parents should be vigilant about their child's safety, watching out for potential hazards and ensuring the child behaves appropriately in the shared space."}]}, {"id": "000000107975", "image": "coco/train2017/000000107975.jpg", "conversations": [{"from": "human", "value": "What can be said about the social dynamic in this scene?\n<image>"}, {"from": "gpt", "value": "In the scene, a group of people is gathered around a tasty-looking pizza with multiple toppings like bell peppers, black olives, and pineapple, placed on a wooden cutting board. The social dynamic appears to be friendly and casual, as the people enjoy sharing a delicious meal. This scenario suggests a sense of camaraderie among the individuals, as they come together to partake in a communal experience, bonding over their shared love for pizza. The act of holding up and sharing the pizza showcases cooperation and potentially a lighthearted and fun atmosphere."}]}, {"id": "000000280132", "image": "coco/train2017/000000280132.jpg", "conversations": [{"from": "human", "value": "What unusual sight are the group of people on the bridge likely looking at, and why is it noteworthy?\n<image>"}, {"from": "gpt", "value": "The large group of people standing on the bridge is likely looking at a sheep that is grazing on the grass. The unusual aspect of this scene is that the sheep is somehow colored pink, which is not a natural color for sheep. The pink sheep grazing in an open field close to the water and the crowd is a noteworthy sight because it attracts attention and curiosity \u2013 people may wonder why the sheep is pink and how it got that color. This unique sight creates an interesting contrast between the ordinary activities of the sheep and the bold, unexpected pink appearance."}]}, {"id": "000000446670", "image": "coco/train2017/000000446670.jpg", "conversations": [{"from": "human", "value": "What might the different chairs around the table signify?\n<image>"}, {"from": "gpt", "value": "Having four different chairs around the wooden dining table could signify a variety of things. It might indicate the owner's preference for an eclectic and unique design style, where each chair brings its own character to the space. This non-traditional approach can create a more visually interesting and welcoming environment for gatherings or meals. Alternatively, it could also be a practical choice, where the chairs have been collected over time or have been repurposed from other areas of the house to accommodate guests at the dining table. It symbolizes flexibility, adaptability, and an appreciation for diverse design elements in a home setting."}]}, {"id": "000000372789", "image": "coco/train2017/000000372789.jpg", "conversations": [{"from": "human", "value": "Considering the design of this toilet, what potential problem might the users experience?\n<image>"}, {"from": "gpt", "value": "In the image, there is a white western toilet with no seat cover. The lack of a seat cover can cause a few problems for the users, such as discomfort while sitting on the cold porcelain, potential hygiene concerns, and a less pleasant aesthetic appearance. A seat cover usually provides comfort and insulation from the cold, making the user experience more enjoyable. Additionally, it can serve as a barrier against germs and bacteria, promoting good hygiene practices in the bathroom. In this case, users might prefer placing an aftermarket seat cover or replacing the toilet with one that includes a seat cover for better comfort, hygiene, and appearance."}]}, {"id": "000000513888", "image": "coco/train2017/000000513888.jpg", "conversations": [{"from": "human", "value": "How will the dog's activity impact its post-beach care?\n<image>"}, {"from": "gpt", "value": "After having fun walking and running through the water on the wet beach, the dog will likely require some post-beach care. As the dog has been in contact with sand and saltwater, it will likely be wet and have sand or other debris attached to its fur or paws. To ensure the dog's comfort and cleanliness, the dog's owner should rinse or wash the dog with fresh water to remove salt and sand, paying close attention to its paws, legs, fur, and any areas that might have sand trapped. After rinsing, the owner should thoroughly dry the dog with a towel to keep it warm and comfortable. Regular post-beach care also helps maintain the dog's coat and overall skin health."}]}, {"id": "000000550532", "image": "coco/train2017/000000550532.jpg", "conversations": [{"from": "human", "value": "What might be the impact of using parking meters on the street?\n<image>"}, {"from": "gpt", "value": "The presence of parking meters on the street helps regulate and manage parking spaces outside the business they are positioned in front of. The use of parking meters can have several benefits and impacts, such as:\n\n1. Encouraging turnover of parking spaces, ensuring more customers can access the business over time by limiting long-term parking.\n2. Assisting in maintaining order and managing on-street parking, preventing overcrowding and congestion.\n3. Generating revenue for the local government or municipal authority, which can be used to fund improvements in the area, such as infrastructure, public services, or amenities.\n4. Promoting the use of alternative transportation options such as public transit, walking, or cycling, as drivers may opt for these modes instead of paying for parking.\n\nHowever, there can also be some drawbacks or challenges, such as:\n1. Potential inconvenience for users, who must ensure they have coins or payment methods compatible with the parking meters.\n2. Can be a source of frustration for drivers searching for parking, especially during peak times.\n\nOverall, the use of parking meters can aid in supporting local businesses and promoting effective space management when properly implemented and maintained."}]}, {"id": "000000251360", "image": "coco/train2017/000000251360.jpg", "conversations": [{"from": "human", "value": "<image>\nWhy might the cat be sitting under the umbrella indoors?"}, {"from": "gpt", "value": "The cat might be sitting under the umbrella indoors due to its curiosity and natural instincts to seek out small, enclosed spaces. Cats often find comfort and security in confined areas that provide shelter and protection, as it resembles their natural habitat of dens or hiding spots in the wild. The cat could be attracted to the umbrella as a novel or playful object that peaks its interest, or it may find the umbrella an interesting alternative to a typical hiding spot. Additionally, cats are known for their quirky and unpredictable behaviors, which can lead to amusing and unusual situations like the one depicted in the image."}]}, {"id": "000000098162", "image": "coco/train2017/000000098162.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat factors contributed to a fun and refreshing time for these people at the pool?"}, {"from": "gpt", "value": "On a hot day, three people (two women and a man) are cooling off and having fun in a blue in-ground pool. They are playing with a frisbee, which adds a playful and engaging element to their time spent in the pool. This activity allows them to enjoy the water while also socializing, staying active, and fostering a lighthearted atmosphere. The combination of the cool water, the sunny weather, and the interactive game make for a refreshing and enjoyable experience for these individuals."}]}, {"id": "000000013988", "image": "coco/train2017/000000013988.jpg", "conversations": [{"from": "human", "value": "<image>\nWhy might these horses exhibit calmer behavior in a sunny field?"}, {"from": "gpt", "value": "Horses generally exhibit calmer behavior in open, sunny fields because they have space to graze, roam, and interact with their surroundings in a more natural and stress-free setting. The presence of grass provides them with an ample food supply, and their innate social behavior allows them to interact and bond with other horses. The sunny weather also contributes to their well-being, as it provides an ideal environment for their physical and mental wellbeing. Access to sunlight is crucial for the synthesis of Vitamin D, which is essential for maintaining their bone health. Therefore, the serene environment of the sunny field, combined with the presence of other horses and a sufficient food supply, allows these horses to exhibit more relaxed and content behavior."}]}, {"id": "000000351480", "image": "coco/train2017/000000351480.jpg", "conversations": [{"from": "human", "value": "<image>\nCan you identify any unusual accessories or clothing the man is wearing?"}, {"from": "gpt", "value": "In the image, the bald man with a black beard is wearing a grey suit and a yellow vest, which is an unusual combination. This stands out from the typical suit attire as people usually wear vests of a similar color or a more subdued shade to match their suit. The man's choice of a yellow vest adds a distinctive touch to his outfit, exhibiting personal style or possibly representing an event where he was encouraged to wear colorful attire."}]}, {"id": "000000044227", "image": "coco/train2017/000000044227.jpg", "conversations": [{"from": "human", "value": "Why might the dog be having trouble to hold the ball properly in its mouth?\n<image>"}, {"from": "gpt", "value": "The dog may be having trouble holding the ball properly in its mouth because the ball appears to be deflated or partially deflated, making it more challenging to grip securely. In the image, a large brown dog is running outside with a deflated soccer ball in its mouth. When a ball is deflated, it loses its shape and rigidity, which could cause the dog to struggle to hold it in a stable position while running. Additionally, this might also make it more difficult for the dog to play with the ball or carry it around, as it does not have the typical bounce and structure of a fully inflated ball."}]}, {"id": "000000209933", "image": "coco/train2017/000000209933.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat advantages can be gained from having both a toilet and a bidet in a bathroom?"}, {"from": "gpt", "value": "Having both a toilet and a bidet in a bathroom offers several advantages to users. Firstly, a toilet is designed for the disposal of human waste, whereas a bidet provides a stream of water for cleansing and personal hygiene after using the toilet. The combination of a toilet and a bidet can significantly improve the cleanliness and comfort of users.\n\nSecondly, using a bidet can be more environmentally friendly and cost-effective, as it reduces the need for toilet paper consumption. This can lead to less waste and lower overall expenses in the long run.\n\nLastly, having a bidet in the bathroom can cater to the preferences and cultural habits of different individuals, providing a more inclusive and welcoming space for everyone. It also helps in accommodating guests from different backgrounds who may be more accustomed to using a bidet for personal hygiene."}]}, {"id": "000000250380", "image": "coco/train2017/000000250380.jpg", "conversations": [{"from": "human", "value": "Can you describe the activity happening in the park and the possible intention of the two people?\n<image>"}, {"from": "gpt", "value": "In the park, two people and a small black dog are engaged in a playful activity on a bright, clear day. The area is filled with green and flowering trees, making the scene picturesque. The dog is trotting with a frisbee in its mouth, while the people are running, one in front of the dog and the other behind it. They seem to be trying to encourage the dog to release the frisbee or chase it as part of the game. This activity likely serves as an enjoyable way for the people and their dog to bond, exercise, and spend leisure time outdoors."}]}, {"id": "000000191156", "image": "coco/train2017/000000191156.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat concerns might arise from this unusual situation?"}, {"from": "gpt", "value": "In the image, two cats are sitting inside a full refrigerator, surrounded by various food items such as bottles, bowls, apples, and oranges. This unusual situation raises several concerns, including hygiene, safety, and potential damage to the refrigerator or its contents.\n\nFirstly, having the cats in the refrigerator can lead to hygiene issues, as they are living creatures and could contaminate the food items with germs or hair. It is essential to keep food properly stored and away from animals to ensure the safety and health of the people consuming the food.\n\nSecondly, there is a safety concern for the cats in this situation. The cold temperature of the refrigerator can be harmful to the animals if they remain inside for an extended period. Also, there is a risk that the cats might knock over or damage fragile items such as bottles, which could lead to spills, broken glass, or other hazards inside the refrigerator.\n\nIt is important to address such concerns by removing the cats from the refrigerator, checking for any contamination or damaged items, and ensuring that the refrigerator is closed and secured to prevent similar incidents in the future."}]}, {"id": "000000116123", "image": "coco/train2017/000000116123.jpg", "conversations": [{"from": "human", "value": "What can one infer about the surroundings, given the presence of these birds and boats?\n<image>"}, {"from": "gpt", "value": "From the presence of numerous birds, including swans and ducks, swimming in the water, and the variety of boats docked at the marina, one can infer that the surroundings might be a popular location or a recreational area. The birds find this environment suitable for feeding and resting, while the marina serves as a docking space for boats used for transportation, leisure, or other water-related activities. The location might attract tourists or local visitors due to the picturesque natural scenery and access to water-based recreational opportunities."}]}, {"id": "000000247700", "image": "coco/train2017/000000247700.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat challenges might local businesses face in this area to attract customers?"}, {"from": "gpt", "value": "In this busy shopping area in China, local businesses may face challenges in attracting customers due to the significant number of signs with Asian and English writing, advertisements, and competition from surrounding businesses. With so many signs vying for attention, it could be difficult for individual businesses to stand out and entice customers. They may need to find unique or creative ways to market their products and services, while also offering compelling deals, exceptional customer service, or superior quality to compete effectively with neighboring businesses. Additionally, businesses would have to deal with heavy traffic and a large number of pedestrians which may create logistical challenges or make accessibility less convenient for potential customers. Effective marketing strategies, innovative promotions, and efficient operations would be crucial for success in this highly competitive marketplace."}]}, {"id": "000000425576", "image": "coco/train2017/000000425576.jpg", "conversations": [{"from": "human", "value": "What implications might eating this snack have on the woman's health if consumed frequently?\n<image>"}, {"from": "gpt", "value": "If the woman consumes mini donuts or similar sugary snacks frequently, it can have negative implications on her health. Regular intake of such high-sugar and high-calorie snacks can lead to weight gain and an increased risk of obesity. Additionally, a diet high in sugar can contribute to the development of type 2 diabetes, tooth decay, and heart disease. It is important to maintain a balanced diet and limit the consumption of unhealthy snacks to ensure overall health and well-being. Instead, incorporating healthier snack options like fruits, nuts, and whole grain products can help maintain a balanced diet and reduce the risk of health issues caused by consuming sugary snacks."}]}, {"id": "000000417230", "image": "coco/train2017/000000417230.jpg", "conversations": [{"from": "human", "value": "What benefits do these officers gain by patrolling on horseback in this location?\n<image>"}, {"from": "gpt", "value": "Patrolling on horseback provides several advantages to these officers, especially in this specific location by the beach or near a body of water. Horses can easily navigate through sandy, uneven, or wet terrain, which might be difficult for vehicles. This allows the officers to efficiently patrol the area and easily reach places that might be inaccessible or less convenient for other modes of transport. Moreover, being on horseback grants the officers an elevated vantage point, making it easier for them to observe a wider area and have better visibility of their surroundings. Additionally, having a police presence on horseback can be engaging and approachable, potentially leading to positive community relations between officers and the public."}]}, {"id": "000000475316", "image": "coco/train2017/000000475316.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat improvements can be made to enhance the overall appearance of this kitchen and dining area?"}, {"from": "gpt", "value": "While the kitchen and dining area already have a nice ambiance with wood floors, wood cabinets, and attractive wood colors, some improvements can be made to enhance its appearance further. Additional storage options like shelves, hooks, or even a kitchen island for holding cups, bottles, knives, and books would help to declutter the space and make it more organized. Upgrading the lighting to create a warm and inviting atmosphere can also be beneficial. Additionally, placing some decorations like artwork or plants on the walls, countertops, or around the dining area will add a personal touch and make the space feel cozier and more inviting."}]}, {"id": "000000281230", "image": "coco/train2017/000000281230.jpg", "conversations": [{"from": "human", "value": "What factors might have influenced the person's choice of location for flying the kite?\n<image>"}, {"from": "gpt", "value": "The person chose to fly the kite at the beach, standing in shallow water. Several factors might have influenced this decision. Beaches usually provide wide, open spaces, enabling the kite to fly freely without obstructions such as trees or buildings. Additionally, winds near the coast and beaches tend to be stronger and more consistent, providing favorable conditions for flying a kite. This allows for better kite control and more enjoyable kite-flying experience. Moreover, the beach and water make for a pleasant and visually appealing environment to spend time outdoors, which could also contribute to the choice of location."}]}, {"id": "000000341741", "image": "coco/train2017/000000341741.jpg", "conversations": [{"from": "human", "value": "How can one maintain a healthier work-life balance in this living space?\n<image>"}, {"from": "gpt", "value": "To maintain a healthier work-life balance in this living space featuring a bed, a small table with an open laptop, and a chair, it is essential to establish clear boundaries between work areas and leisure areas. One way to achieve this is by creating a dedicated workspace, separate from the bed. This could involve setting up the laptop and chair at another location within the room, perhaps near a window for natural light, or arranging a small desk as a separate work area. Another important aspect is to maintain a schedule differentiating work time from personal time, avoiding using the laptop for work-related tasks outside of the designated working hours. Additionally, maintaining a clutter-free environment, organizing the workspace, and creating a daily routine that includes breaks, exercise, and social activities will further contribute to a more balanced lifestyle."}]}, {"id": "000000201706", "image": "coco/train2017/000000201706.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat possible reason could explain the group of people with matching backpacks near the double-decker bus?"}, {"from": "gpt", "value": "One possible explanation for the group of people with matching backpacks near the double-decker bus could be that they are tourists on a guided tour. The matching backpacks might indicate that they are part of an organized tour group, which often provides participants with similar gear for identification purposes or as a souvenir. These groups typically travel together, and the bus could be the transportation method provided for them to explore the city more conveniently. It is not uncommon for tour groups to use double-decker buses, especially in cities like London, where this particular type of bus is a popular and iconic choice."}]}, {"id": "000000469988", "image": "coco/train2017/000000469988.jpg", "conversations": [{"from": "human", "value": "What challenges might the person or people living in this home be facing right now?\n<image>"}, {"from": "gpt", "value": "The image depicts a living room with several bags, including backpacks, a handbag, and a suitcase, piled on the floor in the middle of the room. This suggests that the person or people living in the home might be facing challenges related to travel, packing, or organizing their belongings. They could be preparing for a trip and trying to decide what to pack or possibly returning from a trip and facing the task of unpacking and putting things away. The presence of a large number of bags could indicate that multiple people are involved, which adds to the complexity of managing the situation. The challenge is to efficiently pack or unpack and restore order and organization to the living room while maintaining the function and aesthetics of the space."}]}, {"id": "000000393924", "image": "coco/train2017/000000393924.jpg", "conversations": [{"from": "human", "value": "<image>\nHow could the importance of this couple's relationship be inferred in the photo?"}, {"from": "gpt", "value": "In the photo, the couple stands next to each other, with the woman in a pink dress and the man in a suit sporting a purple tie. They are hugging each other, posing for the camera. The fact that they are dressed formally, especially with the man's suit and the woman's elegant pink dress, suggests that they are attending a significant event, possibly a wedding or a formal celebration. Their closeness\u2014both physically and emotionally\u2014as they embrace and pose together implies that they share a strong bond and that their relationship is important to them. The atmosphere indicates that they are celebrating a special moment in their lives, adding to the significance of their relationship."}]}, {"id": "000000059351", "image": "coco/train2017/000000059351.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat might be the purpose of this woman's journey with the horse and the dog?"}, {"from": "gpt", "value": "The woman's purpose for her journey with the horse and dog could be various reasons such as transportation, exploration, or engaging in a leisurely pastime. In the image, the woman is walking on a dirt path alongside a horse, which appears to be carrying a pack on its back, and a dog. This suggests that they might be traveling a significant distance or on an adventure. The woman could be enjoying the company of her animals, while also using the horse to transport goods, equipment, or supplies during her journey. Additionally, they could be exploring nature or partaking in a relaxing outdoor activity that allows them to connect with the environment and their animals."}]}, {"id": "000000010735", "image": "coco/train2017/000000010735.jpg", "conversations": [{"from": "human", "value": "<image>\nWhy might these elephants be interacting with toys such as logs and tires in their enclosure?"}, {"from": "gpt", "value": "These elephants could be interacting with toys such as logs and tires in their enclosure as a part of enrichment activities provided by the zookeepers. Enrichment activities are designed to stimulate the animals' natural behaviors, improve their well-being, and reduce boredom and stress in captivity. Toys like logs and tires help elephants engage in physical activity, provide mental stimulation, and encourage social interactions between the elephants, all of which are essential for their overall health and happiness in the zoo environment. Providing a variety of enrichment activities mimics the challenges and experiences the animals would encounter in the wild, making their life in captivity more appealing and enjoyable."}]}, {"id": "000000451983", "image": "coco/train2017/000000451983.jpg", "conversations": [{"from": "human", "value": "What difficulties might the man be facing?\n<image>"}, {"from": "gpt", "value": "The man in the image faces the challenge of carrying a suitcase up a small flight of stairs. This physical task could be difficult depending on the weight and size of the suitcase, the number of stairs, and the man's strength and stamina. Carrying luggage up the stairs can also be cumbersome and tiring, especially if there is no alternative way to transport the suitcase, such as an elevator or escalator. Additionally, if the man has any physical limitations or health issues, this task could pose further challenges and discomfort for him."}]}, {"id": "000000447994", "image": "coco/train2017/000000447994.jpg", "conversations": [{"from": "human", "value": "What could be the reason behind having a little wine in each glass?\n<image>"}, {"from": "gpt", "value": "Having a little wine in each of the four glasses on the table might be due to a wine tasting event. In such events, participants sample and evaluate small amounts of various wines, comparing their flavors, aromas, and other characteristics. Typically, these glasses are only partially filled to allow participants to swirl the wine around the glass, which enables them to better examine the color, texture, and scent of the wine. The presence of the books and papers on the table further suggests that this might be an educational or professional setting, where people are discussing and taking notes on the wines being tasted."}]}, {"id": "000000103775", "image": "coco/train2017/000000103775.jpg", "conversations": [{"from": "human", "value": "What aspects of the scene indicate a relaxing atmosphere for the two people sitting near the water?\n<image>"}, {"from": "gpt", "value": "The relaxing atmosphere in the scene is indicated by several aspects. Firstly, the two people are sitting in chairs next to each other and facing the water, which suggests that they are enjoying the calming view of the ocean and sailboats. The presence of multiple boats, including sailboats, further adds to the serene ambiance, as people often associate sailing with relaxation and leisurely activities. Additionally, the chairs are placed close to the water, offering an unobstructed view of the harbor and allowing the couple to immerse themselves in the tranquil surroundings. The fact that they are seated also conveys a sense of relaxation and comfort, as they are taking the time to sit and appreciate the peaceful setting."}]}, {"id": "000000295655", "image": "coco/train2017/000000295655.jpg", "conversations": [{"from": "human", "value": "Besides the girl, what other distractions or hazards might pedestrians be aware of in this area?\n<image>"}, {"from": "gpt", "value": "In the image where the girl is looking at her phone near a flower garden, there are multiple bicycles, both parked and ridden, as well as cars parked or moving on the street. Pedestrians should be aware of these potential distractions or hazards while walking in the area. They need to ensure they are cautious and vigilant around the bicycles and cars to avoid accidents, especially as people might be focused on their phones or rushing to their destinations. In addition to this, there are several other people present in the scene which might cause some distractions or require attention to maintain safe navigation in the space."}]}, {"id": "000000304889", "image": "coco/train2017/000000304889.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat emotion might the man be experiencing and why?"}, {"from": "gpt", "value": "The man appears to be experiencing shock or surprise, as evidenced by the shocked face he is making. It is not entirely clear from the image as to why he is reacting this way; however, it could be due to a surprising conversation, an unexpected event or incident, or even a tasting experience with the bright-colored beverage in his wine glass. As he is holding a wine glass and wearing a black hat and shirt, it can be inferred that he is at a social gathering or event, where such emotions might arise in response to interactions or circumstances."}]}, {"id": "000000155505", "image": "coco/train2017/000000155505.jpg", "conversations": [{"from": "human", "value": "What could be the potential purpose behind transporting these large tractors?\n<image>"}, {"from": "gpt", "value": "The potential purpose behind transporting these large tractors could be that they are being delivered to a customer, a farm, or a construction site where they are needed for specific tasks. Tractors are commonly used in agricultural and construction applications for their versatility and ability to perform various jobs efficiently. They might be used for tilling, plowing, planting, and other heavy-duty tasks on farms or for heavy lifting, excavation, and general construction projects. The semi-truck in the image is hauling three tractors on its trailer, suggesting that these machines might be destined for different locations or for a particularly large project that requires multiple tractors to be used simultaneously."}]}, {"id": "000000216766", "image": "coco/train2017/000000216766.jpg", "conversations": [{"from": "human", "value": "What are some factors affecting the cyclist's relaxation experience, and how could they impact their well-being?\n<image>"}, {"from": "gpt", "value": "The cyclist in the image is resting on a bench by the windy beach, with their bicycle parked nearby. The location next to the ocean offers a serene environment for relaxation, with the calming sound of the waves and the vast open view that can help alleviate stress. Moreover, the physical activity of cycling contributes positively to their physical and mental well-being.\n\nHowever, some factors might affect the cyclist's relaxation experience. The presence of numerous birds in the vicinity could potentially be a source of disturbance or distractions. The wind at the beach might also make it challenging for the cyclist to fully relax due to strong gusts or shifting sand. Additionally, the cyclist's personal belongings, such as the handbag and backpack, need to be attended to, which may pose a risk of theft and could prevent the person from fully immersing in the relaxation experience.\n\nOverall, while the beach presents a beautiful setting for relaxation, the cyclist should be aware of various environmental factors and pay attention to personal belongings to ensure a safe and peaceful experience."}]}, {"id": "000000074403", "image": "coco/train2017/000000074403.jpg", "conversations": [{"from": "human", "value": "What potential health benefits might one expect from this dish?\n<image>"}, {"from": "gpt", "value": "The dish on the white plate consists of broccoli and other vegetables, as well as meat, covered in sauce. This meal can offer various health benefits due to its combination of nutrient-rich ingredients. Broccoli is a cruciferous vegetable, high in vitamins C and K, and a good source of fiber, potassium, and antioxidants, which can support the immune system, bone health, digestion, and overall well-being. The other vegetables likely contribute additional vitamins, minerals, and fiber, promoting balanced nutrition. The meat in the dish serves as a source of protein, essential for muscle growth and repair, as well as for maintaining healthy hair, skin, and nails. However, it is essential to consider that the nutritional benefits may vary depending on the type of meat, cooking method, and sauce used. A health-conscious choice would involve lean meats and a sauce low in sodium and unhealthy fats. Overall, a meal with a mix of vegetables and protein provides a balanced diet for various health benefits."}]}, {"id": "000000437889", "image": "coco/train2017/000000437889.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is out of place in the scene?"}, {"from": "gpt", "value": "In the scene, there is an out-of-place object when considering the view of vegetation and the landscape through a window. A bottle can be spotted in the image, which seems unrelated to the surrounding view of trees and hills. While the focus should be on the landscape or the window frame, the presence of the bottle diverts attention and can be deemed out of place in this context."}]}, {"id": "000000117884", "image": "coco/train2017/000000117884.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat might the person be doing or intending to do with the doughnut?"}, {"from": "gpt", "value": "The person holding the large frosted doughnut in both hands seems to be showing it off for the camera. They might be presenting the doughnut to others, possibly to share it or to highlight its size and pink icing. This could be a fun and playful gesture, or it might be related to an event, celebration, or some form of social media content showcasing unique or eye-catching food items."}]}, {"id": "000000400710", "image": "coco/train2017/000000400710.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat might the skateboarder be focused on or aiming for when using the skatepark?"}, {"from": "gpt", "value": "At the skatepark, the skateboarder is likely focused on performing tricks, improving his skills, and having fun while riding his skateboard. He could be aiming to ride ramps, grind on rails or edges, and achieve better control and balance on his skateboard. As he uses the various features of the skatepark, such as ramps and ledges adorned with graffiti murals, he can challenge himself and progress in his abilities while safely practicing different maneuvers within the designated skateboarding area."}]}, {"id": "000000463464", "image": "coco/train2017/000000463464.jpg", "conversations": [{"from": "human", "value": "What advice would you give to someone who wants to replicate the restaurant-style grilled cheese sandwiches at home?\n<image>"}, {"from": "gpt", "value": "To replicate the restaurant-style grilled cheese sandwiches at home, follow these steps:\n\n1. Choose quality ingredients: Pick a good-quality bread with a nice crust, and use a flavorful cheese that melts well, such as cheddar, mozzarella, or Swiss.\n\n2. Preheat your griddle or pan: Heat your griddle or pan on medium heat to ensure even cooking without burning the bread.\n\n3. Prepare the bread: Lightly spread softened butter on one side of each bread slice. This will help create a crisp and golden-brown exterior when grilling.\n\n4. Assemble the sandwiches: Place a generous amount of cheese between the non-buttered side of the bread slices. The buttered sides should face outward.\n\n5. Grill the sandwiches: Place the assembled sandwiches on the preheated griddle or pan. Cook them carefully, flipping once the bread turns golden brown and the cheese begins to melt. Keep an eye to avoid burning, adjusting the heat if necessary.\n\n6. Monitor the cooking process: Use a spatula to occasionally press down on the sandwiches to ensure even contact with the griddle, but avoid squashing them.\n\n7. Serve immediately: Once both sides of the sandwiches are golden brown and the cheese is melted, remove them from the griddle, slice them in half, and serve immediately.\n\nBy following these steps and paying attention to the details, you can create delicious restaurant-style grilled cheese sandwiches in your home kitchen."}]}, {"id": "000000069424", "image": "coco/train2017/000000069424.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat potential issues could arise for the horse in this type of terrain, and what precautions could be taken to help it?"}, {"from": "gpt", "value": "The horse is navigating a hill covered in tall, dry grass, which can pose several potential issues such as slipping hazards, possible presence of insects or hidden objects, and overexertion due to the incline. To ensure the horse's safety and minimize these risks, measures can be taken such as:\n\n1. Regularly checking and maintaining the horse's hooves and shoes to ensure they are in good condition for better traction on the uneven terrain.\n2. Being cautious and maintaining a steady pace while the horse walks down the hill to prevent slipping or losing balance.\n3. Clearing a path, if possible, to remove any hidden obstacles or debris in the tall grass.\n4. Monitoring the horse for signs of fatigue and taking breaks when needed to prevent overexertion.\n5. Applying insect repellent and regularly checking the horse for ticks, as the tall grass can be a suitable habitat for various insects.\n\nBy incorporating these precautions, the horse will be better protected and able to navigate this type of terrain more comfortably and safely."}]}, {"id": "000000577484", "image": "coco/train2017/000000577484.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of bathroom experience does the hotel provide?"}, {"from": "gpt", "value": "The hotel provides a clean and minimalist bathroom experience. The image shows a beautiful white bathroom with a single sink, white towels, white walls, and a huge mirror. Two cups are placed on the vanity next to the sink. The simplicity of the design creates a calming and uncluttered atmosphere for guests, focusing on providing essential amenities and comfort during their stay. The presence of towels on a rack and the well-lit space with a large mirror enhance the functionality and convenience of the bathroom for guests."}]}, {"id": "000000185830", "image": "coco/train2017/000000185830.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat precautions should be considered by the skier in this situation?"}, {"from": "gpt", "value": "In the image, a skier is skiing down a snow-covered slope while wearing a backpack. The skier should consider several precautions to ensure safety during the adventure. First, the skier must ensure that they have appropriate safety gear, such as a helmet, goggles, and suitable clothing to protect against cold temperatures and to maintain visibility during the activity. The skier should also be aware of their skill level and choose slopes that match their abilities to avoid accidents or overexerting themselves.\n\nUsing well-maintained equipment, including properly fitted skis and bindings, is essential for safety and performance. Additionally, since the skier is carrying a backpack, they need to consider the extra weight and the impact it has on their balance, maneuverability, and stamina.\n\nMoreover, the skier should familiarize themselves with the terrain, including any obstacles, steep sections, or potential avalanche risks, and always follow the designated slopes, trails, and safety guidelines at the skiing location. Finally, keeping track of weather conditions, skiing in pairs or groups, and maintaining communication with relevant authorities or emergency services can significantly increase safety and help in case of unexpected incidents."}]}, {"id": "000000422170", "image": "coco/train2017/000000422170.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat are some possible reasons for the lady sitting on the bleachers to use her cell phone?"}, {"from": "gpt", "value": "There are numerous reasons for the lady sitting on the bleachers to use her cell phone. She could be communicating with friends or family, checking social media, browsing the internet, or accessing relevant information. She might also be using her phone for entertainment purposes, such as playing games, watching videos, or listening to music. Alternatively, she could be using her phone to capture the moment or setting either for a picture or a video. In today's digital age, cell phones serve as powerful tools that allow users to stay connected, informed, entertained, and productive in a variety of situations, including while sitting on bleachers in public spaces."}]}, {"id": "000000111831", "image": "coco/train2017/000000111831.jpg", "conversations": [{"from": "human", "value": "What challenges might the city face during peak hours or large events?\n<image>"}, {"from": "gpt", "value": "During peak hours or large events, the city might face challenges related to transportation, congestion, and pedestrian safety. In the image, there is a very busy intersection filled with a large crowd of people, numerous cars and buses, and traffic lights. With such a high volume of commuters and vehicles, traffic congestion and increased travel time become more likely. Additionally, the city needs to ensure effective traffic management and signal synchronization to maintain traffic flow and reduce delays. Moreover, pedestrian safety becomes a concern, as crowded sidewalks and crosswalks may lead to accidents or delays for those on foot. The city must consider developing infrastructure and policies to manage the high volume of commuters and promote alternative modes of transportation, such as public transit or cycling, to alleviate these challenges."}]}, {"id": "000000030805", "image": "coco/train2017/000000030805.jpg", "conversations": [{"from": "human", "value": "What are some possible uses of the liquid inside the cup?\n<image>"}, {"from": "gpt", "value": "The yellow or white-beige liquid inside the cup (blender or glass measuring cup) could have various uses depending on its content. If it is a freshly blended smoothie, juice, or shake made from fruits or vegetables, it can be consumed as a healthy and refreshing beverage. Alternatively, if it is a sauce or dressing, it can be drizzled over salads, used as a dipping sauce, or added to recipes to enhance the flavors of a dish. Additionally, if it is a batter or mixture for cooking, such as pancake mix or cake batter, it can be used as a base to prepare various baked goods or breakfast items. The precise use of the liquid depends on the ingredients and the desired end product."}]}, {"id": "000000309523", "image": "coco/train2017/000000309523.jpg", "conversations": [{"from": "human", "value": "What's an activity these two people might be engaged in, and why would they perform it in high heels?\n<image>"}, {"from": "gpt", "value": "These two people might be engaged in a social event, such as a party or gathering, where dressing up and wearing high heels is an essential part of their attire. High heels are often worn to formal occasions or events that require stylish and elegant clothing. Wearing high heels can enhance the appearance, adding height and sophistication to their overall look. As the two people are standing close together with crossed legs, it also suggests that they might be engaged in a conversation or enjoying each other's company during the event."}]}, {"id": "000000385940", "image": "coco/train2017/000000385940.jpg", "conversations": [{"from": "human", "value": "What possible purpose does the color scheme of the train serve?\n<image>"}, {"from": "gpt", "value": "The yellow and black color scheme of the train serves a few possible purposes. One significant purpose is that it increases visibility, helping the train stand out against the background and making it easily recognizable for people around the tracks or operators of other transportation modes. The high contrast between yellow and black ensures that the train is noticeable even during low-light conditions or poor weather. This color scheme, in turn, can help enhance safety for both the train passengers and people near the railroad tracks by minimizing the chance of collisions or accidents. Additionally, the color scheme might also contribute to the train's branding and identity, making it unique and easily distinguishable from other trains."}]}, {"id": "000000007567", "image": "coco/train2017/000000007567.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat factors can contribute to the smooth and successful operation of commercial flights in such weather conditions?"}, {"from": "gpt", "value": "In the image, a large commercial passenger jet is flying through the clear blue sky, indicating favorable weather conditions. Several factors contribute to the smooth and successful operation of commercial flights in these conditions:\n\n1. Good visibility: The clear blue sky allows for excellent visibility for the pilots, enabling them to navigate the aircraft easily and to spot any potential hazards in the air.\n\n2. Absence of extreme weather: Clear skies imply that there are no storms, turbulence, or harsh winds present in the atmosphere, which can adversely affect the aircraft or cause discomfort to passengers.\n\n3. Optimal air traffic: Air traffic controllers can more easily manage commercial flights under such weather conditions, with minimal delays and easier route planning to avoid congestion.\n\n4. Aircraft maintenance: Good weather conditions allow for more effective pre-flight inspections and routine maintenance on the ground, ensuring that the aircraft is safe and ready for the journey ahead.\n\n5. Passenger comfort: Passengers can enjoy the journey with a smooth ride and unobstructed views of the clear skies, leading to higher satisfaction and a pleasant flying experience.\n\nWhen all these factors come together, the overall operation of commercial flights is enhanced, leading to a more efficient and enjoyable travel experience for everyone involved."}]}, {"id": "000000219204", "image": "coco/train2017/000000219204.jpg", "conversations": [{"from": "human", "value": "What potential renovations could improve the appearance of the bathroom?\n<image>"}, {"from": "gpt", "value": "Some potential renovations to improve the appearance of the bathroom could include updating the current white toilet with a more modern and sleek design, which might impact the overall aesthetics of the space. Additionally, the dark vanity or cabinet could be refinished or replaced to make it more visually appealing, and coordinate with the other elements of the bathroom. New faucets and hardware for the vanity could also be considered. Adding stylish accents such as lighting fixtures, mirrors, and decorative elements will enhance the bathroom atmosphere. Lastly, repainting walls or installing new tiles can help create a fresh and updated appearance in the bathroom."}]}, {"id": "000000083000", "image": "coco/train2017/000000083000.jpg", "conversations": [{"from": "human", "value": "What is distinctive about the woman's cooking setup?\n<image>"}, {"from": "gpt", "value": "The woman's cooking setup is distinctive because she is cooking on the ground with various ingredients and utensils spread around her. She has multiple bowls containing ingredients, and there are plates and cooking implements nearby. This traditional and informal cooking style contrasts with the more familiar kitchen setup, where cooking takes place on stovetops or countertops. Additionally, her colorful clothing adds to the overall ethnic and cultural ambiance of the scene. Cooking directly on the ground can be culturally significant in certain regions and offers a unique perspective on food preparation techniques."}]}, {"id": "000000189912", "image": "coco/train2017/000000189912.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat might be a common concern for the people in this setting?"}, {"from": "gpt", "value": "In the image, people are waiting around a luggage carousel in an airport, with bags and suitcases on the conveyor belt. A common concern for the passengers in this setting would likely be locating their own luggage among the many suitcases on the conveyor belt and ensuring that they collect their bags without accidentally taking someone else's. This process can sometimes be challenging and time-consuming, depending on the volume of luggage and the similarity of bags. Proper tagging and distinctive identification marks on luggage can help alleviate this concern and ensure that passengers can quickly and easily collect their belongings."}]}, {"id": "000000049191", "image": "coco/train2017/000000049191.jpg", "conversations": [{"from": "human", "value": "What are some crucial skills required for this activity?\n<image>"}, {"from": "gpt", "value": "To successfully ride waves on a surfboard, as the person in the image is doing, there are several crucial skills one must have. Some of these skills include:\n\n1. Balance: Balancing on a surfboard is a fundamental skill, as it is necessary to maintain stability while riding the waves. Good balance allows surfers to adjust their body position and weight distribution on the board in response to the changing motion of the waves.\n\n2. Paddling: Effective paddling is essential to catch a wave and gain enough speed to stay in position as the wave breaks. Surfers must master a solid paddling technique that propels them with minimal energy expenditure through the water.\n\n3. Timing: Accurate timing is crucial when it comes to catching and riding a wave. Surfers must be able to read the waves, understand when to paddle for a wave, and determine the right moment to stand up on the board to ride the wave efficiently.\n\n4. Wave knowledge and reading: A surfer needs to understand different types of waves and how they break, as well as be able to read the conditions to make the best decisions about wave selection and positioning.\n\n5. Maneuvering: Advanced surfers need to be able to perform various maneuvers on the wave, such as turns, cutbacks, and aerials, to control their speed and direction while maximizing style and fun.\n\nMastering these skills enables surfers to enjoy the exciting and challenging sport of surfing while navigating the constantly changing conditions of the ocean."}]}, {"id": "000000418600", "image": "coco/train2017/000000418600.jpg", "conversations": [{"from": "human", "value": "Why might the young woman be closing her eyes while on the phone?\n<image>"}, {"from": "gpt", "value": "The young woman might be closing her eyes while talking on the phone for various reasons. She could be focusing on the conversation or trying to recall a piece of information. It's also possible that she's feeling emotional or expressing empathy towards the person she's speaking with. Additionally, closing her eyes might be a way for her to momentarily disconnect from her surroundings and concentrate on the phone call. Lastly, it might just be a natural reaction for her when she is deep in thought or having an intense discussion."}]}, {"id": "000000408266", "image": "coco/train2017/000000408266.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat could be a possible reason that the young boy appears unhappy while eating pizza?"}, {"from": "gpt", "value": "There could be multiple reasons why the young boy appears unhappy while eating pizza at the dining table. He might not be fond of the pizza's flavor, have a personal issue on his mind, or simply be tired. Alternatively, the presence of other people in the scene, including some sitting close to him, could be a contributing factor to his discomfort. Ultimately, it is crucial to consider multiple potential reasons and understand that a person's emotions and reactions are complex and multifaceted, influenced by various internal and external factors."}]}, {"id": "000000459003", "image": "coco/train2017/000000459003.jpg", "conversations": [{"from": "human", "value": "What precautions should the people take while walking outside during the snowstorm?\n<image>"}, {"from": "gpt", "value": "When walking outside during a snowstorm, people should take several precautions to ensure their safety and comfort. In the image, a group of people is walking down a city street amidst a snowy blizzard. They should:\n\n1. Dress warmly: Layer clothing with a focus on insulating and waterproof layers to keep themselves warm and protected from the cold, wet conditions.\n2. Wear appropriate footwear: Choose footwear with a strong grip and insulation, such as snow boots, to avoid slipping and keep their feet dry and warm.\n3. Be visible: Wear bright or reflective clothing to increase their visibility to motorists and other pedestrians in low-visibility conditions.\n4. Use caution while walking: Walk slowly and maintain balance as the snowy and icy surfaces can be slippery.\n5. Choose well-lit paths: Stick to well-lit sidewalks and streets to navigate better and see potential hazards.\n6. Keep a charged cell phone with them: Carry a fully charged cell phone in case of emergencies or the need to contact someone.\n7. Walk with others or share their plans with someone: In case of emergencies or accidents, having company or letting someone know their route can improve safety.\n\nTaking these precautions can reduce the risks associated with walking in snowy conditions and can ensure a more comfortable experience during winter weather."}]}, {"id": "000000382890", "image": "coco/train2017/000000382890.jpg", "conversations": [{"from": "human", "value": "What could be the reason for the two buses being parked next to each other on the street?\n<image>"}, {"from": "gpt", "value": "There could be several reasons for the two red double-decker buses being parked next to each other on the street. One possible reason is that they are waiting for passengers to board or disembark at a designated bus stop or terminal. Another possibility is that the buses are temporarily parked due to a short break for the drivers, a shift change, or vehicle inspections. Additionally, the buses could be parked together as part of a coordinated schedule to maintain a consistent flow of bus services along the route, ensuring that multiple buses on the same route do not cause overcrowding or long waiting periods for passengers. The actual reason can vary depending on the city's specific transit system policies and operations."}]}, {"id": "000000012283", "image": "coco/train2017/000000012283.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat could be a possible reason for the horse to be in the urban setting?"}, {"from": "gpt", "value": "One possible reason for the horse being present in the urban setting could be related to a special event or tourist attraction. Cities sometimes feature horse-drawn carriages or unique guided tours on horseback for visitors as an interesting way to explore the area. The horse might also be used for promotional purposes or cultural shows. Another possibility is that it could be part of a police patrol that utilizes horses, where mounted officers patrol the streets to maintain order and provide crowd control during events. In the image, the horse is crossing the street near a group of people walking along the sidewalk, which could suggest it is involved in one of these activities or events."}]}, {"id": "000000043383", "image": "coco/train2017/000000043383.jpg", "conversations": [{"from": "human", "value": "What benefits could the herd of animals provide to the environment and the ecosystem?\n<image>"}, {"from": "gpt", "value": "The herd of animals, in this case, a group of sheep grazing on a lush green hillside, can provide numerous benefits to the environment and the ecosystem. Firstly, their grazing helps manage vegetation growth which can lead to healthier grasslands and promote the growth and distribution of plant species. By maintaining the grasslands and keeping the vegetation under control, they can contribute to preventing overgrowth, which reduces the risk of wildfires.\n\nMoreover, sheep can also promote soil health by stimulating biological activity through their grazing, trampling, and manure deposition, enhancing nutrient cycling and soil structure. Well-managed grazing can also help sequester carbon, supporting efforts to combat climate change. These benefits positively affect other organisms in the ecosystem and contribute to maintaining biodiversity and a balanced ecosystem. Additionally, they can provide wool, meat, and other products to humans, contributing to local economies and community livelihoods."}]}, {"id": "000000374174", "image": "coco/train2017/000000374174.jpg", "conversations": [{"from": "human", "value": "Why might the sedan be loaded onto the tow truck?\n<image>"}, {"from": "gpt", "value": "There could be several reasons for the sedan being loaded onto the tow truck. First, the car might have experienced a mechanical issue or breakdown that requires it to be towed to a service center or garage for repair. Second, the vehicle could have been involved in an accident, making it unsafe or impossible to drive, so a tow truck is needed to transport it to a repair facility or an insurance-approved location. Third, the car may have been parked illegally or violated parking regulations, resulting in it being towed or impounded by local authorities. Lastly, the tow truck could be a car carrier truck, which is responsible for transporting vehicles from the manufacturer to dealerships or from one location to another for various reasons like relocations or car rentals. It is also possible that the sedan is being repossessed by a financial institution if the car owner failed to make their loan payments."}]}, {"id": "000000190798", "image": "coco/train2017/000000190798.jpg", "conversations": [{"from": "human", "value": "Why might the cat resort to drinking water from the toilet bowl?\n<image>"}, {"from": "gpt", "value": "Several reasons could lead the cat to drink water from the toilet bowl in the image. It is possible that the cat's water bowl may be empty, which forces the cat to seek alternative sources of hydration. Another reason could be that the cat is curious by nature and might have discovered the water in the toilet bowl as a new and interesting place to drink from. In some cases, cats may prefer the cool and fresh water of the toilet bowl over the water in their bowl as it is more refreshing to them. It is important for the pet owners to consistently provide fresh water in the cat's water bowl and clean it regularly to encourage the cat to drink water from the designated source, ensuring its health and well-being. Moreover, ensuring the bathroom door is closed or toilet lid is down can prevent the cat from accessing the toilet bowl."}]}, {"id": "000000221696", "image": "coco/train2017/000000221696.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat can be inferred about the person enjoying this meal?"}, {"from": "gpt", "value": "It can be inferred that the person enjoying this meal appreciates Asian cuisine and may seek comfort in a warm and nutritious dish. The bowl of Asian noodle soup contains various ingredients such as noodles, tofu, broccoli, celery, and onions, providing a good mix of textures and flavors. Additionally, the presence of a bottle of sauce or beer next to the bowl on the dining table suggests that the person may like to enhance the taste of their meal using condiments or have an accompaniment while eating. This dining experience indicates their preference for a flavorful, comforting, and potentially customizable meal."}]}, {"id": "000000436073", "image": "coco/train2017/000000436073.jpg", "conversations": [{"from": "human", "value": "What are some measures the young child's caretaker has taken to maintain the child's hygiene?\n<image>"}, {"from": "gpt", "value": "The caretaker has taken several measures to maintain the young child's hygiene. In the image, the child is being assisted in brushing their teeth with a pink toothbrush. This highlights the importance of oral hygiene and the caretaker's dedication to establishing healthy habits for the child from a young age. Besides that, there are multiple bottles present around the bathroom, most likely containing hygiene products like shampoo, body wash, and hand soap. This further indicates the caretaker's attention to cleanliness and providing the child with proper hygiene products for their use. With these measures in place, the caretaker helps create a healthy environment and instills the importance of maintaining personal hygiene in the young child's daily routine."}]}, {"id": "000000082881", "image": "coco/train2017/000000082881.jpg", "conversations": [{"from": "human", "value": "What potential factors might be affecting the skiing experience of these two individuals?\n<image>"}, {"from": "gpt", "value": "Several factors might be affecting the skiing experience of the two individuals in the image. These factors can include the snow conditions, which appears to be abundant and freshly fallen, allowing for a smooth skiing experience. Additionally, the presence of trees, a shed, and a small building in the background indicates that the skiing area may not be a designated ski resort or slope, potentially presenting obstacles or areas to avoid. The skill levels of the skiers, their skiing equipment, and the weather during their skiing session can also affect their experience. The girl wearing skis is following another skier wearing blue, which might suggest their ability to collaborate and support each other as they navigate the snow-covered ground. Overall, their skiing experience will be influenced by the combined effect of these factors and their ability to adapt to the environment and conditions."}]}, {"id": "000000276739", "image": "coco/train2017/000000276739.jpg", "conversations": [{"from": "human", "value": "What makes the displayed motorcycle stand out from the others?\n<image>"}, {"from": "gpt", "value": "The displayed motorcycle stands out from the others because it has been modified to include four seats, allowing it to accommodate multiple passengers. This unique design is different from the typical motorcycles which usually have only one or, at most, two seats. The other motorcycles parked in a row nearby seem to have standard designs, making the modified multiple-seat motorcycle a point of interest and the focus of the indoor display."}]}, {"id": "000000170832", "image": "coco/train2017/000000170832.jpg", "conversations": [{"from": "human", "value": "What might the purpose of such tall clock towers in historical contexts be, and are they still relevant today?\n<image>"}, {"from": "gpt", "value": "Historically, tall clock towers served multiple purposes in a city or town. One primary function was to provide the local population with an easily visible and accurate time reference, allowing people to coordinate their daily activities, as most individuals did not have personal timekeeping devices. Additionally, the tower's height and distinctive design often added architectural and aesthetic value to the cityscape, making it a point of reference and pride for the community. Clock towers might also have been built to showcase the city's prosperity and technological advancements, as precise and complex clock mechanisms demonstrated the skill and knowledge of local craftsmen.\n\nWhile personal timekeeping devices like watches and smartphones are now widely accessible, clock towers still hold significance today. They can serve as landmarks for wayfinding, represent local heritage, and carry historical or sentimental value for the community. Furthermore, clock towers continue to have an aesthetic and architectural appeal, attracting tourists and contributing to maintaining the city's unique character."}]}, {"id": "000000039064", "image": "coco/train2017/000000039064.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat charitable event is likely happening at the hockey game?"}, {"from": "gpt", "value": "It is highly likely that the hockey game is hosting a \"Teddy Bear Toss\" event. During a Teddy Bear Toss, spectators are encouraged to bring new stuffed animals to the game and throw them onto the ice after a designated goal is scored by the home team. These collected stuffed animals are then donated to local charities, hospitals, and children in need during the holiday season or throughout the year. In the image, we see a hockey player standing on the ice, surrounded by numerous stuffed animals such as teddy bears, indicating that such an event has taken place."}]}, {"id": "000000257951", "image": "coco/train2017/000000257951.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat qualities does the dog need to have to participate in this activity?"}, {"from": "gpt", "value": "For a dog to participate in this activity, it needs to have a range of qualities such as good balance, athleticism, confidence in water, and a strong bond with its owner. The dog must be comfortable and relaxed while standing on a moving surfboard to maintain its balance along with the surfer. Additionally, having a trusting relationship with the owner is crucial, as the dog needs to feel safe and secure while navigating the waves together. Some dogs are more naturally predisposed to such water-based activities, particularly those breeds that have a history of working in and around water, but ultimately, the dog's individual temperament, adaptability, and socialization around water are key factors in its ability to enjoy and participate in surfing."}]}, {"id": "000000183690", "image": "coco/train2017/000000183690.jpg", "conversations": [{"from": "human", "value": "What potential risks should be considered when a toddler interacts with electronic devices like laptops?\n<image>"}, {"from": "gpt", "value": "When a toddler interacts with electronic devices like laptops, there are several potential risks to consider, which include:\n\n1. Physical damage: Toddlers may accidentally drop or mishandle the device, leading to screen cracks, broken keys, or damaged hardware.\n\n2. Data loss: Young children may unintentionally delete important files or alter settings, causing potential data loss or software malfunction.\n\n3. Exposure to inappropriate content: Unsuitable websites, videos, or images might be accessed by the toddler, which could negatively impact their development.\n\n4. Health concerns: Excessive screen time can lead to developmental delays, sleep disturbances, and issues related to posture and eyesight in young children.\n\n5. Safety hazards: Electrical cords, chargers, or small removable parts on the device could pose choking or electrocution risks.\n\nTo minimize these risks, adult supervision and guidance are crucial when toddlers interact with electronic devices. Parental control settings, protective covers, and limiting screen time can also help ensure safer and more productive experiences for young children with technology."}]}, {"id": "000000215242", "image": "coco/train2017/000000215242.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat design aspect of this bathroom could be a potential issue?"}, {"from": "gpt", "value": "In this bathroom, there is a window located directly above the toilet. While it might provide natural light and a view of the city, this design aspect may pose potential privacy concerns. The placement of the window could allow passerby or neighboring building occupants to view into the bathroom, making users feel uneasy or uncomfortable. Additionally, if the window is left wide open, the bathroom could be exposed to the elements or attract bugs or other unwanted pests. Solutions to this issue could involve adding curtains, installing a frosted window, or moving the toilet to a different location within the bathroom to ensure adequate privacy and comfort."}]}, {"id": "000000476188", "image": "coco/train2017/000000476188.jpg", "conversations": [{"from": "human", "value": "Why might the woman need to check on her food periodically while cooking?\n<image>"}, {"from": "gpt", "value": "Periodically checking on food during cooking is essential to ensure that it is cooked evenly and consistently without being overcooked or undercooked. Monitoring the food's progress in the oven allows the woman to adjust cooking time or temperature as needed, based on the visual and olfactory cues. By observing the food's appearance and aroma, she can determine whether the dish is cooked to the desired level, ensuring a delicious and well-prepared meal. It also helps prevent potential food-related accidents, like burning or spilling, by addressing any issues promptly."}]}, {"id": "000000027711", "image": "coco/train2017/000000027711.jpg", "conversations": [{"from": "human", "value": "How could the presence of a double-decker bus impact public transportation in this city?\n<image>"}, {"from": "gpt", "value": "The presence of a blue double-decker bus in the city suggests an increased capacity for public transportation. Double-decker buses can accommodate more passengers than traditional single-level buses, which can help alleviate overcrowding on busy routes and reduce wait times. This could lead to enhanced efficiency in the public transportation system and encourage more people to use public transit, potentially reducing congestion and pollution in the city. Additionally, double-decker buses can provide a unique experience for passengers, especially tourists, who can enjoy an elevated view of the city on the upper level. However, with increased capacity, it might also be crucial for the city to ensure the infrastructure, such as roads, bridges, and bus stops, can accommodate these larger vehicles properly."}]}, {"id": "000000187280", "image": "coco/train2017/000000187280.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat potential risks are present for pedestrians in this busy urban setting?"}, {"from": "gpt", "value": "In the image, there are two red double-decker buses driving down the road, and a car is present as well. The urban setting also features traffic lights and multiple pedestrians. Potential risks for pedestrians in this busy setting might include crossing the road safely without being too close to the double-decker buses or the car. They should be attentive to the traffic signals and the flow of traffic. Moreover, with large vehicles like double-decker buses, visibility might be limited for both pedestrians and the bus drivers, increasing the chances of accidents if proper precautions are not taken. Pedestrians should ensure that they use designated crossing areas and obey traffic signals to minimize risks in this high-traffic environment."}]}, {"id": "000000056065", "image": "coco/train2017/000000056065.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat are some possible reasons for the presence of multiple trucks at the airport?"}, {"from": "gpt", "value": "There are several possible reasons for the presence of multiple trucks at the airport in the image. These reasons include:\n\n1. Ground support and maintenance: Trucks can be part of the ground support equipment that provide various services such as fueling, waste disposal, deicing, catering, and maintenance of the airplanes.\n\n2. Cargo handling and transportation: Some of the trucks could be handling cargo, transporting bags and other containers from the terminal or storage areas to the airplanes.\n\n3. Emergency services: Some trucks may belong to airport emergency services and fire-fighting teams, and they are on standby, ready to respond to any incidents at the airport.\n\n4. Construction or renovation: The airport might be undergoing construction or improvements, requiring trucks for the transportation of materials, equipment, or waste.\n\nThe presence of multiple trucks adds to the complexity and diverse operations required to keep an airport functioning and efficient, ensuring the safety of passengers and efficient loading and unloading of airplanes."}]}, {"id": "000000316676", "image": "coco/train2017/000000316676.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat are the possible hazards caused by the snowy conditions in the image?"}, {"from": "gpt", "value": "The snowy conditions in the image create several potential hazards, primarily affecting visibility and transportation. The traffic light, which is essential for managing traffic at an intersection, is covered in snow, making it difficult for drivers to see the light signals. This might increase the risk of accidents due to misunderstanding or misinterpreting the traffic signals. Additionally, the snowy conditions can make the roads slippery and challenging to navigate for both vehicles and pedestrians. The presence of several people in the image indicates that there is foot traffic in the area, which means they need to be cautious while walking on slippery surfaces to avoid falls and injuries. Overall, these hazards highlight the importance of proper snow management and caution when navigating through such conditions."}]}, {"id": "000000397513", "image": "coco/train2017/000000397513.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the primary skill that the baseball pitcher in the image needs to excel in his position?"}, {"from": "gpt", "value": "The primary skill that the baseball pitcher in the image needs to excel in his position is the ability to throw the ball with accuracy, speed, and various types of pitches, such as fastballs, curveballs, and sliders. This will help the pitcher deceive the opposing batters and prevent the opposing team from scoring runs. In the image, the pitcher is in the middle of pitching a baseball, and his focus, grip, and body positioning all contribute to the effectiveness of his pitch. Excelling in pitching requires practice, strength, agility, and a deep understanding of the game's mechanics, making it crucial for the pitcher to master these aspects to perform well on the mound."}]}, {"id": "000000261381", "image": "coco/train2017/000000261381.jpg", "conversations": [{"from": "human", "value": "What conformity might the men have in this old photo?\n<image>"}, {"from": "gpt", "value": "In the old black and white photo, the four men sitting on the bench share a subtle conformity in their attire, specifically by wearing neckties. This suggests that the men might be formally dressed or following a dress code that was more common in older times for social or work gatherings. In addition to their clothing, their posture and proximity on the bench also indicate a certain level of camaraderie and shared experience among the group."}]}, {"id": "000000139389", "image": "coco/train2017/000000139389.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat might the owner of the car be planning to do, and how could the weather affect their plans?"}, {"from": "gpt", "value": "The owner of the blue car might be planning to go surfing, as a surfboard is strapped to the top of their vehicle. Judging from the image, the car is parked in a shopping center lot on a rainy day. The rainy weather and potentially rough sea conditions could affect their plans by making surfing conditions risky and less enjoyable. It may also lead to potential hazards or delays, such as reduced visibility or difficulty in assessing the safety of the surf conditions. The surfer might decide to wait for the weather to clear up or assess the conditions carefully before deciding whether or not to proceed with their surfing plans."}]}, {"id": "000000543201", "image": "coco/train2017/000000543201.jpg", "conversations": [{"from": "human", "value": "What might be the reason for the little girl to hold the umbrella on the patio?\n<image>"}, {"from": "gpt", "value": "The little girl could be holding the umbrella on the patio for various reasons, such as shielding herself from the sun or rain, pretending to play in the rain, or simply playing with the umbrella as a prop in her imaginative play. The presence of several potted plants on the patio suggests that it may be an outdoor area vulnerable to weather conditions, so it is plausible that the girl is using the umbrella for protection from the sun or rain. However, with little visual information about the current weather in the image, it could also be that she is just having fun holding the umbrella and engaging in creative play while surrounded by the plants."}]}, {"id": "000000099316", "image": "coco/train2017/000000099316.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat can one infer about the atmosphere at this beach scene?"}, {"from": "gpt", "value": "Based on the image, one can infer that the atmosphere at the beach is quiet, peaceful, and possibly a bit lonely. There is a beach umbrella and an empty bench near the water, but only a single person is seen sitting on a lawn chair next to a fence. This suggests that it is not a crowded or bustling beach environment. The presence of the umbrella and empty bench indicates that it might be a good spot for relaxation and contemplation, as someone can sit down and enjoy the view while being protected from the sun. The rocky beach setting adds to the tranquil and serene atmosphere of the scene."}]}, {"id": "000000565600", "image": "coco/train2017/000000565600.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat challenges might a tennis player face when playing against a skilled opponent?"}, {"from": "gpt", "value": "When playing against a skilled tennis opponent, a player may face several challenges, such as anticipating and reacting to the opponent's shots, maintaining consistency in serves and returns, and employing effective strategies to outwit the opponent. In the image, two men are competing on a tennis court, holding their rackets, and one of them is swinging for a shot with a grimacing facial expression. This could indicate the level of effort required to perform well during the match. A player must continually adapt to the opponent's playing style, speed, and tactics while maintaining their mental focus and physical endurance throughout the match. Developing court coverage skills, improving stroke technique, enhancing physical fitness, and gaining mental resilience are all essential to overcome the challenges posed by a skilled tennis opponent."}]}, {"id": "000000043071", "image": "coco/train2017/000000043071.jpg", "conversations": [{"from": "human", "value": "What safety measures should someone consider while snowboarding?\n<image>"}, {"from": "gpt", "value": "While snowboarding, there are several safety measures that individuals should consider to minimize the risk of injuries and accidents:\n\n1. Wear appropriate protective gear: Helmets, goggles, wrist guards, and padding on your knees and elbows help protect you from injuries in case of a fall or collision.\n\n2. Choose the right snowboard and bindings: Select a snowboard that is suitable for your level of expertise and matches the terrain you plan to ride on, and ensure that your bindings are set up correctly and compatible with your boots.\n\n3. Dress for the weather: Wear warm, waterproof, and breathable layers, including thermal base layers, insulating layers, and waterproof outer layers, as well as gloves or mittens, and proper snowboarding socks.\n\n4. Take lessons from a qualified instructor: Learn the correct techniques, body posture, and safety practices to reduce the likelihood of accidents and increase your skill level.\n\n5. Learn and follow the rules of the slope: Understand and respect the guidelines and etiquette while on the slopes, such as giving right-of-way, using appropriate signals, and observing trail signs and warnings.\n\n6. Know your limits: Ride within your skill level and physical capabilities, and avoid pushing yourself too hard, particularly when fatigue sets in.\n\n7. Check and adjust equipment regularly: Regular inspection and maintenance of your snowboard, bindings, boots, and safety gear is crucial to ensure their proper function and safety.\n\nBy following these safety measures, snowboarders can significantly reduce the risk of accidents and injuries, making their snowboarding experience more enjoyable and safer."}]}, {"id": "000000336752", "image": "coco/train2017/000000336752.jpg", "conversations": [{"from": "human", "value": "What could be the possible uses of this setup at home?\n<image>"}, {"from": "gpt", "value": "The setup with a keyboard, mouse, large monitor, or big screen television on a wooden table can serve various purposes at home. It can be used as a home office workspace, where the user can comfortably work on documents, emails, presentations, or engage in video conferencing. Alternatively, it can also function as a gaming station where an individual can connect the keyboard and mouse to play computer games on the big screen, providing an immersive gaming experience. Moreover, the setup can be a work station for editing videos, photos, or other creative work that requires a larger display to review and edit content. Additionally, by connecting streaming devices or platforms, this setup can serve as an entertainment hub for watching movies or series, browsing the internet, or even following along with workout routines. Overall, this versatile setup can cater to numerous personal and professional needs in a home setting."}]}, {"id": "000000363829", "image": "coco/train2017/000000363829.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat strategy could improve the man's tennis skills?"}, {"from": "gpt", "value": "One strategy that could improve the man's tennis skills is to focus on practicing his technique and form. This would involve spending time on the tennis court, working on basic strokes (forehand, backhand, serve, and volley), footwork, and positioning. Watching professional tennis players in action and analyzing their technique can also be beneficial. Additionally, the man should consider incorporating fitness and endurance training into his regimen to build physical strength and agility, which are essential for high-level tennis performance. Participating in local tennis clubs or tournaments, and seeking advice or coaching from experienced players or certified tennis coaches would further aid in improving his overall tennis performance."}]}, {"id": "000000304067", "image": "coco/train2017/000000304067.jpg", "conversations": [{"from": "human", "value": "What safety precautions should the bikers consider during their ride?\n<image>"}, {"from": "gpt", "value": "When riding motorcycles, the bikers should consider several safety precautions to ensure a smooth and secure ride. In the image, they are riding on a curvy road near a house, which requires extra attention to the road conditions and surroundings. Some key safety precautions include:\n\n1. Wearing appropriate safety gear, such as helmets, gloves, and protective clothing, to minimize the risk of injury in case of an accident.\n2. Maintaining a safe distance between each rider to avoid collisions, especially during turns and on curvy roads. In this case, one biker is falling slightly behind, so they should maintain that safe distance.\n3. Riding at a reasonable speed and adjusting it according to the road conditions, visibility, and traffic. This is particularly important when navigating around corners and in residential areas.\n4. Being cautious and vigilant of other road users, such as pedestrians, cars, and bicycles, that might be sharing the road or crossing the street.\n5. Regularly inspecting and maintaining their motorcycles, including checking tire pressure, brakes, and lights, to ensure optimal performance and safety during the ride."}]}, {"id": "000000512325", "image": "coco/train2017/000000512325.jpg", "conversations": [{"from": "human", "value": "What might the woman's experience be like in this setting?\n<image>"}, {"from": "gpt", "value": "The woman is likely having a peaceful and relaxing experience as she sits on a wooden bench in the garden, surrounded by flowers and bushes. The natural setting with vibrant colors and fragrances from the plants may provide a calm environment for her to enjoy her phone conversation or take a break from her day. The presence of greenery and open space can have a positive impact on a person's mood and overall well-being, making this an ideal place for her to unwind and connect with nature."}]}, {"id": "000000133905", "image": "coco/train2017/000000133905.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat might be the reason the woman is preparing her hair?"}, {"from": "gpt", "value": "The young woman may be preparing her hair while sitting on the bed in a hotel room as she might be getting ready for an event, a meeting, or going out to explore the city. Since she is in a hotel, it suggests that she might be traveling and may have plans or commitments during her stay. Ensuring her appearance is well-groomed demonstrates her attention to self-presentation in these situations. Additionally, the presence of a suitcase on another bed also supports the idea of her being a traveler and possibly preparing for a particular event."}]}, {"id": "000000249132", "image": "coco/train2017/000000249132.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat could be a potential reason for people to prefer traveling by this bus?"}, {"from": "gpt", "value": "One potential reason for people to prefer traveling by this red bus is its route through a scenic environment, as shown in the image. The bus is driving down a street lined with trees and hedgerows, making for a pleasant and visually appealing journey for passengers. This natural, picturesque setting can provide a calming atmosphere and a refreshing break from the urban landscape, making it more appealing for commuters and travelers alike. Additionally, using public transportation like buses can reduce individual car usage, contributing to lower traffic congestion, reduced air pollution, and a more sustainable mode of transportation."}]}, {"id": "000000520321", "image": "coco/train2017/000000520321.jpg", "conversations": [{"from": "human", "value": "What common theme can be observed in the setting?\n<image>"}, {"from": "gpt", "value": "The common theme observed in the setting is a harmonious display of large pottery (vases) and potted bonsai trees. In the scene, there are several tall vases and potted plants that are lined up in front of a building, possibly a temple. The vases and bonsai trees enhance the beauty and tranquility of the environment, bringing nature and art together in a balanced and aesthetically pleasing manner. This theme reflects traditional Chinese style and appreciation for nature and craftsmanship."}]}, {"id": "000000203673", "image": "coco/train2017/000000203673.jpg", "conversations": [{"from": "human", "value": "What message might the person who placed the apple on the laptop want to convey?\n<image>"}, {"from": "gpt", "value": "By placing an apple on the keyboard of a MacBook Pro laptop, the person might be creatively conveying the connection between the apple logo of Apple Inc. and the company's products. Alternatively, they might be representing the concept of \"knowledge,\" as an apple is often used as a symbol for education, and laptops are tools used in learning and accessing information. The image might also imply a balance between natural and technological aspects, emphasizing the importance of incorporating nature or maintaining a healthy lifestyle amidst the increasingly technological world."}]}, {"id": "000000301558", "image": "coco/train2017/000000301558.jpg", "conversations": [{"from": "human", "value": "What precautions should the skiers take for their safety on the slopes?\n<image>"}, {"from": "gpt", "value": "While skiing, it is essential for skiers to take several precautions for their safety on the slopes. These precautions include wearing appropriate protective gear, such as helmets, goggles, gloves, and proper ski clothing to maintain warmth and protect from the elements. They should also ensure that their ski bindings are appropriately adjusted for their skill level and body type, and their skis and poles are in good condition. Skiers should familiarize themselves with the specific run's difficulty rating and terrain before skiing down the mountain to make sure it is suitable for their skill level. They should follow the marked trails and avoid skiing in restricted or closed areas. Moreover, they should be aware of their surroundings and respectful of other skiers' and snowboarders' space to avoid collisions. Lastly, following the mountain's rules and guidelines and being aware of weather conditions are crucial for a safe and enjoyable skiing experience."}]}, {"id": "000000246160", "image": "coco/train2017/000000246160.jpg", "conversations": [{"from": "human", "value": "What other desserts could complement this small three-layer raspberry confection?\n<image>"}, {"from": "gpt", "value": "Alongside the small three-layer raspberry confection, other complementary desserts could include fruit tarts, chocolate mousse cups, mini cheesecakes, \u00e9clairs, assorted macarons, or petit fours. These dessert selections offer a variety of flavors and textures, and their smaller sizes make them a perfect accompaniment to the featured three-layer dessert. Since the raspberry confection already provides a fruity flavor, incorporating desserts with different flavor profiles, such as chocolate, vanilla, or caramel, would offer a more diverse and balanced dessert experience for guests or customers."}]}, {"id": "000000011065", "image": "coco/train2017/000000011065.jpg", "conversations": [{"from": "human", "value": "What might be the purpose of the interaction between the man, the woman, and the horse?\n<image>"}, {"from": "gpt", "value": "Based on the image, the purpose of the interaction between the man, the woman, and the horse might be to assess or care for the horse's health, comfort, or well-being. The man is reaching down to touch the hoof of the brown horse, while the woman holds the bridle, ensuring the horse stays calm and still. The people might be checking the horse's hooves for injuries, dirt, or stones, or the man could be assessing the fit of the horse's shoes. Proper hoof care is essential for the overall health and performance of the horse, so their interaction may be a routine maintenance check or a more specific inspection based on the horse's situation."}]}, {"id": "000000189182", "image": "coco/train2017/000000189182.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat safety measures should one consider before attempting similar activities?"}, {"from": "gpt", "value": "Before attempting similar activities, such as performing skateboard tricks in an enclosed area like a garage, it is important to consider several safety measures to minimize the risk of injury. Some of these safety measures include:\n\n1. Wearing proper safety gear: This includes a helmet, elbow and knee pads, and wrist guards to protect oneself from injuries during falls or accidents.\n2. Ensuring the skateboarding area is clear and free from obstacles: Remove any objects, debris or hazards from the area. Ensure there is enough space to maneuver safely and without obstacles.\n3. Practicing basic skateboarding skills: Before attempting advanced tricks, it is crucial to have a good foundation in essential skateboarding techniques, including balance, control, and familiarity with the board.\n4. Start with simple tricks: Gradually progress from basic tricks to more complex ones, aiming to master each trick before attempting the next level.\n5. Skateboarding within personal limitations: Understand personal strengths and weaknesses and skate within these boundaries.\n6. Skating with a buddy or in a supervised setting: Having someone to watch, offer assistance, or provide guidance is essential - especially when learning new tricks or attempting risky maneuvers.\n\nBy taking these safety measures, one can mitigate the risks associated with skateboarding and enjoy the activity while minimizing the likelihood of injuries or accidents."}]}, {"id": "000000464965", "image": "coco/train2017/000000464965.jpg", "conversations": [{"from": "human", "value": "Which factors suggest that the man may be taking a lunch break in his work environment?\n<image>"}, {"from": "gpt", "value": "There are several factors in the image that indicate the man may be taking a lunch break in his work environment. He is holding a foil-wrapped sandwich or a large hotdog, which suggests that he is about to have a meal. Additionally, he is seated next to a computer and a keyboard, implying that he has been working on the computer. The presence of a chair and a bottle further supports the idea that he is in an office setting. All these elements combined suggest that the man is most likely taking a lunch break in his work environment."}]}, {"id": "000000127296", "image": "coco/train2017/000000127296.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat potential issue could these individuals be discussing with the police officer?"}, {"from": "gpt", "value": "Given the context of the image and the presence of a crowd of well-dressed businesspeople speaking with a police officer on the street corner, the potential issue could be related to a business or legal matter, a public safety concern, or a disruption in their daily routines. The group may be seeking guidance, reporting an incident, or sharing information about a matter which directly impacts their business or the community. This discussion might involve concerns related to traffic, street vendors, or community safety measures. The presence of multiple people in the conversation suggests that the matter is of collective interest to the individuals involved."}]}, {"id": "000000365934", "image": "coco/train2017/000000365934.jpg", "conversations": [{"from": "human", "value": "What is unique about the girl's tooth-brushing experience?\n<image>"}, {"from": "gpt", "value": "The unique aspect of the girl's tooth-brushing experience is that she is sitting on the edge of a garden bathtub while brushing her teeth, enjoying a window view. This is unconventional as people typically brush their teeth standing in front of the bathroom mirror, near the sink. By changing her setting from a typical bathroom setup to a more relaxed environment near the window, the girl adds an element of novelty and relaxation to her daily routine."}]}, {"id": "000000005260", "image": "coco/train2017/000000005260.jpg", "conversations": [{"from": "human", "value": "What is an important skill that the young batter should develop to be successful in baseball?\n<image>"}, {"from": "gpt", "value": "One essential skill that the young batter needs to develop to be successful in baseball is proper swinging technique. This includes proper stance, grip, stride, weight transfer, and timing. By mastering these elements, the batter will be able to effectively hit the ball with power and accuracy. Additionally, the young player should work on hand-eye coordination, as this is crucial for making consistent contact with the ball. Developing these abilities will ensure the batter improves their performance and contributes to their team's success on the field."}]}, {"id": "000000160573", "image": "coco/train2017/000000160573.jpg", "conversations": [{"from": "human", "value": "What interesting activity are the women doing, and why might this be entertaining or enjoyable for them?\n<image>"}, {"from": "gpt", "value": "The two women in the image are sitting at a table in a donut shop, showing off their funny-shaped donuts to each other. This activity might be entertaining or enjoyable for them because they are sharing their unique doughnut choices, which could be an amusing conversation topic or even a light-hearted competition to see who found the most interesting or odd-shaped doughnut. Additionally, spending time together in a relaxed setting like a doughnut shop allows them to bond, share a fun experience, and create memories together. It also could be a form of self-expression where the women enjoy showcasing their preferences and tastes through their chosen doughnuts."}]}, {"id": "000000191350", "image": "coco/train2017/000000191350.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat potential risks should the woman consider while engaging in this activity?"}, {"from": "gpt", "value": "While surfing, the woman should consider several potential risks associated with the sport. These include strong currents, powerful waves, and the possibility of falling off the surfboard. She should also be cautious of sharp rocks or reefs hidden beneath the water's surface, which can lead to injuries if she falls. Other potential hazards include marine life, such as jellyfish, sharks, or other aquatic animals that might pose a threat to her safety. To mitigate these risks, the woman should follow safety guidelines, maintain awareness of her surroundings, practice proper techniques, and consult locals or lifeguards about current conditions before entering the ocean. In addition, using proper safety equipment, such as a leash attached to the board, can help minimize the risk of losing the surfboard or being separated from the board in case of a fall."}]}, {"id": "000000122097", "image": "coco/train2017/000000122097.jpg", "conversations": [{"from": "human", "value": "What factors contribute to the appearance of a balanced meal in this image?\n<image>"}, {"from": "gpt", "value": "The factors that contribute to the appearance of a balanced meal in this image include the variety of food items and the combination of flavors and textures. The meal consists of a sandwich, possibly containing meat like bacon or barbecue, accompanied by coleslaw as a side dish, and both a bottled and a cup drink. The sandwich offers a combination of protein and carbohydrates, while the coleslaw provides a refreshing crunch and vegetables. Additionally, the two drinks can offer hydration and enhance the overall dining experience. The meal is thoughtfully placed on a tray, along with a knife and a fork. The dining table setting, with accessibility to utensils, contributes to a comfortable and organized dining experience. Overall, the various components of the meal and the presentation create a pleasing and balanced meal experience."}]}, {"id": "000000164146", "image": "coco/train2017/000000164146.jpg", "conversations": [{"from": "human", "value": "<image>\nHow would the occupant of this bedroom maintain a comfortable temperature during different weather conditions?"}, {"from": "gpt", "value": "To maintain a comfortable temperature in the bedroom during different weather conditions, the occupant can utilize the available appliances and furnishings. For instance, during hotter weather, they can use the ceiling fan to create airflow and cool the room down. They can also partially or fully open the curtains and the window to let in fresh air to improve ventilation. On the other hand, during colder weather, they can close the curtains and window to keep out the cold drafts and retain warmth inside the room. Additionally, the presence of an A/C unit suggests that the occupant could have access to temperature control for heating and cooling purposes as needed. This combination of appliances and furnishings allows the occupant to create a comfortable living environment in the bedroom, regardless of the season or climate outside."}]}, {"id": "000000008309", "image": "coco/train2017/000000008309.jpg", "conversations": [{"from": "human", "value": "What potential distractions could the woman face while engaging in her current activity?\n<image>"}, {"from": "gpt", "value": "While the woman is sitting on the grass in a field and talking on her cell phone, she might face distractions from the surrounding environment. In the image, there are cars nearby, which could produce noise that might make it harder for her to hear the person on the other end of the phone call. Additionally, if this field is near a soccer net, the possibility of a nearby game or practice taking place could result in increased noise levels and potential interruptions. Moreover, other people engaging in outdoor activities in the area might create distractions and make it more challenging for the woman to focus on her conversation."}]}, {"id": "000000223121", "image": "coco/train2017/000000223121.jpg", "conversations": [{"from": "human", "value": "<image>\nConsidering the activity at this airport, what might be happening behind the scenes?"}, {"from": "gpt", "value": "At the airport, two large jetliners are parked on the tarmac, and several trucks are present, possibly for loading or servicing the planes. This suggests that various behind-the-scenes activities might be occurring to prepare the aircraft for the next flight. These activities may include refueling the planes, loading cargo and passengers' luggage, performing routine maintenance or repairs, cleaning the cabin, stocking food and beverages for in-flight services, and conducting safety and security checks. Additionally, the ground crew might be coordinating with the pilots, air traffic control, and other airport personnel to ensure smooth operations, adherence to safety protocols, and timely departures and arrivals."}]}, {"id": "000000502894", "image": "coco/train2017/000000502894.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat activity does the woman seem to be juggling while managing her dog?"}, {"from": "gpt", "value": "The woman appears to be managing her dog on a leash while also handling her bicycle. In the image, she is standing beside the bicycle, seemingly walking the dog as she pushes her bike alongside her. This suggests that she is trying to multitask and take care of her dog while looking for a convenient place to ride her bicycle or navigate through pedestrian areas where she needs to walk her bike rather than ride. Managing both the bicycle and the dog's movements simultaneously can be a challenging task, especially in crowded or busy areas."}]}, {"id": "000000405959", "image": "coco/train2017/000000405959.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat could be the purpose of placing a teddy bear on top of the menu board?"}, {"from": "gpt", "value": "Placing a teddy bear on top of the menu board can serve a few purposes. One potential reason is to attract the attention of passersby and draw them to the cafe with its unique and eye-catching decoration. The teddy bear adds a touch of whimsy and friendliness to the establishment, making it appear more inviting and appealing, especially to families with children. Additionally, the teddy bear might be used as an informal mascot or branding for the cafe, helping to create a memorable identity and differentiate it from other establishments in the area. Overall, the teddy bear serves to enhance the visual appeal and attractiveness of the cafe while possibly establishing a connection with potential customers."}]}, {"id": "000000199619", "image": "coco/train2017/000000199619.jpg", "conversations": [{"from": "human", "value": "What health benefits might someone get from consuming the fruits in the bowl?\n<image>"}, {"from": "gpt", "value": "Eating the fruits in the bowl, which includes mangoes and bananas, can provide several health benefits to individuals. Mangoes are rich in vitamins A and C, antioxidants, and dietary fiber. Consuming mangoes can help support a healthy immune system, eye health, and digestion. Bananas, on the other hand, are an excellent source of vitamins, such as vitamin C and B6, minerals like potassium, and dietary fiber. Consuming bananas can contribute to better heart health, improved digestion, and balanced blood sugar levels. Together, both fruits offer a nutritious and delicious way to support overall health and well-being."}]}, {"id": "000000164634", "image": "coco/train2017/000000164634.jpg", "conversations": [{"from": "human", "value": "<image>\nHow does the child in the image feel about the situation, and why might they feel that way?"}, {"from": "gpt", "value": "The child in the image appears to feel happy and relaxed as they lay on the grass. There is a big smile on their face, suggesting that they are enjoying the situation. The child might be feeling this way because they are outdoors, surrounded by nature, and possibly enjoying a sunny day, indicated by the presence of an umbrella nearby. The umbrella might have been used either to provide shade from the sun or as a playful accessory. Moreover, lying on the grass often gives a sense of connection to the environment and the freedom to unwind, which might be contributing to the child's contentment."}]}, {"id": "000000481209", "image": "coco/train2017/000000481209.jpg", "conversations": [{"from": "human", "value": "<image>\nWhy is the presence of a fire hydrant on the street important?"}, {"from": "gpt", "value": "The presence of a fire hydrant on the street is vital for the safety and well-being of those living or working in the area. In the image, a black and silver fire hydrant is located on the side of a busy city street with cars driving and parked along the street, and several people walking. Fire hydrants are a critical piece of firefighting equipment, providing firefighters with accessible and high-pressure water sources to extinguish fires quickly and effectively. They play a crucial role in containing fires, reducing the damage to property and infrastructure, and potentially saving lives. In urban environments like the one depicted, where buildings and vehicles are in close proximity, quick access to water for firefighting is essential to prevent the spread of fires and protect the local community."}]}, {"id": "000000146841", "image": "coco/train2017/000000146841.jpg", "conversations": [{"from": "human", "value": "What are the benefits of purchasing fruits and vegetables from this market?\n<image>"}, {"from": "gpt", "value": "Purchasing fruits and vegetables from this market has several benefits. First, the market offers a variety of fresh fruits such as bananas, oranges, and vegetables like broccoli, which contributes to a healthy and balanced diet. Second, the fruits and vegetables are displayed in wicker baskets and laid out, making it easy for customers to examine and select their desired items based on quality and ripeness. This allows for a more personal and engaging shopping experience as compared to pre-packaged goods found in many conventional supermarkets. Lastly, the shop provides fixed-rate pricing, which can help customers to easily manage their budget for fresh and nutritious produce. Overall, shopping at this market supports healthier food choices and a more enjoyable, transparent buying experience."}]}, {"id": "000000359363", "image": "coco/train2017/000000359363.jpg", "conversations": [{"from": "human", "value": "What safety concerns should the woman be aware of in this situation?\n<image>"}, {"from": "gpt", "value": "In this situation, the woman should be aware of several safety concerns while she cooks. First, she should handle the hot pan with appropriate oven mitts or cloth to protect her hands from burns. Second, since the dog is watching her closely and is in close proximity to the oven, she should ensure that the pet maintains a safe distance from the hot oven and the hot food to prevent any accidents or injuries. Lastly, when handling hot dishes and tools, she should make sure to close the oven door after use and turn off the oven once she is done cooking to prevent potential fire hazards and to protect both her and her dog's safety."}]}, {"id": "000000212935", "image": "coco/train2017/000000212935.jpg", "conversations": [{"from": "human", "value": "What do you think is the likely purpose of these boats on the river?\n<image>"}, {"from": "gpt", "value": "The image shows several boats floating calmly on the river near the city and its harbor. Given their proximity to the city, these boats are probably used for various purposes such as transportation, leisure activities like fishing and boating, or sightseeing tours. It wouldn't be surprising to see these boats offering river cruises or guided tours to provide tourists an opportunity to appreciate the city's skyline and the beauty of the river. Considering the calm river water and nearby green trees, this scenic location likely attracts visitors and locals alike to engage in recreational activities or simply enjoy the view."}]}, {"id": "000000386640", "image": "coco/train2017/000000386640.jpg", "conversations": [{"from": "human", "value": "What are the potential challenges or drawbacks of this particular bathroom setup?\n<image>"}, {"from": "gpt", "value": "In this small green bathroom, there is a urinal situated close to a sink. The limited space and close proximity between the urinal and sink might create a few challenges or drawbacks for users. For instance, it could lead to discomfort and limited movement during usage. Additionally, the closeness of the sink to the urinal might lead to possible hygiene concerns as there is little space to maintain distance between the two areas during use. Users may have to be extra cautious to avoid splashing or cross-contamination issues. Moreover, this cramped space might not be suitable for wheelchair users or individuals with mobility impairments who require more room for accessibility and movement within the bathroom."}]}, {"id": "000000515062", "image": "coco/train2017/000000515062.jpg", "conversations": [{"from": "human", "value": "What would someone with a sweet tooth think about this scene?\n<image>"}, {"from": "gpt", "value": "Someone with a sweet tooth would likely find this scene delightful and tempting. The image features a box full of twelve cupcakes with various candy, chocolate, and marshmallow toppings. The assortment of toppings, combined with the cupcakes themselves, offer a variety of flavors and textures, catering to different personal preferences. The vibrant colors and attractive presentation would surely entice someone with a sweet tooth to indulge in these delicious treats."}]}, {"id": "000000103355", "image": "coco/train2017/000000103355.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of project or activity might someone be engaged in with these supplies?"}, {"from": "gpt", "value": "Given the presence of scissors, yarn, sewing tools, construction supplies, a pattern, wires, and zip ties, it's likely that someone is about to start a crafting project. This project may involve sewing, cutting, and assembling materials or textiles. Such activities can range from creating garments or accessories, making home decorations, or even constructing a small DIY project, like assembling intricate models or building a useful item for their home or hobbies. The wide variety of tools and materials suggest that the person is prepared for handling multiple types of tasks and is engaged in a complex or versatile project."}]}, {"id": "000000556162", "image": "coco/train2017/000000556162.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat could be the reason for having a sign with the number 20 crossed out in the picture?"}, {"from": "gpt", "value": "It is difficult to ascertain the exact reason for the sign with the number 20 crossed out without more context. However, one plausible explanation could be that the two boys are making a statement or marking a milestone related to their age, achievements, or opinions. For example, they might be celebrating their combined age of 20 years, or it could be a symbolic way of bidding farewell to an old habit or idea. Another possibility is that the sign is part of a game or activity involving the teddy bears. The presence of three teddy bears and two boys in the image further adds to the playful and celebratory atmosphere, which supports these interpretations."}]}, {"id": "000000257162", "image": "coco/train2017/000000257162.jpg", "conversations": [{"from": "human", "value": "What makes this truck stand out from regular trucks?\n<image>"}, {"from": "gpt", "value": "What makes this truck stand out from regular trucks is that it is carrying a life-size sculpture called \"Lunchtime on a Skyscraper\" on its back. The sculpture features several men sitting on a bench, giving the illusion that they are sitting on top of the truck. This unique scene differentiates it from ordinary trucks as it serves as both a transportation vehicle and a moving art display, drawing attention and admiration from passersby. The sculpture is an interesting and engaging piece, making the truck much more noticeable and memorable than typical vehicles."}]}, {"id": "000000342294", "image": "coco/train2017/000000342294.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat aspect of the presentation might enhance the appeal of the dessert?"}, {"from": "gpt", "value": "The presentation of the cake on a white plate with multicolored polka dots enhances the visual appeal of the dessert. The vibrant, playful design of the plate contrasts with the cake, drawing attention to the slice itself. Additionally, the dark syrup drizzled over the cake adds to its tempting appearance, making it look even more enticing and delicious. The presence of a fork on the plate suggests that the dessert is ready to be enjoyed, adding to the overall presentation and allure of the sweet treat."}]}, {"id": "000000532175", "image": "coco/train2017/000000532175.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat safety precautions should the woman in the white dress take when cycling through the busy city intersection?"}, {"from": "gpt", "value": "As a cyclist, the woman in the white dress should take several safety precautions when navigating the busy city intersection:\n\n1. She should follow traffic rules and obey traffic signals. In the image, there are multiple traffic lights present; ensure to stop at red lights and follow the signals accordingly.\n2. She should stay aware of her surroundings, including the many pedestrians, cars, and any potential obstacles in her path.\n3. When possible, she should use designated bike lanes to minimize the risk of collisions with pedestrians and vehicles.\n4. She should use proper hand signals to indicate her intentions to turn or change lanes, ensuring other road users understand her actions.\n5. Wearing a helmet is essential for protecting her head in case of accidents.\n6. Utilizing front and rear lights and wearing reflective clothing (or adding reflective accessories) can improve her visibility to both pedestrians and drivers, especially in low light conditions.\n\nBy following these precautions, the woman in the white dress can ensure a safer and more enjoyable cycling experience in the busy city intersection."}]}, {"id": "000000542488", "image": "coco/train2017/000000542488.jpg", "conversations": [{"from": "human", "value": "What might be the reason behind the zebra's unusual color?\n<image>"}, {"from": "gpt", "value": "The zebra's unusual color might be due to several reasons, such as lighting conditions, the angle at which the image was taken, or the presence of dirt or dust on the zebra's stripes. In the given image, the zebra is laying down on a field of dirt and rocks, suggesting that some of its color may be affected by the surrounding dust or dirt, making the stripes appear less prominent or different from their usual contrast. Additionally, factors like natural variations in coloration or birthmarks could also contribute to the zebra's unique appearance. Regardless of the cause, this distinctive coloration may make this particular zebra stand out in its environment compared to other zebras with their typical contrasting stripes."}]}, {"id": "000000362067", "image": "coco/train2017/000000362067.jpg", "conversations": [{"from": "human", "value": "What unusual aspect can be seen on the parked bus's exterior design?\n<image>"}, {"from": "gpt", "value": "The parked bus in the image has an unusual and unique exterior design featuring a large guitar, specifically a Gibson guitar, on its side. This stands out and attracts attention as it is not a common sight on regular travel buses. The distinct design might suggest that this bus is associated with the Gibson Guitar company or a music-related event or tour, reflecting the company's branding or theme."}]}, {"id": "000000062075", "image": "coco/train2017/000000062075.jpg", "conversations": [{"from": "human", "value": "<image>\nConsidering the food and drinks visible in the scene, what kind of gathering might be happening?"}, {"from": "gpt", "value": "In the image, a large pizza with various toppings is placed on a dining table, accompanied by a bowl containing either grapes or olives, a glass of beer, and a bottle. Additionally, utensils like a fork and a knife are also present on the table. From the available food and drinks, it seems like a casual gathering, possibly a relaxed dinner party, movie night, or a social event with friends or family. The setting allows for attendees to enjoy a laid-back atmosphere while indulging in food and drinks, engaging in conversations or watching some form of entertainment."}]}, {"id": "000000092585", "image": "coco/train2017/000000092585.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat impacts could this boat have on the surrounding wildlife, given the presence of birds in the area?"}, {"from": "gpt", "value": "Considering the presence of nine birds in the area, it is possible that the boat can have an impact on the surrounding wildlife. If the boat is a fishing vessel, it could potentially disrupt the natural food chain by overfishing or harming fish stocks, which in turn might affect the birds and other marine animals that feed on fish. Additionally, if the boat produces excessive noise or pollution, it may cause distress to the wildlife in its vicinity, including the birds seen in the picture. Boat traffic can also lead to the disruption of nesting sites and resting areas for birds, which could negatively impact their populations in the longer term. The boat's crew should make sure to follow responsible boating practices to minimize any harmful effects on the environment and marine life in the area."}]}, {"id": "000000313007", "image": "coco/train2017/000000313007.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat important feature does this train have to cater to people with disabilities?"}, {"from": "gpt", "value": "The train in the image features a prominent handicap placard or sign on its side. This signifies that the train has designated spaces or accommodations for passengers with disabilities. These accommodations might include wheelchair-accessible areas, priority seating, visual or auditory aids, and other features aimed at making public transportation more accessible and comfortable for people with disabilities. The presence of this sign on the train highlights the commitment to inclusivity and equal access to transportation services for all passengers."}]}, {"id": "000000088382", "image": "coco/train2017/000000088382.jpg", "conversations": [{"from": "human", "value": "What possible reason could explain why these cows are on the shore?\n<image>"}, {"from": "gpt", "value": "There could be various reasons for these two brown and white cows to be on the shore. It is possible that the cows are grazing, as they may have wandered from their usual pasture to the shoreline in search of food or water. The shoreline area may also be part of their normal grazing area, where they can find various types of grasses or plants. Another reason could be that the cows are simply resting or cooling down near the body of water to escape the heat, as the access to the water can provide a relaxing environment for them. The presence of cows on the shore also suggests that this is a rural or semi-rural setting, where agricultural activities and livestock grazing have access to coastal areas."}]}, {"id": "000000194722", "image": "coco/train2017/000000194722.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat factors make this biplane flight experience unique?"}, {"from": "gpt", "value": "The biplane flight experience depicted in the image is unique due to several factors. The airplane is flying over the blue ocean and the rocky coastline, offering breathtaking views of both the water and the shore. The clear skies further suggest that the passengers on board would have great visibility during the flight, allowing them to appreciate the stunning scenery fully. Also, biplanes have an open cockpit and a classic design, which adds to the charm and novelty of the flying experience. This combination of picturesque natural landscapes and the distinctive characteristics of the biplane come together to create a memorable and exclusive adventure for those on board."}]}, {"id": "000000471839", "image": "coco/train2017/000000471839.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat important step should be taken for a better pizza?"}, {"from": "gpt", "value": "For a better pizza, before placing the uncooked pizza with cheese and meat toppings into the oven, it is crucial to ensure that the oven is preheated to the proper temperature. This step helps create the ideal conditions to cook the dough evenly and achieve a perfect crust while melting the cheese and cooking the sausage. Also, if whole slices of cheese are used, you might consider shredding or distributing them evenly for uniform melting and better taste. Ensuring these essential steps and using quality ingredients can significantly improve the outcome of the pizza."}]}, {"id": "000000128561", "image": "coco/train2017/000000128561.jpg", "conversations": [{"from": "human", "value": "How can children benefit from engaging in outdoor activities like playing with a flying disc in a large grassy area?\n<image>"}, {"from": "gpt", "value": "Children can gain numerous benefits from engaging in outdoor activities like playing with a flying disc in a large grassy area. Physical benefits include increased cardiovascular fitness, improved muscle strength, and better hand-eye coordination. These activities also promote flexibility and overall body awareness. Playing outdoors contributes to their mental well-being as well by reducing stress levels, enhancing mood, and improving concentration. Engaging in such games also fosters social skills development as children learn to communicate effectively, work as a team, and handle winning and losing gracefully. Additionally, being in nature exposes them to fresh air and sunshine, providing essential vitamin D for their growth and development. Overall, participating in outdoor activities supports a healthy lifestyle and the holistic development of children."}]}, {"id": "000000501565", "image": "coco/train2017/000000501565.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat valuable lesson might the children learn during this event?"}, {"from": "gpt", "value": "The children at the birthday party can learn valuable lessons on sharing, patience, and collaboration. As they gather around the table with the cake, they must wait for the cake to be sliced and served appropriately. They are likely to share not only the cake but also the overall party experience with their peers. This event offers them an opportunity to interact and bond with other children, enhancing social skills and creating cherished memories. Also, they may learn about the tradition of celebrating birthdays, the importance of giving and receiving gifts, understanding gratitude, and the significance of respecting everyone's feelings during special occasions."}]}, {"id": "000000230152", "image": "coco/train2017/000000230152.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat benefits can be derived from consuming the fruits on this plate?"}, {"from": "gpt", "value": "The fruits on the plate, which include bananas, pears, and oranges, provide an array of essential nutrients that are beneficial for overall health. Bananas are rich in potassium, Vitamin C, and dietary fiber, which may help in maintaining heart health, digestive health, and boosting the immune system. Pears are also a good source of dietary fiber, along with Vitamin K, which can aid in digestive health and promote blood clotting. Oranges are particularly high in Vitamin C, which contributes to a strong immune system, helps in iron absorption, and supports collagen production, promoting healthy skin. The combination of these fruits provides a diverse range of beneficial nutrients that support a balanced diet and promote overall wellness."}]}, {"id": "000000457618", "image": "coco/train2017/000000457618.jpg", "conversations": [{"from": "human", "value": "What might be causing the man's puzzled expression?\n<image>"}, {"from": "gpt", "value": "It's not possible to determine the specific cause of the man's puzzled expression based on the image alone. However, since he is wearing a white dress shirt, a red tie, and appears to be in an office setting, one may infer that he could be facing a work-related issue, a challenging problem, or a perplexing situation. The man looking sideways may also indicate that he is seeking assistance, observing something out of the frame, or trying to understand the situation fully. To pinpoint the exact cause, more information or context about the scene would be required."}]}, {"id": "000000507928", "image": "coco/train2017/000000507928.jpg", "conversations": [{"from": "human", "value": "What are the possible consequences or challenges that the motorbike rider may encounter while riding on this muddy trail?\n<image>"}, {"from": "gpt", "value": "Riding a motorbike through a muddy trail can pose various challenges and potential consequences for the rider. The slippery and uneven surface can make it difficult to maintain proper control of the motorbike, increasing the risk of accidents or falls. The rider may struggle to keep balance, navigate sharp turns, or move at high speeds without sliding or skidding. Additionally, mud can get into the mechanical parts of the motorbike, causing damage or malfunction if not thoroughly cleaned after the ride. The rider is also likely to get covered in mud, adding to the discomfort and potential for obscured visibility if mud splatters onto their goggles or helmet. Therefore, the rider should exercise caution, wear appropriate gear, and regularly maintain their motorbike to minimize risks associated with riding on a muddy trail."}]}, {"id": "000000170235", "image": "coco/train2017/000000170235.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat could be the consequences of a well-executed swing by the batter in the game?"}, {"from": "gpt", "value": "A well-executed swing by the batter in the game could have several possible consequences depending on the quality of contact with the ball and the batter's skill. If the batter makes solid contact with the ball, the results could include hitting a single, double, triple, or home run, potentially scoring runs for the team and contributing to their overall success in the game. The batter might also advance any base runners currently on the field by making good contact, thereby putting more pressure on the opposing team's defense. On the other hand, if the batter fails to make appropriate contact with the ball, the result could be a foul ball, a groundout, a flyout, or a strikeout, in which case the opposing team gains an advantage by getting closer to the end of the inning."}]}, {"id": "000000578775", "image": "coco/train2017/000000578775.jpg", "conversations": [{"from": "human", "value": "What is unique about the table's design, and how may this influence the user experience?\n<image>"}, {"from": "gpt", "value": "The table's design is unique because it is covered with rail road tracks, making it visually appealing and creative. This distinctive design may enhance the user experience by providing a refreshing and engaging environment. Having a colorful and thematic work environment might spark inspiration and creativity for the person using the laptop on this table. Additionally, it serves as a conversation starter and adds flair to the otherwise common and mundane workstations. However, it is essential to ensure that the table's functionalities are not compromised due to the design, and it still provides an adequate surface for working comfortably with the laptop, mouse, and keyboard."}]}, {"id": "000000337786", "image": "coco/train2017/000000337786.jpg", "conversations": [{"from": "human", "value": "What is the potential reason the cat might be doing this?\n<image>"}, {"from": "gpt", "value": "One potential reason the cat might be chewing on the metal fiber brush or comb is that it's experiencing teething pain or dental discomfort. Chewing the object may provide some relief to the cat, as the pressure and texture of the brush can help alleviate the discomfort. Additionally, the cat could be chewing on the brush simply out of curiosity or as a play behavior, as cats are known to explore their environment through their senses, including touching and biting objects. However, it is essential to monitor the cat's behavior to ensure that it does not swallow any parts of the brush or damage its teeth in the process. If dental issues or abnormal chewing habits persist, consulting a veterinarian is advised."}]}, {"id": "000000057340", "image": "coco/train2017/000000057340.jpg", "conversations": [{"from": "human", "value": "<image>\nWhy might the American flag play a significant role in the tower's appearance?"}, {"from": "gpt", "value": "The American flag on top of the clock tower plays a significant role in its appearance because it showcases national pride and patriotism. The flag indicates that the structure is located in the United States and serves as a symbol of unity and shared values. Additionally, the clock tower, being a prominent and symbolic structure, acts as a fitting place to display the American flag, as it can be easily seen by passers-by and contributes to the overall visual impression of the tower. By combining the clock tower's architectural features with the American flag, the scene evokes feelings of pride, history, and a sense of community, thus enhancing the tower's overall impact on the cityscape."}]}, {"id": "000000112959", "image": "coco/train2017/000000112959.jpg", "conversations": [{"from": "human", "value": "What can be inferred about the girl's surroundings and the reason for her outdoor meal?\n<image>"}, {"from": "gpt", "value": "Based on the image, the girl is enjoying her pizza in a green, forest-like area, which implies that she is surrounded by nature. Considering the fact that she is wearing pajamas, it could be inferred that this occasion might be part of a casual, relaxed activity, such as a family picnic or a camping trip. Eating outside in this beautiful environment might have been chosen to create an enjoyable and unique experience, which allows the girl to appreciate nature while also having a delicious meal."}]}, {"id": "000000082858", "image": "coco/train2017/000000082858.jpg", "conversations": [{"from": "human", "value": "<image>\nHow can the presentation of the dish on this dining table be described?"}, {"from": "gpt", "value": "The presentation of the dish on the dining table can be described as elegant and appetizing. The image highlights two pieces of meat covered in sauce, placed on a pristine white plate. The white plate brings attention to the well-prepared food items, enhancing their visual appeal. This fine food arrangement suggests that the dish could be served at a high-end restaurant or a special occasion. In addition to the dish, the dining table includes a cup, a knife, and a bowl, contributing to the overall sophisticated and classy presentation."}]}, {"id": "000000420859", "image": "coco/train2017/000000420859.jpg", "conversations": [{"from": "human", "value": "What is the man doing that can be considered a leisure activity and how might it benefit him?\n<image>"}, {"from": "gpt", "value": "The man is riding a blue bike on the beach near the water, which can be considered a leisure activity. Engaging in this activity can be beneficial to the man in several ways. Firstly, cycling on the beach provides a form of physical exercise that can help improve his cardiovascular health, build muscles, and burn calories. Secondly, the natural environment of the beach, the sound of the waves, and the fresh air can contribute to relaxation and stress relief. Moreover, such leisure activities allow an individual to take a break from their daily routine, rejuvenate, and improve their overall well-being."}]}, {"id": "000000198936", "image": "coco/train2017/000000198936.jpg", "conversations": [{"from": "human", "value": "How can the setting of the scene affect the atmosphere or mood of the woman and her Boston terrier?\n<image>"}, {"from": "gpt", "value": "In the scene, a woman is sitting on a red couch next to her Boston terrier, with a remote control in her hand. This setting conveys a comfortable and relaxed atmosphere. The presence of the couch and remote control suggests that the woman is likely watching TV, enjoying her downtime in a cozy environment. The dog's presence is an additional factor that contributes to the warmth and companionship within the scene. Having a pet, like a Boston terrier, to cuddle and relax with on the couch can be emotionally comforting for its owner, transforming the atmosphere from merely a space for leisure to one that also nurtures emotional well-being. This setting of shared relaxation can undoubtedly deepen the bond between the woman and her dog, promoting a positive, nurturing atmosphere for both."}]}, {"id": "000000465196", "image": "coco/train2017/000000465196.jpg", "conversations": [{"from": "human", "value": "What advice would you give to someone trying to improve their skiing ability?\n<image>"}, {"from": "gpt", "value": "To improve skiing ability, one should consider the following tips:\n\n1. Take ski lessons: Joining a skiing class or hiring a professional ski instructor can help beginners or intermediate skiers refine their techniques and learn new skills efficiently.\n\n2. Practice regularly: Developing any skill requires consistent practice, and skiing is no exception. Spend more time on the slopes to build muscle memory, balance, and confidence.\n\n3. Learn to read the terrain: Understanding different types of snow and slope conditions will allow skiers to adapt their skiing techniques as required, promoting both safety and performance.\n\n4. Maintain proper body posture: Focus on maintaining a balanced, athletic posture with knees slightly bent, hips over the feet, and arms forward. This will help skiers remain stable and agile on the slopes.\n\n5. Wear appropriate gear: Invest in high-quality skiing equipment and clothing that fits well and is suitable for the type of skiing and conditions one plans to encounter.\n\n6. Work on physical fitness: Skiing involves a combination of strength, endurance, flexibility, and balance. Engage in regular exercise, including strength training, cardiovascular workouts, and flexibility training to enhance overall performance on the slopes.\n\n7. Learn from others: Observe more experienced skiers and consider their technique, style, and decision-making. This can offer valuable insights that help with improvement.\n\n8. Have patience: Progression in skiing may be slow and gradual. It's essential to be patient and allow oneself the time to improve by setting realistic goals and celebrating small victories.\n\nIn the image, a woman wearing a bright red jacket is posing on her skis in the snow under a cloudy sky, exhibiting her enthusiasm and joy for the sport. Following these tips, others can also enjoy and improve their skiing skills over time."}]}, {"id": "000000258611", "image": "coco/train2017/000000258611.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat preparations can be inferred from the scene that the man might be engaged in?"}, {"from": "gpt", "value": "From the scene, it can be inferred that the man might be preparing for a trip or has recently returned from one. This is suggested by the presence of a suitcase next to him while he is seated on the red couch. The man appears to be resting or relaxing, either before departing or after arriving home. The fact that there are also some other items in the room, like a backpack, a dining table with a bowl on it, chairs, and books, indicates that he might be in the process of organizing, packing, or unpacking belongings."}]}, {"id": "000000401822", "image": "coco/train2017/000000401822.jpg", "conversations": [{"from": "human", "value": "What feature in this kitchen could make cooking more enjoyable and efficient?\n<image>"}, {"from": "gpt", "value": "The luxury kitchen in the image is equipped with an outside ventilation system for the stove. This feature allows for efficient removal of cooking odors, smoke, and excess heat, making the cooking experience more enjoyable and comfortable. Additionally, proper ventilation helps maintain a cleaner environment in the kitchen by reducing the accumulation of grease and airborne particles, resulting in a more hygienic cooking space. Overall, the outside ventilation system contributes to a more pleasant and efficient cooking experience."}]}, {"id": "000000465353", "image": "coco/train2017/000000465353.jpg", "conversations": [{"from": "human", "value": "What makes this outdoor scene an enjoyable location for people to visit?\n<image>"}, {"from": "gpt", "value": "The outdoor scene in the image appears to be an enjoyable location for people to visit for several reasons. The setting includes a variety of green umbrellas, which provide shade and outdoor seating for customers outside a restaurant, possibly situated in a picturesque mountainous region. People can be seen walking and socializing in the area, contributing to a lively atmosphere. Additionally, there are benches for visitors to sit and relax, allowing them to take in the beautiful surroundings and savor the experience. The presence of various vehicles, such as a four-wheeler and a motorcycle, implies that this location might offer opportunities for outdoor recreational activities and exploration as well. Overall, the combination of nature, leisure, dining, and socializing options make this outdoor scene attractive for visitors."}]}, {"id": "000000329766", "image": "coco/train2017/000000329766.jpg", "conversations": [{"from": "human", "value": "How has this train station accommodated people who are waiting for their trains and those who arrive with bicycles?\n<image>"}, {"from": "gpt", "value": "The train station provides seating options for the people waiting for their trains by offering several red chairs and benches, which are visible near the man and the subway train. Additionally, the station has taken into consideration the needs of individuals who use bicycles as their mode of transportation. There are multiple bicycles parked and placed in a designated area close to the platform, allowing for safe storage and convenient access for commuters who arrive with bicycles or plan to use them after disembarking from the train. This facilitates a smooth transition between different transport options for these commuters and encourages eco-friendly practices."}]}, {"id": "000000389159", "image": "coco/train2017/000000389159.jpg", "conversations": [{"from": "human", "value": "<image>\nWhy might there be a significant number of plants inside a subway train?"}, {"from": "gpt", "value": "One possible explanation for the presence of a significant number of plants inside a subway train could be a special event or a unique initiative aimed at improving the commuting experience or promoting environmental awareness among the passengers. The plants, acting as air purifiers and natural stress-relievers, could create a more pleasant atmosphere within the train. Additionally, the unconventional presence of plants inside the subway train might serve as a conversation starter or an opportunity for community engagement. This unusual setting with people trying to navigate around the potted plants in a public transport environment suggests the city might be experimenting or celebrating a specific theme, making the commute experience different and memorable for the passengers."}]}, {"id": "000000272899", "image": "coco/train2017/000000272899.jpg", "conversations": [{"from": "human", "value": "What valuable lesson can be inferred from the scene?\n<image>"}, {"from": "gpt", "value": "From the image, we can infer that the young boy, who is sitting near two birds, might be experiencing a valuable lesson on the importance of taking a moment to pause, appreciate nature, and enjoy the simple things in life. It demonstrates that even in our busy lives, there can be moments when one can connect with nature and find tranquility, which can have a positive impact on overall well-being and mental health. This scene also highlights the importance of nurturing our innate curiosity and understanding that there is something to learn from observing the world around us, even from seemingly insignificant experiences and interactions."}]}, {"id": "000000083738", "image": "coco/train2017/000000083738.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat essential items are missing in this bathroom for personal hygiene?"}, {"from": "gpt", "value": "While the bathroom in the image appears to be well-equipped with a toilet, sink, mirror, and some cups, it is missing essential personal hygiene items such as soap, shampoo, and towels. These items are crucial for maintaining cleanliness and personal care. It's important for the bathroom to provide these essentials to ensure that users can effectively clean and groom themselves."}]}, {"id": "000000468826", "image": "coco/train2017/000000468826.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat might be the occasion for this gathering?"}, {"from": "gpt", "value": "This gathering might be a birthday party or a special celebration, as there is a large group of people \u2013 including both children and adults \u2013 sitting around a long dining table with multiple cakes distributed along the table. The presence of cakes suggests that they are celebrating an event or milestone, with everyone enjoying the festive atmosphere and delights together."}]}, {"id": "000000374520", "image": "coco/train2017/000000374520.jpg", "conversations": [{"from": "human", "value": "What considerations do the pilots of large airplanes, such as the red and white Austrian Airlines airplane in the image, have to take into account during takeoff and landing?\n<image>"}, {"from": "gpt", "value": "Pilots of large airplanes, like the red and white Austrian Airlines airplane in the image, have to consider a wide range of factors during takeoff and landing to ensure a safe and smooth flight experience. Key considerations include:\n\n1. Aircraft weight and balance: Proper distribution of payload, including passengers, cargo, and fuel, to maintain the center of gravity within limits.\n\n2. Runway length: Ensuring the available runway length is sufficient for the airplane to safely accelerate during takeoff and decelerate during landing.\n\n3. Weather conditions: Taking into account potential turbulence, crosswinds, visibility, and other weather-related factors that may impact the approach, takeoff or landing.\n\n4. Air traffic control instructions: Following communication and guidance from air traffic controllers regarding altitude, speed, and direction to safely navigate the airspace and avoid potential conflicts.\n\n5. Aircraft performance: Monitoring the airplane's engines, systems, and equipment to ensure proper functionality and performance during critical takeoff and landing phases.\n\n6. Approach and landing procedures: Following established procedures and pre-defined routes to approach the airport, align with the runway, and execute a stable descent and touchdown.\n\nBy carefully considering these factors, pilots can help to ensure a safe and efficient takeoff and landing, minimizing risks for both the passengers on board and others in the surrounding airspace."}]}, {"id": "000000414888", "image": "coco/train2017/000000414888.jpg", "conversations": [{"from": "human", "value": "What could be the purpose of people interacting with horses in the grassy field?\n<image>"}, {"from": "gpt", "value": "In the image, there are people with horses in a grassy field, and a man is holding the reins of a large brown horse, possibly controlling it. The purpose of people interacting with horses in such a setting could be for various reasons, such as horse riding, training the horse, providing care or exercise to the horse, or simply enjoying the company of the animal. In rural settings, horses may also be used for agricultural work such as plowing the fields or other tasks that require physical strength. The interaction between the people and these horses could be part of daily chores, leisure or professional activities, or even practicing and honing skills like horse riding and training. With the presence of a car in the image, it could potentially be related to transportation after the planned activities or to move horse-related equipment."}]}, {"id": "000000451160", "image": "coco/train2017/000000451160.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat can you learn from this exhibit?"}, {"from": "gpt", "value": "In this exhibit, you can learn about the different military uniforms worn by soldiers throughout history. The display features mannequins dressed in various military uniforms, providing a visual representation of the costumes and attire used by soldiers during different periods or wars. This exhibit not only helps in understanding the evolution of military fashion but also offers insights into the roles, ranks, and functions of servicemen and women. Additionally, the exhibit may provide an understanding of how uniforms contributed to the discipline and identity of military personnel while reflecting the significance of historical events and military tradition."}]}, {"id": "000000111612", "image": "coco/train2017/000000111612.jpg", "conversations": [{"from": "human", "value": "What should beginners keep in mind when attempting to join these surfers?\n<image>"}, {"from": "gpt", "value": "When attempting to join the surfers in the image, beginners should keep in mind the following tips and precautions:\n\n1. Choose the right equipment: Beginners must choose a surfboard that is suitable for their skill level. In the image, many surfers are using surfboards designed for more experienced surfers. A wider, longer, and more stable board with a foam top would be ideal for beginners.\n\n2. Observe surf etiquette: Beginners should learn and respect the unwritten rules of surfing, such as not dropping in on another person's wave or respecting the local surfers to avoid conflicts in the water.\n\n3. Learn basic skills on land: Practice basic skills like the pop-up and basic stance on the beach before entering the water. This will make it easier to perform them when riding waves.\n\n4. Select an appropriate location: Join these surfers in a location where the waves are small and gentle, similar to the small wave ridden by the man in the image. A sandy bottom beach break would provide a safer environment with a lower risk of injury.\n\n5. Take lessons or join a surf school: Learning from professionals in a structured environment will provide a solid foundation for technique and understanding of the ocean and wave conditions.\n\n6. Always be aware of the conditions: Pay attention to weather and ocean conditions (e.g., tides, currents, and winds) before entering the water, as they can significantly affect the ease and safety of surfing.\n\nBy considering these factors, beginners can significantly improve their chances of having an enjoyable and safe surfing experience when joining these surfers in the ocean."}]}, {"id": "000000443857", "image": "coco/train2017/000000443857.jpg", "conversations": [{"from": "human", "value": "What detail could provide a calming atmosphere in the room?\n<image>"}, {"from": "gpt", "value": "The room has a nicely made bed with a blue comforter and blue pillow, which contribute to a calming atmosphere. Additionally, there is a picture of a bird on the wall by the bed. The peaceful imagery and the blue color palette can create a sense of tranquility, relaxation, and a soothing environment that is ideal for a bedroom setting. The combination of the neatly made bed, the blue lamp next to it, and the bird artwork helps to promote a calming atmosphere in the room."}]}, {"id": "000000243895", "image": "coco/train2017/000000243895.jpg", "conversations": [{"from": "human", "value": "What potential hazard could be associated with this scenario?\n<image>"}, {"from": "gpt", "value": "In the image, the presence of the large airplane flying close to the power transformer, or electrical tower with power lines, can pose a potential hazard. If the airplane gets too close to the power lines, there could be a risk of an accident or electrocution due to contact with the live wires. Such an incident could have severe consequences, including damage to the aircraft, disruption of the power supply, and even the potential for loss of life. In order to avoid such hazards, it is crucial for aircraft pilots to maintain a safe distance from power infrastructures and follow air traffic guidelines, and for the authorities to ensure proper clearance and height restrictions around power lines near flight paths."}]}, {"id": "000000139571", "image": "coco/train2017/000000139571.jpg", "conversations": [{"from": "human", "value": "What could be a possible reason behind the presence of people from two different nationalities cutting the cake together?\n<image>"}, {"from": "gpt", "value": "A possible reason for people from two different nationalities cutting the cake together could be that they are celebrating a collaborative event or a union between the two nationalities. This can include joint endeavors, partnerships, international conferences, or even personal events such as a wedding or engagement between families of different backgrounds. In the image, there are several people watching as two men in white uniforms cut the cake, highlighting the importance of the occasion and the significance of the different nationalities working together or celebrating as one."}]}, {"id": "000000170235", "image": "coco/train2017/000000170235.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the name of the position directly behind the batter?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Catcher"}, {"from": "human", "value": "Did the catcher get the ball?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the batters number?"}, {"from": "gpt", "value": "46"}]}, {"id": "000000264183", "image": "coco/train2017/000000264183.jpg", "conversations": [{"from": "human", "value": "<image>\nAre these actually candle holders?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What material are these containers made of?"}, {"from": "gpt", "value": "Glass"}, {"from": "human", "value": "What is the orange drink?"}, {"from": "gpt", "value": "Candle"}]}, {"id": "000000133905", "image": "coco/train2017/000000133905.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the girl combing her hair?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a hotel?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How many beds are here?"}, {"from": "gpt", "value": "3"}]}, {"id": "000000003008", "image": "coco/train2017/000000003008.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is the woman's hair?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Brown"}, {"from": "human", "value": "What color is the woman's hair?"}, {"from": "gpt", "value": "Brown"}, {"from": "human", "value": "What is the woman wearing?"}, {"from": "gpt", "value": "Shirt and vest"}, {"from": "human", "value": "How many women are in the picture?"}, {"from": "gpt", "value": "1"}, {"from": "human", "value": "Is the woman an artist?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the woman winding the clock?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How many people are wearing blue tops?"}, {"from": "gpt", "value": "0"}, {"from": "human", "value": "Is this woman married?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What color is the girl's shirt?"}, {"from": "gpt", "value": "White"}]}, {"id": "000000003915", "image": "coco/train2017/000000003915.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color are the bowls?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "Is the kitchen neat?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How many plates are stacked?"}, {"from": "gpt", "value": "8"}, {"from": "human", "value": "Did they make a mess?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the woman wearing an apron?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are those new cabinets?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What are the circular white things on the right?"}, {"from": "gpt", "value": "Plates"}, {"from": "human", "value": "Is it dark?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is in the jars?"}, {"from": "gpt", "value": "No jars"}, {"from": "human", "value": "What color is the refrigerator?"}, {"from": "gpt", "value": "Silver"}, {"from": "human", "value": "What type of flowers are in the vase?"}, {"from": "gpt", "value": "Purple"}, {"from": "human", "value": "What color are the flowers on the left wall?"}, {"from": "gpt", "value": "Purple"}, {"from": "human", "value": "What color are the two small bowls?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "What is the red item under the bowl?"}, {"from": "gpt", "value": "Counter"}, {"from": "human", "value": "Is there wine?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Does the purple flower match the decor?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What appliance has been used?"}, {"from": "gpt", "value": "Dishwasher"}, {"from": "human", "value": "How many people are there?"}, {"from": "gpt", "value": "1"}, {"from": "human", "value": "What kind of flowers are show?"}, {"from": "gpt", "value": "2"}, {"from": "human", "value": "Where are the flowers?"}, {"from": "gpt", "value": "On counter"}, {"from": "human", "value": "What color are the plates?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "What chips are on the counter?"}, {"from": "gpt", "value": "None"}, {"from": "human", "value": "How many cans are on the bar?"}, {"from": "gpt", "value": "0"}, {"from": "human", "value": "What is on the counter?"}, {"from": "gpt", "value": "Plates"}, {"from": "human", "value": "Where are the clean plates stacked?"}, {"from": "gpt", "value": "Counter"}, {"from": "human", "value": "Are there any muffins?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What are you not supposed to feed?"}, {"from": "gpt", "value": "Nothing"}]}, {"id": "000000393924", "image": "coco/train2017/000000393924.jpg", "conversations": [{"from": "human", "value": "<image>\nAre the people a couple?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are the two people in this image of the same ethnicity?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the girl a brunette?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What pattern is the tie that the gentleman is wearing?"}, {"from": "gpt", "value": "Solid"}, {"from": "human", "value": "What is the woman doing?"}, {"from": "gpt", "value": "Smiling"}, {"from": "human", "value": "What color are the stones in her earrings?"}, {"from": "gpt", "value": "Black"}, {"from": "human", "value": "Shouldn't the woman lose some weight?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Does this woman have tan lines?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Why would he be dressed like this?"}, {"from": "gpt", "value": "Wedding"}, {"from": "human", "value": "How many adults are in the photo?"}, {"from": "gpt", "value": "2"}, {"from": "human", "value": "Does it look like these people have been drinking?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What are these people doing?"}, {"from": "gpt", "value": "Posing"}]}, {"id": "000000005260", "image": "coco/train2017/000000005260.jpg", "conversations": [{"from": "human", "value": "<image>\nIs it raining?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What sport are they playing?"}, {"from": "gpt", "value": "Baseball"}, {"from": "human", "value": "How many people are standing behind the batter's box?"}, {"from": "gpt", "value": "2"}, {"from": "human", "value": "What game is he playing?"}, {"from": "gpt", "value": "Baseball"}, {"from": "human", "value": "Is this a professional baseball game?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How many people are visible in the background?"}, {"from": "gpt", "value": "8"}]}, {"id": "000000088382", "image": "coco/train2017/000000088382.jpg", "conversations": [{"from": "human", "value": "<image>\nIs it foggy outside?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How many cows are standing?"}, {"from": "gpt", "value": "2"}, {"from": "human", "value": "Are the cows going for a walk on the beach?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How many days until the cows are slaughtered?"}, {"from": "gpt", "value": "5"}]}, {"id": "000000532175", "image": "coco/train2017/000000532175.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat method of transportation is nearest the camera?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Bike"}, {"from": "human", "value": "Why is the woman wearing a helmet?"}, {"from": "gpt", "value": "For safety"}, {"from": "human", "value": "What major city is this?"}, {"from": "gpt", "value": "New york"}, {"from": "human", "value": "What vehicles are in the street?"}, {"from": "gpt", "value": "Cars"}, {"from": "human", "value": "Is there a bus in the picture?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000270269", "image": "coco/train2017/000000270269.jpg", "conversations": [{"from": "human", "value": "<image>\nIs it night time?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What color is the traffic light?"}, {"from": "gpt", "value": "Green"}, {"from": "human", "value": "Is it safe for people to walk across the crosswalk now?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000191350", "image": "coco/train2017/000000191350.jpg", "conversations": [{"from": "human", "value": "<image>\nWho rides the wave?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "IS that a women?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Does the woman have long hair?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000008309", "image": "coco/train2017/000000008309.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the woman talking on her cell phone?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What color is the cell phone case?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "What is behind the woman?"}, {"from": "gpt", "value": "Net"}]}, {"id": "000000139389", "image": "coco/train2017/000000139389.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the street wet?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is on top on this car?"}, {"from": "gpt", "value": "Surfboard"}, {"from": "human", "value": "Is the car door ajar?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is this a good car for a family?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What make of car is this?"}, {"from": "gpt", "value": "Vw"}]}, {"id": "000000139571", "image": "coco/train2017/000000139571.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat flags are on the cake?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Usa and bangladesh"}, {"from": "human", "value": "What is the date of this ceremony?"}, {"from": "gpt", "value": "2012"}, {"from": "human", "value": "What rank is the American cutting the cake?"}, {"from": "gpt", "value": "General"}]}, {"id": "000000401822", "image": "coco/train2017/000000401822.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the door broken?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is stacked on the bottom shelf of the cabinet?"}, {"from": "gpt", "value": "Nothing"}, {"from": "human", "value": "Is this kitchen open?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a restaurant?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is this kitchen mostly empty?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What room is this?"}, {"from": "gpt", "value": "Kitchen"}, {"from": "human", "value": "Are the counters made of wood?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the backsplash made of?"}, {"from": "gpt", "value": "Tile"}]}, {"id": "000000437889", "image": "coco/train2017/000000437889.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the scenery passing by?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What can be seen out of the window?"}, {"from": "gpt", "value": "Trees"}, {"from": "human", "value": "Is there a bottle in the picture?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000010735", "image": "coco/train2017/000000010735.jpg", "conversations": [{"from": "human", "value": "<image>\nCan we see both faces?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are these elephants in the wild?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How many elephants?"}, {"from": "gpt", "value": "2"}]}, {"id": "000000272899", "image": "coco/train2017/000000272899.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is the boys hair?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Black"}, {"from": "human", "value": "What are the birds doing?"}, {"from": "gpt", "value": "Sitting"}, {"from": "human", "value": "Is there a boat in this picture?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000011065", "image": "coco/train2017/000000011065.jpg", "conversations": [{"from": "human", "value": "<image>\nDo the horses have long manes?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What animal is this?"}, {"from": "gpt", "value": "Horse"}, {"from": "human", "value": "What color is the horse?"}, {"from": "gpt", "value": "Brown"}, {"from": "human", "value": "What is this breed of horses called?"}, {"from": "gpt", "value": "Clydesdale"}, {"from": "human", "value": "What kind of animal is the horse standing by?"}, {"from": "gpt", "value": "Human"}, {"from": "human", "value": "What color is the horse?"}, {"from": "gpt", "value": "Brown"}, {"from": "human", "value": "What is the woman wearing on her back?"}, {"from": "gpt", "value": "Coat"}, {"from": "human", "value": "What are the animals looking at?"}, {"from": "gpt", "value": "Person"}, {"from": "human", "value": "What type of animal is in the photo?"}, {"from": "gpt", "value": "Horse"}, {"from": "human", "value": "What  Western figures, traditionally go everywhere on these creatures?"}, {"from": "gpt", "value": "Cowboys"}]}, {"id": "000000012283", "image": "coco/train2017/000000012283.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is the man's shirt?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Black"}, {"from": "human", "value": "Is this house most likely located in the country or in the city?"}, {"from": "gpt", "value": "Country"}, {"from": "human", "value": "What church is this?"}, {"from": "gpt", "value": "Rocco's"}, {"from": "human", "value": "Who is riding the horses?"}, {"from": "gpt", "value": "No one"}, {"from": "human", "value": "Is this picture recent?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this building more than 5 stories tall?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the name on the building?"}, {"from": "gpt", "value": "Rocco's"}, {"from": "human", "value": "What is the horse doing?"}, {"from": "gpt", "value": "Walking"}, {"from": "human", "value": "Are the people waiting for a bus?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color is the center building?"}, {"from": "gpt", "value": "Red"}, {"from": "human", "value": "Is the guy on a sidewalk?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are the people running away?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are the people tourists?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is this a recent photo?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What was the sexual orientation of the person that designed parking area of this building?"}, {"from": "gpt", "value": "Heterosexual"}, {"from": "human", "value": "Are there any people on the street?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are these kids walking home?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color is the truck?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "How many women are here?"}, {"from": "gpt", "value": "6"}, {"from": "human", "value": "What are the cylindrical objects attached to the telephone polls?"}, {"from": "gpt", "value": "Transformers"}, {"from": "human", "value": "Do you see a mailbox?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000405959", "image": "coco/train2017/000000405959.jpg", "conversations": [{"from": "human", "value": "<image>\nIs this a teddy bear?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is this business called?"}, {"from": "gpt", "value": "Cafe pepper rose"}, {"from": "human", "value": "What kind of tree is covering the train?"}, {"from": "gpt", "value": "No train"}, {"from": "human", "value": "What kind of sign is this?"}, {"from": "gpt", "value": "Menu"}]}, {"id": "000000276739", "image": "coco/train2017/000000276739.jpg", "conversations": [{"from": "human", "value": "<image>\nIs it on display?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this cycle unusual?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How many passengers can this motorcycle accommodate?"}, {"from": "gpt", "value": "1"}]}, {"id": "000000111831", "image": "coco/train2017/000000111831.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many busses in the picture?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "3"}, {"from": "human", "value": "Are all the people waiting for the bus?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is this night time?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000408266", "image": "coco/train2017/000000408266.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the boy happy?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color shirt is the boy wearing?"}, {"from": "gpt", "value": "Red"}, {"from": "human", "value": "What is the boy eating?"}, {"from": "gpt", "value": "Pizza"}, {"from": "human", "value": "What is being eaten?"}, {"from": "gpt", "value": "Pizza"}]}, {"id": "000000146841", "image": "coco/train2017/000000146841.jpg", "conversations": [{"from": "human", "value": "<image>\nAre most of the bananas yellow?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the long skinny fruit?"}, {"from": "gpt", "value": "Banana"}, {"from": "human", "value": "How much is per weight of Celeriac?"}, {"from": "gpt", "value": "1.90"}, {"from": "human", "value": "Is this someone's home?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What vegetable name is written above one of the bins?"}, {"from": "gpt", "value": "Celeriac"}, {"from": "human", "value": "Is this a donut shop?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000279648", "image": "coco/train2017/000000279648.jpg", "conversations": [{"from": "human", "value": "<image>\nHow are the waves in the pic?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Small"}, {"from": "human", "value": "Is the girl submerged underwater?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is she \"riding\" a wave?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this girl over the age of 18?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color is the surfboard?"}, {"from": "gpt", "value": "Pink"}]}, {"id": "000000542488", "image": "coco/train2017/000000542488.jpg", "conversations": [{"from": "human", "value": "<image>\nIs this dirt rocky?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What position is the animal in?"}, {"from": "gpt", "value": "Laying down"}, {"from": "human", "value": "Is the animal active?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the color of the zebra?"}, {"from": "gpt", "value": "Black and white"}]}, {"id": "000000542937", "image": "coco/train2017/000000542937.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the animal looking at the camera?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What are these animals?"}, {"from": "gpt", "value": "Yak"}, {"from": "human", "value": "Does any animal have antlers?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000543201", "image": "coco/train2017/000000543201.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color are the umbrellas?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Green"}, {"from": "human", "value": "Does the child have a soul?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Do all of the plants have blooms?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the lady selling in her basket?"}, {"from": "gpt", "value": "Flowers"}, {"from": "human", "value": "What expression is on her face?"}, {"from": "gpt", "value": "Confusion"}, {"from": "human", "value": "What is the child playing with?"}, {"from": "gpt", "value": "Umbrella"}, {"from": "human", "value": "Is it raining?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the girl crying?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000545409", "image": "coco/train2017/000000545409.jpg", "conversations": [{"from": "human", "value": "<image>\nDo these look like comfortable shoes?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the woman standing?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What type of shoes are these?"}, {"from": "gpt", "value": "Heels"}]}, {"id": "000000313979", "image": "coco/train2017/000000313979.jpg", "conversations": [{"from": "human", "value": "<image>\nIs this a public toilet?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How many rolls of tissue do you see?"}, {"from": "gpt", "value": "3"}, {"from": "human", "value": "Where is the toilet tissue?"}, {"from": "gpt", "value": "Shelf"}, {"from": "human", "value": "How many toilets are in the room?"}, {"from": "gpt", "value": "1"}, {"from": "human", "value": "What is the metal item to the right of the toilet?"}, {"from": "gpt", "value": "Trash can"}, {"from": "human", "value": "What is the light located next to?"}, {"from": "gpt", "value": "Vent"}, {"from": "human", "value": "Is this picture black and white?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are the toilet seats up or down?"}, {"from": "gpt", "value": "Down"}, {"from": "human", "value": "Is the toilet clean?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is there a shower in this room?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is there a shower in this bathroom?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the toilet lid down?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color is the accent stripe?"}, {"from": "gpt", "value": "Brown"}]}, {"id": "000000545538", "image": "coco/train2017/000000545538.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many animals are in this picture?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "2"}, {"from": "human", "value": "What color is the ground?"}, {"from": "gpt", "value": "Brown"}, {"from": "human", "value": "Is there anyone wearing green?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000114879", "image": "coco/train2017/000000114879.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat are the children holding onto?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Hands"}, {"from": "human", "value": "What color is the chair the man is sitting on?"}, {"from": "gpt", "value": "Rainbow"}, {"from": "human", "value": "Is there a boat?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Does it appear to be high or low tide?"}, {"from": "gpt", "value": "Low"}, {"from": "human", "value": "Were people moving when this picture was taken?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000414888", "image": "coco/train2017/000000414888.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many ponies is this man standing behind?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "1"}, {"from": "human", "value": "Is the man wearing a hat?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What kind of horses are these?"}, {"from": "gpt", "value": "Clydesdale"}]}, {"id": "000000309523", "image": "coco/train2017/000000309523.jpg", "conversations": [{"from": "human", "value": "<image>\nAre these women walking with a natural gait?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is there an umbrella in the photo?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are these women wearing dress shoes?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000417230", "image": "coco/train2017/000000417230.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat are these men's jobs?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Police"}, {"from": "human", "value": "What area are these police officers patrolling?"}, {"from": "gpt", "value": "Beach"}, {"from": "human", "value": "Where is LAPD stamped?"}, {"from": "gpt", "value": "Saddle blanket"}]}, {"id": "000000280132", "image": "coco/train2017/000000280132.jpg", "conversations": [{"from": "human", "value": "<image>\nIs this in the wild or zoo?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Zoo"}, {"from": "human", "value": "What animal is this?"}, {"from": "gpt", "value": "Sheep"}, {"from": "human", "value": "Are these wild animals?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the baby elephant doing?"}, {"from": "gpt", "value": "Eating"}, {"from": "human", "value": "What color are the cows?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "What is in the foreground of the image?"}, {"from": "gpt", "value": "Sheep"}, {"from": "human", "value": "Has this sheep been dyed a particular color?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the fence made of?"}, {"from": "gpt", "value": "Wood"}, {"from": "human", "value": "How tall is the plant?"}, {"from": "gpt", "value": "Few inches"}, {"from": "human", "value": "What plant is growing from the water?"}, {"from": "gpt", "value": "Grass"}, {"from": "human", "value": "What many animals are in the picture?"}, {"from": "gpt", "value": "1"}, {"from": "human", "value": "Is the grass mowed?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000083738", "image": "coco/train2017/000000083738.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich room is this?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Bathroom"}, {"from": "human", "value": "What color accents the room?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "What color are the bottles in the corner?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "Is this a hotel bathroom?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color are the towels?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "What kind of flooring in the room?"}, {"from": "gpt", "value": "Tile"}, {"from": "human", "value": "Has the walls in the bathroom been painted?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the green towel unused?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What color is the rug?"}, {"from": "gpt", "value": "Blue and white"}, {"from": "human", "value": "Where does one hang their towels here?"}, {"from": "gpt", "value": "Cabinet"}, {"from": "human", "value": "How many types of tiles?"}, {"from": "gpt", "value": "2"}, {"from": "human", "value": "Are there windows in the picture?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color is the towel?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "What is on the top of the counter?"}, {"from": "gpt", "value": "Soap"}, {"from": "human", "value": "Does this bathroom offer privacy and seclusion?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000286877", "image": "coco/train2017/000000286877.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat mode of transportation is this?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Subway"}, {"from": "human", "value": "Does this need to be cleaned?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How many seats are on the bus?"}, {"from": "gpt", "value": "8"}]}, {"id": "000000418600", "image": "coco/train2017/000000418600.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is in the woman's right hand?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Phone"}, {"from": "human", "value": "Where are her glasses?"}, {"from": "gpt", "value": "Shirt"}, {"from": "human", "value": "Is the image in black and white?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000025421", "image": "coco/train2017/000000025421.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich brand of television is the cat watching?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Samsung"}, {"from": "human", "value": "What kind of TV is shown?"}, {"from": "gpt", "value": "Flat screen"}, {"from": "human", "value": "What is on the TV?"}, {"from": "gpt", "value": "Cat"}]}, {"id": "000000025461", "image": "coco/train2017/000000025461.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many people are here?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "4"}, {"from": "human", "value": "Is this a dry summer?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What type of bus is in the background?"}, {"from": "gpt", "value": "Rv"}]}, {"id": "000000397513", "image": "coco/train2017/000000397513.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is the hat?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "Is this a pro sports team?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Which city does this team represent?"}, {"from": "gpt", "value": "Los angeles"}]}, {"id": "000000550532", "image": "coco/train2017/000000550532.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color are the meters?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Green"}, {"from": "human", "value": "What is the total number of minutes that are left on both meters?"}, {"from": "gpt", "value": "0"}, {"from": "human", "value": "What is the number of the meter on the left?"}, {"from": "gpt", "value": "68"}, {"from": "human", "value": "What is the number on the parking meter on the left?"}, {"from": "gpt", "value": "68"}, {"from": "human", "value": "What number appears on both meters?"}, {"from": "gpt", "value": "6"}]}, {"id": "000000420859", "image": "coco/train2017/000000420859.jpg", "conversations": [{"from": "human", "value": "<image>\nDo the colors of the bike pop in this beach scene?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Do these guys need shoes where they're going?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Where is the man riding his bike?"}, {"from": "gpt", "value": "Beach"}, {"from": "human", "value": "Is the man wearing a helmet?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the person holding?"}, {"from": "gpt", "value": "Handlebars"}]}, {"id": "000000421542", "image": "coco/train2017/000000421542.jpg", "conversations": [{"from": "human", "value": "<image>\nIs there a laptop in the picture?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Why is there a computer in this person's kitchen?"}, {"from": "gpt", "value": "Recipe"}, {"from": "human", "value": "What room is this?"}, {"from": "gpt", "value": "Kitchen"}]}, {"id": "000000422100", "image": "coco/train2017/000000422100.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color are the boy's sneakers?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Black"}, {"from": "human", "value": "What is this person riding?"}, {"from": "gpt", "value": "Skateboard"}, {"from": "human", "value": "Is this person in a gang?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How many white hats are there?"}, {"from": "gpt", "value": "0"}, {"from": "human", "value": "What color is his hat?"}, {"from": "gpt", "value": "Black"}]}, {"id": "000000422170", "image": "coco/train2017/000000422170.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the man paying attention to his book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the color of the girl's cell phone?"}, {"from": "gpt", "value": "Purple"}, {"from": "human", "value": "Could this be a stadium?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000160573", "image": "coco/train2017/000000160573.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat are they holding?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Donuts"}, {"from": "human", "value": "What food are they holding?"}, {"from": "gpt", "value": "Donuts"}, {"from": "human", "value": "Do they look happy?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000292053", "image": "coco/train2017/000000292053.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many bears are in the picture?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "3"}, {"from": "human", "value": "What color are the peoples' suits?"}, {"from": "gpt", "value": "Brown"}, {"from": "human", "value": "What does it say on the front of the bikes?"}, {"from": "gpt", "value": "No to bike parking tax"}, {"from": "human", "value": "What are these people riding?"}, {"from": "gpt", "value": "Motorcycle"}, {"from": "human", "value": "Are those real bears?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Who are riding the bikes?"}, {"from": "gpt", "value": "Men"}]}, {"id": "000000292177", "image": "coco/train2017/000000292177.jpg", "conversations": [{"from": "human", "value": "<image>\nWhere is this shot taken at?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Africa"}, {"from": "human", "value": "Is the animal a light brown or dark brown?"}, {"from": "gpt", "value": "Dark brown"}, {"from": "human", "value": "Is this animal tall?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Where is this animal's tail?"}, {"from": "gpt", "value": "Behind it"}]}, {"id": "000000030805", "image": "coco/train2017/000000030805.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the water boiling?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is there anything been stirred?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there paper towels on the table?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the pot sitting on?"}, {"from": "gpt", "value": "Counter"}, {"from": "human", "value": "What is in the measuring cup?"}, {"from": "gpt", "value": "Milk"}, {"from": "human", "value": "What is in the bucket?"}, {"from": "gpt", "value": "Milk"}]}, {"id": "000000031411", "image": "coco/train2017/000000031411.jpg", "conversations": [{"from": "human", "value": "<image>\nHow much of the grass is dry?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "All"}, {"from": "human", "value": "Is it snowing here?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How many total animals are there?"}, {"from": "gpt", "value": "2"}, {"from": "human", "value": "Are the animals touching?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Do the giraffes have horns?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are these zebras grooming each other?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000556162", "image": "coco/train2017/000000556162.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the bear wearing?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Shirt"}, {"from": "human", "value": "Is there a cartoon mustache in the picture?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is crossed out?"}, {"from": "gpt", "value": "20"}, {"from": "human", "value": "What is on the boy?"}, {"from": "gpt", "value": "Teddy bear"}, {"from": "human", "value": "What color is the little boy's shirt?"}, {"from": "gpt", "value": "Green"}, {"from": "human", "value": "How many bears are being held?"}, {"from": "gpt", "value": "3"}, {"from": "human", "value": "Is this bear in the shade?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How many people are in the picture?"}, {"from": "gpt", "value": "2"}, {"from": "human", "value": "What numbers are shown in the background?"}, {"from": "gpt", "value": "20"}, {"from": "human", "value": "How old is the boy?"}, {"from": "gpt", "value": "8"}, {"from": "human", "value": "Are the boys brothers?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What type of fabric are the bears made of?"}, {"from": "gpt", "value": "Cotton"}]}, {"id": "000000425576", "image": "coco/train2017/000000425576.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many donuts are in this scene?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "1"}, {"from": "human", "value": "Does she think this donut will be tasty?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is there icing on the donut?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color are her sunglasses?"}, {"from": "gpt", "value": "Red"}, {"from": "human", "value": "Is the woman's complexion flush?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000295655", "image": "coco/train2017/000000295655.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the girl texting?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is there flowers here?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How many bikes are visible?"}, {"from": "gpt", "value": "2"}]}, {"id": "000000164634", "image": "coco/train2017/000000164634.jpg", "conversations": [{"from": "human", "value": "<image>\nCould the child  have on shoes?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is there a tree in the background?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the boy holding?"}, {"from": "gpt", "value": "Grass"}, {"from": "human", "value": "Is the baby cute?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000426976", "image": "coco/train2017/000000426976.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat would you do at this sign?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Stop"}, {"from": "human", "value": "Is there graffiti on the sign?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this American?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000427283", "image": "coco/train2017/000000427283.jpg", "conversations": [{"from": "human", "value": "<image>\nWhy is the train at platform 5?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "To pick up passengers"}, {"from": "human", "value": "Are the lights on the train on?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color is the train?"}, {"from": "gpt", "value": "Purple"}]}, {"id": "000000034261", "image": "coco/train2017/000000034261.jpg", "conversations": [{"from": "human", "value": "<image>\nAre all four of the giraffe's feet planted on the ground?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "In what way does the giraffe and the wall match?"}, {"from": "gpt", "value": "Brown spots match"}, {"from": "human", "value": "Is the giraffe planning to go through this door?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000027711", "image": "coco/train2017/000000027711.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat does it say in front of the bus?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Sapphire"}, {"from": "human", "value": "What color is the bus?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "How many levels does the bus have?"}, {"from": "gpt", "value": "2"}]}, {"id": "000000049191", "image": "coco/train2017/000000049191.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the surfer wearing pants?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What happens if the surfer loses control of the board?"}, {"from": "gpt", "value": "Falls in water"}, {"from": "human", "value": "What color is the surfboard stripes?"}, {"from": "gpt", "value": "Black and white"}]}, {"id": "000000167330", "image": "coco/train2017/000000167330.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat does it say under the stop sign?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "All-war"}, {"from": "human", "value": "What shape is the red sign?"}, {"from": "gpt", "value": "Octagon"}, {"from": "human", "value": "Is the person who modified this sign liberal or conservative?"}, {"from": "gpt", "value": "Liberal"}, {"from": "human", "value": "What color are the characters on the signs?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "Is this a restaurant sign?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What does the bottom sign say?"}, {"from": "gpt", "value": "All-war"}, {"from": "human", "value": "What is the name on the top street sign?"}, {"from": "gpt", "value": "Electric"}, {"from": "human", "value": "How many signs are there?"}, {"from": "gpt", "value": "3"}, {"from": "human", "value": "What does it say under Stop?"}, {"from": "gpt", "value": "All-war"}, {"from": "human", "value": "How many cables can you see?"}, {"from": "gpt", "value": "9"}, {"from": "human", "value": "Is it summer time?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Where is this located?"}, {"from": "gpt", "value": "Electric ave"}, {"from": "human", "value": "What does the second sign say?"}, {"from": "gpt", "value": "All-war"}, {"from": "human", "value": "Does this sign appear to be in the United States?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How does the weather appear in this photo?"}, {"from": "gpt", "value": "Sunny"}]}, {"id": "000000268190", "image": "coco/train2017/000000268190.jpg", "conversations": [{"from": "human", "value": "<image>\nHas this bear been well worn?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How many teddy bears?"}, {"from": "gpt", "value": "1"}, {"from": "human", "value": "Do you see a human in the picture?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are both shoes standing up?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How many of the teddy bears have pants?"}, {"from": "gpt", "value": "0"}, {"from": "human", "value": "What kind of animal is in this image?"}, {"from": "gpt", "value": "Bear"}, {"from": "human", "value": "Is the teddy bear bigger than the shoes?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000036282", "image": "coco/train2017/000000036282.jpg", "conversations": [{"from": "human", "value": "<image>\nIs there an umbrella?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the woman looking for in the gravel?"}, {"from": "gpt", "value": "Shells"}, {"from": "human", "value": "Could two people fit under this umbrella?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000481209", "image": "coco/train2017/000000481209.jpg", "conversations": [{"from": "human", "value": "<image>\nAre the street lights on?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the name on the building?"}, {"from": "gpt", "value": "Conway"}, {"from": "human", "value": "Is the fire hydrant functional?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What color is the stripe along the sidewalk?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "How is the fire hydrant painted?"}, {"from": "gpt", "value": "Black and silver"}, {"from": "human", "value": "Is this fire hydrant taller than most?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color is the fire hydrant?"}, {"from": "gpt", "value": "Black and silver"}, {"from": "human", "value": "Which side of the road is the hydrant on?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is the street clean?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000036373", "image": "coco/train2017/000000036373.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is on his hand?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Glove"}, {"from": "human", "value": "About how old is the child in the photo?"}, {"from": "gpt", "value": "10"}, {"from": "human", "value": "Will the boy catch the ball?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000561590", "image": "coco/train2017/000000561590.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat kind of pants is the man wearing?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Jeans"}, {"from": "human", "value": "What color is the horse's bridle?"}, {"from": "gpt", "value": "Pink"}, {"from": "human", "value": "Is the woman folding her arms wearing a watch?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000169607", "image": "coco/train2017/000000169607.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is out on the water?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Boat"}, {"from": "human", "value": "Is morning approaching?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How far away is the person?"}, {"from": "gpt", "value": "Not far"}, {"from": "human", "value": "Is the boat moving?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000301558", "image": "coco/train2017/000000301558.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the middle person wearing only one ski?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What number of men are standing near each other?"}, {"from": "gpt", "value": "3"}, {"from": "human", "value": "Are the people looking at the camera?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Was it probably cold when this picture was taken?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is there a mountain in the background?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000225060", "image": "coco/train2017/000000225060.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is the man's shirt?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Gray"}, {"from": "human", "value": "What material is the football on his desk made from?"}, {"from": "gpt", "value": "Foam"}, {"from": "human", "value": "How many windows are open on the computer screen?"}, {"from": "gpt", "value": "4"}, {"from": "human", "value": "Does he drink soda?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000170832", "image": "coco/train2017/000000170832.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the material this building is made of?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Brick"}, {"from": "human", "value": "What country is this?"}, {"from": "gpt", "value": "England"}, {"from": "human", "value": "What time is on the clock?"}, {"from": "gpt", "value": "5:40"}]}, {"id": "000000565600", "image": "coco/train2017/000000565600.jpg", "conversations": [{"from": "human", "value": "<image>\nDoes the man's headband match his wristband?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Does the guy in white have a ring on his finger?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What sport is being played?"}, {"from": "gpt", "value": "Tennis"}, {"from": "human", "value": "What letter is on the men's tennis racket?"}, {"from": "gpt", "value": "P"}, {"from": "human", "value": "What is he stretched out for?"}, {"from": "gpt", "value": "Swinging"}]}, {"id": "000000116123", "image": "coco/train2017/000000116123.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is in the water?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Ducks"}, {"from": "human", "value": "What kind of birds are swimming in the bay?"}, {"from": "gpt", "value": "Swans and ducks"}, {"from": "human", "value": "How many geese are there?"}, {"from": "gpt", "value": "0"}]}, {"id": "000000443857", "image": "coco/train2017/000000443857.jpg", "conversations": [{"from": "human", "value": "<image>\nIs this a hotel room?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Does this room have hardwood floors?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is there a picture of a bird?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is on the bed?"}, {"from": "gpt", "value": "Pillows"}]}, {"id": "000000304067", "image": "coco/train2017/000000304067.jpg", "conversations": [{"from": "human", "value": "<image>\nIs this a motorbike race?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the home sitting close to the road?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the line in the road solid?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is it a sunny day?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are the hedges well-maintained?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the entire picture in focus?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000203673", "image": "coco/train2017/000000203673.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of computer is in the picture?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Macbook pro"}, {"from": "human", "value": "Is the fruit sitting on the 4 and 5 key?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What type of fruit is in the picture?"}, {"from": "gpt", "value": "Apple"}]}, {"id": "000000304889", "image": "coco/train2017/000000304889.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the man doing?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Drinking"}, {"from": "human", "value": "Does this man have a calm expression?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What ethnicity is the man?"}, {"from": "gpt", "value": "Caucasian"}]}, {"id": "000000567803", "image": "coco/train2017/000000567803.jpg", "conversations": [{"from": "human", "value": "<image>\nIs this plant edible?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is there water on this vegetable?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What kind of vegetable is this?"}, {"from": "gpt", "value": "Broccoli"}, {"from": "human", "value": "Is it ready to be picked?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000044227", "image": "coco/train2017/000000044227.jpg", "conversations": [{"from": "human", "value": "<image>\nWhere is the dog?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Park"}, {"from": "human", "value": "What kind of dog?"}, {"from": "gpt", "value": "Pitbull"}, {"from": "human", "value": "What color is the dog?"}, {"from": "gpt", "value": "Brown"}, {"from": "human", "value": "What does the dog have in his mouth?"}, {"from": "gpt", "value": "Ball"}, {"from": "human", "value": "Can you see the dog's tongue?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the dog holding?"}, {"from": "gpt", "value": "Ball"}, {"from": "human", "value": "What is the dog standing on?"}, {"from": "gpt", "value": "Ground"}, {"from": "human", "value": "What is the dog doing?"}, {"from": "gpt", "value": "Running"}, {"from": "human", "value": "Does this dog have a curly tail?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What type of dog is it?"}, {"from": "gpt", "value": "Boxer"}, {"from": "human", "value": "How could this dog have fleas?"}, {"from": "gpt", "value": "Outside"}, {"from": "human", "value": "What does the dog have in its mouth?"}, {"from": "gpt", "value": "Ball"}, {"from": "human", "value": "What happened to the ball?"}, {"from": "gpt", "value": "Popped"}, {"from": "human", "value": "What color is the ball?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "Is the dog thirsty?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000043071", "image": "coco/train2017/000000043071.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the person sad?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the person riding?"}, {"from": "gpt", "value": "Snowboard"}, {"from": "human", "value": "Is it cold out?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000400710", "image": "coco/train2017/000000400710.jpg", "conversations": [{"from": "human", "value": "<image>\nIs anyone wearing wrist protection?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the person wearing?"}, {"from": "gpt", "value": "T shirt and jeans"}, {"from": "human", "value": "What is this boy about to do?"}, {"from": "gpt", "value": "Skateboard"}, {"from": "human", "value": "What is the child standing on?"}, {"from": "gpt", "value": "Skateboard"}, {"from": "human", "value": "Is he in a kiddie pool?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color is the boy's helmet?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "What is in the background?"}, {"from": "gpt", "value": "Graffiti"}, {"from": "human", "value": "Is everyone wearing flip flops on their feet?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000047328", "image": "coco/train2017/000000047328.jpg", "conversations": [{"from": "human", "value": "<image>\nHas anyone eaten any yet?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What kind of cheese is topping the quesadilla?"}, {"from": "gpt", "value": "Cheddar"}, {"from": "human", "value": "Would a vegetarian eat this?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000521437", "image": "coco/train2017/000000521437.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is this person holding?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Wii remote"}, {"from": "human", "value": "Is she blind?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the item in the corner of the room?"}, {"from": "gpt", "value": "Lamp"}, {"from": "human", "value": "What is the woman holding?"}, {"from": "gpt", "value": "Wii controller"}]}, {"id": "000000573453", "image": "coco/train2017/000000573453.jpg", "conversations": [{"from": "human", "value": "<image>\nDoes this person appear to be a professional or amateur skier?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Amateur"}, {"from": "human", "value": "Is this a steep mountain?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What are the metal pole structures for?"}, {"from": "gpt", "value": "Starting gates"}, {"from": "human", "value": "Are there any clouds in the sky?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the person a skier or snowboarder?"}, {"from": "gpt", "value": "Snowboarder"}]}, {"id": "000000575305", "image": "coco/train2017/000000575305.jpg", "conversations": [{"from": "human", "value": "<image>\nWho are the people on the bench?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Spectators"}, {"from": "human", "value": "What number is on the batters uniform?"}, {"from": "gpt", "value": "27"}, {"from": "human", "value": "Who is behind the batter?"}, {"from": "gpt", "value": "Umpire"}, {"from": "human", "value": "Will he hit the ball?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the umpire touching the catcher?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000183690", "image": "coco/train2017/000000183690.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the child wearing a hoodie?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are the computers on?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Does the baby look peaceful?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the baby a girl baby or a boy baby?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "Why is the child's arm raised?"}, {"from": "gpt", "value": "To reach screen"}, {"from": "human", "value": "What is the phone resting on?"}, {"from": "gpt", "value": "Laptop"}, {"from": "human", "value": "Is the child typing something?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is this a boy or a girl?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "Does this child appear to know how to use a computer?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000249132", "image": "coco/train2017/000000249132.jpg", "conversations": [{"from": "human", "value": "<image>\nDoes the bus have a driver at the seat?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What does the blue sign on the bus say?"}, {"from": "gpt", "value": "Prom night"}, {"from": "human", "value": "Are there lights on inside the bus?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000446670", "image": "coco/train2017/000000446670.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is the wall?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "What is the centerpiece dish made of?"}, {"from": "gpt", "value": "Bananas"}, {"from": "human", "value": "Which room is this?"}, {"from": "gpt", "value": "Dining room"}, {"from": "human", "value": "What kind of wood is the table made of?"}, {"from": "gpt", "value": "Maple"}, {"from": "human", "value": "Where are the books at?"}, {"from": "gpt", "value": "Bookshelf"}, {"from": "human", "value": "Are the books open?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there any people in the photo?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What are the black pieces of the furniture?"}, {"from": "gpt", "value": "Chairs"}, {"from": "human", "value": "How many chairs are there?"}, {"from": "gpt", "value": "4"}, {"from": "human", "value": "How many chairs?"}, {"from": "gpt", "value": "4"}, {"from": "human", "value": "Is the chair in a dining room?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What color are the sheets on the bed?"}, {"from": "gpt", "value": "No bed"}, {"from": "human", "value": "Is this a house or apartment?"}, {"from": "gpt", "value": "Apartment"}, {"from": "human", "value": "What kind of room is this?"}, {"from": "gpt", "value": "Dining room"}, {"from": "human", "value": "How many chairs are in the room?"}, {"from": "gpt", "value": "4"}, {"from": "human", "value": "What room is this?"}, {"from": "gpt", "value": "Dining room"}, {"from": "human", "value": "If rice spilled on the table, would it all stay on the table?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What color are the walls around the table?"}, {"from": "gpt", "value": "White"}]}, {"id": "000000053840", "image": "coco/train2017/000000053840.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is the inside of the closest boat?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "Are there sails on the boat?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a sunset or a sunrise?"}, {"from": "gpt", "value": "Sunset"}, {"from": "human", "value": "How many boats?"}, {"from": "gpt", "value": "1"}, {"from": "human", "value": "How many boats are in the photo?"}, {"from": "gpt", "value": "1"}, {"from": "human", "value": "How many boats can be seen?"}, {"from": "gpt", "value": "1"}, {"from": "human", "value": "What color is the sky?"}, {"from": "gpt", "value": "Red"}]}, {"id": "000000053864", "image": "coco/train2017/000000053864.jpg", "conversations": [{"from": "human", "value": "<image>\nDid the cat make the paw prints on the sign?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the cat sitting on?"}, {"from": "gpt", "value": "Computer"}, {"from": "human", "value": "What is the cat looking at?"}, {"from": "gpt", "value": "Pencil"}, {"from": "human", "value": "What is this cat pawing at?"}, {"from": "gpt", "value": "Pencil"}, {"from": "human", "value": "Does the cat look comfortable?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000316059", "image": "coco/train2017/000000316059.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the grass all the same length?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is there a chain on the fire hydrant?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this fire hydrant located next to a street?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000447994", "image": "coco/train2017/000000447994.jpg", "conversations": [{"from": "human", "value": "<image>\nDo the glasses all have the same amount of liquid?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are the goblets empty?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What are the glasses sitting on?"}, {"from": "gpt", "value": "Counter"}, {"from": "human", "value": "Are these video game controllers?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What type of glasses are these?"}, {"from": "gpt", "value": "Wine"}, {"from": "human", "value": "Do any of the glasses contain wine?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there documents on the table?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000011713", "image": "coco/train2017/000000011713.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color lines are on the left?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "How many people are jumping?"}, {"from": "gpt", "value": "2"}, {"from": "human", "value": "Are the people standing in the snow?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000342294", "image": "coco/train2017/000000342294.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat kind of cake is this?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Cheesecake"}, {"from": "human", "value": "How many tines does the fork have?"}, {"from": "gpt", "value": "3"}, {"from": "human", "value": "What is the pattern on the plate?"}, {"from": "gpt", "value": "Polka dots"}]}, {"id": "000000056065", "image": "coco/train2017/000000056065.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat airline is the plane?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Air canada"}, {"from": "human", "value": "Airplanes from how many airlines are visible in this picture?"}, {"from": "gpt", "value": "4"}, {"from": "human", "value": "Where is the picture taken?"}, {"from": "gpt", "value": "Airport"}, {"from": "human", "value": "Was this taken in a harbor?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is it a sunny day?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000187368", "image": "coco/train2017/000000187368.jpg", "conversations": [{"from": "human", "value": "<image>\nIs there a shower curtain?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What kind of room is this?"}, {"from": "gpt", "value": "Bathroom"}, {"from": "human", "value": "Is the toilet seat up?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000577484", "image": "coco/train2017/000000577484.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the shower curtain closed?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are the towels on the shelf folded?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a residential bathroom?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000281230", "image": "coco/train2017/000000281230.jpg", "conversations": [{"from": "human", "value": "<image>\nAre there clouds  in the sky?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How many kites are there?"}, {"from": "gpt", "value": "1"}, {"from": "human", "value": "Is this probably saltwater?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000057340", "image": "coco/train2017/000000057340.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is on top of the tower?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Flag"}, {"from": "human", "value": "Is the clock on the tower lit up?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How many clocks are there?"}, {"from": "gpt", "value": "2"}]}, {"id": "000000451160", "image": "coco/train2017/000000451160.jpg", "conversations": [{"from": "human", "value": "<image>\nWere these 'people' in the military?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How many people are in the picture?"}, {"from": "gpt", "value": "5"}, {"from": "human", "value": "Are these people real?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000189182", "image": "coco/train2017/000000189182.jpg", "conversations": [{"from": "human", "value": "<image>\nHow would you describe the organization of the man's desk space?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "There is no desk"}, {"from": "human", "value": "What type of trick is the guy doing with the skateboard?"}, {"from": "gpt", "value": "Jumping"}, {"from": "human", "value": "What kind of room is this?"}, {"from": "gpt", "value": "Warehouse"}]}, {"id": "000000451983", "image": "coco/train2017/000000451983.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the man pulling?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Suitcase"}, {"from": "human", "value": "Is he on stairs?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What kind of vest is he wearing?"}, {"from": "gpt", "value": "Sweater"}, {"from": "human", "value": "How many steps are there?"}, {"from": "gpt", "value": "5"}]}, {"id": "000000512325", "image": "coco/train2017/000000512325.jpg", "conversations": [{"from": "human", "value": "<image>\nAre there any people on the bench?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is there any dogs in the park with this person?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is this for whom the chair was intended?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are the leaves starting to die on the trees?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is this woman completely alone on that bench?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are these wild flowers?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the bench occupied?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What are the green items?"}, {"from": "gpt", "value": "Plants"}, {"from": "human", "value": "What color is the bench?"}, {"from": "gpt", "value": "Brown"}, {"from": "human", "value": "What color is the chair?"}, {"from": "gpt", "value": "Brown"}]}, {"id": "000000059351", "image": "coco/train2017/000000059351.jpg", "conversations": [{"from": "human", "value": "<image>\nAre these wild or domestic animals?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Domestic"}, {"from": "human", "value": "Where was this photo taken?"}, {"from": "gpt", "value": "Farm"}, {"from": "human", "value": "What kind of animal is the lady walking with?"}, {"from": "gpt", "value": "Horse"}, {"from": "human", "value": "Is someone on the horse?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Does this path look muddy?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What color boots is the woman on the right wearing?"}, {"from": "gpt", "value": "Black"}, {"from": "human", "value": "Is this a city?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color is the ladies shirt?"}, {"from": "gpt", "value": "Brown"}]}, {"id": "000000190601", "image": "coco/train2017/000000190601.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat kind of animal is this?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Dog"}, {"from": "human", "value": "What is the dog doing?"}, {"from": "gpt", "value": "Resting"}, {"from": "human", "value": "What is the pattern to the material the dog is lying on?"}, {"from": "gpt", "value": "Leopard"}]}, {"id": "000000190798", "image": "coco/train2017/000000190798.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the cat drinking out of?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Toilet"}, {"from": "human", "value": "What color is the kitty?"}, {"from": "gpt", "value": "Black"}, {"from": "human", "value": "What color towel is hanging on the right?"}, {"from": "gpt", "value": "Pink"}]}, {"id": "000000191156", "image": "coco/train2017/000000191156.jpg", "conversations": [{"from": "human", "value": "<image>\nIs there a red pepper?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this inside of a bakery?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Can you  see coca cola in the fridge?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What color is the shelf?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "What is the kat in?"}, {"from": "gpt", "value": "Refrigerator"}, {"from": "human", "value": "Which animal is in the photo?"}, {"from": "gpt", "value": "Cat"}]}, {"id": "000000447049", "image": "coco/train2017/000000447049.jpg", "conversations": [{"from": "human", "value": "<image>\nIs this a transportation station?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a passenger train?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this train moving?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color is the train?"}, {"from": "gpt", "value": "Silver"}]}, {"id": "000000258110", "image": "coco/train2017/000000258110.jpg", "conversations": [{"from": "human", "value": "<image>\nIs that a shortboard?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How many surfers are carrying boards?"}, {"from": "gpt", "value": "1"}, {"from": "human", "value": "How tall are the waves?"}, {"from": "gpt", "value": "Small"}, {"from": "human", "value": "Is this a real person?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there people in the water?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is he reading a book?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the bright object on the right?"}, {"from": "gpt", "value": "Sun"}, {"from": "human", "value": "Is the man rinsing off?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is this a giraffe?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is  man leaving the water or going in?"}, {"from": "gpt", "value": "Going in"}, {"from": "human", "value": "Is it evening or day?"}, {"from": "gpt", "value": "Evening"}]}, {"id": "000000062075", "image": "coco/train2017/000000062075.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the table  metal?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the white napkin folded or flat?"}, {"from": "gpt", "value": "Folded"}, {"from": "human", "value": "How many plates are on the table?"}, {"from": "gpt", "value": "2"}, {"from": "human", "value": "Is the beer glass full?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is on the pizza?"}, {"from": "gpt", "value": "Vegetables"}]}, {"id": "000000381758", "image": "coco/train2017/000000381758.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the weather like?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Rainy"}, {"from": "human", "value": "What is the yellow sign?"}, {"from": "gpt", "value": "Unclear"}, {"from": "human", "value": "Is this a busy intersection?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How many buses are there?"}, {"from": "gpt", "value": "2"}, {"from": "human", "value": "What color are the traffic poles?"}, {"from": "gpt", "value": "Black"}]}, {"id": "000000455744", "image": "coco/train2017/000000455744.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the tile set square or on the diagonal?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Diagonal"}, {"from": "human", "value": "Is the floor clean?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What color is the animal?"}, {"from": "gpt", "value": "Black"}]}, {"id": "000000063626", "image": "coco/train2017/000000063626.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is the bus?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "What route is this bus on?"}, {"from": "gpt", "value": "14"}, {"from": "human", "value": "Where is the bike?"}, {"from": "gpt", "value": "Front of bus"}]}, {"id": "000000194722", "image": "coco/train2017/000000194722.jpg", "conversations": [{"from": "human", "value": "<image>\nHow is the weather?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Clear"}, {"from": "human", "value": "Is there a boat in the picture?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the ocean calm?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is he riding on?"}, {"from": "gpt", "value": "Plane"}, {"from": "human", "value": "Why does the water have white spots?"}, {"from": "gpt", "value": "Waves"}, {"from": "human", "value": "Is this plane flying to low to the ground and water?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What iconic structure can be seen in the background?"}, {"from": "gpt", "value": "None"}, {"from": "human", "value": "Is the water calm?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How many birds are in the picture?"}, {"from": "gpt", "value": "0"}]}, {"id": "000000457618", "image": "coco/train2017/000000457618.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is the man's tie?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Burgundy"}, {"from": "human", "value": "Is the man upset?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Does this man have a beard?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000098162", "image": "coco/train2017/000000098162.jpg", "conversations": [{"from": "human", "value": "<image>\nWhere is the pool?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "On ground"}, {"from": "human", "value": "How many women are in the pool?"}, {"from": "gpt", "value": "2"}, {"from": "human", "value": "What does the 13 stand for?"}, {"from": "gpt", "value": "Date"}]}, {"id": "000000578775", "image": "coco/train2017/000000578775.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is on the bench?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Laptop"}, {"from": "human", "value": "What is under the laptop?"}, {"from": "gpt", "value": "Train tracks"}, {"from": "human", "value": "What color is the mouse?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "What color is the floor?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "Are there tiles visible?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000316676", "image": "coco/train2017/000000316676.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat numbers are seen?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "0"}, {"from": "human", "value": "Are there any lights on?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is it cold here?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000458505", "image": "coco/train2017/000000458505.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat number do you see on the sign behind the motorcycle?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "88"}, {"from": "human", "value": "What size are the tires on the motorcycle?"}, {"from": "gpt", "value": "Medium"}, {"from": "human", "value": "What number do you show in the picture?"}, {"from": "gpt", "value": "88"}, {"from": "human", "value": "Would a cautious person wear leather pants to ride this?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the motorcycle parked legally?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000459003", "image": "coco/train2017/000000459003.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat kind of weather is present in the scene?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Snowy"}, {"from": "human", "value": "What is the time in the scene?"}, {"from": "gpt", "value": "12:00"}, {"from": "human", "value": "Are they families?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are this policemen?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the man doing?"}, {"from": "gpt", "value": "Walking"}, {"from": "human", "value": "Is it daytime?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What type of weather is occurring?"}, {"from": "gpt", "value": "Snow"}, {"from": "human", "value": "What is the name of the building in the background?"}, {"from": "gpt", "value": "Helly hansen"}]}, {"id": "000000273119", "image": "coco/train2017/000000273119.jpg", "conversations": [{"from": "human", "value": "<image>\nIs anybody in the boat?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is this a diver?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What happens if the man can't swim?"}, {"from": "gpt", "value": "Drown"}]}, {"id": "000000185830", "image": "coco/train2017/000000185830.jpg", "conversations": [{"from": "human", "value": "<image>\nIs this skier wearing a helmet?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is covering the skiers eyes?"}, {"from": "gpt", "value": "Glasses"}, {"from": "human", "value": "What is on his feet?"}, {"from": "gpt", "value": "Skis"}, {"from": "human", "value": "Is the man alone?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000066828", "image": "coco/train2017/000000066828.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many people are riding on the elephants?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "8"}, {"from": "human", "value": "Are the people getting wet?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there any baby elephants?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000198240", "image": "coco/train2017/000000198240.jpg", "conversations": [{"from": "human", "value": "<image>\nDo the children have drinks?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the baby outside?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the baby eating?"}, {"from": "gpt", "value": "Cake"}, {"from": "human", "value": "What is on these boys faces?"}, {"from": "gpt", "value": "Cake"}, {"from": "human", "value": "Is he using his fork?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000189912", "image": "coco/train2017/000000189912.jpg", "conversations": [{"from": "human", "value": "<image>\nIs that a conveyor belt in front of the people?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this outdoors?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What are the people waiting for?"}, {"from": "gpt", "value": "Luggage"}, {"from": "human", "value": "What color is her blouse?"}, {"from": "gpt", "value": "White"}]}, {"id": "000000329766", "image": "coco/train2017/000000329766.jpg", "conversations": [{"from": "human", "value": "<image>\nWhere are the covered platforms for the passengers?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "On right"}, {"from": "human", "value": "What color is the front of the train?"}, {"from": "gpt", "value": "Yellow"}, {"from": "human", "value": "How many people are waiting on the platform?"}, {"from": "gpt", "value": "1"}, {"from": "human", "value": "What colors is the train?"}, {"from": "gpt", "value": "Gray and yellow"}, {"from": "human", "value": "Is the sign square?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are any train doors open?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the train red?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is this a high-speed train?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Does the train have passengers?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Why are the train track barricades there?"}, {"from": "gpt", "value": "To stop train"}, {"from": "human", "value": "Is it a sunny day?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What numbers are on the train?"}, {"from": "gpt", "value": "624"}, {"from": "human", "value": "How many people are in the picture?"}, {"from": "gpt", "value": "1"}, {"from": "human", "value": "Is the train entering the tunnel?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is it daytime?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What time of day is this?"}, {"from": "gpt", "value": "Morning"}, {"from": "human", "value": "Is there more than one train?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How many telephone poles are on the left hand side?"}, {"from": "gpt", "value": "6"}, {"from": "human", "value": "Where is number 6?"}, {"from": "gpt", "value": "Train"}, {"from": "human", "value": "Is it sunny?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color is the sky?"}, {"from": "gpt", "value": "Gray"}, {"from": "human", "value": "Is this taken outdoors?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the ground made of?"}, {"from": "gpt", "value": "Brick"}, {"from": "human", "value": "How many people are walking on the left?"}, {"from": "gpt", "value": "1"}, {"from": "human", "value": "Is the train still in use?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the train outside?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What color are the benches?"}, {"from": "gpt", "value": "Red"}]}, {"id": "000000198936", "image": "coco/train2017/000000198936.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat animal is here?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Dog"}, {"from": "human", "value": "Which leg is on top?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Does the woman color her hair?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000199619", "image": "coco/train2017/000000199619.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many different fruits can be seen?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "2"}, {"from": "human", "value": "Is it sunny or a little shady?"}, {"from": "gpt", "value": "Sunny"}, {"from": "human", "value": "How many bananas are in the bowl?"}, {"from": "gpt", "value": "3"}]}, {"id": "000000069424", "image": "coco/train2017/000000069424.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the landscape of the picture?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Grassy hill"}, {"from": "human", "value": "What brand typically uses this animal in its advertisements?"}, {"from": "gpt", "value": "Marlboro"}, {"from": "human", "value": "Is the horse walking through a field?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this picture tilted?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color is the horse?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "Does this horse look to be wild?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are the animals roaming free range?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the grass green?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Do these horses have on saddles?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Do you see a fence?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color is the animal's face?"}, {"from": "gpt", "value": "White"}]}, {"id": "000000331824", "image": "coco/train2017/000000331824.jpg", "conversations": [{"from": "human", "value": "<image>\nIs this daytime?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is one of the buildings much taller than the others?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there any people in the photo?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How high is the clock?"}, {"from": "gpt", "value": "1000 feet"}, {"from": "human", "value": "Are there any people in the scene?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What time is it?"}, {"from": "gpt", "value": "5:26"}, {"from": "human", "value": "How many tall buildings are in the background?"}, {"from": "gpt", "value": "3"}, {"from": "human", "value": "Is there a popular, all-in-one-pot dish that this sky might be said to resemble?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is there visible graffiti?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is it likely to rain in the next few minutes?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000069826", "image": "coco/train2017/000000069826.jpg", "conversations": [{"from": "human", "value": "<image>\nIs there toothpaste on the counter?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is on the cup holding the toothbrush?"}, {"from": "gpt", "value": "Skull"}, {"from": "human", "value": "What is plugged into the wall?"}, {"from": "gpt", "value": "Hair dryer"}]}, {"id": "000000463464", "image": "coco/train2017/000000463464.jpg", "conversations": [{"from": "human", "value": "<image>\nAre any of the burners lit?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How many sandwiches are on the grill?"}, {"from": "gpt", "value": "3"}, {"from": "human", "value": "Is the cooktop gas?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the spatula resting on the towel?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What type of grill is being used?"}, {"from": "gpt", "value": "Electric"}, {"from": "human", "value": "What is cooking?"}, {"from": "gpt", "value": "Sandwiches"}, {"from": "human", "value": "What is the person cooking?"}, {"from": "gpt", "value": "Grilled cheese"}]}, {"id": "000000426778", "image": "coco/train2017/000000426778.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the animal sleeping?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color is this cat?"}, {"from": "gpt", "value": "Orange"}, {"from": "human", "value": "Where is the cat?"}, {"from": "gpt", "value": "Sink"}]}, {"id": "000000201706", "image": "coco/train2017/000000201706.jpg", "conversations": [{"from": "human", "value": "<image>\nIs this an antique double Decker bus?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How many red backpacks are there?"}, {"from": "gpt", "value": "6"}, {"from": "human", "value": "What number is the bus?"}, {"from": "gpt", "value": "24"}, {"from": "human", "value": "Is this in America?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the bus number?"}, {"from": "gpt", "value": "24"}, {"from": "human", "value": "Where is the front bus going?"}, {"from": "gpt", "value": "Hampstead"}]}, {"id": "000000464965", "image": "coco/train2017/000000464965.jpg", "conversations": [{"from": "human", "value": "<image>\nWhere is the plate?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No plate"}, {"from": "human", "value": "Is the person happy with his meal?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What food will the man be eating?"}, {"from": "gpt", "value": "Hot dog"}, {"from": "human", "value": "Is this man sitting?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Where is the water bottle?"}, {"from": "gpt", "value": "Table"}]}, {"id": "000000465196", "image": "coco/train2017/000000465196.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat does the gesture the people are making mean?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Posing"}, {"from": "human", "value": "What color is the jacket?"}, {"from": "gpt", "value": "Red"}, {"from": "human", "value": "What is the man carrying in his hands?"}, {"from": "gpt", "value": "Ski poles"}, {"from": "human", "value": "Is the girl skiing?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a child?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is this person wearing a hat?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the woman's hand?"}, {"from": "gpt", "value": "Poles"}, {"from": "human", "value": "Is there a long line of people waiting to ski?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a man or a woman?"}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "Is the skier wearing goggles?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What color pants is the woman wearing?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "How old is the woman in the picture?"}, {"from": "gpt", "value": "35"}, {"from": "human", "value": "What color is the woman's jacket?"}, {"from": "gpt", "value": "Red"}, {"from": "human", "value": "Does the weather look clear?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000465353", "image": "coco/train2017/000000465353.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color are the umbrellas?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Green"}, {"from": "human", "value": "Is the guy in the front shirtless?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What type of vehicle is on the left?"}, {"from": "gpt", "value": "4 wheeler"}]}, {"id": "000000074403", "image": "coco/train2017/000000074403.jpg", "conversations": [{"from": "human", "value": "<image>\nHow would a food critic judge this meal?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Decent"}, {"from": "human", "value": "What color is the plate?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "What kind of vegetable is in the image?"}, {"from": "gpt", "value": "Broccoli"}, {"from": "human", "value": "Does this meal look tasty?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000336752", "image": "coco/train2017/000000336752.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the mouse wireless?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is plugged into the computer on the left?"}, {"from": "gpt", "value": "Keyboard"}, {"from": "human", "value": "About how far is the TV from the keyboard?"}, {"from": "gpt", "value": "3 feet"}, {"from": "human", "value": "What devices are on?"}, {"from": "gpt", "value": "Monitor"}, {"from": "human", "value": "What is the brand of the computer?"}, {"from": "gpt", "value": "Dell"}, {"from": "human", "value": "How many computers are there?"}, {"from": "gpt", "value": "1"}, {"from": "human", "value": "How many monitors are on the desk?"}, {"from": "gpt", "value": "1"}, {"from": "human", "value": "What is the tall object to the left of the TV?"}, {"from": "gpt", "value": "Chair"}, {"from": "human", "value": "What type of computer is this?"}, {"from": "gpt", "value": "Pc"}, {"from": "human", "value": "Is there a calendar?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the desk messy?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color is the mouse?"}, {"from": "gpt", "value": "Black"}]}, {"id": "000000468826", "image": "coco/train2017/000000468826.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat food are the people learning to make?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Cake"}, {"from": "human", "value": "Why are the people sitting at the table?"}, {"from": "gpt", "value": "Eating"}, {"from": "human", "value": "Is this a restaurant?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How many people at table?"}, {"from": "gpt", "value": "12"}, {"from": "human", "value": "What are the people staring at?"}, {"from": "gpt", "value": "Each other"}, {"from": "human", "value": "What color is the top of the tablecloth?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "What is the nationality of the students?"}, {"from": "gpt", "value": "American"}, {"from": "human", "value": "What is the boy squeezing?"}, {"from": "gpt", "value": "Frosting"}, {"from": "human", "value": "How many people are in the picture?"}, {"from": "gpt", "value": "17"}, {"from": "human", "value": "What type of food is on the bottom plate?"}, {"from": "gpt", "value": "Cake"}, {"from": "human", "value": "Are there any children in the restaurant?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How many kids are there at the table?"}, {"from": "gpt", "value": "11"}, {"from": "human", "value": "Are these people all eating out of same box?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is this woman on the left doing with her right hand?"}, {"from": "gpt", "value": "Squeezing lettuce"}, {"from": "human", "value": "What color are the chairs?"}, {"from": "gpt", "value": "Black"}, {"from": "human", "value": "What are they eating?"}, {"from": "gpt", "value": "Cake"}, {"from": "human", "value": "How many people are at the table?"}, {"from": "gpt", "value": "12"}, {"from": "human", "value": "Are the children working on an art project?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000337786", "image": "coco/train2017/000000337786.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the cat eating cat food?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Aside from black, what is the color seen on the grooming brush?"}, {"from": "gpt", "value": "Red"}, {"from": "human", "value": "Is this cat fixated on the grooming brush?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000515062", "image": "coco/train2017/000000515062.jpg", "conversations": [{"from": "human", "value": "<image>\nWould chocolate lover love these?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are these expensive?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is on top of the cupcakes?"}, {"from": "gpt", "value": "Candy"}]}, {"id": "000000427692", "image": "coco/train2017/000000427692.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat time was this picture taken?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "2:30"}, {"from": "human", "value": "Is this a mall?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Does the building have more than one window?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000469988", "image": "coco/train2017/000000469988.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the window covering?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Blinds"}, {"from": "human", "value": "How can you tell it might be close to Christmas?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What team logo is on the baseball cap?"}, {"from": "gpt", "value": "Boston"}, {"from": "human", "value": "What kind of floor is there?"}, {"from": "gpt", "value": "Wood"}, {"from": "human", "value": "How many bags are on the ground?"}, {"from": "gpt", "value": "5"}, {"from": "human", "value": "Is there a trip being planned?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000190241", "image": "coco/train2017/000000190241.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many legs are in the image?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "4"}, {"from": "human", "value": "What pattern does the animal's coat display?"}, {"from": "gpt", "value": "Stripes"}, {"from": "human", "value": "What is the animal standing on?"}, {"from": "gpt", "value": "Ground"}]}, {"id": "000000313007", "image": "coco/train2017/000000313007.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat vehicle is the box designed to represent?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Wheelchair"}, {"from": "human", "value": "What does the sticker say?"}, {"from": "gpt", "value": "Handicap"}, {"from": "human", "value": "What letter is in the blue circle?"}, {"from": "gpt", "value": "None"}, {"from": "human", "value": "Why is the train stopped?"}, {"from": "gpt", "value": "Training"}, {"from": "human", "value": "What is on the train door?"}, {"from": "gpt", "value": "Sign"}, {"from": "human", "value": "Is there anyone sitting?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there any passengers on the train?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What blue sigh is on the train?"}, {"from": "gpt", "value": "Handicap"}, {"from": "human", "value": "What are these doors marked to be used for?"}, {"from": "gpt", "value": "Handicapped"}, {"from": "human", "value": "What does the white sign say?"}, {"from": "gpt", "value": "Training train"}, {"from": "human", "value": "What colors make up the train's doors?"}, {"from": "gpt", "value": "Silver"}]}, {"id": "000000471839", "image": "coco/train2017/000000471839.jpg", "conversations": [{"from": "human", "value": "<image>\nAre there vegetables on the pizza?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What's for lunch?"}, {"from": "gpt", "value": "Pizza"}, {"from": "human", "value": "What kind of food is the white topping?"}, {"from": "gpt", "value": "Cheese"}, {"from": "human", "value": "Is the pizza on a wooden table?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000209745", "image": "coco/train2017/000000209745.jpg", "conversations": [{"from": "human", "value": "<image>\nHow strands of cheese are on the pizza?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "5"}, {"from": "human", "value": "How many glasses are on the table?"}, {"from": "gpt", "value": "2"}, {"from": "human", "value": "Are these thin crust pizzas?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the table made out of?"}, {"from": "gpt", "value": "Wood"}]}, {"id": "000000209933", "image": "coco/train2017/000000209933.jpg", "conversations": [{"from": "human", "value": "<image>\nWhere is the button to flush the toilet?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Side"}, {"from": "human", "value": "What is the main color in this picture?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "How many people can poop at once?"}, {"from": "gpt", "value": "2"}, {"from": "human", "value": "What is the device to the left of the toilette?"}, {"from": "gpt", "value": "Bidet"}, {"from": "human", "value": "Why is there no privacy panel put in place?"}, {"from": "gpt", "value": "1 toilet 1 bene"}]}, {"id": "000000210187", "image": "coco/train2017/000000210187.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is the child's hair?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Blonde"}, {"from": "human", "value": "Is the girl in a restaurant?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is she using a plate?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000341741", "image": "coco/train2017/000000341741.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is the laptop?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "Are the blinds in the back crooked?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What color is the spread?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "Is this a full or twin bed?"}, {"from": "gpt", "value": "Twin"}]}, {"id": "000000164146", "image": "coco/train2017/000000164146.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the bed made?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What room of the house is this?"}, {"from": "gpt", "value": "Bedroom"}, {"from": "human", "value": "What kind of pattern is on the towel?"}, {"from": "gpt", "value": "Stripes"}, {"from": "human", "value": "Is the window open?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000212935", "image": "coco/train2017/000000212935.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat body of water is pictured?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "River"}, {"from": "human", "value": "Do any of the buildings have domes?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Where is the building located next to?"}, {"from": "gpt", "value": "River"}]}, {"id": "000000475316", "image": "coco/train2017/000000475316.jpg", "conversations": [{"from": "human", "value": "<image>\nWhere is the green cup?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "On table"}, {"from": "human", "value": "What color is the table in the background?"}, {"from": "gpt", "value": "Brown"}, {"from": "human", "value": "Is it dark outside?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How many chairs at the table?"}, {"from": "gpt", "value": "4"}]}, {"id": "000000082881", "image": "coco/train2017/000000082881.jpg", "conversations": [{"from": "human", "value": "<image>\nAre the skiers using poles?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How many people are in the scene?"}, {"from": "gpt", "value": "2"}, {"from": "human", "value": "What is the color of the ladies jacket?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "What is covering the ground?"}, {"from": "gpt", "value": "Snow"}]}, {"id": "000000476188", "image": "coco/train2017/000000476188.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat food is on top of the stove?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Turkey"}, {"from": "human", "value": "What does it say on the picture on floor?"}, {"from": "gpt", "value": "Follow your dreams"}, {"from": "human", "value": "What colors the tile floor?"}, {"from": "gpt", "value": "Beige"}]}, {"id": "000000083000", "image": "coco/train2017/000000083000.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat gender is the person in the scene?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Female"}, {"from": "human", "value": "Is this flour or flower?"}, {"from": "gpt", "value": "Flour"}, {"from": "human", "value": "Is she baking bread?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000083079", "image": "coco/train2017/000000083079.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the roadway paved?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What does the red/white/black traffic sign mean?"}, {"from": "gpt", "value": "Cars may enter"}, {"from": "human", "value": "What shape is the sign?"}, {"from": "gpt", "value": "Round"}, {"from": "human", "value": "How many people are visible?"}, {"from": "gpt", "value": "2"}, {"from": "human", "value": "What conflict is mentioned?"}, {"from": "gpt", "value": "None"}]}, {"id": "000000345590", "image": "coco/train2017/000000345590.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many animals do you see?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "2"}, {"from": "human", "value": "Is this a bright and sunny day?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are the animals facing the same direction?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000033332", "image": "coco/train2017/000000033332.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many rolls of Toilet tissue do you see?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "1"}, {"from": "human", "value": "What room is this?"}, {"from": "gpt", "value": "Bathroom"}, {"from": "human", "value": "What is the shape of the mirror?"}, {"from": "gpt", "value": "Oval"}]}, {"id": "000000013988", "image": "coco/train2017/000000013988.jpg", "conversations": [{"from": "human", "value": "<image>\nAre the houses almost covered by trees?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are these horses tame?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Where could a person sit and rest?"}, {"from": "gpt", "value": "Grass"}, {"from": "human", "value": "What structure is in the background?"}, {"from": "gpt", "value": "House"}, {"from": "human", "value": "Is there a road in the forest?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is there a clock?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Do you see an animal in the photo?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is there to sit on in the field?"}, {"from": "gpt", "value": "Grass"}, {"from": "human", "value": "What kind of animal is this?"}, {"from": "gpt", "value": "Horse"}, {"from": "human", "value": "Is there a street in the scene?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is this a city block?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is there something about these animals reminiscent of the psychedelic flavor of the sixties?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How many benches are here?"}, {"from": "gpt", "value": "0"}]}, {"id": "000000215242", "image": "coco/train2017/000000215242.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat kind of room is this?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Bathroom"}, {"from": "human", "value": "Is the window open?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this room near the ground?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000347248", "image": "coco/train2017/000000347248.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color are the containers?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Green"}, {"from": "human", "value": "What is the orange food?"}, {"from": "gpt", "value": "Carrots"}, {"from": "human", "value": "Could this food be Asian?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Do this kitchen appear recently cleaned?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is there cereal in the bowl?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How many carrots are there?"}, {"from": "gpt", "value": "6"}, {"from": "human", "value": "Do all the containers have beans?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What are you going to make?"}, {"from": "gpt", "value": "Dinner"}]}, {"id": "000000216766", "image": "coco/train2017/000000216766.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is in the basket on the bicycle?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Bag"}, {"from": "human", "value": "What kind of birds are those?"}, {"from": "gpt", "value": "Seagulls"}, {"from": "human", "value": "What holds the boards together?"}, {"from": "gpt", "value": "Nails"}, {"from": "human", "value": "What is in the sky?"}, {"from": "gpt", "value": "Birds"}, {"from": "human", "value": "What are flying?"}, {"from": "gpt", "value": "Birds"}, {"from": "human", "value": "Where us the bench?"}, {"from": "gpt", "value": "Beach"}, {"from": "human", "value": "What is parked by the bench?"}, {"from": "gpt", "value": "Bike"}, {"from": "human", "value": "How many birds are in the picture?"}, {"from": "gpt", "value": "4"}, {"from": "human", "value": "How many bikes are in this scene?"}, {"from": "gpt", "value": "1"}, {"from": "human", "value": "What is sitting on the chair?"}, {"from": "gpt", "value": "Person"}, {"from": "human", "value": "What is the person laying on?"}, {"from": "gpt", "value": "Bench"}, {"from": "human", "value": "How many birds are there?"}, {"from": "gpt", "value": "4"}, {"from": "human", "value": "Where is the bench?"}, {"from": "gpt", "value": "Beach"}]}, {"id": "000000218237", "image": "coco/train2017/000000218237.jpg", "conversations": [{"from": "human", "value": "<image>\nAre there Christmas lights?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the man sitting on the couch holding in his hand?"}, {"from": "gpt", "value": "Glass"}, {"from": "human", "value": "Is that a man or a woman?"}, {"from": "gpt", "value": "Man"}, {"from": "human", "value": "What gender is here?"}, {"from": "gpt", "value": "Male"}]}, {"id": "000000167505", "image": "coco/train2017/000000167505.jpg", "conversations": [{"from": "human", "value": "<image>\nDoes it look like it might rain?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the bus at a bus stop?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is being advertised on the side of the bus?"}, {"from": "gpt", "value": "Lancashire united"}, {"from": "human", "value": "What colors is this bus?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "What company does this bus belong to?"}, {"from": "gpt", "value": "Lancashire united"}, {"from": "human", "value": "What color is the bus, besides red?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "What are the weather conditions in this picture?"}, {"from": "gpt", "value": "Partly cloudy"}, {"from": "human", "value": "Is the bus the same color as the sky?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is anyone riding in the second deck of the bus?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How many different colors of vehicles are there?"}, {"from": "gpt", "value": "4"}, {"from": "human", "value": "Is the bus moving?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the bus in service?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What neon colors are painted on the side of the bus?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "Is it night time?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is there a white car in the picture?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What direction is the bus turning?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What word is on the side of the bus?"}, {"from": "gpt", "value": "Lancashire"}, {"from": "human", "value": "How many cars are there?"}, {"from": "gpt", "value": "4"}, {"from": "human", "value": "Which direction is the bus heading?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "What are the two prominent colors on the bus?"}, {"from": "gpt", "value": "Blue red"}, {"from": "human", "value": "Is there a red car in the picture?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Can you see thru the windows of the bus?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are the bus's front lights on?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color is this bus?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "Is this bus in service?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What color is the front bottom of the bus?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "How many buses are there?"}, {"from": "gpt", "value": "1"}, {"from": "human", "value": "What is the blue and green vehicle called?"}, {"from": "gpt", "value": "Bus"}, {"from": "human", "value": "What is the dominant color of the bus?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "How many people are on the bus?"}, {"from": "gpt", "value": "Many"}, {"from": "human", "value": "What color is the bus?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "How many windows does the bus have?"}, {"from": "gpt", "value": "28"}, {"from": "human", "value": "Is this scene over two decades ago?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the bus full or empty?"}, {"from": "gpt", "value": "Full"}, {"from": "human", "value": "Is this bus in transit during daytime hours?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What kind of vehicle is passing?"}, {"from": "gpt", "value": "Bus"}, {"from": "human", "value": "How many cars are there in the photo?"}, {"from": "gpt", "value": "4"}, {"from": "human", "value": "What's the color of the building to the right of the picture?"}, {"from": "gpt", "value": "Tan"}]}, {"id": "000000219204", "image": "coco/train2017/000000219204.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat room is this?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Bathroom"}, {"from": "human", "value": "What's the date on the picture?"}, {"from": "gpt", "value": "02/07/2012"}, {"from": "human", "value": "Which toilet is red?"}, {"from": "gpt", "value": "0"}, {"from": "human", "value": "How many drawers are there?"}, {"from": "gpt", "value": "4"}, {"from": "human", "value": "Are the floor tiles even?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Where is the flush handle?"}, {"from": "gpt", "value": "Top"}]}, {"id": "000000350810", "image": "coco/train2017/000000350810.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat number is the ear touching?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "5"}, {"from": "human", "value": "Is the cat's collar new?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What type of animal is this?"}, {"from": "gpt", "value": "Cat"}]}, {"id": "000000351480", "image": "coco/train2017/000000351480.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the man sad?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color is the man's suit?"}, {"from": "gpt", "value": "Gray"}, {"from": "human", "value": "What type of shoes is the person wearing?"}, {"from": "gpt", "value": "Dress shoes"}, {"from": "human", "value": "Is there more hair on the man's head or face?"}, {"from": "gpt", "value": "Face"}, {"from": "human", "value": "Which primary color is the man *not* wearing?"}, {"from": "gpt", "value": "Red"}, {"from": "human", "value": "Which ear has an earring?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "What has happened to the door?"}, {"from": "gpt", "value": "Paint chipped"}, {"from": "human", "value": "What is behind this gentleman?"}, {"from": "gpt", "value": "Door"}]}, {"id": "000000221696", "image": "coco/train2017/000000221696.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is to the left of the bowl?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Bottle"}, {"from": "human", "value": "What is the small green items?"}, {"from": "gpt", "value": "Broccoli"}, {"from": "human", "value": "What culture is this food from?"}, {"from": "gpt", "value": "China"}]}, {"id": "000000223121", "image": "coco/train2017/000000223121.jpg", "conversations": [{"from": "human", "value": "<image>\nIs there any people in this picture?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is there a fire truck?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the vehicle in the foreground capable of carrying more than five passengers?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the relationship of the truck to the plane?"}, {"from": "gpt", "value": "Perpendicular"}, {"from": "human", "value": "How many tail fins are in this picture?"}, {"from": "gpt", "value": "3"}, {"from": "human", "value": "Are those planes flying?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000092585", "image": "coco/train2017/000000092585.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many birds in the shot?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "8"}, {"from": "human", "value": "How are the waters?"}, {"from": "gpt", "value": "Calm"}, {"from": "human", "value": "Are there any ducks in the water?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000094179", "image": "coco/train2017/000000094179.jpg", "conversations": [{"from": "human", "value": "<image>\nAre they wearing uniforms?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How many people are there?"}, {"from": "gpt", "value": "2"}, {"from": "human", "value": "What brand of socks is the man on the left wearing?"}, {"from": "gpt", "value": "Nike"}]}, {"id": "000000488547", "image": "coco/train2017/000000488547.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich traffic sign is the man on the stairs imitating?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Stairway"}, {"from": "human", "value": "Is the man wearing his baseball cap forwards or backwards?"}, {"from": "gpt", "value": "Forward"}, {"from": "human", "value": "What print is on the mans coat?"}, {"from": "gpt", "value": "Checkered"}]}, {"id": "000000374174", "image": "coco/train2017/000000374174.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat country is this?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "England"}, {"from": "human", "value": "Is the black car being towed?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What color is the car?"}, {"from": "gpt", "value": "Black"}]}, {"id": "000000007567", "image": "coco/train2017/000000007567.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many jets does the plane have?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "2"}, {"from": "human", "value": "What color is the plane`?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "What color is the sky?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "Is this a jet airplane?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000158821", "image": "coco/train2017/000000158821.jpg", "conversations": [{"from": "human", "value": "<image>\nCan you see the tennis player's ankles?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color are the boys shorts?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "What is the color of the ball?"}, {"from": "gpt", "value": "Yellow"}, {"from": "human", "value": "What brand of shirt is the player wearing?"}, {"from": "gpt", "value": "Adidas"}]}, {"id": "000000155505", "image": "coco/train2017/000000155505.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the sky cloudy?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is there a Mercedes on the road?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are the tractors driving themselves?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000359363", "image": "coco/train2017/000000359363.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is she taking out of the oven?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Pizza"}, {"from": "human", "value": "Is it daytime?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is this dog standing on?"}, {"from": "gpt", "value": "Floor"}, {"from": "human", "value": "What food is shown?"}, {"from": "gpt", "value": "Pizza"}, {"from": "human", "value": "Where was this picture taken?"}, {"from": "gpt", "value": "Kitchen"}, {"from": "human", "value": "What appliance is she using?"}, {"from": "gpt", "value": "Oven"}, {"from": "human", "value": "What kind of animal is shown?"}, {"from": "gpt", "value": "Dog"}, {"from": "human", "value": "What room in the house is this?"}, {"from": "gpt", "value": "Kitchen"}, {"from": "human", "value": "Is the dog wearing a harness?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What kind of animal is visible?"}, {"from": "gpt", "value": "Dog"}]}, {"id": "000000228442", "image": "coco/train2017/000000228442.jpg", "conversations": [{"from": "human", "value": "<image>\nIs there a window?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is inside the shower stall?"}, {"from": "gpt", "value": "Stool"}, {"from": "human", "value": "Can you shower here?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000187280", "image": "coco/train2017/000000187280.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the bus moving?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What word is on the information screen on the front of the bus?"}, {"from": "gpt", "value": "Bank"}, {"from": "human", "value": "How many buses are there?"}, {"from": "gpt", "value": "2"}, {"from": "human", "value": "What number is in the reflection?"}, {"from": "gpt", "value": "25"}, {"from": "human", "value": "How many levels does the bus have?"}, {"from": "gpt", "value": "2"}, {"from": "human", "value": "Is this bus in service?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000230152", "image": "coco/train2017/000000230152.jpg", "conversations": [{"from": "human", "value": "<image>\nAre the bananas ripe?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How many types of fruits are there?"}, {"from": "gpt", "value": "3"}, {"from": "human", "value": "What fruit is behind the bananas?"}, {"from": "gpt", "value": "Pear"}, {"from": "human", "value": "What is shown in pairs?"}, {"from": "gpt", "value": "Bananas pears oranges"}]}, {"id": "000000099316", "image": "coco/train2017/000000099316.jpg", "conversations": [{"from": "human", "value": "<image>\nIs it windy?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the picture white and black?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the pattern on the umbrella?"}, {"from": "gpt", "value": "Stripes"}]}, {"id": "000000362067", "image": "coco/train2017/000000362067.jpg", "conversations": [{"from": "human", "value": "<image>\nCan you see trees?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What doe Gibson represent?"}, {"from": "gpt", "value": "Guitars"}, {"from": "human", "value": "Are the trees fully leafed out?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000257162", "image": "coco/train2017/000000257162.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is the truck?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Black"}, {"from": "human", "value": "What is being transported by the truck?"}, {"from": "gpt", "value": "Statues"}, {"from": "human", "value": "What is the phone number on the truck?"}, {"from": "gpt", "value": "9176875593"}, {"from": "human", "value": "What color is the vehicle just entering the scene on the left?"}, {"from": "gpt", "value": "Yellow"}]}, {"id": "000000363829", "image": "coco/train2017/000000363829.jpg", "conversations": [{"from": "human", "value": "<image>\nWhy is there a letter on the racket?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "W"}, {"from": "human", "value": "How many players are there?"}, {"from": "gpt", "value": "1"}, {"from": "human", "value": "What sport is the man participating in?"}, {"from": "gpt", "value": "Tennis"}, {"from": "human", "value": "What color is his outfit?"}, {"from": "gpt", "value": "White"}]}, {"id": "000000497746", "image": "coco/train2017/000000497746.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the building in the background?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "House"}, {"from": "human", "value": "What color is the house?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "Is there a window scene?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is growing here?"}, {"from": "gpt", "value": "Vegetables"}]}, {"id": "000000039064", "image": "coco/train2017/000000039064.jpg", "conversations": [{"from": "human", "value": "<image>\nIs there a hockey puck in the picture?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is all over the ice?"}, {"from": "gpt", "value": "Stuffed animals"}, {"from": "human", "value": "Is Tweety the largest stuffed animal?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000103355", "image": "coco/train2017/000000103355.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many scissors are on the board?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "2"}, {"from": "human", "value": "Why is there a graph under the work mat?"}, {"from": "gpt", "value": "No idea"}, {"from": "human", "value": "What are the black objects on the board?"}, {"from": "gpt", "value": "Scissors"}]}, {"id": "000000365536", "image": "coco/train2017/000000365536.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the pipeline in the back carrying oil?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Can you swim in this water?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color is the roof of the house?"}, {"from": "gpt", "value": "Red"}, {"from": "human", "value": "How many animals are pictured?"}, {"from": "gpt", "value": "1"}, {"from": "human", "value": "Are there puddles in this image?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000365934", "image": "coco/train2017/000000365934.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the woman doing?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Brushing teeth"}, {"from": "human", "value": "What is the woman sitting on?"}, {"from": "gpt", "value": "Bathtub"}, {"from": "human", "value": "Is the woman taking a bath?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000082858", "image": "coco/train2017/000000082858.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many glasses are in the background?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "1"}, {"from": "human", "value": "Does the food look expensive?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there any vegetables on the plate?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How many items on the plate?"}, {"from": "gpt", "value": "2"}, {"from": "human", "value": "Is there broccoli in this meal?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What kind of meat in the middle of this dish?"}, {"from": "gpt", "value": "Beef"}, {"from": "human", "value": "How many eggs are on the plate?"}, {"from": "gpt", "value": "0"}, {"from": "human", "value": "Is that a meat dish?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What shape is the plate?"}, {"from": "gpt", "value": "Oval"}, {"from": "human", "value": "How many items of food are there?"}, {"from": "gpt", "value": "2"}]}, {"id": "000000235987", "image": "coco/train2017/000000235987.jpg", "conversations": [{"from": "human", "value": "<image>\nDoes the woman wear traditional tennis clothing?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Why is the outfit odd?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there buildings behind the woman?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the tennis player returning the ball?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How many tennis rackets is this woman holding?"}, {"from": "gpt", "value": "1"}, {"from": "human", "value": "What color is the court?"}, {"from": "gpt", "value": "Green"}, {"from": "human", "value": "Does the player appear to be in shape?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000369859", "image": "coco/train2017/000000369859.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat sport is happening here?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Skiing"}, {"from": "human", "value": "What color is the coat?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "Is this person a beginner?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000502894", "image": "coco/train2017/000000502894.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the woman holding?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Leash"}, {"from": "human", "value": "What is the dog trying to do?"}, {"from": "gpt", "value": "Smell ground"}, {"from": "human", "value": "What is the animal?"}, {"from": "gpt", "value": "Dog"}]}, {"id": "000000258611", "image": "coco/train2017/000000258611.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the purpose of the red chair?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Sitting"}, {"from": "human", "value": "Is he having a party?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How many posters are shown in the background?"}, {"from": "gpt", "value": "4"}, {"from": "human", "value": "What is the person doing?"}, {"from": "gpt", "value": "Sitting"}, {"from": "human", "value": "What is on the walls?"}, {"from": "gpt", "value": "Pictures"}, {"from": "human", "value": "How many square pillows are shown?"}, {"from": "gpt", "value": "2"}, {"from": "human", "value": "Is the man relaxed?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000241667", "image": "coco/train2017/000000241667.jpg", "conversations": [{"from": "human", "value": "<image>\nIs this a grandfather clock?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the clock up against?"}, {"from": "gpt", "value": "Wall"}, {"from": "human", "value": "What time does the clock read?"}, {"from": "gpt", "value": "12:15"}]}, {"id": "000000372789", "image": "coco/train2017/000000372789.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the toilet still in good condition?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What company is written on the top of the commode?"}, {"from": "gpt", "value": "Unknown"}, {"from": "human", "value": "Does the floor look clean?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Does the bottom of the toilet cover only one flooring tile?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the color of the floor?"}, {"from": "gpt", "value": "Gray"}, {"from": "human", "value": "Is there a toilet brush next to the toilet?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is this toilet indoors?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How many toilets in the picture?"}, {"from": "gpt", "value": "1"}, {"from": "human", "value": "What is the use of this item?"}, {"from": "gpt", "value": "Go to bathroom"}, {"from": "human", "value": "Is the flushing mechanism visible?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Does the bathroom need fixing?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is this usable?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What style of toilet is this?"}, {"from": "gpt", "value": "Standard"}, {"from": "human", "value": "What is missing from the toilet?"}, {"from": "gpt", "value": "Seat"}]}, {"id": "000000241836", "image": "coco/train2017/000000241836.jpg", "conversations": [{"from": "human", "value": "<image>\nIs there a soda next to the food?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is in this sandwich?"}, {"from": "gpt", "value": "Meat and cheese"}, {"from": "human", "value": "What color is the wrapper?"}, {"from": "gpt", "value": "Tan"}, {"from": "human", "value": "How many pieces of sandwich are in the photo?"}, {"from": "gpt", "value": "1"}, {"from": "human", "value": "What else is in the sandwich besides ham?"}, {"from": "gpt", "value": "Cheese"}, {"from": "human", "value": "What is wrapped around the sandwiches?"}, {"from": "gpt", "value": "Paper"}, {"from": "human", "value": "What is in this sandwich?"}, {"from": "gpt", "value": "Ham and cheese"}]}, {"id": "000000111612", "image": "coco/train2017/000000111612.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat are the tall things far in the distance?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Boats"}, {"from": "human", "value": "How to the boys not lose their boards?"}, {"from": "gpt", "value": "Ride it"}, {"from": "human", "value": "Is the man wearing a wetsuit?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the man on the yellow board surfing?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Which surfer has his feet balanced on the surf board?"}, {"from": "gpt", "value": "One in green"}, {"from": "human", "value": "Is the beach deserted?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color is the surfers wetsuit?"}, {"from": "gpt", "value": "Green, blue, white"}, {"from": "human", "value": "How many people are in  the  water?"}, {"from": "gpt", "value": "4"}]}, {"id": "000000084243", "image": "coco/train2017/000000084243.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the cow stuck in a tree?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which animal is this?"}, {"from": "gpt", "value": "Cow"}, {"from": "human", "value": "Are both animals standing?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color is the cows face?"}, {"from": "gpt", "value": "Brown"}, {"from": "human", "value": "Does the cow have horns?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000374520", "image": "coco/train2017/000000374520.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat country is this?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Austria"}, {"from": "human", "value": "Is this an American plane?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What type of plane is this?"}, {"from": "gpt", "value": "Passenger"}, {"from": "human", "value": "Is the plane in motion?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which country's flag is shown on the side of the airplane?"}, {"from": "gpt", "value": "Austria"}, {"from": "human", "value": "Does this plane have flights to Los Angeles?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What airline owns this plane?"}, {"from": "gpt", "value": "Austrian airlines"}, {"from": "human", "value": "Are these planes gearing for takeoff?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What color is the tail of the plane?"}, {"from": "gpt", "value": "Red"}]}, {"id": "000000411969", "image": "coco/train2017/000000411969.jpg", "conversations": [{"from": "human", "value": "<image>\nAre these doughnuts hot?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are the donuts being glazed?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How many doughnuts can you see?"}, {"from": "gpt", "value": "30"}, {"from": "human", "value": "Is the donut machine under human supervision?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000243895", "image": "coco/train2017/000000243895.jpg", "conversations": [{"from": "human", "value": "<image>\nIs this plane going to hit the tower?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is in the foreground of this picture?"}, {"from": "gpt", "value": "Tower"}, {"from": "human", "value": "What company owns this plane?"}, {"from": "gpt", "value": "Lufthansa"}]}, {"id": "000000112959", "image": "coco/train2017/000000112959.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is the little heart button?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Pink"}, {"from": "human", "value": "What is the pattern of the girl's top?"}, {"from": "gpt", "value": "Leopard"}, {"from": "human", "value": "What food is the girl eating?"}, {"from": "gpt", "value": "Pizza"}]}, {"id": "000000507928", "image": "coco/train2017/000000507928.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the rider is sand, gravel or dirt?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Dirt"}, {"from": "human", "value": "Is this a race?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the rider muddy?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000246160", "image": "coco/train2017/000000246160.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the dessert sitting on a plate?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the name of this dish?"}, {"from": "gpt", "value": "Cake"}, {"from": "human", "value": "What is the fruit on top of the desert?"}, {"from": "gpt", "value": "Raspberry"}]}, {"id": "000000103775", "image": "coco/train2017/000000103775.jpg", "conversations": [{"from": "human", "value": "<image>\nAre they watching the boats?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is there water shown?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What are the people drinking?"}, {"from": "gpt", "value": "Water"}]}, {"id": "000000247700", "image": "coco/train2017/000000247700.jpg", "conversations": [{"from": "human", "value": "<image>\nAre the signs located on the street?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What color is the sign?"}, {"from": "gpt", "value": "Red"}, {"from": "human", "value": "Where else would you find streets like this?"}, {"from": "gpt", "value": "China"}, {"from": "human", "value": "What famous song is also the name of a store pictured here?"}, {"from": "gpt", "value": "Tattoo"}, {"from": "human", "value": "Where is this photo taken?"}, {"from": "gpt", "value": "China"}, {"from": "human", "value": "Is this in United States?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What type of characters are printed on the sign?"}, {"from": "gpt", "value": "Chinese"}, {"from": "human", "value": "What does Freeway Entrance mean?"}, {"from": "gpt", "value": "Entering freeway"}]}, {"id": "000000117884", "image": "coco/train2017/000000117884.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is the glaze?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Red"}, {"from": "human", "value": "What color icing is on the donut?"}, {"from": "gpt", "value": "Red"}, {"from": "human", "value": "What do you call the donut topping?"}, {"from": "gpt", "value": "Frosting"}, {"from": "human", "value": "What is the donut on top of?"}, {"from": "gpt", "value": "Napkin"}, {"from": "human", "value": "How many rings is this person holding?"}, {"from": "gpt", "value": "2"}]}, {"id": "000000250380", "image": "coco/train2017/000000250380.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is the woman's hair?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Red"}, {"from": "human", "value": "What color are the flowers in the background?"}, {"from": "gpt", "value": "Pink"}, {"from": "human", "value": "How many women in this photo?"}, {"from": "gpt", "value": "2"}]}, {"id": "000000251360", "image": "coco/train2017/000000251360.jpg", "conversations": [{"from": "human", "value": "<image>\nHow old do you think this cat is?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "5"}, {"from": "human", "value": "What breed of cat is it?"}, {"from": "gpt", "value": "Tabby"}, {"from": "human", "value": "Are the animals pictured related to donkeys?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Does someone own this cat?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000513888", "image": "coco/train2017/000000513888.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the dog's tongue out?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are both dogs feet in the water?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color is the dog's collar?"}, {"from": "gpt", "value": "Red"}]}, {"id": "000000382890", "image": "coco/train2017/000000382890.jpg", "conversations": [{"from": "human", "value": "<image>\nThese buses are named what?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Double decker"}, {"from": "human", "value": "How many buses are there?"}, {"from": "gpt", "value": "2"}, {"from": "human", "value": "What movie is being advertised on the first bus?"}, {"from": "gpt", "value": "007"}]}, {"id": "000000122097", "image": "coco/train2017/000000122097.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the person eating a sandwich with a fork?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is this a corn beef sandwich?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is served with the sandwich?"}, {"from": "gpt", "value": "Cole slaw"}, {"from": "human", "value": "What is in the brown bottle?"}, {"from": "gpt", "value": "Can't tell"}, {"from": "human", "value": "What is the sandwich?"}, {"from": "gpt", "value": "Roast beef"}, {"from": "human", "value": "Is this a healthy meal?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000107975", "image": "coco/train2017/000000107975.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the pizza on?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Tray"}, {"from": "human", "value": "Is the pizza on paper plates?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What are the wavy green strips?"}, {"from": "gpt", "value": "Peppers"}, {"from": "human", "value": "How many slices of pizza?"}, {"from": "gpt", "value": "8"}]}, {"id": "000000254779", "image": "coco/train2017/000000254779.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the toilet being used?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the toilet clean?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is there a level in the picture?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is there a live fish in the image?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000385940", "image": "coco/train2017/000000385940.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is the train?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yellow"}, {"from": "human", "value": "Is the train turning?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What kind of vehicle is this?"}, {"from": "gpt", "value": "Train"}]}, {"id": "000000386640", "image": "coco/train2017/000000386640.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat room is this?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Bathroom"}, {"from": "human", "value": "Where is the light coming from?"}, {"from": "gpt", "value": "Above"}, {"from": "human", "value": "What color is the floor?"}, {"from": "gpt", "value": "Brown"}]}, {"id": "000000387368", "image": "coco/train2017/000000387368.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the woman doing?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Sitting"}, {"from": "human", "value": "How many chairs are in the photo?"}, {"from": "gpt", "value": "2"}, {"from": "human", "value": "Does the couch have any number of pillows on it?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the lamp lit?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What color are the two sofas?"}, {"from": "gpt", "value": "Yellow"}, {"from": "human", "value": "Is there a clock on the wall?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000501565", "image": "coco/train2017/000000501565.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat are the girls playing in?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Party"}, {"from": "human", "value": "How many boys are here?"}, {"from": "gpt", "value": "4"}, {"from": "human", "value": "Does everyone want cake?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is being celebrated?"}, {"from": "gpt", "value": "Birthday"}, {"from": "human", "value": "What colors are the cake frosting?"}, {"from": "gpt", "value": "Pink"}]}, {"id": "000000436073", "image": "coco/train2017/000000436073.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the child wearing a bathrobe?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What room is this?"}, {"from": "gpt", "value": "Bathroom"}, {"from": "human", "value": "What does the boy have in his mouth?"}, {"from": "gpt", "value": "Toothbrush"}, {"from": "human", "value": "What is the little boy having done?"}, {"from": "gpt", "value": "Brushing teeth"}]}, {"id": "000000257951", "image": "coco/train2017/000000257951.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich of these living creatures decided to do this activity today?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Man"}, {"from": "human", "value": "What color is the man's wetsuit?"}, {"from": "gpt", "value": "Black"}, {"from": "human", "value": "Is the dog surfing?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000389159", "image": "coco/train2017/000000389159.jpg", "conversations": [{"from": "human", "value": "<image>\nIs this a normal bus?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color is her scarf?"}, {"from": "gpt", "value": "Pink"}, {"from": "human", "value": "What color are the girl's pants?"}, {"from": "gpt", "value": "Blue"}]}, {"id": "000000520321", "image": "coco/train2017/000000520321.jpg", "conversations": [{"from": "human", "value": "<image>\nIs this China or Japan?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Japan"}, {"from": "human", "value": "What are the painted objects?"}, {"from": "gpt", "value": "Vases"}, {"from": "human", "value": "Are there bonsai trees?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000127296", "image": "coco/train2017/000000127296.jpg", "conversations": [{"from": "human", "value": "<image>\nWhy are the police there?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "To protect and serve"}, {"from": "human", "value": "Are they on a street?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What mode of transportation is the fastest in this picture?"}, {"from": "gpt", "value": "Motorcycle"}, {"from": "human", "value": "Is there more than one person shown?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000389654", "image": "coco/train2017/000000389654.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many slices of pizza are left?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "7"}, {"from": "human", "value": "What color is the plate?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "What type of food is this?"}, {"from": "gpt", "value": "Pizza"}, {"from": "human", "value": "Is the pizza eaten?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the pizza pan all the way on the table?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "000000520769", "image": "coco/train2017/000000520769.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat kind of ball did she throw?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Softball"}, {"from": "human", "value": "What is the sign advertising?"}, {"from": "gpt", "value": "Englewood aluminum"}, {"from": "human", "value": "Are the people standing together or apart from one another?"}, {"from": "gpt", "value": "Apart"}, {"from": "human", "value": "What sport is being played?"}, {"from": "gpt", "value": "Softball"}, {"from": "human", "value": "What color are the socks of the team?"}, {"from": "gpt", "value": "Orange"}, {"from": "human", "value": "What sport is this?"}, {"from": "gpt", "value": "Softball"}]}, {"id": "000000521176", "image": "coco/train2017/000000521176.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the person on a hill?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What color is this person's hat?"}, {"from": "gpt", "value": "Pink"}, {"from": "human", "value": "Is it raining?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000128561", "image": "coco/train2017/000000128561.jpg", "conversations": [{"from": "human", "value": "<image>\nDoes the grass needs some maintenance?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the guy doing?"}, {"from": "gpt", "value": "Playing frisbee"}, {"from": "human", "value": "How many people are in the picture?"}, {"from": "gpt", "value": "4"}, {"from": "human", "value": "Is there a fence?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Why is he running?"}, {"from": "gpt", "value": "To catch frisbee"}, {"from": "human", "value": "Where behind the child has the parent probably told the child not to play?"}, {"from": "gpt", "value": "Water"}, {"from": "human", "value": "How many kids are there?"}, {"from": "gpt", "value": "4"}, {"from": "human", "value": "What is behind the kids?"}, {"from": "gpt", "value": "Lake"}]}, {"id": "000000129071", "image": "coco/train2017/000000129071.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat kind of skiing are they doing?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Downhill"}, {"from": "human", "value": "Is this a rural area?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is on top of the mountains?"}, {"from": "gpt", "value": "Snow"}, {"from": "human", "value": "How many people are in this photo?"}, {"from": "gpt", "value": "3"}, {"from": "human", "value": "What color is the skier on the left's jacket?"}, {"from": "gpt", "value": "Black"}]}, {"id": "000000043383", "image": "coco/train2017/000000043383.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many sheep are in this photo?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "14"}, {"from": "human", "value": "Are there more than 5 animals in this image?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is there a lot of grass in this image?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are the sheep grazing?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this in a natural setting or manmade?"}, {"from": "gpt", "value": "Natural"}]}, {"id": "000000261381", "image": "coco/train2017/000000261381.jpg", "conversations": [{"from": "human", "value": "<image>\nIs it hard to tell the weather precipitation in the black and white photo?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is this foto black and  white?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What type of trees are in the photograph?"}, {"from": "gpt", "value": "Palm"}, {"from": "human", "value": "Is this taken in present day?"}, {"from": "gpt", "value": "No"}]}, {"id": "000000426778", "image": "coco/train2017/000000426778.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is supposed to go here?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Dish"}]}, {"id": "000000088382", "image": "coco/train2017/000000088382.jpg", "conversations": [{"from": "human", "value": "<image>\nAre these herbivorous or carnivorous animals?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Herbivorous"}]}, {"id": "000000468826", "image": "coco/train2017/000000468826.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat material is used to cover the tables?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Cloth"}]}, {"id": "000000451160", "image": "coco/train2017/000000451160.jpg", "conversations": [{"from": "human", "value": "<image>\nAre we united or divided?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "United"}]}, {"id": "000000543201", "image": "coco/train2017/000000543201.jpg", "conversations": [{"from": "human", "value": "<image>\nHow does the thing falling help the plants?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Water them"}]}, {"id": "000000465353", "image": "coco/train2017/000000465353.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat country is this in?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Us"}]}, {"id": "000000264183", "image": "coco/train2017/000000264183.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the yellow item located inside of the glass?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Candle"}]}, {"id": "000000561590", "image": "coco/train2017/000000561590.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat breed of horse is shown?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Mustang"}]}, {"id": "000000099316", "image": "coco/train2017/000000099316.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the name of the design on the umbrella?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Spiral"}]}, {"id": "000000427692", "image": "coco/train2017/000000427692.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat style of architechure is the building?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Spanish"}]}, {"id": "000000268190", "image": "coco/train2017/000000268190.jpg", "conversations": [{"from": "human", "value": "<image>\nWho made those shoes?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Shoemaker"}]}, {"id": "000000221696", "image": "coco/train2017/000000221696.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of protein is in this dish?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Tofu"}]}, {"id": "000000189182", "image": "coco/train2017/000000189182.jpg", "conversations": [{"from": "human", "value": "<image>\nIs this skateboarder doing dangerous stunts or is he safe?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Safe"}]}, {"id": "000000421542", "image": "coco/train2017/000000421542.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat food is being made in this kitchen?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Soup"}]}, {"id": "000000545409", "image": "coco/train2017/000000545409.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat are the black objects depicted used for?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Walk"}]}, {"id": "000000117884", "image": "coco/train2017/000000117884.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many calories are in an average one of these?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "200"}]}, {"id": "000000342294", "image": "coco/train2017/000000342294.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat utensil is this?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Fork"}]}, {"id": "000000083000", "image": "coco/train2017/000000083000.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of nutrition value does the dish the lady is making have?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Carbohydrate"}]}, {"id": "000000411969", "image": "coco/train2017/000000411969.jpg", "conversations": [{"from": "human", "value": "<image>\nHealthy or unhealthy?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Unhealthy"}]}, {"id": "000000133905", "image": "coco/train2017/000000133905.jpg", "conversations": [{"from": "human", "value": "<image>\nWhy are there so many beds?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Sleepover"}]}, {"id": "000000005260", "image": "coco/train2017/000000005260.jpg", "conversations": [{"from": "human", "value": "<image>\nIf the hitter hits the ball so it soars in a high arc it is called a what?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Fly ball"}]}, {"id": "000000458505", "image": "coco/train2017/000000458505.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat brand is this bike?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Harley"}]}, {"id": "000000030805", "image": "coco/train2017/000000030805.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat does this cup look made out of?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Glass"}]}, {"id": "000000241836", "image": "coco/train2017/000000241836.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat meal is this typically eaten for?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Lunch"}]}, {"id": "000000139389", "image": "coco/train2017/000000139389.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of gasoline does this vehicle use?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Unleaded"}]}, {"id": "000000111831", "image": "coco/train2017/000000111831.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat public transit option might these people be waiting for?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Bus"}]}, {"id": "000000437889", "image": "coco/train2017/000000437889.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the weather like outside this window?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Sunny"}]}, {"id": "000000389654", "image": "coco/train2017/000000389654.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat geometric shape is this?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Circle"}]}, {"id": "000000127296", "image": "coco/train2017/000000127296.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat kind of formal wear are the men wearing?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Suit"}]}, {"id": "000000246160", "image": "coco/train2017/000000246160.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat food is this?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Cake"}]}, {"id": "000000069826", "image": "coco/train2017/000000069826.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the toothbrush inside of?\nA. cabinet\nB. flower pot\nC. skull dish\nD. milk crate\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000069826", "image": "coco/train2017/000000069826.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the toothbrush inside of?\nA. flower pot\nB. skull dish\nC. milk crate\nD. cabinet\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000069826", "image": "coco/train2017/000000069826.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the toothbrush inside of?\nA. skull dish\nB. milk crate\nC. cabinet\nD. flower pot\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000069826", "image": "coco/train2017/000000069826.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the toothbrush inside of?\nA. milk crate\nB. cabinet\nC. flower pot\nD. skull dish\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000198936", "image": "coco/train2017/000000198936.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the girl doing?\nA. feeding dog\nB. watching tv\nC. selling dog\nD. stealing dog\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000198936", "image": "coco/train2017/000000198936.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the girl doing?\nA. watching tv\nB. selling dog\nC. stealing dog\nD. feeding dog\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000198936", "image": "coco/train2017/000000198936.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the girl doing?\nA. selling dog\nB. stealing dog\nC. feeding dog\nD. watching tv\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000198936", "image": "coco/train2017/000000198936.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the girl doing?\nA. stealing dog\nB. feeding dog\nC. watching tv\nD. selling dog\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000422170", "image": "coco/train2017/000000422170.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat are the people sitting on?\nA. bleachers\nB. beach\nC. beds\nD. chairs\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000422170", "image": "coco/train2017/000000422170.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat are the people sitting on?\nA. beach\nB. beds\nC. chairs\nD. bleachers\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000422170", "image": "coco/train2017/000000422170.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat are the people sitting on?\nA. beds\nB. chairs\nC. bleachers\nD. beach\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000422170", "image": "coco/train2017/000000422170.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat are the people sitting on?\nA. chairs\nB. bleachers\nC. beach\nD. beds\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000187280", "image": "coco/train2017/000000187280.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is shown on the front of the bus?\nA. destination\nB. warning\nC. owner\nD. speed\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000187280", "image": "coco/train2017/000000187280.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is shown on the front of the bus?\nA. warning\nB. owner\nC. speed\nD. destination\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000187280", "image": "coco/train2017/000000187280.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is shown on the front of the bus?\nA. owner\nB. speed\nC. destination\nD. warning\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000187280", "image": "coco/train2017/000000187280.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is shown on the front of the bus?\nA. speed\nB. destination\nC. warning\nD. owner\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000374520", "image": "coco/train2017/000000374520.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich continent headquarters this airline company?\nA. asia\nB. europe\nC. north america\nD. africa\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000374520", "image": "coco/train2017/000000374520.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich continent headquarters this airline company?\nA. europe\nB. north america\nC. africa\nD. asia\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000374520", "image": "coco/train2017/000000374520.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich continent headquarters this airline company?\nA. north america\nB. africa\nC. asia\nD. europe\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000374520", "image": "coco/train2017/000000374520.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich continent headquarters this airline company?\nA. africa\nB. asia\nC. europe\nD. north america\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000313007", "image": "coco/train2017/000000313007.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat does the blue sign mean?\nA. handicap accessible\nB. caution\nC. stop\nD. go\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000313007", "image": "coco/train2017/000000313007.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat does the blue sign mean?\nA. caution\nB. stop\nC. go\nD. handicap accessible\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000313007", "image": "coco/train2017/000000313007.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat does the blue sign mean?\nA. stop\nB. go\nC. handicap accessible\nD. caution\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000313007", "image": "coco/train2017/000000313007.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat does the blue sign mean?\nA. go\nB. handicap accessible\nC. caution\nD. stop\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000270269", "image": "coco/train2017/000000270269.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat does the bottom red light prohibit?\nA. loitering\nB. crossing\nC. trading\nD. racing\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000270269", "image": "coco/train2017/000000270269.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat does the bottom red light prohibit?\nA. crossing\nB. trading\nC. racing\nD. loitering\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000270269", "image": "coco/train2017/000000270269.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat does the bottom red light prohibit?\nA. trading\nB. racing\nC. loitering\nD. crossing\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000270269", "image": "coco/train2017/000000270269.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat does the bottom red light prohibit?\nA. racing\nB. loitering\nC. crossing\nD. trading\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000515062", "image": "coco/train2017/000000515062.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat person would avoid this food?\nA. diabetic\nB. pescatarian\nC. glutton\nD. vegetarian\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000515062", "image": "coco/train2017/000000515062.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat person would avoid this food?\nA. pescatarian\nB. glutton\nC. vegetarian\nD. diabetic\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000515062", "image": "coco/train2017/000000515062.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat person would avoid this food?\nA. glutton\nB. vegetarian\nC. diabetic\nD. pescatarian\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000515062", "image": "coco/train2017/000000515062.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat person would avoid this food?\nA. vegetarian\nB. diabetic\nC. pescatarian\nD. glutton\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000146841", "image": "coco/train2017/000000146841.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of fruit is shown?\nA. banana\nB. peach\nC. watermelon\nD. strawberry\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000146841", "image": "coco/train2017/000000146841.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of fruit is shown?\nA. peach\nB. watermelon\nC. strawberry\nD. banana\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000146841", "image": "coco/train2017/000000146841.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of fruit is shown?\nA. watermelon\nB. strawberry\nC. banana\nD. peach\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000146841", "image": "coco/train2017/000000146841.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of fruit is shown?\nA. strawberry\nB. banana\nC. peach\nD. watermelon\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000521176", "image": "coco/train2017/000000521176.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is in the metal tin?\nA. water\nB. erasers\nC. paint\nD. snacks\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000521176", "image": "coco/train2017/000000521176.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is in the metal tin?\nA. erasers\nB. paint\nC. snacks\nD. water\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000521176", "image": "coco/train2017/000000521176.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is in the metal tin?\nA. paint\nB. snacks\nC. water\nD. erasers\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000521176", "image": "coco/train2017/000000521176.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is in the metal tin?\nA. snacks\nB. water\nC. erasers\nD. paint\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000224916", "image": "coco/train2017/000000224916.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of bird is the one on the far left?\nA. toucan\nB. cockatiel\nC. parrot\nD. dove\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000224916", "image": "coco/train2017/000000224916.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of bird is the one on the far left?\nA. cockatiel\nB. parrot\nC. dove\nD. toucan\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000224916", "image": "coco/train2017/000000224916.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of bird is the one on the far left?\nA. parrot\nB. dove\nC. toucan\nD. cockatiel\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000224916", "image": "coco/train2017/000000224916.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of bird is the one on the far left?\nA. dove\nB. toucan\nC. cockatiel\nD. parrot\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000502894", "image": "coco/train2017/000000502894.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is a basket on a bicycle called?\nA. storage\nB. carrier\nC. compartment\nD. bicycle basket\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000502894", "image": "coco/train2017/000000502894.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is a basket on a bicycle called?\nA. carrier\nB. compartment\nC. bicycle basket\nD. storage\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000502894", "image": "coco/train2017/000000502894.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is a basket on a bicycle called?\nA. compartment\nB. bicycle basket\nC. storage\nD. carrier\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000502894", "image": "coco/train2017/000000502894.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is a basket on a bicycle called?\nA. bicycle basket\nB. storage\nC. carrier\nD. compartment\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000198240", "image": "coco/train2017/000000198240.jpg", "conversations": [{"from": "human", "value": "<image>\nWhy is this person so messy?\nA. is misbehaving\nB. bad manners\nC. baby\nD. is blind\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000198240", "image": "coco/train2017/000000198240.jpg", "conversations": [{"from": "human", "value": "<image>\nWhy is this person so messy?\nA. bad manners\nB. baby\nC. is blind\nD. is misbehaving\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000198240", "image": "coco/train2017/000000198240.jpg", "conversations": [{"from": "human", "value": "<image>\nWhy is this person so messy?\nA. baby\nB. is blind\nC. is misbehaving\nD. bad manners\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000198240", "image": "coco/train2017/000000198240.jpg", "conversations": [{"from": "human", "value": "<image>\nWhy is this person so messy?\nA. is blind\nB. is misbehaving\nC. bad manners\nD. baby\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000111612", "image": "coco/train2017/000000111612.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich rider is catching the wave the best?\nA. boogie boarder\nB. skim boarder\nC. kite surfer\nD. surfer\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000111612", "image": "coco/train2017/000000111612.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich rider is catching the wave the best?\nA. skim boarder\nB. kite surfer\nC. surfer\nD. boogie boarder\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000111612", "image": "coco/train2017/000000111612.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich rider is catching the wave the best?\nA. kite surfer\nB. surfer\nC. boogie boarder\nD. skim boarder\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000111612", "image": "coco/train2017/000000111612.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich rider is catching the wave the best?\nA. surfer\nB. boogie boarder\nC. skim boarder\nD. kite surfer\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000459003", "image": "coco/train2017/000000459003.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the composition of the falling material?\nA. stone\nB. brick\nC. cloth\nD. water\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000459003", "image": "coco/train2017/000000459003.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the composition of the falling material?\nA. brick\nB. cloth\nC. water\nD. stone\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000459003", "image": "coco/train2017/000000459003.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the composition of the falling material?\nA. cloth\nB. water\nC. stone\nD. brick\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000459003", "image": "coco/train2017/000000459003.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the composition of the falling material?\nA. water\nB. stone\nC. brick\nD. cloth\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000399759", "image": "coco/train2017/000000399759.jpg", "conversations": [{"from": "human", "value": "<image>\nWhy is the woman holding the hot dog in her hand?\nA. to cook\nB. to sell\nC. to eat\nD. to throw\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000399759", "image": "coco/train2017/000000399759.jpg", "conversations": [{"from": "human", "value": "<image>\nWhy is the woman holding the hot dog in her hand?\nA. to sell\nB. to eat\nC. to throw\nD. to cook\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000399759", "image": "coco/train2017/000000399759.jpg", "conversations": [{"from": "human", "value": "<image>\nWhy is the woman holding the hot dog in her hand?\nA. to eat\nB. to throw\nC. to cook\nD. to sell\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000399759", "image": "coco/train2017/000000399759.jpg", "conversations": [{"from": "human", "value": "<image>\nWhy is the woman holding the hot dog in her hand?\nA. to throw\nB. to cook\nC. to sell\nD. to eat\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000250380", "image": "coco/train2017/000000250380.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the animal doing?\nA. eating\nB. being trained\nC. attacking\nD. fleeing\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000250380", "image": "coco/train2017/000000250380.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the animal doing?\nA. being trained\nB. attacking\nC. fleeing\nD. eating\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000250380", "image": "coco/train2017/000000250380.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the animal doing?\nA. attacking\nB. fleeing\nC. eating\nD. being trained\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000250380", "image": "coco/train2017/000000250380.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the animal doing?\nA. fleeing\nB. eating\nC. being trained\nD. attacking\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000389159", "image": "coco/train2017/000000389159.jpg", "conversations": [{"from": "human", "value": "<image>\nThis bus is decorated as what?\nA. greenhouse\nB. school\nC. weeding venue\nD. wedding\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000389159", "image": "coco/train2017/000000389159.jpg", "conversations": [{"from": "human", "value": "<image>\nThis bus is decorated as what?\nA. school\nB. weeding venue\nC. wedding\nD. greenhouse\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000389159", "image": "coco/train2017/000000389159.jpg", "conversations": [{"from": "human", "value": "<image>\nThis bus is decorated as what?\nA. weeding venue\nB. wedding\nC. greenhouse\nD. school\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000389159", "image": "coco/train2017/000000389159.jpg", "conversations": [{"from": "human", "value": "<image>\nThis bus is decorated as what?\nA. wedding\nB. greenhouse\nC. school\nD. weeding venue\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000011713", "image": "coco/train2017/000000011713.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the area marked in blue used for?\nA. laying\nB. wrestling\nC. sitting\nD. jumping\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000011713", "image": "coco/train2017/000000011713.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the area marked in blue used for?\nA. wrestling\nB. sitting\nC. jumping\nD. laying\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000011713", "image": "coco/train2017/000000011713.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the area marked in blue used for?\nA. sitting\nB. jumping\nC. laying\nD. wrestling\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000011713", "image": "coco/train2017/000000011713.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the area marked in blue used for?\nA. jumping\nB. laying\nC. wrestling\nD. sitting\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000011065", "image": "coco/train2017/000000011065.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of animals are present?\nA. dog\nB. elephant\nC. deer\nD. horse\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000011065", "image": "coco/train2017/000000011065.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of animals are present?\nA. elephant\nB. deer\nC. horse\nD. dog\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000011065", "image": "coco/train2017/000000011065.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of animals are present?\nA. deer\nB. horse\nC. dog\nD. elephant\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000011065", "image": "coco/train2017/000000011065.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of animals are present?\nA. horse\nB. dog\nC. elephant\nD. deer\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000360673", "image": "coco/train2017/000000360673.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is this country?\nA. india\nB. united states\nC. china\nD. italy\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000360673", "image": "coco/train2017/000000360673.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is this country?\nA. united states\nB. china\nC. italy\nD. india\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000360673", "image": "coco/train2017/000000360673.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is this country?\nA. china\nB. italy\nC. india\nD. united states\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000360673", "image": "coco/train2017/000000360673.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is this country?\nA. italy\nB. india\nC. united states\nD. china\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000540763", "image": "coco/train2017/000000540763.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat decorates the wall?\nA. hummer\nB. monster truck\nC. sun\nD. tank\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000540763", "image": "coco/train2017/000000540763.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat decorates the wall?\nA. monster truck\nB. sun\nC. tank\nD. hummer\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000540763", "image": "coco/train2017/000000540763.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat decorates the wall?\nA. sun\nB. tank\nC. hummer\nD. monster truck\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000540763", "image": "coco/train2017/000000540763.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat decorates the wall?\nA. tank\nB. hummer\nC. monster truck\nD. sun\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000420859", "image": "coco/train2017/000000420859.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat will happen to this mans feet if he doesn't stop?\nA. nothing\nB. get wet\nC. twist\nD. burn\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000420859", "image": "coco/train2017/000000420859.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat will happen to this mans feet if he doesn't stop?\nA. get wet\nB. twist\nC. burn\nD. nothing\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000420859", "image": "coco/train2017/000000420859.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat will happen to this mans feet if he doesn't stop?\nA. twist\nB. burn\nC. nothing\nD. get wet\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000420859", "image": "coco/train2017/000000420859.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat will happen to this mans feet if he doesn't stop?\nA. burn\nB. nothing\nC. get wet\nD. twist\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000386165", "image": "coco/train2017/000000386165.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the purpose of the power cube on the back of the wheelchair?\nA. storage\nB. for aesthetics\nC. for weight\nD. move it\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000386165", "image": "coco/train2017/000000386165.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the purpose of the power cube on the back of the wheelchair?\nA. for aesthetics\nB. for weight\nC. move it\nD. storage\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000386165", "image": "coco/train2017/000000386165.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the purpose of the power cube on the back of the wheelchair?\nA. for weight\nB. move it\nC. storage\nD. for aesthetics\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000386165", "image": "coco/train2017/000000386165.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the purpose of the power cube on the back of the wheelchair?\nA. move it\nB. storage\nC. for aesthetics\nD. for weight\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000094179", "image": "coco/train2017/000000094179.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat do the men's uniforms typically represent?\nA. sports\nB. school\nC. graduation\nD. work\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000094179", "image": "coco/train2017/000000094179.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat do the men's uniforms typically represent?\nA. school\nB. graduation\nC. work\nD. sports\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000094179", "image": "coco/train2017/000000094179.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat do the men's uniforms typically represent?\nA. graduation\nB. work\nC. sports\nD. school\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000094179", "image": "coco/train2017/000000094179.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat do the men's uniforms typically represent?\nA. work\nB. sports\nC. school\nD. graduation\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000403389", "image": "coco/train2017/000000403389.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat has caused the food on the plate to look shiny?\nA. air\nB. sauce\nC. glare\nD. soda\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000403389", "image": "coco/train2017/000000403389.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat has caused the food on the plate to look shiny?\nA. sauce\nB. glare\nC. soda\nD. air\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000403389", "image": "coco/train2017/000000403389.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat has caused the food on the plate to look shiny?\nA. glare\nB. soda\nC. air\nD. sauce\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000403389", "image": "coco/train2017/000000403389.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat has caused the food on the plate to look shiny?\nA. soda\nB. air\nC. sauce\nD. glare\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000127296", "image": "coco/train2017/000000127296.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the man closest to the motorcycle?\nA. cop\nB. wrestler\nC. fireman\nD. shop owner\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000127296", "image": "coco/train2017/000000127296.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the man closest to the motorcycle?\nA. wrestler\nB. fireman\nC. shop owner\nD. cop\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000127296", "image": "coco/train2017/000000127296.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the man closest to the motorcycle?\nA. fireman\nB. shop owner\nC. cop\nD. wrestler\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000127296", "image": "coco/train2017/000000127296.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the man closest to the motorcycle?\nA. shop owner\nB. cop\nC. wrestler\nD. fireman\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000451008", "image": "coco/train2017/000000451008.jpg", "conversations": [{"from": "human", "value": "<image>\nWhy is the man spreading a substance on his surf board?\nA. sun protection\nB. bug repellent\nC. grip\nD. water protection\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000451008", "image": "coco/train2017/000000451008.jpg", "conversations": [{"from": "human", "value": "<image>\nWhy is the man spreading a substance on his surf board?\nA. bug repellent\nB. grip\nC. water protection\nD. sun protection\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000451008", "image": "coco/train2017/000000451008.jpg", "conversations": [{"from": "human", "value": "<image>\nWhy is the man spreading a substance on his surf board?\nA. grip\nB. water protection\nC. sun protection\nD. bug repellent\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000451008", "image": "coco/train2017/000000451008.jpg", "conversations": [{"from": "human", "value": "<image>\nWhy is the man spreading a substance on his surf board?\nA. water protection\nB. sun protection\nC. bug repellent\nD. grip\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000066828", "image": "coco/train2017/000000066828.jpg", "conversations": [{"from": "human", "value": "<image>\nWhy are the people riding the elephants?\nA. to perform\nB. circus act\nC. to race\nD. cross river\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000066828", "image": "coco/train2017/000000066828.jpg", "conversations": [{"from": "human", "value": "<image>\nWhy are the people riding the elephants?\nA. circus act\nB. to race\nC. cross river\nD. to perform\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000066828", "image": "coco/train2017/000000066828.jpg", "conversations": [{"from": "human", "value": "<image>\nWhy are the people riding the elephants?\nA. to race\nB. cross river\nC. to perform\nD. circus act\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000066828", "image": "coco/train2017/000000066828.jpg", "conversations": [{"from": "human", "value": "<image>\nWhy are the people riding the elephants?\nA. cross river\nB. to perform\nC. circus act\nD. to race\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000392991", "image": "coco/train2017/000000392991.jpg", "conversations": [{"from": "human", "value": "<image>\nAnother is being added to the cake?\nA. fork\nB. spoon\nC. frosting\nD. layer\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000392991", "image": "coco/train2017/000000392991.jpg", "conversations": [{"from": "human", "value": "<image>\nAnother is being added to the cake?\nA. spoon\nB. frosting\nC. layer\nD. fork\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000392991", "image": "coco/train2017/000000392991.jpg", "conversations": [{"from": "human", "value": "<image>\nAnother is being added to the cake?\nA. frosting\nB. layer\nC. fork\nD. spoon\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000392991", "image": "coco/train2017/000000392991.jpg", "conversations": [{"from": "human", "value": "<image>\nAnother is being added to the cake?\nA. layer\nB. fork\nC. spoon\nD. frosting\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000260695", "image": "coco/train2017/000000260695.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat sort of game is played here?\nA. trivia\nB. baseball\nC. monopoly\nD. tennis\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000260695", "image": "coco/train2017/000000260695.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat sort of game is played here?\nA. baseball\nB. monopoly\nC. tennis\nD. trivia\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000260695", "image": "coco/train2017/000000260695.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat sort of game is played here?\nA. monopoly\nB. tennis\nC. trivia\nD. baseball\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000260695", "image": "coco/train2017/000000260695.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat sort of game is played here?\nA. tennis\nB. trivia\nC. baseball\nD. monopoly\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000193936", "image": "coco/train2017/000000193936.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of group does this seem to be?\nA. criminals\nB. wizards\nC. athletes\nD. classmates\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000193936", "image": "coco/train2017/000000193936.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of group does this seem to be?\nA. wizards\nB. athletes\nC. classmates\nD. criminals\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000193936", "image": "coco/train2017/000000193936.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of group does this seem to be?\nA. athletes\nB. classmates\nC. criminals\nD. wizards\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000193936", "image": "coco/train2017/000000193936.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of group does this seem to be?\nA. classmates\nB. criminals\nC. wizards\nD. athletes\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000170235", "image": "coco/train2017/000000170235.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat will the standing player do next?\nA. sit\nB. squat\nC. run\nD. hide\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000170235", "image": "coco/train2017/000000170235.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat will the standing player do next?\nA. squat\nB. run\nC. hide\nD. sit\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000170235", "image": "coco/train2017/000000170235.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat will the standing player do next?\nA. run\nB. hide\nC. sit\nD. squat\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000170235", "image": "coco/train2017/000000170235.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat will the standing player do next?\nA. hide\nB. sit\nC. squat\nD. run\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000356708", "image": "coco/train2017/000000356708.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich skier is teaching here?\nA. both\nB. none\nC. tallest\nD. shortest\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000356708", "image": "coco/train2017/000000356708.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich skier is teaching here?\nA. none\nB. tallest\nC. shortest\nD. both\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000356708", "image": "coco/train2017/000000356708.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich skier is teaching here?\nA. tallest\nB. shortest\nC. both\nD. none\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000356708", "image": "coco/train2017/000000356708.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich skier is teaching here?\nA. shortest\nB. both\nC. none\nD. tallest\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000281230", "image": "coco/train2017/000000281230.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many people are kiteboarding in this photo?\nA. two\nB. four\nC. one\nD. three\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000281230", "image": "coco/train2017/000000281230.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many people are kiteboarding in this photo?\nA. four\nB. one\nC. three\nD. two\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000281230", "image": "coco/train2017/000000281230.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many people are kiteboarding in this photo?\nA. one\nB. three\nC. two\nD. four\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000281230", "image": "coco/train2017/000000281230.jpg", "conversations": [{"from": "human", "value": "<image>\nHow many people are kiteboarding in this photo?\nA. three\nB. two\nC. four\nD. one\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000296303", "image": "coco/train2017/000000296303.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat kind of animal do you see in the picture?\nA. insect\nB. fish\nC. mammal\nD. reptile\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000296303", "image": "coco/train2017/000000296303.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat kind of animal do you see in the picture?\nA. fish\nB. mammal\nC. reptile\nD. insect\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000296303", "image": "coco/train2017/000000296303.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat kind of animal do you see in the picture?\nA. mammal\nB. reptile\nC. insect\nD. fish\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000296303", "image": "coco/train2017/000000296303.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat kind of animal do you see in the picture?\nA. reptile\nB. insect\nC. fish\nD. mammal\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000139389", "image": "coco/train2017/000000139389.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat matches the color of the car?\nA. cow\nB. sky\nC. chicken\nD. mud\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000139389", "image": "coco/train2017/000000139389.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat matches the color of the car?\nA. sky\nB. chicken\nC. mud\nD. cow\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000139389", "image": "coco/train2017/000000139389.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat matches the color of the car?\nA. chicken\nB. mud\nC. cow\nD. sky\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000139389", "image": "coco/train2017/000000139389.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat matches the color of the car?\nA. mud\nB. cow\nC. sky\nD. chicken\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000465353", "image": "coco/train2017/000000465353.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the terrain near the parking lot?\nA. beach\nB. urban center\nC. mountainous\nD. deep valley\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000465353", "image": "coco/train2017/000000465353.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the terrain near the parking lot?\nA. urban center\nB. mountainous\nC. deep valley\nD. beach\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000465353", "image": "coco/train2017/000000465353.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the terrain near the parking lot?\nA. mountainous\nB. deep valley\nC. beach\nD. urban center\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000465353", "image": "coco/train2017/000000465353.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the terrain near the parking lot?\nA. deep valley\nB. beach\nC. urban center\nD. mountainous\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000335539", "image": "coco/train2017/000000335539.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat style of lamp is the one above the table?\nA. retro style\nB. candle style\nC. chandelier\nD. tiffany style\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}, {"from": "human", "value": "What shape is the black tiles on the floor?\nA. triangle\nB. oval\nC. square\nD. diamond"}, {"from": "gpt", "value": "D"}]}, {"id": "000000335539", "image": "coco/train2017/000000335539.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat style of lamp is the one above the table?\nA. candle style\nB. chandelier\nC. tiffany style\nD. retro style\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}, {"from": "human", "value": "What shape is the black tiles on the floor?\nA. oval\nB. square\nC. diamond\nD. triangle"}, {"from": "gpt", "value": "C"}]}, {"id": "000000335539", "image": "coco/train2017/000000335539.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat style of lamp is the one above the table?\nA. chandelier\nB. tiffany style\nC. retro style\nD. candle style\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}, {"from": "human", "value": "What shape is the black tiles on the floor?\nA. square\nB. diamond\nC. triangle\nD. oval"}, {"from": "gpt", "value": "B"}]}, {"id": "000000335539", "image": "coco/train2017/000000335539.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat style of lamp is the one above the table?\nA. tiffany style\nB. retro style\nC. candle style\nD. chandelier\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}, {"from": "human", "value": "What shape is the black tiles on the floor?\nA. diamond\nB. triangle\nC. oval\nD. square"}, {"from": "gpt", "value": "A"}]}, {"id": "000000505243", "image": "coco/train2017/000000505243.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of television set is set up next to the clock on the chair?\nA. smart tv\nB. digital\nC. analog\nD. lcd\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000505243", "image": "coco/train2017/000000505243.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of television set is set up next to the clock on the chair?\nA. digital\nB. analog\nC. lcd\nD. smart tv\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000505243", "image": "coco/train2017/000000505243.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of television set is set up next to the clock on the chair?\nA. analog\nB. lcd\nC. smart tv\nD. digital\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000505243", "image": "coco/train2017/000000505243.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of television set is set up next to the clock on the chair?\nA. lcd\nB. smart tv\nC. digital\nD. analog\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000092585", "image": "coco/train2017/000000092585.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat movie is related to the word on the boat?\nA. lobster\nB. die hard\nC. cats\nD. small soldiers\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000092585", "image": "coco/train2017/000000092585.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat movie is related to the word on the boat?\nA. die hard\nB. cats\nC. small soldiers\nD. lobster\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000092585", "image": "coco/train2017/000000092585.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat movie is related to the word on the boat?\nA. cats\nB. small soldiers\nC. lobster\nD. die hard\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000092585", "image": "coco/train2017/000000092585.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat movie is related to the word on the boat?\nA. small soldiers\nB. lobster\nC. die hard\nD. cats\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000550532", "image": "coco/train2017/000000550532.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich meter has the higher number on it?\nA. leftmost\nB. rightmost\nC. center\nD. third one\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}, {"from": "human", "value": "Which meter has the higher number on it?\nA. right\nB. center\nC. fifth one\nD. left"}, {"from": "gpt", "value": "D"}]}, {"id": "000000550532", "image": "coco/train2017/000000550532.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich meter has the higher number on it?\nA. rightmost\nB. center\nC. third one\nD. leftmost\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}, {"from": "human", "value": "Which meter has the higher number on it?\nA. center\nB. fifth one\nC. left\nD. right"}, {"from": "gpt", "value": "C"}]}, {"id": "000000550532", "image": "coco/train2017/000000550532.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich meter has the higher number on it?\nA. center\nB. third one\nC. leftmost\nD. rightmost\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}, {"from": "human", "value": "Which meter has the higher number on it?\nA. fifth one\nB. left\nC. right\nD. center"}, {"from": "gpt", "value": "B"}]}, {"id": "000000550532", "image": "coco/train2017/000000550532.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich meter has the higher number on it?\nA. third one\nB. leftmost\nC. rightmost\nD. center\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}, {"from": "human", "value": "Which meter has the higher number on it?\nA. left\nB. right\nC. center\nD. fifth one"}, {"from": "gpt", "value": "A"}]}, {"id": "000000223121", "image": "coco/train2017/000000223121.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat country is the most likely destination for this airport?\nA. united kingdom\nB. australia\nC. united states\nD. china\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "D"}]}, {"id": "000000223121", "image": "coco/train2017/000000223121.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat country is the most likely destination for this airport?\nA. australia\nB. united states\nC. china\nD. united kingdom\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "C"}]}, {"id": "000000223121", "image": "coco/train2017/000000223121.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat country is the most likely destination for this airport?\nA. united states\nB. china\nC. united kingdom\nD. australia\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "B"}]}, {"id": "000000223121", "image": "coco/train2017/000000223121.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat country is the most likely destination for this airport?\nA. china\nB. united kingdom\nC. australia\nD. united states\nAnswer with the option's letter from the given choices directly."}, {"from": "gpt", "value": "A"}]}, {"id": "000000246160", "image": "coco/train2017/000000246160.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.83, 0.32, 1.0, 0.74]."}, {"from": "gpt", "value": "White treat mostly cut off."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: cake with raspberry."}, {"from": "gpt", "value": "[0.16, 0.32, 0.71, 0.78]"}, {"from": "human", "value": "Please provide a short description for this region: [0.83, 0.32, 1.0, 0.74]."}, {"from": "gpt", "value": "Cake really hidden."}, {"from": "human", "value": "Please provide a short description for this region: [0.16, 0.32, 0.71, 0.78]."}, {"from": "gpt", "value": "Raspberry."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.1, 0.3, 0.49]."}, {"from": "gpt", "value": "Chocolate pastry."}, {"from": "human", "value": "Please provide a short description for this region: [0.46, 0.16, 0.98, 0.48]."}, {"from": "gpt", "value": "White cake in back."}, {"from": "human", "value": "Please provide a short description for this region: [0.46, 0.16, 0.98, 0.48]."}, {"from": "gpt", "value": "White cake with yellow."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: dessert."}, {"from": "gpt", "value": "[0.16, 0.32, 0.71, 0.78]"}, {"from": "human", "value": "Please provide a short description for this region: [0.16, 0.32, 0.71, 0.78]."}, {"from": "gpt", "value": "Strawberry cake."}]}, {"id": "000000246160", "image": "coco/train2017/000000246160.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.46, 0.16, 0.98, 0.48]."}, {"from": "gpt", "value": "White cake with yellow blurry."}, {"from": "human", "value": "Please provide a short description for this region: [0.83, 0.32, 1.0, 0.74]."}, {"from": "gpt", "value": "White cookie that is cut off in the front."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.1, 0.3, 0.49]."}, {"from": "gpt", "value": "Chocolate cake."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white thing just above purple lower right corner."}, {"from": "gpt", "value": "[0.83, 0.32, 1.0, 0.74]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: upper right looks lemon flavored."}, {"from": "gpt", "value": "[0.46, 0.16, 0.98, 0.48]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.1, 0.3, 0.49]."}, {"from": "gpt", "value": "Chocolate cake."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white food behind pink one."}, {"from": "gpt", "value": "[0.46, 0.16, 0.98, 0.48]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.1, 0.3, 0.49]."}, {"from": "gpt", "value": "Back left choc tart."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a dessert with raspberry mousse , pink icing and a raspberry on top."}, {"from": "gpt", "value": "[0.16, 0.32, 0.71, 0.78]"}]}, {"id": "000000246160", "image": "coco/train2017/000000246160.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a danish cookie with frosting and a raspberry on top."}, {"from": "gpt", "value": "[0.16, 0.32, 0.71, 0.78]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: rasberry."}, {"from": "gpt", "value": "[0.16, 0.32, 0.71, 0.78]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: cake."}, {"from": "gpt", "value": "[0.16, 0.32, 0.71, 0.78]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white cake nearly out of frame."}, {"from": "gpt", "value": "[0.83, 0.32, 1.0, 0.74]"}, {"from": "human", "value": "Please provide a short description for this region: [0.46, 0.16, 0.98, 0.48]."}, {"from": "gpt", "value": "White cake in back."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.1, 0.3, 0.49]."}, {"from": "gpt", "value": "Chocolate left rear."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.1, 0.3, 0.49]."}, {"from": "gpt", "value": "Chocolate cake."}, {"from": "human", "value": "Please provide a short description for this region: [0.83, 0.32, 1.0, 0.74]."}, {"from": "gpt", "value": "White dessert on the right side."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: chocolate icing."}, {"from": "gpt", "value": "[0.0, 0.1, 0.3, 0.49]"}]}, {"id": "000000276739", "image": "coco/train2017/000000276739.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: headlight."}, {"from": "gpt", "value": "[0.19, 0.24, 0.48, 0.8]"}, {"from": "human", "value": "Please provide a short description for this region: [0.19, 0.24, 0.48, 0.8]."}, {"from": "gpt", "value": "Front bike."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bike in the front."}, {"from": "gpt", "value": "[0.19, 0.24, 0.48, 0.8]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: close bike."}, {"from": "gpt", "value": "[0.19, 0.24, 0.48, 0.8]"}, {"from": "human", "value": "Please provide a short description for this region: [0.19, 0.24, 0.48, 0.8]."}, {"from": "gpt", "value": "Bike closest to you."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bike nearest us."}, {"from": "gpt", "value": "[0.19, 0.24, 0.48, 0.8]"}]}, {"id": "000000170235", "image": "coco/train2017/000000170235.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a baseball umpire."}, {"from": "gpt", "value": "[0.43, 0.61, 0.61, 0.83]"}, {"from": "human", "value": "Please provide a short description for this region: [0.39, 0.31, 0.61, 0.66]."}, {"from": "gpt", "value": "Hey batter."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a baseball player batting."}, {"from": "gpt", "value": "[0.39, 0.31, 0.61, 0.66]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: batter."}, {"from": "gpt", "value": "[0.39, 0.31, 0.61, 0.66]"}, {"from": "human", "value": "Please provide a short description for this region: [0.39, 0.31, 0.61, 0.66]."}, {"from": "gpt", "value": "Batter."}, {"from": "human", "value": "Please provide a short description for this region: [0.39, 0.31, 0.61, 0.66]."}, {"from": "gpt", "value": "Batter."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: batter."}, {"from": "gpt", "value": "[0.39, 0.31, 0.61, 0.66]"}, {"from": "human", "value": "Please provide a short description for this region: [0.39, 0.31, 0.61, 0.66]."}, {"from": "gpt", "value": "Batter."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: player with bat."}, {"from": "gpt", "value": "[0.39, 0.31, 0.61, 0.66]"}, {"from": "human", "value": "Please provide a short description for this region: [0.43, 0.61, 0.61, 0.83]."}, {"from": "gpt", "value": "Umpire crouching during a pitch."}]}, {"id": "000000422170", "image": "coco/train2017/000000422170.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.7, 0.17, 1.0, 0.68]."}, {"from": "gpt", "value": "Man sitting."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: lady."}, {"from": "gpt", "value": "[0.08, 0.48, 0.44, 0.88]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bottom lady."}, {"from": "gpt", "value": "[0.08, 0.48, 0.44, 0.88]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.08, 0.22, 0.63]."}, {"from": "gpt", "value": "Man walking."}, {"from": "human", "value": "Please provide a short description for this region: [0.7, 0.17, 1.0, 0.68]."}, {"from": "gpt", "value": "Right guy with cap."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.08, 0.22, 0.63]."}, {"from": "gpt", "value": "Left guy."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man sitting."}, {"from": "gpt", "value": "[0.7, 0.17, 1.0, 0.68]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: girl sitting."}, {"from": "gpt", "value": "[0.08, 0.48, 0.44, 0.88]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man in baseball hat right side."}, {"from": "gpt", "value": "[0.7, 0.17, 1.0, 0.68]"}]}, {"id": "000000422170", "image": "coco/train2017/000000422170.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.08, 0.48, 0.44, 0.88]."}, {"from": "gpt", "value": "Woman."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.08, 0.22, 0.63]."}, {"from": "gpt", "value": "Guy in black hoodie."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.08, 0.22, 0.63]."}, {"from": "gpt", "value": "Brown hoodie."}, {"from": "human", "value": "Please provide a short description for this region: [0.08, 0.48, 0.44, 0.88]."}, {"from": "gpt", "value": "Purple scarf."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: brown hood standing man."}, {"from": "gpt", "value": "[0.0, 0.08, 0.22, 0.63]"}, {"from": "human", "value": "Please provide a short description for this region: [0.08, 0.48, 0.44, 0.88]."}, {"from": "gpt", "value": "Girl on phone."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.08, 0.22, 0.63]."}, {"from": "gpt", "value": "Person with brown hood."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man at right."}, {"from": "gpt", "value": "[0.7, 0.17, 1.0, 0.68]"}, {"from": "human", "value": "Please provide a short description for this region: [0.7, 0.17, 1.0, 0.68]."}, {"from": "gpt", "value": "Man wearing dark baseball cap and looking at kid in hoodie."}]}, {"id": "000000422100", "image": "coco/train2017/000000422100.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.76, 0.17, 0.92, 0.61]."}, {"from": "gpt", "value": "Second person in on the right of the photo."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man in front on skateboard leaning."}, {"from": "gpt", "value": "[0.21, 0.21, 0.68, 0.67]"}, {"from": "human", "value": "Please provide a short description for this region: [0.76, 0.17, 0.92, 0.61]."}, {"from": "gpt", "value": "Man on right in black shirt."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: dark gray shirt."}, {"from": "gpt", "value": "[0.76, 0.17, 0.92, 0.61]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: right blk shirt."}, {"from": "gpt", "value": "[0.76, 0.17, 0.92, 0.61]"}, {"from": "human", "value": "Please provide a short description for this region: [0.21, 0.21, 0.68, 0.67]."}, {"from": "gpt", "value": "Front skater writing on shirt."}, {"from": "human", "value": "Please provide a short description for this region: [0.21, 0.21, 0.68, 0.67]."}, {"from": "gpt", "value": "Guy about to drop in."}, {"from": "human", "value": "Please provide a short description for this region: [0.8, 0.17, 1.0, 0.66]."}, {"from": "gpt", "value": "Gray shirt closest to edge."}]}, {"id": "000000422100", "image": "coco/train2017/000000422100.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: dark gray shirt and gray pants on ledge."}, {"from": "gpt", "value": "[0.76, 0.17, 0.92, 0.61]"}, {"from": "human", "value": "Please provide a short description for this region: [0.76, 0.17, 0.92, 0.61]."}, {"from": "gpt", "value": "Person on skateboard with white pants."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: gray shirt standing front."}, {"from": "gpt", "value": "[0.8, 0.17, 1.0, 0.66]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man."}, {"from": "gpt", "value": "[0.21, 0.21, 0.68, 0.67]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: guy standing gray cutoff in corner."}, {"from": "gpt", "value": "[0.8, 0.17, 1.0, 0.66]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: guy about to faceplant."}, {"from": "gpt", "value": "[0.21, 0.21, 0.68, 0.67]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: coming down."}, {"from": "gpt", "value": "[0.21, 0.21, 0.68, 0.67]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white shirt right."}, {"from": "gpt", "value": "[0.8, 0.17, 1.0, 0.66]"}]}, {"id": "000000139571", "image": "coco/train2017/000000139571.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: man on left only see half of him."}, {"from": "gpt", "value": "[0.0, 0.24, 0.1, 0.79]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: partial guy on extreme right."}, {"from": "gpt", "value": "[0.91, 0.18, 1.0, 0.85]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: clapping man with hands at chest."}, {"from": "gpt", "value": "[0.24, 0.21, 0.45, 0.68]"}, {"from": "human", "value": "Please provide a short description for this region: [0.56, 0.16, 0.94, 0.78]."}, {"from": "gpt", "value": "Second man from right."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: one cutting cake."}, {"from": "gpt", "value": "[0.56, 0.16, 0.94, 0.78]"}, {"from": "human", "value": "Please provide a short description for this region: [0.08, 0.23, 0.26, 0.72]."}, {"from": "gpt", "value": "Second person on left."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: guy close to green mark on cake."}, {"from": "gpt", "value": "[0.24, 0.21, 0.45, 0.68]"}, {"from": "human", "value": "Please provide a short description for this region: [0.91, 0.18, 1.0, 0.85]."}, {"from": "gpt", "value": "Man on far right partial."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: half of a face."}, {"from": "gpt", "value": "[0.91, 0.18, 1.0, 0.85]"}, {"from": "human", "value": "Please provide a short description for this region: [0.08, 0.23, 0.26, 0.72]."}, {"from": "gpt", "value": "Sailor clapping 2 from the old man fully visible."}]}, {"id": "000000139571", "image": "coco/train2017/000000139571.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.24, 0.21, 0.45, 0.68]."}, {"from": "gpt", "value": "Man with watch and teeth."}, {"from": "human", "value": "Please provide a short description for this region: [0.44, 0.16, 0.7, 0.68]."}, {"from": "gpt", "value": "White man."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: older guy."}, {"from": "gpt", "value": "[0.44, 0.16, 0.7, 0.68]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.24, 0.1, 0.79]."}, {"from": "gpt", "value": "Man clapping you can only see half his body."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man cut of at 9pm."}, {"from": "gpt", "value": "[0.0, 0.24, 0.1, 0.79]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: half a head shown."}, {"from": "gpt", "value": "[0.91, 0.18, 1.0, 0.85]"}, {"from": "human", "value": "Please provide a short description for this region: [0.08, 0.23, 0.26, 0.72]."}, {"from": "gpt", "value": "Second man from left."}, {"from": "human", "value": "Please provide a short description for this region: [0.08, 0.23, 0.26, 0.72]."}, {"from": "gpt", "value": "Man with circle above square chest tags."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: indian man to the right that is pointing to the cake and wearing a watch."}, {"from": "gpt", "value": "[0.56, 0.16, 0.94, 0.78]"}, {"from": "human", "value": "Please provide a short description for this region: [0.44, 0.16, 0.7, 0.68]."}, {"from": "gpt", "value": "Guy with stache."}]}, {"id": "000000139571", "image": "coco/train2017/000000139571.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: the black man cutting the cake."}, {"from": "gpt", "value": "[0.56, 0.16, 0.94, 0.78]"}, {"from": "human", "value": "Please provide a short description for this region: [0.24, 0.21, 0.45, 0.68]."}, {"from": "gpt", "value": "Third from left next to white guy."}, {"from": "human", "value": "Please provide a short description for this region: [0.56, 0.16, 0.94, 0.78]."}, {"from": "gpt", "value": "Dark man cutting cake."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: left guy out of view."}, {"from": "gpt", "value": "[0.0, 0.24, 0.1, 0.79]"}, {"from": "human", "value": "Please provide a short description for this region: [0.44, 0.16, 0.7, 0.68]."}, {"from": "gpt", "value": "Bald guy at cake."}, {"from": "human", "value": "Please provide a short description for this region: [0.44, 0.16, 0.7, 0.68]."}, {"from": "gpt", "value": "White moustache man."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: cutting the cake."}, {"from": "gpt", "value": "[0.56, 0.16, 0.94, 0.78]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.24, 0.1, 0.79]."}, {"from": "gpt", "value": "Left most person half out of pic."}, {"from": "human", "value": "Please provide a short description for this region: [0.44, 0.16, 0.7, 0.68]."}, {"from": "gpt", "value": "Older man."}, {"from": "human", "value": "Please provide a short description for this region: [0.24, 0.21, 0.45, 0.68]."}, {"from": "gpt", "value": "Clapper left of baldy."}]}, {"id": "000000545538", "image": "coco/train2017/000000545538.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.28, 0.38, 0.51, 0.68]."}, {"from": "gpt", "value": "Gray hair lady white shirt behind arm of other person."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: pointing woman."}, {"from": "gpt", "value": "[0.0, 0.26, 0.45, 0.83]"}, {"from": "human", "value": "Please provide a short description for this region: [0.28, 0.38, 0.51, 0.68]."}, {"from": "gpt", "value": "Gray hair blocked by blondes hand."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.26, 0.45, 0.83]."}, {"from": "gpt", "value": "Lady pointing."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: guy in hat."}, {"from": "gpt", "value": "[0.4, 0.33, 0.93, 0.82]"}, {"from": "human", "value": "Please provide a short description for this region: [0.28, 0.38, 0.51, 0.68]."}, {"from": "gpt", "value": "Lady with gray hair."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the woman with gray hair."}, {"from": "gpt", "value": "[0.28, 0.38, 0.51, 0.68]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.26, 0.45, 0.83]."}, {"from": "gpt", "value": "Women in white pointing with black strap across her chest."}]}, {"id": "000000545538", "image": "coco/train2017/000000545538.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.28, 0.38, 0.51, 0.68]."}, {"from": "gpt", "value": "Gray haired woman."}, {"from": "human", "value": "Please provide a short description for this region: [0.4, 0.33, 0.93, 0.82]."}, {"from": "gpt", "value": "Wearing hat."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: woman on left pointing."}, {"from": "gpt", "value": "[0.0, 0.26, 0.45, 0.83]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.26, 0.45, 0.83]."}, {"from": "gpt", "value": "Woman nearest in white shirt."}, {"from": "human", "value": "Please provide a short description for this region: [0.4, 0.33, 0.93, 0.82]."}, {"from": "gpt", "value": "Guy on right with hat."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: person close to center gray hair."}, {"from": "gpt", "value": "[0.28, 0.38, 0.51, 0.68]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man with hat."}, {"from": "gpt", "value": "[0.4, 0.33, 0.93, 0.82]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the person with the hat."}, {"from": "gpt", "value": "[0.4, 0.33, 0.93, 0.82]"}]}, {"id": "000000545538", "image": "coco/train2017/000000545538.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: hat."}, {"from": "gpt", "value": "[0.4, 0.33, 0.93, 0.82]"}]}, {"id": "000000082881", "image": "coco/train2017/000000082881.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.19, 0.39, 0.4, 0.84]."}, {"from": "gpt", "value": "A girl in red ski pants."}, {"from": "human", "value": "Please provide a short description for this region: [0.19, 0.39, 0.4, 0.84]."}, {"from": "gpt", "value": "A woman in a white coat skiing."}]}, {"id": "000000389159", "image": "coco/train2017/000000389159.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.27, 0.47, 0.49, 0.94]."}, {"from": "gpt", "value": "Man in white shirt."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bunch flower by pole holding onto."}, {"from": "gpt", "value": "[0.18, 0.56, 0.39, 0.95]"}, {"from": "human", "value": "Please provide a short description for this region: [0.49, 0.28, 0.7, 0.93]."}, {"from": "gpt", "value": "Jacket color of night."}, {"from": "human", "value": "Please provide a short description for this region: [0.03, 0.21, 0.33, 0.49]."}, {"from": "gpt", "value": "Leafy plant directly above hand on bar to left."}, {"from": "human", "value": "Please provide a short description for this region: [0.23, 0.05, 0.75, 0.29]."}, {"from": "gpt", "value": "Hanging plant over girl."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the greenery with the pink flowers in front of the man in jeans looking down."}, {"from": "gpt", "value": "[0.18, 0.56, 0.39, 0.95]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: flower bush in front."}, {"from": "gpt", "value": "[0.18, 0.56, 0.39, 0.95]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: woman pink scarf."}, {"from": "gpt", "value": "[0.49, 0.28, 0.7, 0.93]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: front sitting guy no glasses."}, {"from": "gpt", "value": "[0.27, 0.47, 0.49, 0.94]"}]}, {"id": "000000389159", "image": "coco/train2017/000000389159.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: the plants above the womans head."}, {"from": "gpt", "value": "[0.23, 0.05, 0.75, 0.29]"}, {"from": "human", "value": "Please provide a short description for this region: [0.18, 0.56, 0.39, 0.95]."}, {"from": "gpt", "value": "Front green bottom flower."}, {"from": "human", "value": "Please provide a short description for this region: [0.23, 0.13, 0.45, 0.5]."}, {"from": "gpt", "value": "Click above black guys head."}, {"from": "human", "value": "Please provide a short description for this region: [0.23, 0.13, 0.45, 0.5]."}, {"from": "gpt", "value": "Pole on above guy holding his phone."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: buzzcut guy."}, {"from": "gpt", "value": "[0.27, 0.47, 0.49, 0.94]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: plant directly above heads of two seated guys."}, {"from": "gpt", "value": "[0.23, 0.13, 0.45, 0.5]"}, {"from": "human", "value": "Please provide a short description for this region: [0.23, 0.13, 0.45, 0.5]."}, {"from": "gpt", "value": "Tree above black haired man."}, {"from": "human", "value": "Please provide a short description for this region: [0.65, 0.13, 0.82, 0.54]."}, {"from": "gpt", "value": "Greenery to the top right of girl but not above her."}, {"from": "human", "value": "Please provide a short description for this region: [0.27, 0.47, 0.49, 0.94]."}, {"from": "gpt", "value": "Man seated blue pants."}]}, {"id": "000000389159", "image": "coco/train2017/000000389159.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: plantsflowers just in front of buzz cut blue jeans guy."}, {"from": "gpt", "value": "[0.18, 0.56, 0.39, 0.95]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: greens at top of image."}, {"from": "gpt", "value": "[0.23, 0.05, 0.75, 0.29]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: plants above her."}, {"from": "gpt", "value": "[0.23, 0.05, 0.75, 0.29]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: woman standing."}, {"from": "gpt", "value": "[0.49, 0.28, 0.7, 0.93]"}, {"from": "human", "value": "Please provide a short description for this region: [0.27, 0.47, 0.49, 0.94]."}, {"from": "gpt", "value": "White man sitting."}, {"from": "human", "value": "Please provide a short description for this region: [0.03, 0.21, 0.33, 0.49]."}, {"from": "gpt", "value": "Plant leaft anover and to the left of the white guy."}, {"from": "human", "value": "Please provide a short description for this region: [0.49, 0.28, 0.7, 0.93]."}, {"from": "gpt", "value": "Center woman."}, {"from": "human", "value": "Please provide a short description for this region: [0.65, 0.13, 0.82, 0.54]."}, {"from": "gpt", "value": "Plants to right of woman."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: person in white on left."}, {"from": "gpt", "value": "[0.27, 0.47, 0.49, 0.94]"}]}, {"id": "000000389159", "image": "coco/train2017/000000389159.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.03, 0.21, 0.33, 0.49]."}, {"from": "gpt", "value": "The plant with the huge leafs above a guy sitting with his legs spread."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: green space above the heads of 2 seated men."}, {"from": "gpt", "value": "[0.23, 0.13, 0.45, 0.5]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: woman."}, {"from": "gpt", "value": "[0.49, 0.28, 0.7, 0.93]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: tree above woman."}, {"from": "gpt", "value": "[0.23, 0.05, 0.75, 0.29]"}, {"from": "human", "value": "Please provide a short description for this region: [0.03, 0.21, 0.33, 0.49]."}, {"from": "gpt", "value": "Bunch of leaves right above the hand on the pole."}, {"from": "human", "value": "Please provide a short description for this region: [0.18, 0.56, 0.39, 0.95]."}, {"from": "gpt", "value": "Green by guy in gray."}, {"from": "human", "value": "Please provide a short description for this region: [0.23, 0.05, 0.75, 0.29]."}, {"from": "gpt", "value": "Plant above the girls head."}, {"from": "human", "value": "Please provide a short description for this region: [0.65, 0.13, 0.82, 0.54]."}, {"from": "gpt", "value": "The plant area right of womans shoulder."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: big light leaves at 9 touching vertical hand rail."}, {"from": "gpt", "value": "[0.03, 0.21, 0.33, 0.49]"}]}, {"id": "000000389159", "image": "coco/train2017/000000389159.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: light yellow green leaves behind man with black hair."}, {"from": "gpt", "value": "[0.23, 0.13, 0.45, 0.5]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the girl."}, {"from": "gpt", "value": "[0.49, 0.28, 0.7, 0.93]"}]}, {"id": "000000160573", "image": "coco/train2017/000000160573.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: girl holding chocolate don."}, {"from": "gpt", "value": "[0.4, 0.18, 0.83, 0.76]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: hot brunette."}, {"from": "gpt", "value": "[0.0, 0.22, 0.69, 0.86]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.22, 0.69, 0.86]."}, {"from": "gpt", "value": "Girl left."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: caucasian girl."}, {"from": "gpt", "value": "[0.0, 0.22, 0.69, 0.86]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: far away man turned."}, {"from": "gpt", "value": "[0.82, 0.21, 1.0, 0.59]"}, {"from": "human", "value": "Please provide a short description for this region: [0.82, 0.21, 1.0, 0.59]."}, {"from": "gpt", "value": "Sorry guy sitting in the back to the right."}, {"from": "human", "value": "Please provide a short description for this region: [0.82, 0.21, 1.0, 0.59]."}, {"from": "gpt", "value": "Person with back to us."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.22, 0.69, 0.86]."}, {"from": "gpt", "value": "A woman in a grey shirt holding up a caramel colored donut."}]}, {"id": "000000160573", "image": "coco/train2017/000000160573.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.82, 0.21, 1.0, 0.59]."}, {"from": "gpt", "value": "Man on the stool on the right."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a woman holding a chocolate doughnut."}, {"from": "gpt", "value": "[0.4, 0.18, 0.83, 0.76]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the man with a jacket sitting on the stool."}, {"from": "gpt", "value": "[0.82, 0.21, 1.0, 0.59]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.22, 0.69, 0.86]."}, {"from": "gpt", "value": "Girl on left."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.22, 0.69, 0.86]."}, {"from": "gpt", "value": "First front chick."}, {"from": "human", "value": "Please provide a short description for this region: [0.82, 0.21, 1.0, 0.59]."}, {"from": "gpt", "value": "Person sitting at window."}, {"from": "human", "value": "Please provide a short description for this region: [0.82, 0.21, 1.0, 0.59]."}, {"from": "gpt", "value": "Man sitting on stool on right with back turned."}, {"from": "human", "value": "Please provide a short description for this region: [0.31, 0.72, 0.94, 0.87]."}, {"from": "gpt", "value": "A white table."}]}, {"id": "000000160573", "image": "coco/train2017/000000160573.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.4, 0.18, 0.83, 0.76]."}, {"from": "gpt", "value": "Lady in hat."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the table the women with donuts are sitting at."}, {"from": "gpt", "value": "[0.31, 0.72, 0.94, 0.87]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: woman closest holding donut."}, {"from": "gpt", "value": "[0.0, 0.22, 0.69, 0.86]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: woman with chocolate donut."}, {"from": "gpt", "value": "[0.4, 0.18, 0.83, 0.76]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the woman without the hat."}, {"from": "gpt", "value": "[0.0, 0.22, 0.69, 0.86]"}, {"from": "human", "value": "Please provide a short description for this region: [0.4, 0.18, 0.83, 0.76]."}, {"from": "gpt", "value": "Person holding darker donut."}, {"from": "human", "value": "Please provide a short description for this region: [0.4, 0.18, 0.83, 0.76]."}, {"from": "gpt", "value": "Woman in hat."}, {"from": "human", "value": "Please provide a short description for this region: [0.82, 0.21, 1.0, 0.59]."}, {"from": "gpt", "value": "A man with a black suit."}]}, {"id": "000000417230", "image": "coco/train2017/000000417230.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a horse blocking another horse walking on the beach with a police officer riding it."}, {"from": "gpt", "value": "[0.09, 0.56, 1.0, 0.83]"}, {"from": "human", "value": "Please provide a short description for this region: [0.57, 0.32, 0.82, 0.82]."}, {"from": "gpt", "value": "Not looking at us."}, {"from": "human", "value": "Please provide a short description for this region: [0.38, 0.34, 0.56, 0.67]."}, {"from": "gpt", "value": "A mounted police officer wearing sunglasses."}, {"from": "human", "value": "Please provide a short description for this region: [0.38, 0.34, 0.56, 0.67]."}, {"from": "gpt", "value": "Cop facing u."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man on left."}, {"from": "gpt", "value": "[0.38, 0.34, 0.56, 0.67]"}, {"from": "human", "value": "Please provide a short description for this region: [0.57, 0.32, 0.82, 0.82]."}, {"from": "gpt", "value": "Guy on right."}, {"from": "human", "value": "Please provide a short description for this region: [0.57, 0.32, 0.82, 0.82]."}, {"from": "gpt", "value": "Man closest to us."}, {"from": "human", "value": "Please provide a short description for this region: [0.38, 0.34, 0.56, 0.67]."}, {"from": "gpt", "value": "Left policeman."}]}, {"id": "000000417230", "image": "coco/train2017/000000417230.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.38, 0.34, 0.56, 0.67]."}, {"from": "gpt", "value": "Left guy."}, {"from": "human", "value": "Please provide a short description for this region: [0.57, 0.32, 0.82, 0.82]."}, {"from": "gpt", "value": "Guy closest to us."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the officer facing the camera."}, {"from": "gpt", "value": "[0.38, 0.34, 0.56, 0.67]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man with shades."}, {"from": "gpt", "value": "[0.38, 0.34, 0.56, 0.67]"}, {"from": "human", "value": "Please provide a short description for this region: [0.57, 0.32, 0.82, 0.82]."}, {"from": "gpt", "value": "The man is laughing with open mouth."}, {"from": "human", "value": "Please provide a short description for this region: [0.57, 0.32, 0.82, 0.82]."}, {"from": "gpt", "value": "Officer on right."}, {"from": "human", "value": "Please provide a short description for this region: [0.57, 0.32, 0.82, 0.82]."}, {"from": "gpt", "value": "Officer on right."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: fartherest man."}, {"from": "gpt", "value": "[0.38, 0.34, 0.56, 0.67]"}]}, {"id": "000000209933", "image": "coco/train2017/000000209933.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a white toilet with no seat on top."}, {"from": "gpt", "value": "[0.24, 0.28, 0.53, 0.67]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the toilet."}, {"from": "gpt", "value": "[0.56, 0.17, 1.0, 0.83]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a white toilet sets with the seat down and the top up."}, {"from": "gpt", "value": "[0.56, 0.17, 1.0, 0.83]"}, {"from": "human", "value": "Please provide a short description for this region: [0.24, 0.28, 0.53, 0.67]."}, {"from": "gpt", "value": "Toilet no rim no top."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: no lid toilet."}, {"from": "gpt", "value": "[0.24, 0.28, 0.53, 0.67]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bidet on left."}, {"from": "gpt", "value": "[0.24, 0.28, 0.53, 0.67]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: right toilet."}, {"from": "gpt", "value": "[0.56, 0.17, 1.0, 0.83]"}, {"from": "human", "value": "Please provide a short description for this region: [0.56, 0.17, 1.0, 0.83]."}, {"from": "gpt", "value": "Toilet."}]}, {"id": "000000209933", "image": "coco/train2017/000000209933.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: toilet with lid."}, {"from": "gpt", "value": "[0.56, 0.17, 1.0, 0.83]"}, {"from": "human", "value": "Please provide a short description for this region: [0.56, 0.17, 1.0, 0.83]."}, {"from": "gpt", "value": "Right toil."}, {"from": "human", "value": "Please provide a short description for this region: [0.56, 0.17, 1.0, 0.83]."}, {"from": "gpt", "value": "Toilet."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bidet next to toilet."}, {"from": "gpt", "value": "[0.24, 0.28, 0.53, 0.67]"}, {"from": "human", "value": "Please provide a short description for this region: [0.24, 0.28, 0.53, 0.67]."}, {"from": "gpt", "value": "Left toilet."}, {"from": "human", "value": "Please provide a short description for this region: [0.24, 0.28, 0.53, 0.67]."}, {"from": "gpt", "value": "Weird toilet."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a bidet in a bathroom next to a toilet."}, {"from": "gpt", "value": "[0.24, 0.28, 0.53, 0.67]"}, {"from": "human", "value": "Please provide a short description for this region: [0.56, 0.17, 1.0, 0.83]."}, {"from": "gpt", "value": "A toilet with it ' s lid up."}]}, {"id": "000000436073", "image": "coco/train2017/000000436073.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: hand with spoon."}, {"from": "gpt", "value": "[0.83, 0.53, 1.0, 0.86]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: hand holding the toothbrush."}, {"from": "gpt", "value": "[0.83, 0.53, 1.0, 0.86]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: child."}, {"from": "gpt", "value": "[0.28, 0.18, 0.89, 0.85]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the hand brushing the child ' s teeth."}, {"from": "gpt", "value": "[0.83, 0.53, 1.0, 0.86]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: hand."}, {"from": "gpt", "value": "[0.83, 0.53, 1.0, 0.86]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: hand holding toothbrush."}, {"from": "gpt", "value": "[0.83, 0.53, 1.0, 0.86]"}, {"from": "human", "value": "Please provide a short description for this region: [0.28, 0.18, 0.89, 0.85]."}, {"from": "gpt", "value": "The little child."}]}, {"id": "000000436073", "image": "coco/train2017/000000436073.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: hand."}, {"from": "gpt", "value": "[0.83, 0.53, 1.0, 0.86]"}, {"from": "human", "value": "Please provide a short description for this region: [0.28, 0.18, 0.89, 0.85]."}, {"from": "gpt", "value": "Kid."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: toddler."}, {"from": "gpt", "value": "[0.28, 0.18, 0.89, 0.85]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: child."}, {"from": "gpt", "value": "[0.28, 0.18, 0.89, 0.85]"}, {"from": "human", "value": "Please provide a short description for this region: [0.83, 0.53, 1.0, 0.86]."}, {"from": "gpt", "value": "Hand."}, {"from": "human", "value": "Please provide a short description for this region: [0.28, 0.18, 0.89, 0.85]."}, {"from": "gpt", "value": "Child."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: adult hand."}, {"from": "gpt", "value": "[0.83, 0.53, 1.0, 0.86]"}]}, {"id": "000000501565", "image": "coco/train2017/000000501565.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.61, 0.23, 1.0, 0.74]."}, {"from": "gpt", "value": "Arm cutting cake."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.23, 0.21, 0.73]."}, {"from": "gpt", "value": "Taller girl."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: front the hand."}, {"from": "gpt", "value": "[0.61, 0.23, 1.0, 0.74]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.23, 0.21, 0.73]."}, {"from": "gpt", "value": "Girl far left."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: kid holding plate."}, {"from": "gpt", "value": "[0.19, 0.41, 0.43, 0.69]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: little girl standing."}, {"from": "gpt", "value": "[0.0, 0.23, 0.21, 0.73]"}, {"from": "human", "value": "Please provide a short description for this region: [0.61, 0.23, 1.0, 0.74]."}, {"from": "gpt", "value": "Person cutting the cake in the red shirt."}, {"from": "human", "value": "Please provide a short description for this region: [0.61, 0.23, 1.0, 0.74]."}, {"from": "gpt", "value": "Person on right arm."}, {"from": "human", "value": "Please provide a short description for this region: [0.19, 0.41, 0.43, 0.69]."}, {"from": "gpt", "value": "First small kid from the left in the red crown and black shirt."}]}, {"id": "000000501565", "image": "coco/train2017/000000501565.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: left girl."}, {"from": "gpt", "value": "[0.0, 0.23, 0.21, 0.73]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: boy in black and red marvin."}, {"from": "gpt", "value": "[0.19, 0.41, 0.43, 0.69]"}, {"from": "human", "value": "Please provide a short description for this region: [0.19, 0.41, 0.43, 0.69]."}, {"from": "gpt", "value": "Boy with hands on table."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: girl far left."}, {"from": "gpt", "value": "[0.0, 0.23, 0.21, 0.73]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: small kid on left next to bigger girl on left."}, {"from": "gpt", "value": "[0.19, 0.41, 0.43, 0.69]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: red shirt."}, {"from": "gpt", "value": "[0.61, 0.23, 1.0, 0.74]"}, {"from": "human", "value": "Please provide a short description for this region: [0.61, 0.23, 1.0, 0.74]."}, {"from": "gpt", "value": "Arms by cake."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: girl touching her mouth."}, {"from": "gpt", "value": "[0.0, 0.23, 0.21, 0.73]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: from left second kid."}, {"from": "gpt", "value": "[0.19, 0.41, 0.43, 0.69]"}]}, {"id": "000000520321", "image": "coco/train2017/000000520321.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: vase directly left of plant."}, {"from": "gpt", "value": "[0.18, 0.21, 0.28, 0.64]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: closest vase."}, {"from": "gpt", "value": "[0.6, 0.19, 0.93, 0.8]"}, {"from": "human", "value": "Please provide a short description for this region: [0.29, 0.41, 0.57, 0.81]."}, {"from": "gpt", "value": "Closest bush."}, {"from": "human", "value": "Please provide a short description for this region: [0.18, 0.21, 0.28, 0.64]."}, {"from": "gpt", "value": "Nearest whole vase."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: right vase."}, {"from": "gpt", "value": "[0.6, 0.19, 0.93, 0.8]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: blue white vase closest and to the right."}, {"from": "gpt", "value": "[0.6, 0.19, 0.93, 0.8]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: large vase second from right."}, {"from": "gpt", "value": "[0.18, 0.21, 0.28, 0.64]"}, {"from": "human", "value": "Please provide a short description for this region: [0.29, 0.41, 0.57, 0.81]."}, {"from": "gpt", "value": "Bush in middle of screen."}]}, {"id": "000000520321", "image": "coco/train2017/000000520321.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: shrub."}, {"from": "gpt", "value": "[0.29, 0.41, 0.57, 0.81]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: blue and white vase closest to us."}, {"from": "gpt", "value": "[0.6, 0.19, 0.93, 0.8]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: front mini tree."}, {"from": "gpt", "value": "[0.29, 0.41, 0.57, 0.81]"}, {"from": "human", "value": "Please provide a short description for this region: [0.29, 0.41, 0.57, 0.81]."}, {"from": "gpt", "value": "Plant on front."}, {"from": "human", "value": "Please provide a short description for this region: [0.6, 0.19, 0.93, 0.8]."}, {"from": "gpt", "value": "Closest vase."}, {"from": "human", "value": "Please provide a short description for this region: [0.18, 0.21, 0.28, 0.64]."}, {"from": "gpt", "value": "Closet vase not cut off."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: vase partially hidden by flower pot."}, {"from": "gpt", "value": "[0.18, 0.21, 0.28, 0.64]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: closest tree to you."}, {"from": "gpt", "value": "[0.29, 0.41, 0.57, 0.81]"}]}, {"id": "000000520321", "image": "coco/train2017/000000520321.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: second from right blue and white vase."}, {"from": "gpt", "value": "[0.18, 0.21, 0.28, 0.64]"}]}, {"id": "000000191156", "image": "coco/train2017/000000191156.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.56, 0.53, 0.74, 0.76]."}, {"from": "gpt", "value": "The cat on the right."}, {"from": "human", "value": "Please provide a short description for this region: [0.56, 0.53, 0.74, 0.76]."}, {"from": "gpt", "value": "A cat whose head is furthest down."}]}, {"id": "000000025461", "image": "coco/train2017/000000025461.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.18, 0.28, 0.38, 0.82]."}, {"from": "gpt", "value": "Fattest shortest standing."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: person on left."}, {"from": "gpt", "value": "[0.05, 0.27, 0.23, 0.81]"}, {"from": "human", "value": "Please provide a short description for this region: [0.18, 0.28, 0.38, 0.82]."}, {"from": "gpt", "value": "Woman in blue with drum on back."}, {"from": "human", "value": "Please provide a short description for this region: [0.18, 0.28, 0.38, 0.82]."}, {"from": "gpt", "value": "Left person facing away."}, {"from": "human", "value": "Please provide a short description for this region: [0.54, 0.2, 0.74, 0.8]."}, {"from": "gpt", "value": "Guy to right standing."}, {"from": "human", "value": "Please provide a short description for this region: [0.05, 0.27, 0.23, 0.81]."}, {"from": "gpt", "value": "Girl pulling bandana."}, {"from": "human", "value": "Please provide a short description for this region: [0.44, 0.42, 0.6, 0.75]."}, {"from": "gpt", "value": "Kneeling guy."}]}, {"id": "000000025461", "image": "coco/train2017/000000025461.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: right girl."}, {"from": "gpt", "value": "[0.54, 0.2, 0.74, 0.8]"}, {"from": "human", "value": "Please provide a short description for this region: [0.54, 0.2, 0.74, 0.8]."}, {"from": "gpt", "value": "Tallest guy with back to us."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: blue coat with drum standing."}, {"from": "gpt", "value": "[0.18, 0.28, 0.38, 0.82]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: small person."}, {"from": "gpt", "value": "[0.44, 0.42, 0.6, 0.75]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: large amn."}, {"from": "gpt", "value": "[0.54, 0.2, 0.74, 0.8]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: kneeling with drum."}, {"from": "gpt", "value": "[0.44, 0.42, 0.6, 0.75]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: tallest person."}, {"from": "gpt", "value": "[0.54, 0.2, 0.74, 0.8]"}]}, {"id": "000000025461", "image": "coco/train2017/000000025461.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: person on ground."}, {"from": "gpt", "value": "[0.44, 0.42, 0.6, 0.75]"}, {"from": "human", "value": "Please provide a short description for this region: [0.05, 0.27, 0.23, 0.81]."}, {"from": "gpt", "value": "Girl adjusting her hat."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: person on left with back to us."}, {"from": "gpt", "value": "[0.18, 0.28, 0.38, 0.82]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: left girl."}, {"from": "gpt", "value": "[0.05, 0.27, 0.23, 0.81]"}, {"from": "human", "value": "Please provide a short description for this region: [0.54, 0.2, 0.74, 0.8]."}, {"from": "gpt", "value": "Man with black bookback."}, {"from": "human", "value": "Please provide a short description for this region: [0.05, 0.27, 0.23, 0.81]."}, {"from": "gpt", "value": "Guy with a uniform on and hat on the left."}, {"from": "human", "value": "Please provide a short description for this region: [0.05, 0.27, 0.23, 0.81]."}, {"from": "gpt", "value": "Squinting girl with both arms up."}]}, {"id": "000000025461", "image": "coco/train2017/000000025461.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: person kneeling."}, {"from": "gpt", "value": "[0.44, 0.42, 0.6, 0.75]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: child."}, {"from": "gpt", "value": "[0.44, 0.42, 0.6, 0.75]"}]}, {"id": "000000264183", "image": "coco/train2017/000000264183.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: yellow candle."}, {"from": "gpt", "value": "[0.57, 0.2, 0.82, 0.69]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the red glass in background."}, {"from": "gpt", "value": "[0.76, 0.23, 0.91, 0.63]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: red vase white yarn around it."}, {"from": "gpt", "value": "[0.76, 0.23, 0.91, 0.63]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: vase with yellow candle."}, {"from": "gpt", "value": "[0.57, 0.2, 0.82, 0.69]"}, {"from": "human", "value": "Please provide a short description for this region: [0.76, 0.23, 0.91, 0.63]."}, {"from": "gpt", "value": "Far right vase."}]}, {"id": "000000264183", "image": "coco/train2017/000000264183.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.57, 0.2, 0.82, 0.69]."}, {"from": "gpt", "value": "Yellow candle."}, {"from": "human", "value": "Please provide a short description for this region: [0.76, 0.23, 0.91, 0.63]."}, {"from": "gpt", "value": "Right side of back glass."}, {"from": "human", "value": "Please provide a short description for this region: [0.76, 0.23, 0.91, 0.63]."}, {"from": "gpt", "value": "Red vase."}, {"from": "human", "value": "Please provide a short description for this region: [0.57, 0.2, 0.82, 0.69]."}, {"from": "gpt", "value": "Vase with candle in it."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: yellow candle."}, {"from": "gpt", "value": "[0.57, 0.2, 0.82, 0.69]"}]}, {"id": "000000264183", "image": "coco/train2017/000000264183.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.57, 0.2, 0.82, 0.69]."}, {"from": "gpt", "value": "Yellow candle."}]}, {"id": "000000414888", "image": "coco/train2017/000000414888.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.85, 0.38, 0.96, 0.73]."}, {"from": "gpt", "value": "Man holding the reigns for large horse in middle of field."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the man holding the ropes attached to the horse."}, {"from": "gpt", "value": "[0.85, 0.38, 0.96, 0.73]"}]}, {"id": "000000451160", "image": "coco/train2017/000000451160.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.23, 0.22, 0.41, 0.72]."}, {"from": "gpt", "value": "Man in tan."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: guy in the back looking like hes on acid right in the middle."}, {"from": "gpt", "value": "[0.45, 0.28, 0.6, 0.68]"}, {"from": "human", "value": "Please provide a short description for this region: [0.23, 0.22, 0.41, 0.72]."}, {"from": "gpt", "value": "Brown uniform."}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.28, 0.6, 0.68]."}, {"from": "gpt", "value": "Third guy from left in black."}, {"from": "human", "value": "Please provide a short description for this region: [0.81, 0.3, 0.99, 0.8]."}, {"from": "gpt", "value": "Right dude."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man close looking at hands."}, {"from": "gpt", "value": "[0.57, 0.28, 0.77, 0.69]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man in white belt."}, {"from": "gpt", "value": "[0.45, 0.28, 0.6, 0.68]"}, {"from": "human", "value": "Please provide a short description for this region: [0.57, 0.28, 0.77, 0.69]."}, {"from": "gpt", "value": "Hands on saw."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: ww2 era white guy."}, {"from": "gpt", "value": "[0.0, 0.21, 0.21, 0.81]"}]}, {"id": "000000451160", "image": "coco/train2017/000000451160.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.23, 0.22, 0.41, 0.72]."}, {"from": "gpt", "value": "Man with pointy hat in tan."}, {"from": "human", "value": "Please provide a short description for this region: [0.81, 0.3, 0.99, 0.8]."}, {"from": "gpt", "value": "P shirt."}, {"from": "human", "value": "Please provide a short description for this region: [0.23, 0.22, 0.41, 0.72]."}, {"from": "gpt", "value": "Second from left."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: far left man."}, {"from": "gpt", "value": "[0.0, 0.21, 0.21, 0.81]"}, {"from": "human", "value": "Please provide a short description for this region: [0.57, 0.28, 0.77, 0.69]."}, {"from": "gpt", "value": "Second guy from right."}, {"from": "human", "value": "Please provide a short description for this region: [0.81, 0.3, 0.99, 0.8]."}, {"from": "gpt", "value": "Person far right."}, {"from": "human", "value": "Please provide a short description for this region: [0.23, 0.22, 0.41, 0.72]."}, {"from": "gpt", "value": "Man in beige uniform."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.21, 0.21, 0.81]."}, {"from": "gpt", "value": "Older white man in more modern uniform."}, {"from": "human", "value": "Please provide a short description for this region: [0.57, 0.28, 0.77, 0.69]."}, {"from": "gpt", "value": "Civil war union soldier in navy blue."}]}, {"id": "000000451160", "image": "coco/train2017/000000451160.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.57, 0.28, 0.77, 0.69]."}, {"from": "gpt", "value": "Man in black jacket with beard black hat."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: person second from the right."}, {"from": "gpt", "value": "[0.57, 0.28, 0.77, 0.69]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.21, 0.21, 0.81]."}, {"from": "gpt", "value": "Figure furthest left."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: black shirt tan hat."}, {"from": "gpt", "value": "[0.45, 0.28, 0.6, 0.68]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: middle person."}, {"from": "gpt", "value": "[0.45, 0.28, 0.6, 0.68]"}, {"from": "human", "value": "Please provide a short description for this region: [0.23, 0.22, 0.41, 0.72]."}, {"from": "gpt", "value": "Solid tan outfit."}, {"from": "human", "value": "Please provide a short description for this region: [0.81, 0.3, 0.99, 0.8]."}, {"from": "gpt", "value": "Man with the p shirt on."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: soldier with brown sam brown belt across chest."}, {"from": "gpt", "value": "[0.0, 0.21, 0.21, 0.81]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.21, 0.21, 0.81]."}, {"from": "gpt", "value": "Furthest left most man."}]}, {"id": "000000565600", "image": "coco/train2017/000000565600.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.7, 0.16, 0.84, 0.6]."}, {"from": "gpt", "value": "A woman in a white shirt with gray pants standing behind two men playing tennis."}, {"from": "human", "value": "Please provide a short description for this region: [0.48, 0.07, 0.89, 0.97]."}, {"from": "gpt", "value": "Striped shirt."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a man in a striped shirt."}, {"from": "gpt", "value": "[0.48, 0.07, 0.89, 0.97]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: stripes."}, {"from": "gpt", "value": "[0.48, 0.07, 0.89, 0.97]"}, {"from": "human", "value": "Please provide a short description for this region: [0.19, 0.06, 0.67, 0.97]."}, {"from": "gpt", "value": "Man in all white clothes."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: stripes."}, {"from": "gpt", "value": "[0.48, 0.07, 0.89, 0.97]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: stripes."}, {"from": "gpt", "value": "[0.48, 0.07, 0.89, 0.97]"}, {"from": "human", "value": "Please provide a short description for this region: [0.7, 0.16, 0.84, 0.6]."}, {"from": "gpt", "value": "The woman standing near the plant texting on her phone."}, {"from": "human", "value": "Please provide a short description for this region: [0.48, 0.07, 0.89, 0.97]."}, {"from": "gpt", "value": "The man with the blue headband."}]}, {"id": "000000565600", "image": "coco/train2017/000000565600.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: all white."}, {"from": "gpt", "value": "[0.19, 0.06, 0.67, 0.97]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white shirt facing away."}, {"from": "gpt", "value": "[0.19, 0.06, 0.67, 0.97]"}, {"from": "human", "value": "Please provide a short description for this region: [0.19, 0.06, 0.67, 0.97]."}, {"from": "gpt", "value": "A man on a tennis court in a white t shirt and white pants with a blue stripe down the side , holding a tennis racket."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man in blue."}, {"from": "gpt", "value": "[0.48, 0.07, 0.89, 0.97]"}, {"from": "human", "value": "Please provide a short description for this region: [0.19, 0.06, 0.67, 0.97]."}, {"from": "gpt", "value": "The gray haired man in white carrying the tennis racket."}, {"from": "human", "value": "Please provide a short description for this region: [0.19, 0.06, 0.67, 0.97]."}, {"from": "gpt", "value": "Man in all white."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: dude in stripes."}, {"from": "gpt", "value": "[0.48, 0.07, 0.89, 0.97]"}, {"from": "human", "value": "Please provide a short description for this region: [0.19, 0.06, 0.67, 0.97]."}, {"from": "gpt", "value": "White shirt."}, {"from": "human", "value": "Please provide a short description for this region: [0.19, 0.06, 0.67, 0.97]."}, {"from": "gpt", "value": "All white guy."}]}, {"id": "000000218237", "image": "coco/train2017/000000218237.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: couch right."}, {"from": "gpt", "value": "[0.12, 0.39, 1.0, 0.88]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the brown couch the men are on."}, {"from": "gpt", "value": "[0.12, 0.39, 1.0, 0.88]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a man laying down on the couch with a drink in his hand."}, {"from": "gpt", "value": "[0.2, 0.35, 0.96, 0.86]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.37, 0.22, 0.85]."}, {"from": "gpt", "value": "Couch with no homoeroticism."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: guy laying."}, {"from": "gpt", "value": "[0.2, 0.35, 0.96, 0.86]"}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.24, 0.83, 0.88]."}, {"from": "gpt", "value": "Shirtless man at right."}, {"from": "human", "value": "Please provide a short description for this region: [0.2, 0.35, 0.96, 0.86]."}, {"from": "gpt", "value": "Man gray shirt."}]}, {"id": "000000218237", "image": "coco/train2017/000000218237.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a shirtless teen on a couch with his father."}, {"from": "gpt", "value": "[0.45, 0.24, 0.83, 0.88]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.37, 0.22, 0.85]."}, {"from": "gpt", "value": "A beige suede couch with a white remote on it."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.37, 0.22, 0.85]."}, {"from": "gpt", "value": "The couch that has no one sitting on it."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: chair on left."}, {"from": "gpt", "value": "[0.0, 0.37, 0.22, 0.85]"}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.24, 0.83, 0.88]."}, {"from": "gpt", "value": "Naked."}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.24, 0.83, 0.88]."}, {"from": "gpt", "value": "A shirtless teen guy holding another man."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: shirtless."}, {"from": "gpt", "value": "[0.45, 0.24, 0.83, 0.88]"}]}, {"id": "000000218237", "image": "coco/train2017/000000218237.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.0, 0.37, 0.22, 0.85]."}, {"from": "gpt", "value": "Empty couch behind glasses guy."}, {"from": "human", "value": "Please provide a short description for this region: [0.2, 0.35, 0.96, 0.86]."}, {"from": "gpt", "value": "A man in a blue shirt lying on a sofa."}, {"from": "human", "value": "Please provide a short description for this region: [0.12, 0.39, 1.0, 0.88]."}, {"from": "gpt", "value": "Only sofa."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: couch they are on."}, {"from": "gpt", "value": "[0.12, 0.39, 1.0, 0.88]"}, {"from": "human", "value": "Please provide a short description for this region: [0.2, 0.35, 0.96, 0.86]."}, {"from": "gpt", "value": "Man with shirt."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: sofa."}, {"from": "gpt", "value": "[0.12, 0.39, 1.0, 0.88]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.37, 0.22, 0.85]."}, {"from": "gpt", "value": "Furniture left."}]}, {"id": "000000218237", "image": "coco/train2017/000000218237.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.12, 0.39, 1.0, 0.88]."}, {"from": "gpt", "value": "Couch."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: no shirt."}, {"from": "gpt", "value": "[0.45, 0.24, 0.83, 0.88]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: guy with shirt."}, {"from": "gpt", "value": "[0.2, 0.35, 0.96, 0.86]"}, {"from": "human", "value": "Please provide a short description for this region: [0.2, 0.35, 0.96, 0.86]."}, {"from": "gpt", "value": "Laying guy."}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.24, 0.83, 0.88]."}, {"from": "gpt", "value": "Shirtless."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: left couch."}, {"from": "gpt", "value": "[0.0, 0.37, 0.22, 0.85]"}, {"from": "human", "value": "Please provide a short description for this region: [0.12, 0.39, 1.0, 0.88]."}, {"from": "gpt", "value": "Couch."}]}, {"id": "000000218237", "image": "coco/train2017/000000218237.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: guy with shirt."}, {"from": "gpt", "value": "[0.2, 0.35, 0.96, 0.86]"}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.24, 0.83, 0.88]."}, {"from": "gpt", "value": "No shirt."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: chair with no people."}, {"from": "gpt", "value": "[0.0, 0.37, 0.22, 0.85]"}]}, {"id": "000000066828", "image": "coco/train2017/000000066828.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: bottom right elephant."}, {"from": "gpt", "value": "[0.51, 0.66, 1.0, 0.87]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: closest e."}, {"from": "gpt", "value": "[0.51, 0.66, 1.0, 0.87]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: animal behind baby elephant."}, {"from": "gpt", "value": "[0.3, 0.53, 0.57, 0.78]"}, {"from": "human", "value": "Please provide a short description for this region: [0.51, 0.66, 1.0, 0.87]."}, {"from": "gpt", "value": "Bottom right elephant."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: elephant carrying two guys one girl."}, {"from": "gpt", "value": "[0.3, 0.53, 0.57, 0.78]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: elephant in rearmost."}, {"from": "gpt", "value": "[0.51, 0.66, 1.0, 0.87]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: elephant with guy in white shirt on its back."}, {"from": "gpt", "value": "[0.3, 0.53, 0.57, 0.78]"}, {"from": "human", "value": "Please provide a short description for this region: [0.3, 0.53, 0.57, 0.78]."}, {"from": "gpt", "value": "Elephant carrying three people one in white shirt and two in black."}]}, {"id": "000000066828", "image": "coco/train2017/000000066828.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.51, 0.66, 1.0, 0.87]."}, {"from": "gpt", "value": "The elephant in the back of the line."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the bottom right elephant but not the people."}, {"from": "gpt", "value": "[0.51, 0.66, 1.0, 0.87]"}, {"from": "human", "value": "Please provide a short description for this region: [0.3, 0.53, 0.57, 0.78]."}, {"from": "gpt", "value": "Middle brown elephant."}, {"from": "human", "value": "Please provide a short description for this region: [0.08, 0.43, 0.32, 0.61]."}, {"from": "gpt", "value": "The elephant leading the pack."}, {"from": "human", "value": "Please provide a short description for this region: [0.3, 0.53, 0.57, 0.78]."}, {"from": "gpt", "value": "Middle big elephant."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the lead elephant with it ' s baby following closely."}, {"from": "gpt", "value": "[0.08, 0.43, 0.32, 0.61]"}, {"from": "human", "value": "Please provide a short description for this region: [0.51, 0.66, 1.0, 0.87]."}, {"from": "gpt", "value": "Nearer ellie."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: an elephant with two women and a man on it."}, {"from": "gpt", "value": "[0.51, 0.66, 1.0, 0.87]"}]}, {"id": "000000069826", "image": "coco/train2017/000000069826.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: white bottle of futur e moisturizer with directions label."}, {"from": "gpt", "value": "[0.12, 0.23, 0.38, 0.82]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bottle left."}, {"from": "gpt", "value": "[0.12, 0.23, 0.38, 0.82]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: future."}, {"from": "gpt", "value": "[0.12, 0.23, 0.38, 0.82]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white bottle without visible writing."}, {"from": "gpt", "value": "[0.73, 0.24, 0.88, 0.77]"}, {"from": "human", "value": "Please provide a short description for this region: [0.12, 0.23, 0.38, 0.82]."}, {"from": "gpt", "value": "Futur e bottle."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: plastic bottle of lotion with grey cap to the right."}, {"from": "gpt", "value": "[0.73, 0.24, 0.88, 0.77]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: short white bottle."}, {"from": "gpt", "value": "[0.73, 0.24, 0.88, 0.77]"}]}, {"id": "000000069826", "image": "coco/train2017/000000069826.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.12, 0.23, 0.38, 0.82]."}, {"from": "gpt", "value": "Left back bottle."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: future white bottle lotsa writing."}, {"from": "gpt", "value": "[0.12, 0.23, 0.38, 0.82]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bottle on right."}, {"from": "gpt", "value": "[0.73, 0.24, 0.88, 0.77]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the side of a white bottle with a silver cap."}, {"from": "gpt", "value": "[0.73, 0.24, 0.88, 0.77]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: future."}, {"from": "gpt", "value": "[0.12, 0.23, 0.38, 0.82]"}, {"from": "human", "value": "Please provide a short description for this region: [0.73, 0.24, 0.88, 0.77]."}, {"from": "gpt", "value": "Wow bottle on right."}, {"from": "human", "value": "Please provide a short description for this region: [0.12, 0.23, 0.38, 0.82]."}, {"from": "gpt", "value": "A bottle of futur e moisturizer."}]}, {"id": "000000069826", "image": "coco/train2017/000000069826.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.73, 0.24, 0.88, 0.77]."}, {"from": "gpt", "value": "Right bottle."}]}, {"id": "000000359363", "image": "coco/train2017/000000359363.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.47, 0.31, 0.77, 0.6]."}, {"from": "gpt", "value": "Woman with red shirt and glasses bending over."}, {"from": "human", "value": "Please provide a short description for this region: [0.47, 0.31, 0.77, 0.6]."}, {"from": "gpt", "value": "Women in purple shit and glasses put pizza in oven."}]}, {"id": "000000468826", "image": "coco/train2017/000000468826.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: kid at head of table closest end."}, {"from": "gpt", "value": "[0.0, 0.38, 0.35, 0.88]"}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.38, 0.79, 0.88]."}, {"from": "gpt", "value": "Boy in hoodie closest."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: green shirt yellow hair band."}, {"from": "gpt", "value": "[0.74, 0.33, 0.9, 0.63]"}, {"from": "human", "value": "Please provide a short description for this region: [0.74, 0.33, 0.9, 0.63]."}, {"from": "gpt", "value": "Green shirt."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.38, 0.35, 0.88]."}, {"from": "gpt", "value": "Girl at head of table in black."}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.38, 0.79, 0.88]."}, {"from": "gpt", "value": "Hoodie."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.38, 0.35, 0.88]."}, {"from": "gpt", "value": "Far left girl in glasses."}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.38, 0.79, 0.88]."}, {"from": "gpt", "value": "Closest boy in black."}]}, {"id": "000000468826", "image": "coco/train2017/000000468826.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: girl with pony tail on right."}, {"from": "gpt", "value": "[0.74, 0.33, 0.9, 0.63]"}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.38, 0.79, 0.88]."}, {"from": "gpt", "value": "Boy bottom screen on left side of table."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: person at head of table."}, {"from": "gpt", "value": "[0.0, 0.38, 0.35, 0.88]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: green shirt girl right."}, {"from": "gpt", "value": "[0.74, 0.33, 0.9, 0.63]"}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.38, 0.79, 0.88]."}, {"from": "gpt", "value": "Bottom center dude in hoodie."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: green girl right."}, {"from": "gpt", "value": "[0.74, 0.33, 0.9, 0.63]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: boy in hoodie with his right hand up in the front."}, {"from": "gpt", "value": "[0.45, 0.38, 0.79, 0.88]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.38, 0.35, 0.88]."}, {"from": "gpt", "value": "Head of the table glasses."}]}, {"id": "000000515062", "image": "coco/train2017/000000515062.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.5, 0.6, 0.76, 0.83]."}, {"from": "gpt", "value": "The cupcake second from the right in the closest row."}, {"from": "human", "value": "Please provide a short description for this region: [0.75, 0.58, 1.0, 0.84]."}, {"from": "gpt", "value": "Bottom right cake."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: cupcake second bottom left."}, {"from": "gpt", "value": "[0.22, 0.58, 0.51, 0.82]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: cupcake at the bottom left corner of the box."}, {"from": "gpt", "value": "[0.0, 0.56, 0.23, 0.82]"}, {"from": "human", "value": "Please provide a short description for this region: [0.5, 0.38, 0.72, 0.59]."}, {"from": "gpt", "value": "Center with 3."}, {"from": "human", "value": "Please provide a short description for this region: [0.75, 0.58, 1.0, 0.84]."}, {"from": "gpt", "value": "Fourth cupcake."}, {"from": "human", "value": "Please provide a short description for this region: [0.5, 0.6, 0.76, 0.83]."}, {"from": "gpt", "value": "Moca cupcake number 3."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: middle row second from right."}, {"from": "gpt", "value": "[0.5, 0.38, 0.72, 0.59]"}]}, {"id": "000000515062", "image": "coco/train2017/000000515062.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.28, 0.38, 0.5, 0.55]."}, {"from": "gpt", "value": "Middle row second from left."}, {"from": "human", "value": "Please provide a short description for this region: [0.28, 0.38, 0.5, 0.55]."}, {"from": "gpt", "value": "Middle row second cupcake."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: top right dessert."}, {"from": "gpt", "value": "[0.69, 0.25, 0.86, 0.42]"}, {"from": "human", "value": "Please provide a short description for this region: [0.5, 0.6, 0.76, 0.83]."}, {"from": "gpt", "value": "Seconf cake from front right."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bottom right corner."}, {"from": "gpt", "value": "[0.75, 0.58, 1.0, 0.84]"}, {"from": "human", "value": "Please provide a short description for this region: [0.5, 0.38, 0.72, 0.59]."}, {"from": "gpt", "value": "Middle row donut next to donut with red topping."}, {"from": "human", "value": "Please provide a short description for this region: [0.22, 0.58, 0.51, 0.82]."}, {"from": "gpt", "value": "Cupcake second from the left bottom row."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: cake at 4pm."}, {"from": "gpt", "value": "[0.75, 0.58, 1.0, 0.84]"}]}, {"id": "000000515062", "image": "coco/train2017/000000515062.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: the cupcake with marshmallows in last column."}, {"from": "gpt", "value": "[0.69, 0.25, 0.86, 0.42]"}, {"from": "human", "value": "Please provide a short description for this region: [0.28, 0.38, 0.5, 0.55]."}, {"from": "gpt", "value": "Yes."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: cupcake 2."}, {"from": "gpt", "value": "[0.22, 0.58, 0.51, 0.82]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bottom cupcake second from right."}, {"from": "gpt", "value": "[0.5, 0.6, 0.76, 0.83]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.56, 0.23, 0.82]."}, {"from": "gpt", "value": "Cupcake with three piece no inside showing."}, {"from": "human", "value": "Please provide a short description for this region: [0.69, 0.25, 0.86, 0.42]."}, {"from": "gpt", "value": "Back right cake."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: cupcake at 500."}, {"from": "gpt", "value": "[0.75, 0.58, 1.0, 0.84]"}, {"from": "human", "value": "Please provide a short description for this region: [0.69, 0.25, 0.86, 0.42]."}, {"from": "gpt", "value": "Top right."}]}, {"id": "000000515062", "image": "coco/train2017/000000515062.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: cupcake number 11 starting counting from back."}, {"from": "gpt", "value": "[0.5, 0.6, 0.76, 0.83]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: far left bottom row."}, {"from": "gpt", "value": "[0.0, 0.56, 0.23, 0.82]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: drizzled in tr corner."}, {"from": "gpt", "value": "[0.69, 0.25, 0.86, 0.42]"}, {"from": "human", "value": "Please provide a short description for this region: [0.75, 0.58, 1.0, 0.84]."}, {"from": "gpt", "value": "Lower right cupcake."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bottom row second from left."}, {"from": "gpt", "value": "[0.22, 0.58, 0.51, 0.82]"}, {"from": "human", "value": "Please provide a short description for this region: [0.28, 0.38, 0.5, 0.55]."}, {"from": "gpt", "value": "2 row 2 cupcake."}, {"from": "human", "value": "Please provide a short description for this region: [0.5, 0.38, 0.72, 0.59]."}, {"from": "gpt", "value": "Cupcake in second row third column from left."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: middle row third from left."}, {"from": "gpt", "value": "[0.5, 0.38, 0.72, 0.59]"}]}, {"id": "000000515062", "image": "coco/train2017/000000515062.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.28, 0.38, 0.5, 0.55]."}, {"from": "gpt", "value": "Row 2 column 3 with choc sauce."}]}, {"id": "000000387368", "image": "coco/train2017/000000387368.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.74, 0.56, 0.99, 0.79]."}, {"from": "gpt", "value": "An old lady who is wearing a black jacket and sitting down."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: empty chair."}, {"from": "gpt", "value": "[0.22, 0.56, 0.56, 0.85]"}, {"from": "human", "value": "Please provide a short description for this region: [0.69, 0.64, 0.96, 0.88]."}, {"from": "gpt", "value": "The man sitting on the ground on his knee."}, {"from": "human", "value": "Please provide a short description for this region: [0.74, 0.56, 0.99, 0.79]."}, {"from": "gpt", "value": "A woman sitting in a chair with a person kneeling in front of her."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: woman in gray and white striped top."}, {"from": "gpt", "value": "[0.69, 0.64, 0.96, 0.88]"}]}, {"id": "000000036282", "image": "coco/train2017/000000036282.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.33, 0.54, 0.47, 0.8]."}, {"from": "gpt", "value": "A handbag with a bow that is being worn by a woman."}, {"from": "human", "value": "Please provide a short description for this region: [0.33, 0.54, 0.47, 0.8]."}, {"from": "gpt", "value": "A black color purse with a silver chain."}]}, {"id": "000000250380", "image": "coco/train2017/000000250380.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: girl n blue."}, {"from": "gpt", "value": "[0.01, 0.09, 0.45, 0.89]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: blue shirt."}, {"from": "gpt", "value": "[0.01, 0.09, 0.45, 0.89]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: woman in blue shirt."}, {"from": "gpt", "value": "[0.01, 0.09, 0.45, 0.89]"}, {"from": "human", "value": "Please provide a short description for this region: [0.59, 0.21, 0.85, 0.59]."}, {"from": "gpt", "value": "Guy in red shirt."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: red shirt."}, {"from": "gpt", "value": "[0.59, 0.21, 0.85, 0.59]"}, {"from": "human", "value": "Please provide a short description for this region: [0.59, 0.21, 0.85, 0.59]."}, {"from": "gpt", "value": "Person in red."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: lady in blue tank."}, {"from": "gpt", "value": "[0.01, 0.09, 0.45, 0.89]"}]}, {"id": "000000250380", "image": "coco/train2017/000000250380.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.59, 0.21, 0.85, 0.59]."}, {"from": "gpt", "value": "A woman with a red shirt and khaki shorts."}, {"from": "human", "value": "Please provide a short description for this region: [0.59, 0.21, 0.85, 0.59]."}, {"from": "gpt", "value": "The man who is going to play with the dog."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: red shirt."}, {"from": "gpt", "value": "[0.59, 0.21, 0.85, 0.59]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: guy."}, {"from": "gpt", "value": "[0.59, 0.21, 0.85, 0.59]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: red shirt."}, {"from": "gpt", "value": "[0.59, 0.21, 0.85, 0.59]"}, {"from": "human", "value": "Please provide a short description for this region: [0.01, 0.09, 0.45, 0.89]."}, {"from": "gpt", "value": "Girl in blue shirt."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: blue shirt on left."}, {"from": "gpt", "value": "[0.01, 0.09, 0.45, 0.89]"}]}, {"id": "000000393924", "image": "coco/train2017/000000393924.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.17, 0.27, 0.6, 0.99]."}, {"from": "gpt", "value": "Woman."}, {"from": "human", "value": "Please provide a short description for this region: [0.17, 0.27, 0.6, 0.99]."}, {"from": "gpt", "value": "Girl."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: woman on the left."}, {"from": "gpt", "value": "[0.17, 0.27, 0.6, 0.99]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man."}, {"from": "gpt", "value": "[0.45, 0.13, 0.83, 0.98]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man."}, {"from": "gpt", "value": "[0.45, 0.13, 0.83, 0.98]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: woman."}, {"from": "gpt", "value": "[0.17, 0.27, 0.6, 0.99]"}]}, {"id": "000000393924", "image": "coco/train2017/000000393924.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.17, 0.27, 0.6, 0.99]."}, {"from": "gpt", "value": "Girl."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man."}, {"from": "gpt", "value": "[0.45, 0.13, 0.83, 0.98]"}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.13, 0.83, 0.98]."}, {"from": "gpt", "value": "The man."}, {"from": "human", "value": "Please provide a short description for this region: [0.17, 0.27, 0.6, 0.99]."}, {"from": "gpt", "value": "A woman in a pink dress."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: dude."}, {"from": "gpt", "value": "[0.45, 0.13, 0.83, 0.98]"}, {"from": "human", "value": "Please provide a short description for this region: [0.17, 0.27, 0.6, 0.99]."}, {"from": "gpt", "value": "Woman."}]}, {"id": "000000393924", "image": "coco/train2017/000000393924.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: groom."}, {"from": "gpt", "value": "[0.45, 0.13, 0.83, 0.98]"}]}, {"id": "000000469988", "image": "coco/train2017/000000469988.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.19, 0.31, 0.4, 0.65]."}, {"from": "gpt", "value": "Large duffel backpack with red bandana tied on it."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: red bag."}, {"from": "gpt", "value": "[0.36, 0.49, 0.66, 0.76]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: red bag in front."}, {"from": "gpt", "value": "[0.36, 0.49, 0.66, 0.76]"}, {"from": "human", "value": "Please provide a short description for this region: [0.19, 0.31, 0.4, 0.65]."}, {"from": "gpt", "value": "Yellow bag."}, {"from": "human", "value": "Please provide a short description for this region: [0.36, 0.49, 0.66, 0.76]."}, {"from": "gpt", "value": "Big red thing."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: tan bag on the left with the pink bandana tied to it."}, {"from": "gpt", "value": "[0.19, 0.31, 0.4, 0.65]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: blue north face backpack."}, {"from": "gpt", "value": "[0.4, 0.31, 0.55, 0.53]"}, {"from": "human", "value": "Please provide a short description for this region: [0.36, 0.49, 0.66, 0.76]."}, {"from": "gpt", "value": "A red bag infront of other bags."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a grey chair in a living room next tobackpacks."}, {"from": "gpt", "value": "[0.0, 0.31, 0.16, 0.57]"}]}, {"id": "000000469988", "image": "coco/train2017/000000469988.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.19, 0.31, 0.4, 0.65]."}, {"from": "gpt", "value": "Yellow."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: blue bag."}, {"from": "gpt", "value": "[0.4, 0.31, 0.55, 0.53]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the empty grey chair on the left side of the room."}, {"from": "gpt", "value": "[0.0, 0.31, 0.16, 0.57]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: blue tall bag."}, {"from": "gpt", "value": "[0.4, 0.31, 0.55, 0.53]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: luggage on the left."}, {"from": "gpt", "value": "[0.19, 0.31, 0.4, 0.65]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the yellow pack on left."}, {"from": "gpt", "value": "[0.19, 0.31, 0.4, 0.65]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: yellow bag."}, {"from": "gpt", "value": "[0.19, 0.31, 0.4, 0.65]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.22, 0.21, 0.45]."}, {"from": "gpt", "value": "A turquoise fabric armed chair sitting in a living room with a folded blanket draped over the back."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: front red bag."}, {"from": "gpt", "value": "[0.36, 0.49, 0.66, 0.76]"}]}, {"id": "000000469988", "image": "coco/train2017/000000469988.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.36, 0.49, 0.66, 0.76]."}, {"from": "gpt", "value": "Red and black bag in front."}, {"from": "human", "value": "Please provide a short description for this region: [0.4, 0.31, 0.55, 0.53]."}, {"from": "gpt", "value": "Blue bag in the middle."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: blue and black noth face bag."}, {"from": "gpt", "value": "[0.4, 0.31, 0.55, 0.53]"}, {"from": "human", "value": "Please provide a short description for this region: [0.36, 0.49, 0.66, 0.76]."}, {"from": "gpt", "value": "Read bag on wooden floor."}, {"from": "human", "value": "Please provide a short description for this region: [0.36, 0.49, 0.66, 0.76]."}, {"from": "gpt", "value": "A red colour bag was on floor."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: blue bag next to yellow bag."}, {"from": "gpt", "value": "[0.4, 0.31, 0.55, 0.53]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.22, 0.21, 0.45]."}, {"from": "gpt", "value": "The blue chair on the left side of the room."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a blue and black bag in front of the table."}, {"from": "gpt", "value": "[0.4, 0.31, 0.55, 0.53]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: yellow."}, {"from": "gpt", "value": "[0.19, 0.31, 0.4, 0.65]"}]}, {"id": "000000316676", "image": "coco/train2017/000000316676.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: the right of the traffic light."}, {"from": "gpt", "value": "[0.59, 0.36, 0.82, 0.78]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: exce."}, {"from": "gpt", "value": "[0.26, 0.22, 0.53, 0.75]"}, {"from": "human", "value": "Please provide a short description for this region: [0.26, 0.22, 0.53, 0.75]."}, {"from": "gpt", "value": "Stop lights covered in snow."}, {"from": "human", "value": "Please provide a short description for this region: [0.59, 0.36, 0.82, 0.78]."}, {"from": "gpt", "value": "Snow on a stop light."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: lights."}, {"from": "gpt", "value": "[0.26, 0.22, 0.53, 0.75]"}, {"from": "human", "value": "Please provide a short description for this region: [0.26, 0.22, 0.53, 0.75]."}, {"from": "gpt", "value": "Traffic intersection lights is covered in snow."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: round things in middle."}, {"from": "gpt", "value": "[0.26, 0.22, 0.53, 0.75]"}, {"from": "human", "value": "Please provide a short description for this region: [0.26, 0.22, 0.53, 0.75]."}, {"from": "gpt", "value": "The round things left of middle in middle."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: three circles near."}, {"from": "gpt", "value": "[0.26, 0.22, 0.53, 0.75]"}, {"from": "human", "value": "Please provide a short description for this region: [0.26, 0.22, 0.53, 0.75]."}, {"from": "gpt", "value": "Traffic lights."}]}, {"id": "000000103775", "image": "coco/train2017/000000103775.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.39, 0.53, 0.6, 0.83]."}, {"from": "gpt", "value": "Chair of person in striped shirt."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the left char."}, {"from": "gpt", "value": "[0.39, 0.53, 0.6, 0.83]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: blue chair on far left."}, {"from": "gpt", "value": "[0.39, 0.53, 0.6, 0.83]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the back of a blue chair with a man ' s white shirt showing."}, {"from": "gpt", "value": "[0.64, 0.52, 0.83, 0.82]"}, {"from": "human", "value": "Please provide a short description for this region: [0.39, 0.53, 0.6, 0.83]."}, {"from": "gpt", "value": "Chair under stripe clothes."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: chair red stripe."}, {"from": "gpt", "value": "[0.39, 0.53, 0.6, 0.83]"}, {"from": "human", "value": "Please provide a short description for this region: [0.39, 0.53, 0.6, 0.83]."}, {"from": "gpt", "value": "Chair the woman in left side is sitting in."}]}, {"id": "000000103775", "image": "coco/train2017/000000103775.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a lady sitting in a chair."}, {"from": "gpt", "value": "[0.41, 0.39, 0.56, 0.67]"}, {"from": "human", "value": "Please provide a short description for this region: [0.39, 0.53, 0.6, 0.83]."}, {"from": "gpt", "value": "Chair striped shirt is sitting on."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a man sitting on a blue chair with a white shirt."}, {"from": "gpt", "value": "[0.61, 0.39, 0.85, 0.68]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the person with the red and white striped shirt."}, {"from": "gpt", "value": "[0.41, 0.39, 0.56, 0.67]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: chair with a person in red and white sitting in it."}, {"from": "gpt", "value": "[0.39, 0.53, 0.6, 0.83]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a guy in a white shirt sitting in a blue chair."}, {"from": "gpt", "value": "[0.61, 0.39, 0.85, 0.68]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the chair the person in the white shirt is sitting in."}, {"from": "gpt", "value": "[0.64, 0.52, 0.83, 0.82]"}]}, {"id": "000000374520", "image": "coco/train2017/000000374520.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a large austrian airlines plane."}, {"from": "gpt", "value": "[0.04, 0.29, 1.0, 0.6]"}, {"from": "human", "value": "Please provide a short description for this region: [0.04, 0.29, 1.0, 0.6]."}, {"from": "gpt", "value": "A large red with a red and white striped tail."}]}, {"id": "000000385940", "image": "coco/train2017/000000385940.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.25, 0.11, 0.57, 0.76]."}, {"from": "gpt", "value": "A black and yellow train."}, {"from": "human", "value": "Please provide a short description for this region: [0.25, 0.11, 0.57, 0.76]."}, {"from": "gpt", "value": "Black and yellow train on track with # c3."}]}, {"id": "000000010735", "image": "coco/train2017/000000010735.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: baby butt."}, {"from": "gpt", "value": "[0.53, 0.38, 0.78, 0.76]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: elephant on log."}, {"from": "gpt", "value": "[0.21, 0.22, 0.57, 0.73]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: taller."}, {"from": "gpt", "value": "[0.21, 0.22, 0.57, 0.73]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: elephant with head down."}, {"from": "gpt", "value": "[0.53, 0.38, 0.78, 0.76]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: left."}, {"from": "gpt", "value": "[0.21, 0.22, 0.57, 0.73]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a old elephant standing on top of a log."}, {"from": "gpt", "value": "[0.21, 0.22, 0.57, 0.73]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: baby elephant butt."}, {"from": "gpt", "value": "[0.53, 0.38, 0.78, 0.76]"}]}, {"id": "000000010735", "image": "coco/train2017/000000010735.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: ass to camera."}, {"from": "gpt", "value": "[0.53, 0.38, 0.78, 0.76]"}, {"from": "human", "value": "Please provide a short description for this region: [0.53, 0.38, 0.78, 0.76]."}, {"from": "gpt", "value": "Big butt elephant."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the butt of a small elephant."}, {"from": "gpt", "value": "[0.53, 0.38, 0.78, 0.76]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: small elephant with butt to you."}, {"from": "gpt", "value": "[0.53, 0.38, 0.78, 0.76]"}, {"from": "human", "value": "Please provide a short description for this region: [0.21, 0.22, 0.57, 0.73]."}, {"from": "gpt", "value": "Elephan looking at us."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the elephant on the left who is perched on a tree stump."}, {"from": "gpt", "value": "[0.21, 0.22, 0.57, 0.73]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: left elephant."}, {"from": "gpt", "value": "[0.21, 0.22, 0.57, 0.73]"}]}, {"id": "000000010735", "image": "coco/train2017/000000010735.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.21, 0.22, 0.57, 0.73]."}, {"from": "gpt", "value": "Elephant on left."}]}, {"id": "000000053864", "image": "coco/train2017/000000053864.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.17, 0.56, 0.32, 0.81]."}, {"from": "gpt", "value": "The book on the far left."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a drawing notebook to the left of a white notepad."}, {"from": "gpt", "value": "[0.17, 0.56, 0.32, 0.8]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a tablet."}, {"from": "gpt", "value": "[0.17, 0.56, 0.32, 0.81]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the black object with a person ' s photo on its front."}, {"from": "gpt", "value": "[0.17, 0.56, 0.32, 0.8]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: laptop under cat."}, {"from": "gpt", "value": "[0.22, 0.0, 0.77, 0.54]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: notepad."}, {"from": "gpt", "value": "[0.23, 0.53, 0.79, 0.95]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: there is a laptop under the cat."}, {"from": "gpt", "value": "[0.22, 0.0, 0.77, 0.54]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a white notebook with a cats paw on it."}, {"from": "gpt", "value": "[0.23, 0.53, 0.79, 0.95]"}]}, {"id": "000000447994", "image": "coco/train2017/000000447994.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.17, 0.42, 0.36, 0.81]."}, {"from": "gpt", "value": "A wine glass which is seen on the left side of other three glasses."}, {"from": "human", "value": "Please provide a short description for this region: [0.68, 0.41, 0.87, 0.8]."}, {"from": "gpt", "value": "Glass of wine in table."}, {"from": "human", "value": "Please provide a short description for this region: [0.41, 0.41, 0.59, 0.79]."}, {"from": "gpt", "value": "Middle wine glass."}, {"from": "human", "value": "Please provide a short description for this region: [0.17, 0.42, 0.36, 0.81]."}, {"from": "gpt", "value": "Left wine glass."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the glass of wine has is fuller than the rest."}, {"from": "gpt", "value": "[0.41, 0.41, 0.59, 0.79]"}, {"from": "human", "value": "Please provide a short description for this region: [0.68, 0.41, 0.87, 0.8]."}, {"from": "gpt", "value": "Corner wine glass."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: glass 1."}, {"from": "gpt", "value": "[0.17, 0.42, 0.36, 0.81]"}]}, {"id": "000000447994", "image": "coco/train2017/000000447994.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: glass with the least amount of wine."}, {"from": "gpt", "value": "[0.68, 0.41, 0.87, 0.8]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: front middle glass."}, {"from": "gpt", "value": "[0.41, 0.41, 0.59, 0.79]"}, {"from": "human", "value": "Please provide a short description for this region: [0.68, 0.41, 0.87, 0.8]."}, {"from": "gpt", "value": "Wine glass front most to right."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: most full glass."}, {"from": "gpt", "value": "[0.41, 0.41, 0.59, 0.79]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: left wine glass."}, {"from": "gpt", "value": "[0.17, 0.42, 0.36, 0.81]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: wine glass 1."}, {"from": "gpt", "value": "[0.17, 0.42, 0.36, 0.81]"}, {"from": "human", "value": "Please provide a short description for this region: [0.17, 0.42, 0.36, 0.81]."}, {"from": "gpt", "value": "First glass on left."}]}, {"id": "000000447994", "image": "coco/train2017/000000447994.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: glass with least wine."}, {"from": "gpt", "value": "[0.68, 0.41, 0.87, 0.8]"}, {"from": "human", "value": "Please provide a short description for this region: [0.41, 0.41, 0.59, 0.79]."}, {"from": "gpt", "value": "Wine glass in the row of three most in line with papers."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: middle cup."}, {"from": "gpt", "value": "[0.41, 0.41, 0.59, 0.79]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: wine glass at 6 o clock."}, {"from": "gpt", "value": "[0.41, 0.41, 0.59, 0.79]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: glass on the edge."}, {"from": "gpt", "value": "[0.68, 0.41, 0.87, 0.8]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: glass at middle center."}, {"from": "gpt", "value": "[0.41, 0.41, 0.59, 0.79]"}, {"from": "human", "value": "Please provide a short description for this region: [0.68, 0.41, 0.87, 0.8]."}, {"from": "gpt", "value": "Glass front right."}]}, {"id": "000000363829", "image": "coco/train2017/000000363829.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.27, 0.08, 0.38, 0.43]."}, {"from": "gpt", "value": "Ball boy in green in the background."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: male tennis player with light red hair wearing white clothing."}, {"from": "gpt", "value": "[0.26, 0.21, 0.64, 0.89]"}, {"from": "human", "value": "Please provide a short description for this region: [0.26, 0.21, 0.64, 0.89]."}, {"from": "gpt", "value": "Someone with a tennis raquet."}, {"from": "human", "value": "Please provide a short description for this region: [0.27, 0.08, 0.38, 0.43]."}, {"from": "gpt", "value": "A man standing in a green shirt."}]}, {"id": "000000094179", "image": "coco/train2017/000000094179.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.17, 0.08, 0.81, 0.98]."}, {"from": "gpt", "value": "Left guy."}, {"from": "human", "value": "Please provide a short description for this region: [0.44, 0.09, 0.83, 0.73]."}, {"from": "gpt", "value": "Person with computer."}, {"from": "human", "value": "Please provide a short description for this region: [0.17, 0.08, 0.81, 0.98]."}, {"from": "gpt", "value": "The guy on the left."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: right guy."}, {"from": "gpt", "value": "[0.44, 0.09, 0.83, 0.73]"}, {"from": "human", "value": "Please provide a short description for this region: [0.17, 0.08, 0.81, 0.98]."}, {"from": "gpt", "value": "Man without computer."}, {"from": "human", "value": "Please provide a short description for this region: [0.17, 0.08, 0.81, 0.98]."}, {"from": "gpt", "value": "Guy on left."}, {"from": "human", "value": "Please provide a short description for this region: [0.17, 0.08, 0.81, 0.98]."}, {"from": "gpt", "value": "Guy 1."}]}, {"id": "000000094179", "image": "coco/train2017/000000094179.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: man without the laptop."}, {"from": "gpt", "value": "[0.17, 0.08, 0.81, 0.98]"}, {"from": "human", "value": "Please provide a short description for this region: [0.17, 0.08, 0.81, 0.98]."}, {"from": "gpt", "value": "The man to the left of the man with the laptop."}, {"from": "human", "value": "Please provide a short description for this region: [0.17, 0.08, 0.81, 0.98]."}, {"from": "gpt", "value": "A man who is not holding a laptop."}, {"from": "human", "value": "Please provide a short description for this region: [0.44, 0.09, 0.83, 0.73]."}, {"from": "gpt", "value": "Right guy."}, {"from": "human", "value": "Please provide a short description for this region: [0.44, 0.09, 0.83, 0.73]."}, {"from": "gpt", "value": "Guy with laptop."}, {"from": "human", "value": "Please provide a short description for this region: [0.44, 0.09, 0.83, 0.73]."}, {"from": "gpt", "value": "Right guy."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man with laptop on lap."}, {"from": "gpt", "value": "[0.44, 0.09, 0.83, 0.73]"}]}, {"id": "000000507928", "image": "coco/train2017/000000507928.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: the guy on the dirtbike."}, {"from": "gpt", "value": "[0.36, 0.3, 0.71, 0.75]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a person riding a dirt bike."}, {"from": "gpt", "value": "[0.36, 0.3, 0.71, 0.75]"}]}, {"id": "000000309523", "image": "coco/train2017/000000309523.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: showing legs."}, {"from": "gpt", "value": "[0.06, 0.13, 0.45, 0.76]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: right legs."}, {"from": "gpt", "value": "[0.48, 0.12, 0.81, 0.72]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: leg of a girl who is to the left of the pic."}, {"from": "gpt", "value": "[0.06, 0.13, 0.45, 0.76]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: right legs."}, {"from": "gpt", "value": "[0.48, 0.12, 0.81, 0.72]"}, {"from": "human", "value": "Please provide a short description for this region: [0.48, 0.12, 0.81, 0.72]."}, {"from": "gpt", "value": "Black pants."}, {"from": "human", "value": "Please provide a short description for this region: [0.06, 0.13, 0.45, 0.76]."}, {"from": "gpt", "value": "Left feet ballet shoes."}, {"from": "human", "value": "Please provide a short description for this region: [0.48, 0.12, 0.81, 0.72]."}, {"from": "gpt", "value": "Blurry shoes black pants."}]}, {"id": "000000309523", "image": "coco/train2017/000000309523.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a lady with bare legs wearing ballett tie on shoes."}, {"from": "gpt", "value": "[0.06, 0.13, 0.45, 0.76]"}, {"from": "human", "value": "Please provide a short description for this region: [0.06, 0.13, 0.45, 0.76]."}, {"from": "gpt", "value": "Bare legs."}, {"from": "human", "value": "Please provide a short description for this region: [0.06, 0.13, 0.45, 0.76]."}, {"from": "gpt", "value": "Shoes on left."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a person wearing black pants."}, {"from": "gpt", "value": "[0.48, 0.12, 0.81, 0.72]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: right pair of shoes and legs."}, {"from": "gpt", "value": "[0.48, 0.12, 0.81, 0.72]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: legs with the see through shoes."}, {"from": "gpt", "value": "[0.06, 0.13, 0.45, 0.76]"}, {"from": "human", "value": "Please provide a short description for this region: [0.48, 0.12, 0.81, 0.72]."}, {"from": "gpt", "value": "The shoes with pants."}]}, {"id": "000000309523", "image": "coco/train2017/000000309523.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a pair of legs wearing dark pants and pointed shoes."}, {"from": "gpt", "value": "[0.48, 0.12, 0.81, 0.72]"}]}, {"id": "000000542937", "image": "coco/train2017/000000542937.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.18, 0.44, 0.5, 0.66]."}, {"from": "gpt", "value": "Left goat."}, {"from": "human", "value": "Please provide a short description for this region: [0.18, 0.44, 0.5, 0.66]."}, {"from": "gpt", "value": "Cow on left."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: little guy."}, {"from": "gpt", "value": "[0.18, 0.44, 0.5, 0.66]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the cow to the left of the other cow."}, {"from": "gpt", "value": "[0.18, 0.44, 0.5, 0.66]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a animal with horns."}, {"from": "gpt", "value": "[0.38, 0.31, 0.77, 0.63]"}, {"from": "human", "value": "Please provide a short description for this region: [0.38, 0.31, 0.77, 0.63]."}, {"from": "gpt", "value": "Animal on right."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: biggest one."}, {"from": "gpt", "value": "[0.38, 0.31, 0.77, 0.63]"}, {"from": "human", "value": "Please provide a short description for this region: [0.18, 0.44, 0.5, 0.66]."}, {"from": "gpt", "value": "Small brown animal next to larger animal."}]}, {"id": "000000542937", "image": "coco/train2017/000000542937.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.38, 0.31, 0.77, 0.63]."}, {"from": "gpt", "value": "Looking at us."}, {"from": "human", "value": "Please provide a short description for this region: [0.18, 0.44, 0.5, 0.66]."}, {"from": "gpt", "value": "Smaller."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: smallest."}, {"from": "gpt", "value": "[0.18, 0.44, 0.5, 0.66]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the one with big horns."}, {"from": "gpt", "value": "[0.38, 0.31, 0.77, 0.63]"}, {"from": "human", "value": "Please provide a short description for this region: [0.18, 0.44, 0.5, 0.66]."}, {"from": "gpt", "value": "Cow on left."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: brown animal with horns in green grass."}, {"from": "gpt", "value": "[0.38, 0.31, 0.77, 0.63]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: cow looking at you."}, {"from": "gpt", "value": "[0.38, 0.31, 0.77, 0.63]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the one looking at the camera."}, {"from": "gpt", "value": "[0.38, 0.31, 0.77, 0.63]"}]}, {"id": "000000122097", "image": "coco/train2017/000000122097.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.82, 0.14, 1.0, 0.56]."}, {"from": "gpt", "value": "Cup on right."}, {"from": "human", "value": "Please provide a short description for this region: [0.82, 0.14, 1.0, 0.56]."}, {"from": "gpt", "value": "The cup with blue and purple swishes on it."}]}, {"id": "000000084243", "image": "coco/train2017/000000084243.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a cow looking into the camera."}, {"from": "gpt", "value": "[0.19, 0.14, 0.81, 0.97]"}, {"from": "human", "value": "Please provide a short description for this region: [0.62, 0.49, 0.82, 0.68]."}, {"from": "gpt", "value": "A cow laying down in the back ground."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a cow lying down next to a standing cow."}, {"from": "gpt", "value": "[0.62, 0.49, 0.82, 0.68]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a rich brown colored cow with an ear tag standing near some very small trees."}, {"from": "gpt", "value": "[0.19, 0.14, 0.81, 0.97]"}]}, {"id": "000000272899", "image": "coco/train2017/000000272899.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.48, 0.3, 0.67, 0.5]."}, {"from": "gpt", "value": "A large gray bird facing toward the right."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the bird whose face is visible."}, {"from": "gpt", "value": "[0.48, 0.3, 0.67, 0.5]"}]}, {"id": "000000189912", "image": "coco/train2017/000000189912.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.7, 0.56, 1.0, 0.69]."}, {"from": "gpt", "value": "A black suitcase moving on a conveyor belt at an airport baggage claim."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a piece of black luggage on the far right of a conveyor belt."}, {"from": "gpt", "value": "[0.7, 0.56, 1.0, 0.69]"}]}, {"id": "000000345590", "image": "coco/train2017/000000345590.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a shaggy adult sheep with big horns."}, {"from": "gpt", "value": "[0.48, 0.34, 0.76, 0.6]"}, {"from": "human", "value": "Please provide a short description for this region: [0.48, 0.34, 0.76, 0.6]."}, {"from": "gpt", "value": "A shaggy sheep standing up."}]}, {"id": "000000223121", "image": "coco/train2017/000000223121.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.28, 0.38, 0.89, 0.58]."}, {"from": "gpt", "value": "Smaller ana airplane to the front."}, {"from": "human", "value": "Please provide a short description for this region: [0.28, 0.38, 0.89, 0.58]."}, {"from": "gpt", "value": "The plane fully visible."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: ana airline plane being boarded , behind another ana airline plane."}, {"from": "gpt", "value": "[0.39, 0.39, 0.96, 0.49]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: an aeroplane whose head part is hidden by a barricade."}, {"from": "gpt", "value": "[0.39, 0.39, 0.96, 0.49]"}]}, {"id": "000000458505", "image": "coco/train2017/000000458505.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.1, 0.18, 0.95, 0.82]."}, {"from": "gpt", "value": "A motorcycle with dual exhaust pipes resting on a kickstand."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: red bike."}, {"from": "gpt", "value": "[0.0, 0.34, 0.33, 0.66]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the moto in red."}, {"from": "gpt", "value": "[0.0, 0.34, 0.33, 0.66]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.34, 0.33, 0.66]."}, {"from": "gpt", "value": "Motorcycle partially cut off red looking seat."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: left bike."}, {"from": "gpt", "value": "[0.0, 0.34, 0.33, 0.66]"}, {"from": "human", "value": "Please provide a short description for this region: [0.1, 0.18, 0.95, 0.82]."}, {"from": "gpt", "value": "A pristine black commando motorcycle with polished chrome."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: red bike."}, {"from": "gpt", "value": "[0.0, 0.34, 0.33, 0.66]"}]}, {"id": "000000155505", "image": "coco/train2017/000000155505.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: the rig hauling three tractors."}, {"from": "gpt", "value": "[0.1, 0.26, 0.95, 0.75]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a truck and trailer carrying three other vehicles."}, {"from": "gpt", "value": "[0.1, 0.26, 0.95, 0.75]"}]}, {"id": "000000543201", "image": "coco/train2017/000000543201.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.08, 0.31, 0.35, 0.58]."}, {"from": "gpt", "value": "Plants next to flowers."}, {"from": "human", "value": "Please provide a short description for this region: [0.29, 0.37, 0.52, 0.65]."}, {"from": "gpt", "value": "Red flowers."}, {"from": "human", "value": "Please provide a short description for this region: [0.08, 0.31, 0.35, 0.58]."}, {"from": "gpt", "value": "Plants at 9 o clock."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: flowers next to little girl."}, {"from": "gpt", "value": "[0.29, 0.37, 0.52, 0.65]"}, {"from": "human", "value": "Please provide a short description for this region: [0.08, 0.31, 0.35, 0.58]."}, {"from": "gpt", "value": "Plant in rectangular stone planter."}]}, {"id": "000000543201", "image": "coco/train2017/000000543201.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: black trough of plants."}, {"from": "gpt", "value": "[0.08, 0.31, 0.35, 0.58]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: pink flowers."}, {"from": "gpt", "value": "[0.29, 0.37, 0.52, 0.65]"}, {"from": "human", "value": "Please provide a short description for this region: [0.29, 0.37, 0.52, 0.65]."}, {"from": "gpt", "value": "Pink flowers."}, {"from": "human", "value": "Please provide a short description for this region: [0.29, 0.37, 0.52, 0.65]."}, {"from": "gpt", "value": "Flowers by little girl."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: gray planter with green bushes."}, {"from": "gpt", "value": "[0.08, 0.31, 0.35, 0.58]"}]}, {"id": "000000543201", "image": "coco/train2017/000000543201.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: flowers beside girl."}, {"from": "gpt", "value": "[0.29, 0.37, 0.52, 0.65]"}]}, {"id": "000000502894", "image": "coco/train2017/000000502894.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a women holding bicycle and a dog."}, {"from": "gpt", "value": "[0.32, 0.15, 0.5, 0.83]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a woman in a pink blouse straddles the frame of her bicycle."}, {"from": "gpt", "value": "[0.32, 0.15, 0.5, 0.83]"}]}, {"id": "000000382890", "image": "coco/train2017/000000382890.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.65, 0.43, 0.91, 0.63]."}, {"from": "gpt", "value": "Furthest bus."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bus to the left."}, {"from": "gpt", "value": "[0.1, 0.29, 0.65, 0.69]"}, {"from": "human", "value": "Please provide a short description for this region: [0.1, 0.29, 0.65, 0.69]."}, {"from": "gpt", "value": "Front bus."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: red bus closest to us."}, {"from": "gpt", "value": "[0.1, 0.29, 0.65, 0.69]"}, {"from": "human", "value": "Please provide a short description for this region: [0.1, 0.29, 0.65, 0.69]."}, {"from": "gpt", "value": "Bus closest to you."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bus furtthest away."}, {"from": "gpt", "value": "[0.65, 0.43, 0.91, 0.63]"}, {"from": "human", "value": "Please provide a short description for this region: [0.65, 0.43, 0.91, 0.63]."}, {"from": "gpt", "value": "Bus on right."}]}, {"id": "000000382890", "image": "coco/train2017/000000382890.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: bus on the left."}, {"from": "gpt", "value": "[0.1, 0.29, 0.65, 0.69]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: farther double decker bus."}, {"from": "gpt", "value": "[0.65, 0.43, 0.91, 0.63]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bus with james bond."}, {"from": "gpt", "value": "[0.1, 0.29, 0.65, 0.69]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bus at the back."}, {"from": "gpt", "value": "[0.65, 0.43, 0.91, 0.63]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a red double - decker bus in front of another red double - decker bus."}, {"from": "gpt", "value": "[0.65, 0.43, 0.91, 0.63]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the red bus that is behind the bus with the bond logo on the side."}, {"from": "gpt", "value": "[0.65, 0.43, 0.91, 0.63]"}, {"from": "human", "value": "Please provide a short description for this region: [0.65, 0.43, 0.91, 0.63]."}, {"from": "gpt", "value": "Right bus."}]}, {"id": "000000292053", "image": "coco/train2017/000000292053.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: the stuffed teddy bear."}, {"from": "gpt", "value": "[0.57, 0.4, 0.84, 0.77]"}, {"from": "human", "value": "Please provide a short description for this region: [0.57, 0.4, 0.84, 0.77]."}, {"from": "gpt", "value": "A large teddy bear wearing biker goggles."}]}, {"id": "000000286877", "image": "coco/train2017/000000286877.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.0, 0.4, 0.23, 0.74]."}, {"from": "gpt", "value": "Blue train seat facing the camera."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.4, 0.23, 0.74]."}, {"from": "gpt", "value": "A blue subway seat facing a pole."}]}, {"id": "000000295655", "image": "coco/train2017/000000295655.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.18, 0.55, 0.46, 0.98]."}, {"from": "gpt", "value": "Bicycle parked behind the lady near camera."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: silver bike next to lady."}, {"from": "gpt", "value": "[0.18, 0.55, 0.46, 0.98]"}]}, {"id": "000000111831", "image": "coco/train2017/000000111831.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: yellow bus left."}, {"from": "gpt", "value": "[0.78, 0.53, 1.0, 0.74]"}, {"from": "human", "value": "Please provide a short description for this region: [0.78, 0.53, 1.0, 0.74]."}, {"from": "gpt", "value": "Yellow jeep."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: middle bus blurry."}, {"from": "gpt", "value": "[0.31, 0.53, 0.71, 0.62]"}, {"from": "human", "value": "Please provide a short description for this region: [0.78, 0.53, 1.0, 0.74]."}, {"from": "gpt", "value": "Yellow bus cut off on the side."}, {"from": "human", "value": "Please provide a short description for this region: [0.78, 0.53, 1.0, 0.74]."}, {"from": "gpt", "value": "The yellow bus."}, {"from": "human", "value": "Please provide a short description for this region: [0.31, 0.53, 0.71, 0.62]."}, {"from": "gpt", "value": "Yellow colour bus cross the road."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: yellow bus lit in street."}, {"from": "gpt", "value": "[0.31, 0.53, 0.71, 0.62]"}]}, {"id": "000000111831", "image": "coco/train2017/000000111831.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.31, 0.53, 0.71, 0.62]."}, {"from": "gpt", "value": "Whatever that blurry light colored vehicle is dead center."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bus in focus."}, {"from": "gpt", "value": "[0.78, 0.53, 1.0, 0.74]"}, {"from": "human", "value": "Please provide a short description for this region: [0.78, 0.53, 1.0, 0.74]."}, {"from": "gpt", "value": "Bus far right."}, {"from": "human", "value": "Please provide a short description for this region: [0.31, 0.53, 0.71, 0.62]."}, {"from": "gpt", "value": "Blurry bus."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: very blurry yellow bus in the very center."}, {"from": "gpt", "value": "[0.31, 0.53, 0.71, 0.62]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a yellow bus stopped at a red light."}, {"from": "gpt", "value": "[0.78, 0.53, 1.0, 0.74]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bus beside car."}, {"from": "gpt", "value": "[0.78, 0.53, 1.0, 0.74]"}]}, {"id": "000000201706", "image": "coco/train2017/000000201706.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.36, 0.2, 0.86, 0.72]."}, {"from": "gpt", "value": "Main bus."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bus."}, {"from": "gpt", "value": "[0.36, 0.2, 0.86, 0.72]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bus."}, {"from": "gpt", "value": "[0.36, 0.2, 0.86, 0.72]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: front bus."}, {"from": "gpt", "value": "[0.36, 0.2, 0.86, 0.72]"}, {"from": "human", "value": "Please provide a short description for this region: [0.36, 0.2, 0.86, 0.72]."}, {"from": "gpt", "value": "Main bus."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bus."}, {"from": "gpt", "value": "[0.36, 0.2, 0.86, 0.72]"}]}, {"id": "000000427283", "image": "coco/train2017/000000427283.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a pink double decker train sitting at the station."}, {"from": "gpt", "value": "[0.17, 0.27, 0.78, 0.83]"}, {"from": "human", "value": "Please provide a short description for this region: [0.17, 0.27, 0.78, 0.83]."}, {"from": "gpt", "value": "The train in between the two platforms seen."}]}, {"id": "000000520769", "image": "coco/train2017/000000520769.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a girl tossing a softball."}, {"from": "gpt", "value": "[0.54, 0.09, 0.92, 0.87]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a girl in a blue uniform and orange socks throws a softball."}, {"from": "gpt", "value": "[0.54, 0.09, 0.92, 0.87]"}]}, {"id": "000000098162", "image": "coco/train2017/000000098162.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.4, 0.35, 0.68, 0.61]."}, {"from": "gpt", "value": "A man and a woman in a pool , where the woman is wearing a red bathing suit and is hitting the man with a noodle."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a woman in a pink bikini."}, {"from": "gpt", "value": "[0.21, 0.26, 0.47, 0.86]"}, {"from": "human", "value": "Please provide a short description for this region: [0.4, 0.35, 0.68, 0.61]."}, {"from": "gpt", "value": "A men is standing between to women in the swimming pool."}, {"from": "human", "value": "Please provide a short description for this region: [0.21, 0.26, 0.47, 0.86]."}, {"from": "gpt", "value": "The girl holding the frisbee in the right hand picture."}]}, {"id": "000000003915", "image": "coco/train2017/000000003915.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.65, 0.58, 1.0, 0.86]."}, {"from": "gpt", "value": "Purple flowers in a white vase next to the silverware."}, {"from": "human", "value": "Please provide a short description for this region: [0.65, 0.58, 1.0, 0.86]."}, {"from": "gpt", "value": "Flowers in front right."}]}, {"id": "000000107975", "image": "coco/train2017/000000107975.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.0, 0.17, 0.41, 0.82]."}, {"from": "gpt", "value": "A person in red shirt smiling and excited about the pizza."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a person in a red shirt."}, {"from": "gpt", "value": "[0.0, 0.17, 0.41, 0.82]"}]}, {"id": "000000209745", "image": "coco/train2017/000000209745.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: man puts a spoon in his mouth."}, {"from": "gpt", "value": "[0.17, 0.03, 0.48, 0.42]"}, {"from": "human", "value": "Please provide a short description for this region: [0.17, 0.03, 0.48, 0.42]."}, {"from": "gpt", "value": "Man who is dining."}]}, {"id": "000000146841", "image": "coco/train2017/000000146841.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.06, 0.56, 0.65, 0.82]."}, {"from": "gpt", "value": "The bananas."}, {"from": "human", "value": "Please provide a short description for this region: [0.06, 0.56, 0.65, 0.82]."}, {"from": "gpt", "value": "Banana bunches."}]}, {"id": "000000374174", "image": "coco/train2017/000000374174.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.5, 0.36, 0.9, 0.56]."}, {"from": "gpt", "value": "A black car being transported on a truck."}, {"from": "human", "value": "Please provide a short description for this region: [0.5, 0.36, 0.9, 0.56]."}, {"from": "gpt", "value": "A black car on a tow truck."}]}, {"id": "000000257162", "image": "coco/train2017/000000257162.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: the black truck."}, {"from": "gpt", "value": "[0.04, 0.54, 0.82, 0.78]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a black pickup truck with a website and phone number on the side."}, {"from": "gpt", "value": "[0.04, 0.54, 0.82, 0.78]"}]}, {"id": "000000199619", "image": "coco/train2017/000000199619.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a pair of bananas at the left of the other."}, {"from": "gpt", "value": "[0.18, 0.21, 0.56, 0.53]"}]}, {"id": "000000258611", "image": "coco/train2017/000000258611.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.0, 0.56, 0.24, 0.82]."}, {"from": "gpt", "value": "An empty chair with wooden arms and legs and light colored padding with an article of clothing hanging over it."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a wooden chair with beige cushions."}, {"from": "gpt", "value": "[0.0, 0.56, 0.24, 0.82]"}]}, {"id": "000000347248", "image": "coco/train2017/000000347248.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: carrots."}, {"from": "gpt", "value": "[0.15, 0.34, 0.34, 0.59]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: four thick , stubby carrots in the corner of a green plastic dish."}, {"from": "gpt", "value": "[0.15, 0.34, 0.34, 0.59]"}]}, {"id": "000000056065", "image": "coco/train2017/000000056065.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: the air canada airplane driving towards the terminal."}, {"from": "gpt", "value": "[0.0, 0.36, 0.42, 0.52]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: an airplane that says air canada."}, {"from": "gpt", "value": "[0.0, 0.36, 0.42, 0.52]"}]}, {"id": "000000488547", "image": "coco/train2017/000000488547.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.47, 0.5, 0.67, 0.86]."}, {"from": "gpt", "value": "Man in plaid jacket on stairs."}, {"from": "human", "value": "Please provide a short description for this region: [0.47, 0.5, 0.67, 0.86]."}, {"from": "gpt", "value": "Man walking up the stairs."}]}, {"id": "000000457618", "image": "coco/train2017/000000457618.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.0, 0.12, 0.99, 0.87]."}, {"from": "gpt", "value": "A man dressed in a white shirt and red tie."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a man with a button up shirt and tie sitting in a room with 2 other people."}, {"from": "gpt", "value": "[0.0, 0.12, 0.99, 0.87]"}]}, {"id": "000000421542", "image": "coco/train2017/000000421542.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.72, 0.61, 1.0, 0.77]."}, {"from": "gpt", "value": "A stove with a pot."}]}, {"id": "VG_100K_2/419", "image": "vg/VG_100K_2/419.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.76, 0.01, 0.99, 0.62]."}, {"from": "gpt", "value": "The blind is in an open position."}, {"from": "human", "value": "Please provide a short description for this region: [0.23, 0.14, 0.45, 0.33]."}, {"from": "gpt", "value": "Blonde hair of a person."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.25, 0.23, 0.43]."}, {"from": "gpt", "value": "Brown paneling on wall."}, {"from": "human", "value": "Please provide a short description for this region: [0.44, 0.46, 0.9, 0.99]."}, {"from": "gpt", "value": "The woman's jacket is black in color."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: woman with blonde hair."}, {"from": "gpt", "value": "[0.55, 0.19, 0.81, 0.5]"}, {"from": "human", "value": "Please provide a short description for this region: [0.52, 0.18, 0.82, 0.49]."}, {"from": "gpt", "value": "The woman's hair is blonde."}, {"from": "human", "value": "Please provide a short description for this region: [0.12, 0.38, 0.4, 0.5]."}, {"from": "gpt", "value": "Man has blue collar."}, {"from": "human", "value": "Please provide a short description for this region: [0.9, 0.59, 0.99, 0.73]."}, {"from": "gpt", "value": "The lampshade is grey in color."}, {"from": "human", "value": "Please provide a short description for this region: [0.21, 0.09, 0.53, 0.4]."}, {"from": "gpt", "value": "The man's hair is dark brown."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man has brown hair."}, {"from": "gpt", "value": "[0.14, 0.07, 0.52, 0.39]"}]}, {"id": "VG_100K_2/667", "image": "vg/VG_100K_2/667.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: A long sleeved white shirt."}, {"from": "gpt", "value": "[0.55, 0.57, 0.63, 0.64]"}, {"from": "human", "value": "Please provide a short description for this region: [0.15, 0.41, 0.49, 0.46]."}, {"from": "gpt", "value": "Red sign on a red wall."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: head of a person."}, {"from": "gpt", "value": "[0.01, 0.54, 0.08, 0.6]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Woman wearing pink sweater."}, {"from": "gpt", "value": "[0.3, 0.53, 0.4, 0.77]"}, {"from": "human", "value": "Please provide a short description for this region: [0.18, 0.57, 0.26, 0.73]."}, {"from": "gpt", "value": "Red dress on a woman."}, {"from": "human", "value": "Please provide a short description for this region: [0.03, 0.61, 0.1, 0.72]."}, {"from": "gpt", "value": "A purple shirt on a woman."}, {"from": "human", "value": "Please provide a short description for this region: [0.2, 0.31, 0.24, 0.4]."}, {"from": "gpt", "value": "Red flag above red and white sign."}, {"from": "human", "value": "Please provide a short description for this region: [0.74, 0.66, 0.8, 0.8]."}, {"from": "gpt", "value": "Black pants on a man."}]}, {"id": "VG_100K_2/726", "image": "vg/VG_100K_2/726.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.81, 0.78, 0.87, 0.82]."}, {"from": "gpt", "value": "Fog light of a car."}, {"from": "human", "value": "Please provide a short description for this region: [0.83, 0.75, 0.89, 0.8]."}, {"from": "gpt", "value": "Headlight on front of car."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A front tire on a motorbike."}, {"from": "gpt", "value": "[0.65, 0.72, 0.68, 0.78]"}, {"from": "human", "value": "Please provide a short description for this region: [0.35, 0.5, 0.4, 0.55]."}, {"from": "gpt", "value": "Window of a building."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: window of a building."}, {"from": "gpt", "value": "[0.18, 0.52, 0.24, 0.61]"}, {"from": "human", "value": "Please provide a short description for this region: [0.74, 0.72, 0.8, 0.78]."}, {"from": "gpt", "value": "Headlight of a car."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.52, 0.16, 0.78]."}, {"from": "gpt", "value": "Graffiti on side of metal building."}, {"from": "human", "value": "Please provide a short description for this region: [0.4, 0.51, 0.44, 0.57]."}, {"from": "gpt", "value": "A lit window on a building."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: brown tree trunk."}, {"from": "gpt", "value": "[0.5, 0.47, 0.55, 0.75]"}, {"from": "human", "value": "Please provide a short description for this region: [0.85, 0.76, 0.91, 0.83]."}, {"from": "gpt", "value": "The headlight of a car."}]}, {"id": "VG_100K_2/1428", "image": "vg/VG_100K_2/1428.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: window on a large brick building."}, {"from": "gpt", "value": "[0.19, 0.3, 0.22, 0.34]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white car on the pavement."}, {"from": "gpt", "value": "[0.35, 0.59, 0.5, 0.63]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a white compact car."}, {"from": "gpt", "value": "[0.36, 0.59, 0.5, 0.65]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: this is a car."}, {"from": "gpt", "value": "[0.36, 0.58, 0.52, 0.67]"}, {"from": "human", "value": "Please provide a short description for this region: [0.36, 0.59, 0.51, 0.65]."}, {"from": "gpt", "value": "Car is white and small."}, {"from": "human", "value": "Please provide a short description for this region: [0.8, 0.27, 0.84, 0.62]."}, {"from": "gpt", "value": "Red lamppost on the street."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Window of a building."}, {"from": "gpt", "value": "[0.95, 0.4, 0.99, 0.44]"}, {"from": "human", "value": "Please provide a short description for this region: [0.95, 0.25, 0.98, 0.27]."}, {"from": "gpt", "value": "Window of a building."}, {"from": "human", "value": "Please provide a short description for this region: [0.34, 0.58, 0.52, 0.66]."}, {"from": "gpt", "value": "A white car on the street."}]}, {"id": "VG_100K_2/1500", "image": "vg/VG_100K_2/1500.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a car on a street."}, {"from": "gpt", "value": "[0.72, 0.41, 0.91, 0.55]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a car in the distnace."}, {"from": "gpt", "value": "[0.63, 0.4, 0.69, 0.45]"}, {"from": "human", "value": "Please provide a short description for this region: [0.09, 0.48, 0.12, 0.57]."}, {"from": "gpt", "value": "A window on a building."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Bike parked at meter."}, {"from": "gpt", "value": "[0.4, 0.44, 0.47, 0.59]"}, {"from": "human", "value": "Please provide a short description for this region: [0.4, 0.46, 0.48, 0.57]."}, {"from": "gpt", "value": "A bike on the sidewalk."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Grill of a car."}, {"from": "gpt", "value": "[0.62, 0.62, 0.75, 0.65]"}, {"from": "human", "value": "Please provide a short description for this region: [0.42, 0.42, 0.45, 0.57]."}, {"from": "gpt", "value": "The parking meter next to the woman walking."}, {"from": "human", "value": "Please provide a short description for this region: [0.75, 0.61, 0.82, 0.65]."}, {"from": "gpt", "value": "Headlight of a car."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a long white line."}, {"from": "gpt", "value": "[0.82, 0.65, 1.0, 0.82]"}]}, {"id": "VG_100K_2/1974", "image": "vg/VG_100K_2/1974.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.33, 0.13, 0.45, 0.38]."}, {"from": "gpt", "value": "Flag hanging on the building."}, {"from": "human", "value": "Please provide a short description for this region: [0.88, 0.31, 0.94, 0.38]."}, {"from": "gpt", "value": "A window on a building."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Letters on the flag."}, {"from": "gpt", "value": "[0.64, 0.15, 0.69, 0.19]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: yellow and white square on red banner."}, {"from": "gpt", "value": "[0.37, 0.23, 0.42, 0.28]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: window in the building."}, {"from": "gpt", "value": "[0.29, 0.19, 0.34, 0.32]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a red color flag with words on it."}, {"from": "gpt", "value": "[0.17, 0.19, 0.26, 0.42]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Shield on the front of the banner."}, {"from": "gpt", "value": "[0.33, 0.15, 0.48, 0.42]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Person in a white shirt."}, {"from": "gpt", "value": "[0.04, 0.46, 0.07, 0.5]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the shield is white in color."}, {"from": "gpt", "value": "[0.36, 0.16, 0.43, 0.31]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: person sitting on steps in white shirt."}, {"from": "gpt", "value": "[0.03, 0.47, 0.08, 0.51]"}]}, {"id": "VG_100K_2/2007", "image": "vg/VG_100K_2/2007.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.44, 0.35, 0.5, 0.46]."}, {"from": "gpt", "value": "White lamp at table."}, {"from": "human", "value": "Please provide a short description for this region: [0.22, 0.3, 0.32, 0.44]."}, {"from": "gpt", "value": "Brown coat hanger."}, {"from": "human", "value": "Please provide a short description for this region: [0.74, 0.4, 0.83, 0.48]."}, {"from": "gpt", "value": "A tv on a dresser in a room."}, {"from": "human", "value": "Please provide a short description for this region: [0.06, 0.44, 0.16, 0.51]."}, {"from": "gpt", "value": "Wall is off white."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a hanger in the closet."}, {"from": "gpt", "value": "[0.24, 0.34, 0.3, 0.42]"}, {"from": "human", "value": "Please provide a short description for this region: [0.88, 0.5, 0.94, 0.61]."}, {"from": "gpt", "value": "White light switch on wall."}, {"from": "human", "value": "Please provide a short description for this region: [0.44, 0.37, 0.49, 0.5]."}, {"from": "gpt", "value": "A lamp on a desk."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white thermostat on wall."}, {"from": "gpt", "value": "[0.04, 0.29, 0.14, 0.41]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the door to the room."}, {"from": "gpt", "value": "[0.52, 0.3, 0.63, 0.56]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a white pillow."}, {"from": "gpt", "value": "[0.23, 0.2, 0.29, 0.32]"}]}, {"id": "VG_100K_2/2267", "image": "vg/VG_100K_2/2267.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.29, 0.48, 0.37, 0.56]."}, {"from": "gpt", "value": "Car is in the street."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: glass window on building."}, {"from": "gpt", "value": "[0.7, 0.16, 0.75, 0.19]"}, {"from": "human", "value": "Please provide a short description for this region: [0.22, 0.65, 0.26, 0.68]."}, {"from": "gpt", "value": "License plate on the gray car."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: dark and light street."}, {"from": "gpt", "value": "[0.4, 0.62, 0.65, 0.78]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a black and silver fire hydrant."}, {"from": "gpt", "value": "[0.0, 0.75, 0.08, 0.87]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Fire hydrant on the left."}, {"from": "gpt", "value": "[0.0, 0.74, 0.08, 0.87]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.34, 0.16, 0.5]."}, {"from": "gpt", "value": "Tree next to street."}, {"from": "human", "value": "Please provide a short description for this region: [0.75, 0.59, 0.86, 0.68]."}, {"from": "gpt", "value": "Back tire of van."}, {"from": "human", "value": "Please provide a short description for this region: [0.9, 0.39, 0.95, 0.45]."}, {"from": "gpt", "value": "A red and white street sign."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Writing on white truck."}, {"from": "gpt", "value": "[0.37, 0.47, 0.42, 0.55]"}]}, {"id": "VG_100K_2/2431", "image": "vg/VG_100K_2/2431.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.5, 0.75, 0.55, 0.78]."}, {"from": "gpt", "value": "Boat on the water."}, {"from": "human", "value": "Please provide a short description for this region: [0.91, 0.64, 0.97, 0.7]."}, {"from": "gpt", "value": "A tall building in the distance."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: thin clouds in sky."}, {"from": "gpt", "value": "[0.12, 0.13, 0.3, 0.37]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A tall building off in the distance."}, {"from": "gpt", "value": "[0.74, 0.66, 0.79, 0.72]"}, {"from": "human", "value": "Please provide a short description for this region: [0.82, 0.62, 0.84, 0.7]."}, {"from": "gpt", "value": "Smoke stack by the water."}, {"from": "human", "value": "Please provide a short description for this region: [0.1, 0.78, 0.34, 0.81]."}, {"from": "gpt", "value": "Dock in the water."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Antenna on the building."}, {"from": "gpt", "value": "[0.49, 0.68, 0.52, 0.72]"}]}, {"id": "VG_100K_2/2680", "image": "vg/VG_100K_2/2680.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.84, 0.43, 0.87, 0.57]."}, {"from": "gpt", "value": "A tree in the park."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.57, 0.95, 0.59]."}, {"from": "gpt", "value": "Grass near the lake."}, {"from": "human", "value": "Please provide a short description for this region: [0.07, 0.5, 0.11, 0.56]."}, {"from": "gpt", "value": "A tree in a field."}, {"from": "human", "value": "Please provide a short description for this region: [0.3, 0.35, 0.48, 0.58]."}, {"from": "gpt", "value": "A tree with no leaves on it."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: grass under the trees."}, {"from": "gpt", "value": "[0.4, 0.55, 0.55, 0.6]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The grass is green in color."}, {"from": "gpt", "value": "[0.01, 0.56, 0.96, 0.6]"}]}, {"id": "VG_100K_2/2688", "image": "vg/VG_100K_2/2688.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.6, 0.57, 0.62, 0.63]."}, {"from": "gpt", "value": "Banner on a pole."}, {"from": "human", "value": "Please provide a short description for this region: [0.35, 0.62, 0.55, 0.68]."}, {"from": "gpt", "value": "Windows from the basement."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Fence next to the sidewalk."}, {"from": "gpt", "value": "[0.14, 0.83, 0.25, 0.99]"}, {"from": "human", "value": "Please provide a short description for this region: [0.25, 0.44, 0.3, 0.5]."}, {"from": "gpt", "value": "Small window with window sill underneath."}, {"from": "human", "value": "Please provide a short description for this region: [0.8, 0.53, 0.87, 0.63]."}, {"from": "gpt", "value": "Small window with window sill underneath."}, {"from": "human", "value": "Please provide a short description for this region: [0.51, 0.71, 0.61, 0.8]."}, {"from": "gpt", "value": "Car parked on the curb."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: barrel near the building."}, {"from": "gpt", "value": "[0.73, 0.79, 0.78, 0.88]"}, {"from": "human", "value": "Please provide a short description for this region: [0.79, 0.66, 0.86, 0.71]."}, {"from": "gpt", "value": "\"hotel\" written on a building."}, {"from": "human", "value": "Please provide a short description for this region: [0.19, 0.65, 0.22, 0.84]."}, {"from": "gpt", "value": "Black pole holding up a clock."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: small window with window sill underneath."}, {"from": "gpt", "value": "[0.43, 0.28, 0.48, 0.33]"}]}, {"id": "VG_100K_2/3296", "image": "vg/VG_100K_2/3296.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: black power line in air."}, {"from": "gpt", "value": "[0.0, 0.15, 0.67, 0.21]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Bottom part of bench is steel."}, {"from": "gpt", "value": "[0.19, 0.74, 0.41, 0.8]"}, {"from": "human", "value": "Please provide a short description for this region: [0.84, 0.14, 0.92, 0.27]."}, {"from": "gpt", "value": "Window on side of building."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the hedges are thick."}, {"from": "gpt", "value": "[0.32, 0.32, 0.66, 0.49]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the hedges are green."}, {"from": "gpt", "value": "[0.36, 0.31, 0.74, 0.39]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A brown and green bench."}, {"from": "gpt", "value": "[0.12, 0.66, 0.48, 0.8]"}, {"from": "human", "value": "Please provide a short description for this region: [0.09, 0.78, 0.36, 0.87]."}, {"from": "gpt", "value": "Shadow on sidewalk."}, {"from": "human", "value": "Please provide a short description for this region: [0.14, 0.66, 0.47, 0.71]."}, {"from": "gpt", "value": "Two back slats of a brown bench."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Top part of bench is wooden."}, {"from": "gpt", "value": "[0.11, 0.66, 0.49, 0.75]"}, {"from": "human", "value": "Please provide a short description for this region: [0.88, 0.4, 0.99, 0.77]."}, {"from": "gpt", "value": "Stone rock column."}]}, {"id": "VG_100K_2/3346", "image": "vg/VG_100K_2/3346.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.25, 0.62, 0.35, 0.68]."}, {"from": "gpt", "value": "The man's pants are white."}, {"from": "human", "value": "Please provide a short description for this region: [0.26, 0.54, 0.34, 0.73]."}, {"from": "gpt", "value": "Man in white pants walking."}, {"from": "human", "value": "Please provide a short description for this region: [0.21, 0.12, 0.23, 0.28]."}, {"from": "gpt", "value": "Shutter on the building."}, {"from": "human", "value": "Please provide a short description for this region: [0.24, 0.64, 0.32, 0.71]."}, {"from": "gpt", "value": "A few plastic grocery bags."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Sun glasses on the man."}, {"from": "gpt", "value": "[0.28, 0.54, 0.32, 0.57]"}, {"from": "human", "value": "Please provide a short description for this region: [0.26, 0.64, 0.29, 0.7]."}, {"from": "gpt", "value": "The bags are white."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a young girl in a white shirt."}, {"from": "gpt", "value": "[0.34, 0.58, 0.42, 0.75]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the person is standing."}, {"from": "gpt", "value": "[0.35, 0.6, 0.39, 0.75]"}, {"from": "human", "value": "Please provide a short description for this region: [0.46, 0.29, 0.58, 0.45]."}, {"from": "gpt", "value": "A row of second floor balconies."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a mature tree in the distance."}, {"from": "gpt", "value": "[0.3, 0.33, 0.42, 0.58]"}]}, {"id": "VG_100K_2/3507", "image": "vg/VG_100K_2/3507.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: can with green cap."}, {"from": "gpt", "value": "[0.64, 0.74, 0.73, 0.87]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: green watering can with spout."}, {"from": "gpt", "value": "[0.81, 0.56, 0.99, 0.83]"}, {"from": "human", "value": "Please provide a short description for this region: [0.81, 0.56, 0.99, 0.84]."}, {"from": "gpt", "value": "A large green tea kettle."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A small kitchen window."}, {"from": "gpt", "value": "[0.0, 0.13, 0.14, 0.35]"}, {"from": "human", "value": "Please provide a short description for this region: [0.4, 0.49, 0.58, 0.6]."}, {"from": "gpt", "value": "A green and tan carton."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: carton is filled with oj."}, {"from": "gpt", "value": "[0.39, 0.49, 0.57, 0.58]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the cup has red outer surface."}, {"from": "gpt", "value": "[0.39, 0.62, 0.46, 0.71]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A tall coffee maker."}, {"from": "gpt", "value": "[0.0, 0.55, 0.22, 0.87]"}, {"from": "human", "value": "Please provide a short description for this region: [0.18, 0.27, 0.23, 0.37]."}, {"from": "gpt", "value": "A white spray bottle."}, {"from": "human", "value": "Please provide a short description for this region: [0.81, 0.55, 1.0, 0.85]."}, {"from": "gpt", "value": "Watering can is green."}]}, {"id": "VG_100K_2/3616", "image": "vg/VG_100K_2/3616.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: woman has a nose."}, {"from": "gpt", "value": "[0.45, 0.49, 0.53, 0.61]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: eyes are color brown."}, {"from": "gpt", "value": "[0.37, 0.46, 0.6, 0.53]"}, {"from": "human", "value": "Please provide a short description for this region: [0.34, 0.24, 0.65, 0.47]."}, {"from": "gpt", "value": "Bangs on a woman's forehead."}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.48, 0.53, 0.61]."}, {"from": "gpt", "value": "A woman's nose."}, {"from": "human", "value": "Please provide a short description for this region: [0.3, 0.47, 0.35, 0.59]."}, {"from": "gpt", "value": "Woman has an ear."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: right ear of a woman."}, {"from": "gpt", "value": "[0.3, 0.45, 0.36, 0.6]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A nose of a human female."}, {"from": "gpt", "value": "[0.44, 0.49, 0.54, 0.62]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: woman has an eye."}, {"from": "gpt", "value": "[0.38, 0.48, 0.47, 0.52]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: brown collar on a sweater."}, {"from": "gpt", "value": "[0.31, 0.68, 0.67, 0.87]"}, {"from": "human", "value": "Please provide a short description for this region: [0.41, 0.63, 0.57, 0.68]."}, {"from": "gpt", "value": "Mouth of a woman."}]}, {"id": "VG_100K_2/3973", "image": "vg/VG_100K_2/3973.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a bowl on a table."}, {"from": "gpt", "value": "[0.3, 0.54, 0.46, 0.63]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A black framed picture hanging on the wall."}, {"from": "gpt", "value": "[0.0, 0.28, 0.06, 0.45]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a green cushion in a chair."}, {"from": "gpt", "value": "[0.55, 0.67, 0.6, 0.72]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: brown bowl sitting on the table."}, {"from": "gpt", "value": "[0.3, 0.55, 0.46, 0.62]"}, {"from": "human", "value": "Please provide a short description for this region: [0.56, 0.36, 0.8, 0.48]."}, {"from": "gpt", "value": "A window on a building."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a brown and white pillow in a small chair."}, {"from": "gpt", "value": "[0.63, 0.52, 0.71, 0.6]"}, {"from": "human", "value": "Please provide a short description for this region: [0.12, 0.53, 0.24, 0.62]."}, {"from": "gpt", "value": "A chair that you sit in."}, {"from": "human", "value": "Please provide a short description for this region: [0.13, 0.35, 0.22, 0.59]."}, {"from": "gpt", "value": "A window on a building."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a pillow in a chair."}, {"from": "gpt", "value": "[0.65, 0.51, 0.71, 0.61]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a light on the wall."}, {"from": "gpt", "value": "[0.91, 0.2, 1.0, 0.35]"}]}, {"id": "VG_100K_2/4306", "image": "vg/VG_100K_2/4306.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: paper towel holder on the wall."}, {"from": "gpt", "value": "[0.74, 0.36, 0.92, 0.48]"}, {"from": "human", "value": "Please provide a short description for this region: [0.83, 0.37, 0.91, 0.44]."}, {"from": "gpt", "value": "A wooden paper towel rack."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: book beside a closed water bottle."}, {"from": "gpt", "value": "[0.49, 0.47, 0.6, 0.6]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Black microwave next to a cabinet."}, {"from": "gpt", "value": "[0.47, 0.17, 0.74, 0.34]"}, {"from": "human", "value": "Please provide a short description for this region: [0.37, 0.48, 0.45, 0.54]."}, {"from": "gpt", "value": "Gray pitcher next to the sink."}, {"from": "human", "value": "Please provide a short description for this region: [0.5, 0.47, 0.53, 0.49]."}, {"from": "gpt", "value": "White cap on the bottle."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Silver sink fixtures."}, {"from": "gpt", "value": "[0.24, 0.48, 0.36, 0.55]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Soap bottle next to the sink."}, {"from": "gpt", "value": "[0.16, 0.43, 0.2, 0.55]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: light switch on the wall."}, {"from": "gpt", "value": "[0.01, 0.46, 0.05, 0.59]"}]}, {"id": "VG_100K_2/4439", "image": "vg/VG_100K_2/4439.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: window above a shower."}, {"from": "gpt", "value": "[0.12, 0.0, 0.17, 0.09]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the hose of the shower head."}, {"from": "gpt", "value": "[0.22, 0.21, 0.32, 0.67]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: White plate on wall."}, {"from": "gpt", "value": "[0.62, 0.46, 0.66, 0.5]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: seat of the toilet."}, {"from": "gpt", "value": "[0.69, 0.65, 0.75, 0.68]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: White box on top of white toilet."}, {"from": "gpt", "value": "[0.7, 0.54, 0.76, 0.59]"}, {"from": "human", "value": "Please provide a short description for this region: [0.57, 0.53, 0.62, 0.62]."}, {"from": "gpt", "value": "A flower vase on the counter top."}, {"from": "human", "value": "Please provide a short description for this region: [0.7, 0.37, 0.77, 0.45]."}, {"from": "gpt", "value": "The top picture frame is dark in color."}, {"from": "human", "value": "Please provide a short description for this region: [0.7, 0.36, 0.77, 0.56]."}, {"from": "gpt", "value": "Black framed pictures hanging on the wall."}, {"from": "human", "value": "Please provide a short description for this region: [0.57, 0.54, 0.62, 0.61]."}, {"from": "gpt", "value": "A vase with flowers on a counter."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the bottom picture frame is dark in color."}, {"from": "gpt", "value": "[0.7, 0.46, 0.77, 0.54]"}]}, {"id": "VG_100K_2/2415079", "image": "vg/VG_100K_2/2415079.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.31, 0.32, 0.47, 0.36]."}, {"from": "gpt", "value": "Blue water."}, {"from": "human", "value": "Please provide a short description for this region: [0.47, 0.14, 0.82, 0.55]."}, {"from": "gpt", "value": "A little boat floating on the water."}, {"from": "human", "value": "Please provide a short description for this region: [0.57, 0.67, 0.82, 1.0]."}, {"from": "gpt", "value": "A table which is next to a chair."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the back of a very old boat."}, {"from": "gpt", "value": "[0.62, 0.45, 0.82, 0.54]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: metal railing on side of boat."}, {"from": "gpt", "value": "[0.48, 0.34, 0.58, 0.46]"}, {"from": "human", "value": "Please provide a short description for this region: [0.62, 0.44, 0.82, 0.54]."}, {"from": "gpt", "value": "Back end of the boat."}, {"from": "human", "value": "Please provide a short description for this region: [0.53, 0.44, 0.64, 0.55]."}, {"from": "gpt", "value": "A twisted rope hanging from the boat."}, {"from": "human", "value": "Please provide a short description for this region: [0.46, 0.24, 0.52, 0.4]."}, {"from": "gpt", "value": "Long pole on boat."}, {"from": "human", "value": "Please provide a short description for this region: [0.48, 0.2, 0.82, 0.32]."}, {"from": "gpt", "value": "Cloth sails on a boat."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a large straw container in the center of the boat."}, {"from": "gpt", "value": "[0.59, 0.36, 0.7, 0.45]"}]}, {"id": "VG_100K/150489", "image": "vg/VG_100K/150489.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.71, 0.51, 0.81, 0.63]."}, {"from": "gpt", "value": "Portable stairs on tarmac."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: front half of white minivan."}, {"from": "gpt", "value": "[0.95, 0.59, 1.0, 0.66]"}, {"from": "human", "value": "Please provide a short description for this region: [0.37, 0.33, 0.4, 0.39]."}, {"from": "gpt", "value": "The surinam airways logo on the tail."}, {"from": "human", "value": "Please provide a short description for this region: [0.7, 0.45, 0.75, 0.51]."}, {"from": "gpt", "value": "Cargo hatch of airplane."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: tail of the aircraft."}, {"from": "gpt", "value": "[0.27, 0.3, 0.43, 0.43]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a small puffy cloud."}, {"from": "gpt", "value": "[0.88, 0.26, 0.96, 0.29]"}, {"from": "human", "value": "Please provide a short description for this region: [0.37, 0.73, 0.46, 0.8]."}, {"from": "gpt", "value": "Pavement is gray."}, {"from": "human", "value": "Please provide a short description for this region: [0.56, 0.4, 0.7, 0.43]."}, {"from": "gpt", "value": "Red writing on side of plane."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white van with dark windows."}, {"from": "gpt", "value": "[0.15, 0.67, 0.34, 0.81]"}, {"from": "human", "value": "Please provide a short description for this region: [0.52, 0.48, 0.64, 0.53]."}, {"from": "gpt", "value": "Tires under large airplane."}]}, {"id": "VG_100K/285640", "image": "vg/VG_100K/285640.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: person skiing on white ground."}, {"from": "gpt", "value": "[0.56, 0.51, 0.65, 0.64]"}, {"from": "human", "value": "Please provide a short description for this region: [0.3, 0.71, 0.39, 0.8]."}, {"from": "gpt", "value": "Ski tracks in white snow."}, {"from": "human", "value": "Please provide a short description for this region: [0.44, 0.7, 0.6, 0.83]."}, {"from": "gpt", "value": "Large patch of snow."}, {"from": "human", "value": "Please provide a short description for this region: [0.6, 0.6, 0.65, 0.66]."}, {"from": "gpt", "value": "A pair of skis."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: tree post on the border of the trail."}, {"from": "gpt", "value": "[0.47, 0.14, 0.54, 0.47]"}, {"from": "human", "value": "Please provide a short description for this region: [0.38, 0.64, 0.44, 0.69]."}, {"from": "gpt", "value": "Ski tracks in white snow."}, {"from": "human", "value": "Please provide a short description for this region: [0.58, 0.52, 0.65, 0.59]."}, {"from": "gpt", "value": "Person wearing a red jacket."}, {"from": "human", "value": "Please provide a short description for this region: [0.73, 0.57, 0.78, 0.62]."}, {"from": "gpt", "value": "Ski tracks in white snow."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A snowy telephone pole."}, {"from": "gpt", "value": "[0.46, 0.12, 0.51, 0.44]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: ski tracks in white snow."}, {"from": "gpt", "value": "[0.39, 0.51, 0.46, 0.57]"}]}, {"id": "VG_100K/285809", "image": "vg/VG_100K/285809.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.73, 0.42, 0.79, 0.54]."}, {"from": "gpt", "value": "The eye is surrounded by black hair."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the eyes are black."}, {"from": "gpt", "value": "[0.68, 0.41, 0.83, 0.56]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Piece of the white ceiling."}, {"from": "gpt", "value": "[0.9, 0.14, 1.0, 0.27]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A link on the fence."}, {"from": "gpt", "value": "[0.64, 0.6, 0.75, 0.71]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: brown spot of a giraffe."}, {"from": "gpt", "value": "[0.61, 0.14, 0.71, 0.25]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.2, 0.09, 0.34]."}, {"from": "gpt", "value": "Ear of a person."}, {"from": "human", "value": "Please provide a short description for this region: [0.63, 0.53, 0.74, 0.63]."}, {"from": "gpt", "value": "A link on the fence."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the side of a person's nose."}, {"from": "gpt", "value": "[0.18, 0.38, 0.23, 0.45]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: brown spot of a giraffe."}, {"from": "gpt", "value": "[0.67, 0.16, 0.75, 0.26]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: right hand of the boy."}, {"from": "gpt", "value": "[0.32, 0.7, 0.5, 0.86]"}]}, {"id": "VG_100K/285955", "image": "vg/VG_100K/285955.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: the bowl of a toilet."}, {"from": "gpt", "value": "[0.5, 0.84, 0.71, 0.93]"}, {"from": "human", "value": "Please provide a short description for this region: [0.61, 0.33, 0.73, 0.52]."}, {"from": "gpt", "value": "Chrome bath tub faucets on blue tile."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The white towel on the right."}, {"from": "gpt", "value": "[0.83, 0.0, 0.87, 0.34]"}, {"from": "human", "value": "Please provide a short description for this region: [0.37, 0.88, 0.42, 0.92]."}, {"from": "gpt", "value": "Blue tile on bathroom floor."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: blue tile on bathroom floor."}, {"from": "gpt", "value": "[0.22, 0.92, 0.27, 0.96]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the tub."}, {"from": "gpt", "value": "[0.27, 0.66, 0.38, 0.73]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The soap holding wall area."}, {"from": "gpt", "value": "[0.51, 0.05, 0.63, 0.16]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the lid of a toilet."}, {"from": "gpt", "value": "[0.54, 0.72, 0.69, 0.86]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: blue tile on bathroom floor."}, {"from": "gpt", "value": "[0.45, 0.86, 0.5, 0.9]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the white tile on a floor."}, {"from": "gpt", "value": "[0.45, 0.93, 0.51, 0.98]"}]}, {"id": "VG_100K/498287", "image": "vg/VG_100K/498287.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.63, 0.53, 0.71, 0.84]."}, {"from": "gpt", "value": "Part of women's body."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the mouth is open."}, {"from": "gpt", "value": "[0.63, 0.29, 0.66, 0.31]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: part of women's body."}, {"from": "gpt", "value": "[0.55, 0.54, 0.58, 0.59]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: part of women's body."}, {"from": "gpt", "value": "[0.6, 0.81, 0.68, 0.87]"}, {"from": "human", "value": "Please provide a short description for this region: [0.58, 0.81, 0.62, 0.86]."}, {"from": "gpt", "value": "Part of women's body."}, {"from": "human", "value": "Please provide a short description for this region: [0.62, 0.26, 0.68, 0.29]."}, {"from": "gpt", "value": "Glasses are clear."}, {"from": "human", "value": "Please provide a short description for this region: [0.67, 0.34, 0.73, 0.61]."}, {"from": "gpt", "value": "Part of women's body."}]}, {"id": "VG_100K/498390", "image": "vg/VG_100K/498390.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: man holding a mouse."}, {"from": "gpt", "value": "[0.04, 0.79, 0.15, 0.87]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a man with red hair."}, {"from": "gpt", "value": "[0.72, 0.38, 0.85, 0.49]"}, {"from": "human", "value": "Please provide a short description for this region: [0.16, 0.52, 0.18, 0.55]."}, {"from": "gpt", "value": "The eye of the face."}, {"from": "human", "value": "Please provide a short description for this region: [0.15, 0.51, 0.18, 0.53]."}, {"from": "gpt", "value": "The eyebrow of the face."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a man wearing a red hat."}, {"from": "gpt", "value": "[0.06, 0.43, 0.2, 0.54]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a red baseball hat."}, {"from": "gpt", "value": "[0.04, 0.41, 0.21, 0.55]"}]}, {"id": "VG_100K/713552", "image": "vg/VG_100K/713552.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: A letter on a sign."}, {"from": "gpt", "value": "[0.23, 0.3, 0.31, 0.43]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the shirt is open."}, {"from": "gpt", "value": "[0.02, 0.1, 0.15, 0.19]"}, {"from": "human", "value": "Please provide a short description for this region: [0.69, 0.85, 0.73, 0.89]."}, {"from": "gpt", "value": "Anklet is around the ankle."}, {"from": "human", "value": "Please provide a short description for this region: [0.64, 0.85, 0.76, 0.98]."}, {"from": "gpt", "value": "White tennis shoe with light green laces."}, {"from": "human", "value": "Please provide a short description for this region: [0.01, 0.02, 0.18, 0.2]."}, {"from": "gpt", "value": "Man wearing a white colored shirt."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a letter on a banner."}, {"from": "gpt", "value": "[0.08, 0.3, 0.17, 0.4]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a letter on a banner."}, {"from": "gpt", "value": "[0.15, 0.3, 0.23, 0.41]"}, {"from": "human", "value": "Please provide a short description for this region: [0.88, 0.06, 0.95, 0.11]."}, {"from": "gpt", "value": "A hat to block the sun."}, {"from": "human", "value": "Please provide a short description for this region: [0.84, 0.58, 0.9, 0.69]."}, {"from": "gpt", "value": "Tennis player with white sneaker."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man wearing a white shirt."}, {"from": "gpt", "value": "[0.24, 0.04, 0.41, 0.21]"}]}, {"id": "VG_100K/1159314", "image": "vg/VG_100K/1159314.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.88, 0.37, 0.93, 0.44]."}, {"from": "gpt", "value": "White clouds in blue sky."}, {"from": "human", "value": "Please provide a short description for this region: [0.6, 0.63, 0.65, 0.67]."}, {"from": "gpt", "value": "Dole logo on the ship."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a container on the boat."}, {"from": "gpt", "value": "[0.54, 0.55, 0.58, 0.69]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white clouds in blue sky."}, {"from": "gpt", "value": "[0.84, 0.24, 0.9, 0.3]"}, {"from": "human", "value": "Please provide a short description for this region: [0.4, 0.51, 0.5, 0.62]."}, {"from": "gpt", "value": "A container on the boat."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A bridge behind a ship."}, {"from": "gpt", "value": "[0.87, 0.58, 1.0, 0.63]"}, {"from": "human", "value": "Please provide a short description for this region: [0.73, 0.48, 0.82, 0.65]."}, {"from": "gpt", "value": "A container on the boat."}, {"from": "human", "value": "Please provide a short description for this region: [0.59, 0.65, 0.66, 0.68]."}, {"from": "gpt", "value": "Logo has blue underline."}, {"from": "human", "value": "Please provide a short description for this region: [0.67, 0.55, 0.79, 0.67]."}, {"from": "gpt", "value": "A container on the boat."}, {"from": "human", "value": "Please provide a short description for this region: [0.58, 0.64, 0.68, 0.68]."}, {"from": "gpt", "value": "Boat has logo on it."}]}, {"id": "VG_100K/1159426", "image": "vg/VG_100K/1159426.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: Expressionless face."}, {"from": "gpt", "value": "[0.51, 0.23, 0.64, 0.37]"}, {"from": "human", "value": "Please provide a short description for this region: [0.46, 0.18, 0.56, 0.35]."}, {"from": "gpt", "value": "The metal security door."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Empty glass on a coffee table."}, {"from": "gpt", "value": "[0.11, 0.63, 0.22, 0.81]"}, {"from": "human", "value": "Please provide a short description for this region: [0.02, 0.33, 0.1, 0.36]."}, {"from": "gpt", "value": "White wii remote control."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Glass sitting on table."}, {"from": "gpt", "value": "[0.12, 0.63, 0.22, 0.8]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: White Wii remote control."}, {"from": "gpt", "value": "[0.32, 0.43, 0.41, 0.47]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: wrist watch on left hand."}, {"from": "gpt", "value": "[0.71, 0.54, 0.74, 0.57]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Gold colored bangle bracelets."}, {"from": "gpt", "value": "[0.82, 0.38, 0.86, 0.44]"}, {"from": "human", "value": "Please provide a short description for this region: [0.43, 0.21, 0.46, 0.26]."}, {"from": "gpt", "value": "The electrical outlet."}, {"from": "human", "value": "Please provide a short description for this region: [0.48, 0.54, 0.64, 0.6]."}, {"from": "gpt", "value": "The zip lock bag between the girls in shorts."}]}, {"id": "VG_100K/1159527", "image": "vg/VG_100K/1159527.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: White lines marking crosswalk."}, {"from": "gpt", "value": "[0.0, 0.56, 0.51, 0.61]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Yellow traffic signal light."}, {"from": "gpt", "value": "[0.46, 0.34, 0.49, 0.4]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a white sign."}, {"from": "gpt", "value": "[0.45, 0.46, 0.48, 0.49]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A low, metal fence."}, {"from": "gpt", "value": "[0.66, 0.49, 0.95, 0.54]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the pole is color silver."}, {"from": "gpt", "value": "[0.44, 0.27, 0.48, 0.56]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a street light."}, {"from": "gpt", "value": "[0.38, 0.24, 0.42, 0.26]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Street lamp attached to pole."}, {"from": "gpt", "value": "[0.38, 0.24, 0.47, 0.55]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the traffic light on a pole."}, {"from": "gpt", "value": "[0.45, 0.34, 0.49, 0.4]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a window on the house."}, {"from": "gpt", "value": "[0.75, 0.46, 0.79, 0.5]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white lines in the street."}, {"from": "gpt", "value": "[0.14, 0.56, 0.21, 0.6]"}]}, {"id": "VG_100K/1159964", "image": "vg/VG_100K/1159964.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: screws holding metal to board."}, {"from": "gpt", "value": "[0.68, 0.93, 0.74, 1.0]"}, {"from": "human", "value": "Please provide a short description for this region: [0.49, 0.61, 0.69, 0.72]."}, {"from": "gpt", "value": "The orange sparks are flying."}, {"from": "human", "value": "Please provide a short description for this region: [0.39, 0.7, 0.48, 0.75]."}, {"from": "gpt", "value": "The fingers of a man."}, {"from": "human", "value": "Please provide a short description for this region: [0.41, 0.66, 0.57, 0.75]."}, {"from": "gpt", "value": "The man is holding rusty scissors."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bolts on the left side."}, {"from": "gpt", "value": "[0.34, 0.83, 0.37, 0.92]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A person eating a orange."}, {"from": "gpt", "value": "[0.64, 0.68, 0.7, 0.81]"}, {"from": "human", "value": "Please provide a short description for this region: [0.17, 0.02, 0.27, 0.22]."}, {"from": "gpt", "value": "Green bush in the background."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a man wearing a brown cap."}, {"from": "gpt", "value": "[0.17, 0.16, 0.24, 0.27]"}]}, {"id": "VG_100K/1591777", "image": "vg/VG_100K/1591777.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: the back tire of a bike."}, {"from": "gpt", "value": "[0.42, 0.66, 0.47, 0.74]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: person in orange shirt riding a bike."}, {"from": "gpt", "value": "[0.4, 0.51, 0.53, 0.77]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a black car."}, {"from": "gpt", "value": "[0.61, 0.56, 0.69, 0.63]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a person riding a bike."}, {"from": "gpt", "value": "[0.42, 0.54, 0.51, 0.73]"}, {"from": "human", "value": "Please provide a short description for this region: [0.4, 0.51, 0.53, 0.75]."}, {"from": "gpt", "value": "Person in orange shirt riding a bike."}, {"from": "human", "value": "Please provide a short description for this region: [0.4, 0.51, 0.52, 0.76]."}, {"from": "gpt", "value": "Person in orange shirt riding a bike."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: person in orange shirt riding a bike."}, {"from": "gpt", "value": "[0.4, 0.49, 0.54, 0.75]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: person wearing orange coat."}, {"from": "gpt", "value": "[0.42, 0.53, 0.5, 0.74]"}, {"from": "human", "value": "Please provide a short description for this region: [0.4, 0.52, 0.53, 0.75]."}, {"from": "gpt", "value": "Person in orange shirt riding a bike."}]}, {"id": "VG_100K/1592056", "image": "vg/VG_100K/1592056.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.57, 0.5, 0.83, 0.56]."}, {"from": "gpt", "value": "The handrail behind the toilet."}, {"from": "human", "value": "Please provide a short description for this region: [0.27, 0.45, 0.51, 0.59]."}, {"from": "gpt", "value": "White handwash hanging in the wall."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the handrail beside the toilet."}, {"from": "gpt", "value": "[0.82, 0.57, 0.87, 0.97]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A sink in a bathroom."}, {"from": "gpt", "value": "[0.27, 0.46, 0.51, 0.59]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A gojo soap dispenser on a bathroom wall."}, {"from": "gpt", "value": "[0.52, 0.37, 0.57, 0.47]"}, {"from": "human", "value": "Please provide a short description for this region: [0.52, 0.36, 0.58, 0.47]."}, {"from": "gpt", "value": "A white and gray soap dispenser."}, {"from": "human", "value": "Please provide a short description for this region: [0.26, 0.46, 0.5, 0.59]."}, {"from": "gpt", "value": "A silver faucet over a white sink."}, {"from": "human", "value": "Please provide a short description for this region: [0.59, 0.34, 0.69, 0.44]."}, {"from": "gpt", "value": "White bricks on the bathroom wall."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A open toilet seat."}, {"from": "gpt", "value": "[0.59, 0.53, 0.74, 0.72]"}, {"from": "human", "value": "Please provide a short description for this region: [0.38, 0.48, 0.43, 0.52]."}, {"from": "gpt", "value": "A silver colored faucet on a white sink."}]}, {"id": "VG_100K/1592217", "image": "vg/VG_100K/1592217.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: can of coca cola."}, {"from": "gpt", "value": "[0.55, 0.64, 0.62, 0.73]"}, {"from": "human", "value": "Please provide a short description for this region: [0.23, 0.44, 0.34, 0.51]."}, {"from": "gpt", "value": "The shoulder of a man."}, {"from": "human", "value": "Please provide a short description for this region: [0.46, 0.26, 0.62, 0.29]."}, {"from": "gpt", "value": "Frame hanging on the wall."}, {"from": "human", "value": "Please provide a short description for this region: [0.56, 0.64, 0.61, 0.72]."}, {"from": "gpt", "value": "Coca-cola can on coffee table."}, {"from": "human", "value": "Please provide a short description for this region: [0.27, 0.44, 0.66, 0.51]."}, {"from": "gpt", "value": "The arm of a man."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white strap around the wrist."}, {"from": "gpt", "value": "[0.18, 0.59, 0.21, 0.68]"}, {"from": "human", "value": "Please provide a short description for this region: [0.24, 0.43, 0.44, 0.67]."}, {"from": "gpt", "value": "The man is wearing a blue shirt."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: arm is lifted up."}, {"from": "gpt", "value": "[0.31, 0.4, 0.69, 0.5]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the portfolio is blue and black."}, {"from": "gpt", "value": "[0.32, 0.66, 0.57, 0.73]"}]}, {"id": "VG_100K/1592355", "image": "vg/VG_100K/1592355.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.2, 0.51, 0.34, 0.68]."}, {"from": "gpt", "value": "Plant on the wall."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: leg of the woman."}, {"from": "gpt", "value": "[0.51, 0.86, 0.54, 0.94]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: purple skirt on woman."}, {"from": "gpt", "value": "[0.56, 0.7, 0.67, 0.82]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: pink flower petal on the ground."}, {"from": "gpt", "value": "[0.62, 0.97, 0.65, 0.99]"}, {"from": "human", "value": "Please provide a short description for this region: [0.62, 0.92, 0.64, 0.96]."}, {"from": "gpt", "value": "Shoe on the foot."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: tan kitten length heeled shoes."}, {"from": "gpt", "value": "[0.45, 0.94, 0.54, 0.98]"}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.95, 0.48, 0.97]."}, {"from": "gpt", "value": "Foot of the person."}]}, {"id": "VG_100K/1592914", "image": "vg/VG_100K/1592914.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.39, 0.68, 0.54, 0.74]."}, {"from": "gpt", "value": "Guy in black swimsuit holding surfboard."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A window on a building."}, {"from": "gpt", "value": "[0.91, 0.31, 0.93, 0.33]"}, {"from": "human", "value": "Please provide a short description for this region: [0.4, 0.66, 0.48, 0.76]."}, {"from": "gpt", "value": "The man is wearing black."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: people on the beach."}, {"from": "gpt", "value": "[0.51, 0.44, 0.59, 0.52]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: person playing near beach and water."}, {"from": "gpt", "value": "[0.43, 0.68, 0.47, 0.73]"}, {"from": "human", "value": "Please provide a short description for this region: [0.37, 0.54, 0.45, 0.64]."}, {"from": "gpt", "value": "The kid is holding a surfboard."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: sign on the beach."}, {"from": "gpt", "value": "[0.73, 0.35, 0.76, 0.42]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: building has a gray roof."}, {"from": "gpt", "value": "[0.86, 0.26, 0.9, 0.29]"}]}, {"id": "VG_100K/1593111", "image": "vg/VG_100K/1593111.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.31, 0.57, 0.48, 0.75]."}, {"from": "gpt", "value": "A person eating a orange."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: sky crane over building under construction."}, {"from": "gpt", "value": "[0.65, 0.27, 0.71, 0.36]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: large construction equipment on top of building."}, {"from": "gpt", "value": "[0.57, 0.25, 0.73, 0.38]"}, {"from": "human", "value": "Please provide a short description for this region: [0.02, 0.43, 0.07, 0.54]."}, {"from": "gpt", "value": "A tall street light."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: blue gate in front of parking area."}, {"from": "gpt", "value": "[0.69, 0.6, 0.81, 0.65]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: line of post keeping traffic off median."}, {"from": "gpt", "value": "[0.81, 0.6, 0.96, 0.64]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a red and white sign."}, {"from": "gpt", "value": "[0.48, 0.41, 0.53, 0.47]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: small area of trees."}, {"from": "gpt", "value": "[0.0, 0.5, 0.3, 0.62]"}, {"from": "human", "value": "Please provide a short description for this region: [0.47, 0.41, 0.53, 0.47]."}, {"from": "gpt", "value": "Red circular sign with white stripe."}]}, {"id": "VG_100K_2/2409242", "image": "vg/VG_100K_2/2409242.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.32, 0.67, 0.46, 0.8]."}, {"from": "gpt", "value": "Small white bush next to hydrant."}, {"from": "human", "value": "Please provide a short description for this region: [0.28, 0.63, 0.56, 0.86]."}, {"from": "gpt", "value": "White bush on the ground."}, {"from": "human", "value": "Please provide a short description for this region: [0.52, 0.54, 0.63, 0.68]."}, {"from": "gpt", "value": "Metal coil attached to a hydrant."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: green grass surrounding fire hydrant."}, {"from": "gpt", "value": "[0.5, 0.9, 0.61, 0.99]"}, {"from": "human", "value": "Please provide a short description for this region: [0.14, 0.64, 0.2, 0.72]."}, {"from": "gpt", "value": "Brown metal pipe in ground."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: brown metal cap on middle left of picture."}, {"from": "gpt", "value": "[0.13, 0.64, 0.2, 0.69]"}, {"from": "human", "value": "Please provide a short description for this region: [0.46, 0.05, 0.54, 0.13]."}, {"from": "gpt", "value": "Small red flag flying in sky."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: red flag on a metal pole."}, {"from": "gpt", "value": "[0.47, 0.06, 0.62, 0.64]"}, {"from": "human", "value": "Please provide a short description for this region: [0.46, 0.05, 0.6, 0.68]."}, {"from": "gpt", "value": "Red flag attached to fire hydrant."}, {"from": "human", "value": "Please provide a short description for this region: [0.47, 0.11, 0.61, 0.65]."}, {"from": "gpt", "value": "Metal rod with a coil on the bottom."}]}, {"id": "VG_100K_2/2408852", "image": "vg/VG_100K_2/2408852.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: hanging tongue of dog."}, {"from": "gpt", "value": "[0.46, 0.42, 0.5, 0.46]"}, {"from": "human", "value": "Please provide a short description for this region: [0.28, 0.35, 0.59, 0.63]."}, {"from": "gpt", "value": "Labrador dog on dirt bike."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A man in jeans."}, {"from": "gpt", "value": "[0.22, 0.24, 0.37, 0.77]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: holes in blue jeans."}, {"from": "gpt", "value": "[0.31, 0.61, 0.36, 0.66]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Exhaust/tail pipe of dirt bike."}, {"from": "gpt", "value": "[0.14, 0.64, 0.18, 0.69]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A dog with it's tongue hanging out."}, {"from": "gpt", "value": "[0.39, 0.33, 0.54, 0.47]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man's hand on steering wheel."}, {"from": "gpt", "value": "[0.35, 0.53, 0.4, 0.57]"}, {"from": "human", "value": "Please provide a short description for this region: [0.17, 0.26, 0.41, 0.82]."}, {"from": "gpt", "value": "Man in blue shirt and jeans riding on a motorcycle."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: This is a guard."}, {"from": "gpt", "value": "[0.14, 0.52, 0.72, 0.72]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: This is the front tire."}, {"from": "gpt", "value": "[0.52, 0.69, 0.81, 0.84]"}]}, {"id": "VG_100K_2/2408931", "image": "vg/VG_100K_2/2408931.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.11, 0.21, 0.47, 0.44]."}, {"from": "gpt", "value": "A dried up plant."}, {"from": "human", "value": "Please provide a short description for this region: [0.12, 0.35, 0.22, 0.55]."}, {"from": "gpt", "value": "Black horns curving away from each other then closer together."}, {"from": "human", "value": "Please provide a short description for this region: [0.56, 0.21, 0.98, 0.5]."}, {"from": "gpt", "value": "Medium sized black and white zebra standing in muddy water."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a zebra standing in the background."}, {"from": "gpt", "value": "[0.58, 0.18, 1.0, 0.48]"}, {"from": "human", "value": "Please provide a short description for this region: [0.11, 0.36, 0.24, 0.55]."}, {"from": "gpt", "value": "Two curved horns."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: light-colored spots on back."}, {"from": "gpt", "value": "[0.52, 0.39, 0.65, 0.51]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Zebra is faced right."}, {"from": "gpt", "value": "[0.6, 0.18, 0.99, 0.5]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: yellowish grass."}, {"from": "gpt", "value": "[0.67, 0.5, 0.99, 0.77]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: low-growing mossy plants behind legs."}, {"from": "gpt", "value": "[0.23, 0.55, 0.84, 0.76]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: zebra's head above muddy ground."}, {"from": "gpt", "value": "[0.83, 0.23, 0.98, 0.55]"}]}, {"id": "VG_100K_2/2408963", "image": "vg/VG_100K_2/2408963.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: black and white soccer boots."}, {"from": "gpt", "value": "[0.59, 0.5, 0.67, 0.64]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white paint on building."}, {"from": "gpt", "value": "[0.13, 0.27, 0.2, 0.39]"}, {"from": "human", "value": "Please provide a short description for this region: [0.58, 0.44, 0.73, 0.53]."}, {"from": "gpt", "value": "Grey shorts wiht white stripe."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Grass."}, {"from": "gpt", "value": "[0.14, 0.7, 0.32, 0.74]"}, {"from": "human", "value": "Please provide a short description for this region: [0.77, 0.35, 0.98, 0.52]."}, {"from": "gpt", "value": "A long sleeve red shirt."}, {"from": "human", "value": "Please provide a short description for this region: [0.41, 0.75, 0.6, 0.81]."}, {"from": "gpt", "value": "White chalk line on grass field."}, {"from": "human", "value": "Please provide a short description for this region: [0.78, 0.42, 1.0, 0.68]."}, {"from": "gpt", "value": "Lady wearing blue shorts."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.29, 0.05, 0.73]."}, {"from": "gpt", "value": "Person on the right with a red hat entering the picture."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A girl wearing grey shorts with a white stripe."}, {"from": "gpt", "value": "[0.6, 0.26, 0.75, 0.6]"}, {"from": "human", "value": "Please provide a short description for this region: [0.77, 0.63, 0.94, 0.8]."}, {"from": "gpt", "value": "Red and white socks."}]}, {"id": "VG_100K_2/2407217", "image": "vg/VG_100K_2/2407217.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: the grass is green."}, {"from": "gpt", "value": "[0.29, 0.69, 0.71, 0.79]"}, {"from": "human", "value": "Please provide a short description for this region: [0.77, 0.37, 0.87, 0.47]."}, {"from": "gpt", "value": "A chimney for the building."}, {"from": "human", "value": "Please provide a short description for this region: [0.03, 0.58, 0.09, 0.68]."}, {"from": "gpt", "value": "Wood fence posts."}, {"from": "human", "value": "Please provide a short description for this region: [0.59, 0.39, 0.82, 0.66]."}, {"from": "gpt", "value": "A giraffe bending over to eat."}, {"from": "human", "value": "Please provide a short description for this region: [0.6, 0.56, 0.72, 0.65]."}, {"from": "gpt", "value": "An entrance to the building."}, {"from": "human", "value": "Please provide a short description for this region: [0.46, 0.6, 1.0, 0.67]."}, {"from": "gpt", "value": "Tall brown grass by the fence."}, {"from": "human", "value": "Please provide a short description for this region: [0.59, 0.37, 0.66, 0.46]."}, {"from": "gpt", "value": "Head of a giraffe."}, {"from": "human", "value": "Please provide a short description for this region: [0.35, 0.56, 0.87, 0.62]."}, {"from": "gpt", "value": "The wall is brown."}, {"from": "human", "value": "Please provide a short description for this region: [0.67, 0.5, 0.77, 0.66]."}, {"from": "gpt", "value": "Front legs of a giraffe."}, {"from": "human", "value": "Please provide a short description for this region: [0.13, 0.69, 0.92, 0.79]."}, {"from": "gpt", "value": "Grass patch in field."}]}, {"id": "VG_100K_2/2406877", "image": "vg/VG_100K_2/2406877.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.04, 0.67, 0.13, 0.77]."}, {"from": "gpt", "value": "Pipe with short red hose."}, {"from": "human", "value": "Please provide a short description for this region: [0.06, 0.13, 0.2, 0.45]."}, {"from": "gpt", "value": "Giraffe standing in front of large feet and hems."}, {"from": "human", "value": "Please provide a short description for this region: [0.32, 0.37, 0.6, 0.82]."}, {"from": "gpt", "value": "The giraffe looks bored."}, {"from": "human", "value": "Please provide a short description for this region: [0.02, 0.48, 0.34, 0.71]."}, {"from": "gpt", "value": "Patch of green grass."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: giraffe walking by painted panel."}, {"from": "gpt", "value": "[0.73, 0.13, 0.9, 0.45]"}, {"from": "human", "value": "Please provide a short description for this region: [0.46, 0.13, 0.56, 0.41]."}, {"from": "gpt", "value": "A painting on the wall."}, {"from": "human", "value": "Please provide a short description for this region: [0.06, 0.68, 0.1, 0.72]."}, {"from": "gpt", "value": "A water spigot in the ground."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: horns on a head."}, {"from": "gpt", "value": "[0.42, 0.4, 0.45, 0.43]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: hieroglyphics written on the statue."}, {"from": "gpt", "value": "[0.62, 0.26, 0.69, 0.34]"}, {"from": "human", "value": "Please provide a short description for this region: [0.04, 0.66, 0.1, 0.77]."}, {"from": "gpt", "value": "A water hydrant."}]}, {"id": "VG_100K_2/2406696", "image": "vg/VG_100K_2/2406696.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: choppy waves of the river."}, {"from": "gpt", "value": "[0.69, 0.58, 1.0, 0.72]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Man sitting on bench."}, {"from": "gpt", "value": "[0.29, 0.35, 0.57, 0.77]"}, {"from": "human", "value": "Please provide a short description for this region: [0.27, 0.34, 0.53, 0.56]."}, {"from": "gpt", "value": "Man with glasses and dark hair."}, {"from": "human", "value": "Please provide a short description for this region: [0.38, 0.37, 0.43, 0.4]."}, {"from": "gpt", "value": "Eyeglasses on the man's face."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: wooden posts in water."}, {"from": "gpt", "value": "[0.0, 0.59, 0.06, 0.68]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: high top Nike sneaker."}, {"from": "gpt", "value": "[0.49, 0.69, 0.58, 0.77]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Man in white tank sitting."}, {"from": "gpt", "value": "[0.3, 0.35, 0.57, 0.76]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Man on bench wearing sport shoes."}, {"from": "gpt", "value": "[0.39, 0.68, 0.56, 0.77]"}, {"from": "human", "value": "Please provide a short description for this region: [0.31, 0.42, 0.5, 0.64]."}, {"from": "gpt", "value": "White tank top on man."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Tall buildings in the distance."}, {"from": "gpt", "value": "[0.1, 0.25, 0.73, 0.44]"}]}, {"id": "VG_100K_2/2406607", "image": "vg/VG_100K_2/2406607.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.58, 0.45, 0.8, 0.61]."}, {"from": "gpt", "value": "Fence along the sidewalk."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: People laying on the beach."}, {"from": "gpt", "value": "[0.73, 0.43, 0.98, 0.54]"}, {"from": "human", "value": "Please provide a short description for this region: [0.07, 0.67, 0.36, 0.79]."}, {"from": "gpt", "value": "Baggy tan pants on crossed legs."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: dog is scavaging on the sidewalk."}, {"from": "gpt", "value": "[0.38, 0.65, 0.48, 0.77]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: sand on the beach."}, {"from": "gpt", "value": "[0.62, 0.44, 1.0, 0.58]"}, {"from": "human", "value": "Please provide a short description for this region: [0.37, 0.49, 0.4, 0.64]."}, {"from": "gpt", "value": "Brick wall along the walkway."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Young man with no shirt."}, {"from": "gpt", "value": "[0.01, 0.45, 0.37, 0.82]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: beige pants on shirtless man."}, {"from": "gpt", "value": "[0.07, 0.67, 0.35, 0.81]"}, {"from": "human", "value": "Please provide a short description for this region: [0.67, 0.49, 0.76, 0.54]."}, {"from": "gpt", "value": "Beach goers on a blanket."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Streetlight beside a beachside walkway."}, {"from": "gpt", "value": "[0.39, 0.19, 0.42, 0.45]"}]}, {"id": "VG_100K_2/2406580", "image": "vg/VG_100K_2/2406580.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: Long green string beans."}, {"from": "gpt", "value": "[0.04, 0.19, 0.29, 0.49]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Vegetables for sale."}, {"from": "gpt", "value": "[0.45, 0.16, 0.61, 0.39]"}, {"from": "human", "value": "Please provide a short description for this region: [0.6, 0.53, 0.83, 0.73]."}, {"from": "gpt", "value": "Lots of fruit for sale."}, {"from": "human", "value": "Please provide a short description for this region: [0.59, 0.51, 0.85, 0.71]."}, {"from": "gpt", "value": "The nuts are brown."}, {"from": "human", "value": "Please provide a short description for this region: [0.28, 0.15, 0.52, 0.4]."}, {"from": "gpt", "value": "A basket of red tomatos."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: cartons of strawberries."}, {"from": "gpt", "value": "[0.81, 0.19, 1.0, 0.43]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: stem in middle of tomato."}, {"from": "gpt", "value": "[0.29, 0.21, 0.41, 0.31]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.12, 0.28, 0.2]."}, {"from": "gpt", "value": "Yellow bananas sitting in crate."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Berries for sale at the market."}, {"from": "gpt", "value": "[0.58, 0.16, 0.74, 0.46]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Strawberries sitting in green crates."}, {"from": "gpt", "value": "[0.56, 0.17, 0.69, 0.4]"}]}, {"id": "VG_100K_2/2405636", "image": "vg/VG_100K_2/2405636.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.43, 0.61, 0.55, 0.66]."}, {"from": "gpt", "value": "Lit headlights on train."}, {"from": "human", "value": "Please provide a short description for this region: [0.58, 0.71, 0.88, 0.76]."}, {"from": "gpt", "value": "Painted curbs."}, {"from": "human", "value": "Please provide a short description for this region: [0.08, 0.67, 0.15, 0.71]."}, {"from": "gpt", "value": "Red car waiting for train."}, {"from": "human", "value": "Please provide a short description for this region: [0.15, 0.48, 0.59, 0.76]."}, {"from": "gpt", "value": "Moving black train with lights on."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: train is black and large."}, {"from": "gpt", "value": "[0.23, 0.45, 0.61, 0.76]"}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.73, 0.99, 0.86]."}, {"from": "gpt", "value": "Train tracks on the road."}, {"from": "human", "value": "Please provide a short description for this region: [0.83, 0.59, 0.89, 0.76]."}, {"from": "gpt", "value": "Stop sign facing camera."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: object in the sky."}, {"from": "gpt", "value": "[0.09, 0.43, 0.12, 0.46]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: green sign showing 2 streets."}, {"from": "gpt", "value": "[0.85, 0.56, 0.92, 0.59]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Curb on a road."}, {"from": "gpt", "value": "[0.02, 0.75, 0.12, 0.87]"}]}, {"id": "VG_100K_2/2405381", "image": "vg/VG_100K_2/2405381.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.73, 0.69, 0.88, 0.74]."}, {"from": "gpt", "value": "A black boat in the water."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white and gray clouds against blue sky."}, {"from": "gpt", "value": "[0.68, 0.17, 0.97, 0.64]"}, {"from": "human", "value": "Please provide a short description for this region: [0.04, 0.7, 0.18, 0.82]."}, {"from": "gpt", "value": "White boat in blue ocean."}, {"from": "human", "value": "Please provide a short description for this region: [0.25, 0.76, 0.84, 0.85]."}, {"from": "gpt", "value": "Dark blue calm ocean."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white boat in blue ocean."}, {"from": "gpt", "value": "[0.57, 0.69, 0.67, 0.76]"}, {"from": "human", "value": "Please provide a short description for this region: [0.4, 0.34, 0.59, 0.45]."}, {"from": "gpt", "value": "The plane is white in color."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the cloud is white."}, {"from": "gpt", "value": "[0.14, 0.39, 0.38, 0.51]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: gray and white clouds against blue sky."}, {"from": "gpt", "value": "[0.17, 0.37, 0.41, 0.65]"}, {"from": "human", "value": "Please provide a short description for this region: [0.29, 0.68, 0.39, 0.78]."}, {"from": "gpt", "value": "White boat in blue ocean."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: water is dark and calm."}, {"from": "gpt", "value": "[0.29, 0.76, 0.85, 0.84]"}]}, {"id": "VG_100K_2/2404577", "image": "vg/VG_100K_2/2404577.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: the ocean on a cloudy day."}, {"from": "gpt", "value": "[0.0, 0.27, 0.68, 0.38]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Plaid blue shorts on a man."}, {"from": "gpt", "value": "[0.68, 0.44, 0.84, 0.7]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the man is wearing blue swim trunks and has a towel over his shoulders."}, {"from": "gpt", "value": "[0.64, 0.22, 0.85, 0.83]"}, {"from": "human", "value": "Please provide a short description for this region: [0.34, 0.76, 0.52, 0.83]."}, {"from": "gpt", "value": "There are flip flops on the sand."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Waves crashing on sand."}, {"from": "gpt", "value": "[0.19, 0.33, 0.6, 0.45]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: teen standing in the sand."}, {"from": "gpt", "value": "[0.66, 0.23, 0.84, 0.8]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the woman is wearing a red skirt, black sweater and a shirt with a white collar."}, {"from": "gpt", "value": "[0.12, 0.54, 0.32, 0.82]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Shoes sitting in sand."}, {"from": "gpt", "value": "[0.31, 0.76, 0.46, 0.82]"}, {"from": "human", "value": "Please provide a short description for this region: [0.04, 0.34, 0.28, 0.48]."}, {"from": "gpt", "value": "The men in the background are wearing shorts."}, {"from": "human", "value": "Please provide a short description for this region: [0.48, 0.42, 0.64, 0.72]."}, {"from": "gpt", "value": "Tripod on sand."}]}, {"id": "VG_100K_2/2403745", "image": "vg/VG_100K_2/2403745.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: the top of the train car is gray."}, {"from": "gpt", "value": "[0.0, 0.24, 0.55, 0.39]"}, {"from": "human", "value": "Please provide a short description for this region: [0.75, 0.46, 0.89, 0.81]."}, {"from": "gpt", "value": "Ladder to get up and down on the train."}, {"from": "human", "value": "Please provide a short description for this region: [0.02, 0.76, 1.0, 0.81]."}, {"from": "gpt", "value": "Railroad track."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the front train car."}, {"from": "gpt", "value": "[0.82, 0.2, 1.0, 0.71]"}, {"from": "human", "value": "Please provide a short description for this region: [0.19, 0.75, 0.56, 0.83]."}, {"from": "gpt", "value": "Gravel in between the train tracks."}, {"from": "human", "value": "Please provide a short description for this region: [0.03, 0.22, 0.6, 0.48]."}, {"from": "gpt", "value": "Train has gray top."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the numbers are yellow."}, {"from": "gpt", "value": "[0.34, 0.45, 0.53, 0.54]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the train has a window."}, {"from": "gpt", "value": "[0.33, 0.33, 0.53, 0.45]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Yellow handles on the train."}, {"from": "gpt", "value": "[0.54, 0.35, 0.65, 0.47]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a yellow handle for the ladder."}, {"from": "gpt", "value": "[0.75, 0.46, 0.89, 0.68]"}]}, {"id": "VG_100K_2/2403684", "image": "vg/VG_100K_2/2403684.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: Large rocks bordering a water pool."}, {"from": "gpt", "value": "[0.31, 0.14, 0.85, 0.34]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the elephant's trunk is curled up."}, {"from": "gpt", "value": "[0.34, 0.55, 0.46, 0.73]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The tail of the small elephant."}, {"from": "gpt", "value": "[0.22, 0.56, 0.25, 0.68]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.74, 0.32, 0.86]."}, {"from": "gpt", "value": "Grass in habitat at zoo."}, {"from": "human", "value": "Please provide a short description for this region: [0.51, 0.5, 0.6, 0.64]."}, {"from": "gpt", "value": "Trunk of adult elephant."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: wooden logs are next to the elephant."}, {"from": "gpt", "value": "[0.0, 0.52, 0.15, 0.77]"}, {"from": "human", "value": "Please provide a short description for this region: [0.53, 0.47, 0.58, 0.68]."}, {"from": "gpt", "value": "An elephants gray trunk."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: steps that you can walk on."}, {"from": "gpt", "value": "[0.01, 0.33, 0.17, 0.41]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: body of water that elephants drink from."}, {"from": "gpt", "value": "[0.3, 0.39, 0.49, 0.47]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The small elephant's back left leg."}, {"from": "gpt", "value": "[0.22, 0.63, 0.26, 0.72]"}]}, {"id": "VG_100K_2/2403668", "image": "vg/VG_100K_2/2403668.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.19, 0.46, 0.25, 0.62]."}, {"from": "gpt", "value": "A man wearing a uniform."}, {"from": "human", "value": "Please provide a short description for this region: [0.38, 0.23, 0.44, 0.3]."}, {"from": "gpt", "value": "A green tree in a distance."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: green leaves on a tree."}, {"from": "gpt", "value": "[0.16, 0.06, 0.35, 0.32]"}, {"from": "human", "value": "Please provide a short description for this region: [0.66, 0.58, 0.8, 0.62]."}, {"from": "gpt", "value": "An empty field."}, {"from": "human", "value": "Please provide a short description for this region: [0.37, 0.26, 0.41, 0.31]."}, {"from": "gpt", "value": "A green tree in a distance."}, {"from": "human", "value": "Please provide a short description for this region: [0.7, 0.64, 0.85, 0.76]."}, {"from": "gpt", "value": "Three wooden fence posts."}, {"from": "human", "value": "Please provide a short description for this region: [0.43, 0.32, 0.55, 0.43]."}, {"from": "gpt", "value": "A green tree in a distance."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: grass growing through the tracks."}, {"from": "gpt", "value": "[0.57, 0.75, 0.68, 0.81]"}, {"from": "human", "value": "Please provide a short description for this region: [0.26, 0.77, 0.73, 0.99]."}, {"from": "gpt", "value": "Train tracks."}, {"from": "human", "value": "Please provide a short description for this region: [0.69, 0.65, 0.83, 0.76]."}, {"from": "gpt", "value": "A fence."}]}, {"id": "VG_100K_2/2402466", "image": "vg/VG_100K_2/2402466.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.65, 0.36, 0.69, 0.4]."}, {"from": "gpt", "value": "The window of a train."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: this is a train door."}, {"from": "gpt", "value": "[0.62, 0.37, 0.64, 0.42]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The sky is blue."}, {"from": "gpt", "value": "[0.81, 0.18, 1.0, 0.25]"}, {"from": "human", "value": "Please provide a short description for this region: [0.07, 0.33, 0.98, 0.46]."}, {"from": "gpt", "value": "The train is blue in color."}, {"from": "human", "value": "Please provide a short description for this region: [0.18, 0.23, 1.0, 0.33]."}, {"from": "gpt", "value": "Green awning over the far platform."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: blue door on passenger train."}, {"from": "gpt", "value": "[0.11, 0.35, 0.19, 0.48]"}, {"from": "human", "value": "Please provide a short description for this region: [0.65, 0.36, 0.69, 0.39]."}, {"from": "gpt", "value": "This is a train window."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bumped pavement for the blind at train station."}, {"from": "gpt", "value": "[0.15, 0.77, 0.51, 0.8]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: city buildings outside of train station."}, {"from": "gpt", "value": "[0.0, 0.13, 0.19, 0.36]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.46, 0.99, 0.57]."}, {"from": "gpt", "value": "Plants growing along tracks near the wall."}]}, {"id": "VG_100K_2/2402036", "image": "vg/VG_100K_2/2402036.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: Pink candle on left side."}, {"from": "gpt", "value": "[0.23, 0.17, 0.29, 0.36]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: chocolate crumbs and frosting on plate."}, {"from": "gpt", "value": "[0.3, 0.82, 0.55, 0.9]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: White candle in the center."}, {"from": "gpt", "value": "[0.45, 0.17, 0.51, 0.32]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: brown edge of frosting."}, {"from": "gpt", "value": "[0.27, 0.75, 0.46, 0.85]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: whipped frosting on corner of the cake."}, {"from": "gpt", "value": "[0.37, 0.53, 0.58, 0.76]"}, {"from": "human", "value": "Please provide a short description for this region: [0.47, 0.31, 0.52, 0.51]."}, {"from": "gpt", "value": "Pink candle in low."}, {"from": "human", "value": "Please provide a short description for this region: [0.57, 0.87, 0.68, 0.9]."}, {"from": "gpt", "value": "Small crumb in groove of blue plate."}, {"from": "human", "value": "Please provide a short description for this region: [0.31, 0.83, 0.36, 0.86]."}, {"from": "gpt", "value": "Small piece of chocolate cake."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: shadow cast on the table."}, {"from": "gpt", "value": "[0.56, 0.07, 0.88, 0.25]"}]}, {"id": "VG_100K_2/2401434", "image": "vg/VG_100K_2/2401434.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.71, 0.36, 0.86, 0.53]."}, {"from": "gpt", "value": "Trash can is in grass."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Tan building in park."}, {"from": "gpt", "value": "[0.74, 0.17, 0.99, 0.39]"}, {"from": "human", "value": "Please provide a short description for this region: [0.71, 0.36, 0.78, 0.48]."}, {"from": "gpt", "value": "Green garbage can."}, {"from": "human", "value": "Please provide a short description for this region: [0.88, 0.45, 0.93, 0.51]."}, {"from": "gpt", "value": "Section of a lawn."}, {"from": "human", "value": "Please provide a short description for this region: [0.22, 0.37, 0.48, 0.87]."}, {"from": "gpt", "value": "Snake in a man's hand."}, {"from": "human", "value": "Please provide a short description for this region: [0.83, 0.83, 0.86, 0.86]."}, {"from": "gpt", "value": "Edge of a bench."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: brown belt of a man."}, {"from": "gpt", "value": "[0.42, 0.65, 0.66, 0.71]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: tattoo on a shoulder."}, {"from": "gpt", "value": "[0.47, 0.37, 0.56, 0.45]"}, {"from": "human", "value": "Please provide a short description for this region: [0.14, 0.81, 0.21, 0.86]."}, {"from": "gpt", "value": "Part of a bench."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: green grass in a park."}, {"from": "gpt", "value": "[0.03, 0.32, 0.38, 0.37]"}]}, {"id": "VG_100K_2/2401263", "image": "vg/VG_100K_2/2401263.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: white pillows and sheets in front of a wooden head board."}, {"from": "gpt", "value": "[0.17, 0.44, 0.51, 0.62]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: tan wall."}, {"from": "gpt", "value": "[0.17, 0.0, 0.53, 0.36]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white vents on the wall."}, {"from": "gpt", "value": "[0.56, 0.0, 0.59, 0.07]"}, {"from": "human", "value": "Please provide a short description for this region: [0.49, 0.36, 0.55, 0.47]."}, {"from": "gpt", "value": "Lamp attached to bed."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: two pillows in white pillowcases."}, {"from": "gpt", "value": "[0.17, 0.47, 0.54, 0.65]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: black arch design on bed."}, {"from": "gpt", "value": "[0.23, 0.38, 0.39, 0.41]"}, {"from": "human", "value": "Please provide a short description for this region: [0.49, 0.35, 0.56, 0.46]."}, {"from": "gpt", "value": "Pastel colored lamp with a white shade."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: black boarder behind the headboard."}, {"from": "gpt", "value": "[0.17, 0.37, 0.47, 0.47]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: brownish red carpeted floor."}, {"from": "gpt", "value": "[0.22, 0.91, 0.29, 0.95]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: light bluish green colored body of lamp."}, {"from": "gpt", "value": "[0.51, 0.4, 0.53, 0.46]"}]}, {"id": "VG_100K_2/2401219", "image": "vg/VG_100K_2/2401219.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.36, 0.25, 0.49, 0.4]."}, {"from": "gpt", "value": "Both arms around left side."}, {"from": "human", "value": "Please provide a short description for this region: [0.28, 0.24, 0.41, 0.46]."}, {"from": "gpt", "value": "Man holding tennis racket."}, {"from": "human", "value": "Please provide a short description for this region: [0.27, 0.23, 0.52, 0.76]."}, {"from": "gpt", "value": "Man on tennis court."}, {"from": "human", "value": "Please provide a short description for this region: [0.26, 0.26, 0.55, 0.76]."}, {"from": "gpt", "value": "Man is wearing black shirt."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man has dark hair."}, {"from": "gpt", "value": "[0.33, 0.26, 0.47, 0.36]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Man is wearing red and black shorts."}, {"from": "gpt", "value": "[0.41, 0.51, 0.49, 0.72]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: black and red sleeveless shrit."}, {"from": "gpt", "value": "[0.36, 0.33, 0.46, 0.56]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: right sock is white."}, {"from": "gpt", "value": "[0.27, 0.67, 0.34, 0.73]"}, {"from": "human", "value": "Please provide a short description for this region: [0.24, 0.59, 0.53, 0.76]."}, {"from": "gpt", "value": "White socks of man."}, {"from": "human", "value": "Please provide a short description for this region: [0.43, 0.62, 0.47, 0.64]."}, {"from": "gpt", "value": "Black nike logo stitched into sock."}]}, {"id": "VG_100K_2/2398513", "image": "vg/VG_100K_2/2398513.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: black wrist band."}, {"from": "gpt", "value": "[0.43, 0.09, 0.49, 0.14]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the hand of a woman."}, {"from": "gpt", "value": "[0.41, 0.01, 0.48, 0.1]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the ear of a woman."}, {"from": "gpt", "value": "[0.41, 0.34, 0.45, 0.36]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Tennis racket with blue handle."}, {"from": "gpt", "value": "[0.33, 0.42, 0.54, 0.54]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a white sock on the woman."}, {"from": "gpt", "value": "[0.51, 0.89, 0.56, 0.93]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the arm of a woman."}, {"from": "gpt", "value": "[0.31, 0.44, 0.42, 0.61]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: tennis players arm straight out."}, {"from": "gpt", "value": "[0.4, 0.03, 0.56, 0.38]"}, {"from": "human", "value": "Please provide a short description for this region: [0.4, 0.61, 0.6, 0.73]."}, {"from": "gpt", "value": "Pink tennis skirt."}, {"from": "human", "value": "Please provide a short description for this region: [0.4, 0.9, 0.59, 0.99]."}, {"from": "gpt", "value": "White tennis shoes."}, {"from": "human", "value": "Please provide a short description for this region: [0.34, 0.29, 0.47, 0.4]."}, {"from": "gpt", "value": "The head of a woman."}]}, {"id": "VG_100K_2/2397829", "image": "vg/VG_100K_2/2397829.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: The sky is overcast."}, {"from": "gpt", "value": "[0.14, 0.28, 0.58, 0.52]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: THE SAND IS BROWN."}, {"from": "gpt", "value": "[0.5, 0.63, 0.55, 0.65]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The truck is silvr and black."}, {"from": "gpt", "value": "[0.36, 0.5, 0.52, 0.58]"}, {"from": "human", "value": "Please provide a short description for this region: [0.74, 0.31, 0.83, 0.42]."}, {"from": "gpt", "value": "The parasail is green & purple."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: THE SAND IS BROWN."}, {"from": "gpt", "value": "[0.58, 0.6, 0.61, 0.64]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the man is wearing a wet suit."}, {"from": "gpt", "value": "[0.18, 0.67, 0.21, 0.71]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A man is flying kite on the water."}, {"from": "gpt", "value": "[0.16, 0.67, 0.27, 0.73]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.67, 1.0, 0.79]."}, {"from": "gpt", "value": "The ocean is calm."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A kite in the sky."}, {"from": "gpt", "value": "[0.73, 0.3, 0.88, 0.44]"}, {"from": "human", "value": "Please provide a short description for this region: [0.16, 0.65, 0.25, 0.73]."}, {"from": "gpt", "value": "The man is leaning over the water."}]}, {"id": "VG_100K_2/2397580", "image": "vg/VG_100K_2/2397580.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: YELLOW PAINT ON RED HORN."}, {"from": "gpt", "value": "[0.56, 0.3, 0.62, 0.38]"}, {"from": "human", "value": "Please provide a short description for this region: [0.61, 0.88, 0.83, 1.0]."}, {"from": "gpt", "value": "Ground covered in rocks."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the word out is written."}, {"from": "gpt", "value": "[0.52, 0.09, 0.64, 0.18]"}, {"from": "human", "value": "Please provide a short description for this region: [0.75, 0.4, 0.83, 0.55]."}, {"from": "gpt", "value": "Tire with metal rim."}, {"from": "human", "value": "Please provide a short description for this region: [0.24, 0.8, 0.4, 0.9]."}, {"from": "gpt", "value": "Nose of a white cow."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: OUT TO THE LEFT RED SIGN."}, {"from": "gpt", "value": "[0.54, 0.12, 0.64, 0.18]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a painted horn."}, {"from": "gpt", "value": "[0.35, 0.08, 0.47, 0.45]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: knee on a cow."}, {"from": "gpt", "value": "[0.27, 0.87, 0.38, 0.95]"}, {"from": "human", "value": "Please provide a short description for this region: [0.41, 0.14, 0.65, 0.49]."}, {"from": "gpt", "value": "Red decorated horns on exotic animal."}, {"from": "human", "value": "Please provide a short description for this region: [0.34, 0.08, 0.47, 0.46]."}, {"from": "gpt", "value": "Cow horn painted red."}]}, {"id": "VG_100K_2/2397552", "image": "vg/VG_100K_2/2397552.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: GREY AND ORANGE WORK TRUCK."}, {"from": "gpt", "value": "[0.8, 0.41, 0.86, 0.49]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a man riding a horse."}, {"from": "gpt", "value": "[0.48, 0.26, 0.68, 0.63]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the tail of a horse."}, {"from": "gpt", "value": "[0.28, 0.45, 0.37, 0.72]"}, {"from": "human", "value": "Please provide a short description for this region: [0.51, 0.25, 0.6, 0.32]."}, {"from": "gpt", "value": "A helmet on the person's head."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Bricks on the ground."}, {"from": "gpt", "value": "[0.7, 0.79, 0.95, 0.86]"}, {"from": "human", "value": "Please provide a short description for this region: [0.53, 0.25, 0.59, 0.32]."}, {"from": "gpt", "value": "The head of a man."}, {"from": "human", "value": "Please provide a short description for this region: [0.76, 0.6, 0.98, 0.76]."}, {"from": "gpt", "value": "Bricks on the ground."}, {"from": "human", "value": "Please provide a short description for this region: [0.81, 0.29, 0.9, 0.42]."}, {"from": "gpt", "value": "Red flag hanging from pole on building."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Many windows on a building."}, {"from": "gpt", "value": "[0.01, 0.26, 0.28, 0.41]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: EIGHT LEGS FROM TWO HORSES."}, {"from": "gpt", "value": "[0.16, 0.57, 0.72, 0.8]"}]}, {"id": "VG_100K_2/2397267", "image": "vg/VG_100K_2/2397267.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.55, 0.14, 0.84, 0.27]."}, {"from": "gpt", "value": "Sign on the bus."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A bike is visible."}, {"from": "gpt", "value": "[0.64, 0.57, 0.78, 0.74]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the door of a bus."}, {"from": "gpt", "value": "[0.31, 0.24, 0.46, 0.73]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: painted numbers on a bus."}, {"from": "gpt", "value": "[0.51, 0.56, 0.6, 0.61]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the turn light of a bus."}, {"from": "gpt", "value": "[0.44, 0.63, 0.54, 0.69]"}, {"from": "human", "value": "Please provide a short description for this region: [0.23, 0.54, 0.33, 0.73]."}, {"from": "gpt", "value": "Black tire and silver rim."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bus says 35a vulcan."}, {"from": "gpt", "value": "[0.54, 0.14, 0.86, 0.28]"}, {"from": "human", "value": "Please provide a short description for this region: [0.52, 0.62, 0.62, 0.68]."}, {"from": "gpt", "value": "Headlight on a bus."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bus doors are open."}, {"from": "gpt", "value": "[0.3, 0.24, 0.53, 0.75]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: black tire and silver rim."}, {"from": "gpt", "value": "[0.05, 0.49, 0.09, 0.6]"}]}, {"id": "VG_100K_2/2397261", "image": "vg/VG_100K_2/2397261.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.36, 0.2, 0.66, 0.45]."}, {"from": "gpt", "value": "Woman has curly hair."}, {"from": "human", "value": "Please provide a short description for this region: [0.05, 0.17, 0.26, 0.47]."}, {"from": "gpt", "value": "Brown kitchen cabinet with white knob."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a white dishwasher."}, {"from": "gpt", "value": "[0.8, 0.65, 1.0, 0.83]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the dark hair of the woman."}, {"from": "gpt", "value": "[0.41, 0.22, 0.62, 0.45]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: handle is white."}, {"from": "gpt", "value": "[0.08, 0.42, 0.13, 0.47]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: tub is yellow."}, {"from": "gpt", "value": "[0.09, 0.6, 0.52, 0.74]"}, {"from": "human", "value": "Please provide a short description for this region: [0.66, 0.31, 0.83, 0.42]."}, {"from": "gpt", "value": "Large window in a kitchen."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a white knob."}, {"from": "gpt", "value": "[0.69, 0.75, 0.79, 0.81]"}, {"from": "human", "value": "Please provide a short description for this region: [0.38, 0.45, 0.44, 0.51]."}, {"from": "gpt", "value": "Dish washing soap next to sink."}, {"from": "human", "value": "Please provide a short description for this region: [0.46, 0.24, 0.65, 0.81]."}, {"from": "gpt", "value": "Woman wearing a black and white shirt."}]}, {"id": "VG_100K_2/2397198", "image": "vg/VG_100K_2/2397198.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: /the grass is brown and green."}, {"from": "gpt", "value": "[0.41, 0.65, 0.8, 0.8]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: largest zebra in the group."}, {"from": "gpt", "value": "[0.63, 0.46, 0.83, 0.67]"}, {"from": "human", "value": "Please provide a short description for this region: [0.01, 0.68, 0.28, 0.81]."}, {"from": "gpt", "value": "Dried brown desert grass."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: barren ground under the zebras' feet."}, {"from": "gpt", "value": "[0.52, 0.64, 0.82, 0.7]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a tree behind a zebra."}, {"from": "gpt", "value": "[0.49, 0.48, 0.56, 0.55]"}, {"from": "human", "value": "Please provide a short description for this region: [0.1, 0.53, 0.23, 0.69]."}, {"from": "gpt", "value": "Small zebra eating on the left."}, {"from": "human", "value": "Please provide a short description for this region: [0.69, 0.76, 0.91, 0.81]."}, {"from": "gpt", "value": "Patches of dirt in the grass."}, {"from": "human", "value": "Please provide a short description for this region: [0.02, 0.5, 0.05, 0.52]."}, {"from": "gpt", "value": "A rock mountain in the back."}, {"from": "human", "value": "Please provide a short description for this region: [0.01, 0.61, 0.07, 0.67]."}, {"from": "gpt", "value": "A small patch of green."}, {"from": "human", "value": "Please provide a short description for this region: [0.46, 0.49, 0.66, 0.67]."}, {"from": "gpt", "value": "Zebra eating grass."}]}, {"id": "VG_100K_2/2397101", "image": "vg/VG_100K_2/2397101.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: the fence is brown."}, {"from": "gpt", "value": "[0.17, 0.46, 0.46, 0.52]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: this is a bus."}, {"from": "gpt", "value": "[0.45, 0.38, 0.62, 0.55]"}, {"from": "human", "value": "Please provide a short description for this region: [0.48, 0.81, 0.52, 0.88]."}, {"from": "gpt", "value": "Part of a wet part."}, {"from": "human", "value": "Please provide a short description for this region: [0.39, 0.81, 0.68, 0.92]."}, {"from": "gpt", "value": "Black stains on the road."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A blue gas pump."}, {"from": "gpt", "value": "[0.17, 0.45, 0.24, 0.55]"}, {"from": "human", "value": "Please provide a short description for this region: [0.17, 0.33, 0.21, 0.38]."}, {"from": "gpt", "value": "Streetlight is red."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the sky is blue in color."}, {"from": "gpt", "value": "[0.63, 0.03, 0.77, 0.15]"}, {"from": "human", "value": "Please provide a short description for this region: [0.44, 0.38, 0.67, 0.56]."}, {"from": "gpt", "value": "The number 76 bus."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: driver wearing blue shirt."}, {"from": "gpt", "value": "[0.54, 0.45, 0.58, 0.48]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: red letters on bus."}, {"from": "gpt", "value": "[0.44, 0.4, 0.59, 0.43]"}]}, {"id": "VG_100K_2/2396809", "image": "vg/VG_100K_2/2396809.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.51, 0.33, 0.7, 0.49]."}, {"from": "gpt", "value": "Girls blue tennis shirt."}, {"from": "human", "value": "Please provide a short description for this region: [0.29, 0.35, 0.33, 0.4]."}, {"from": "gpt", "value": "Nike emblem on boys shirt."}, {"from": "human", "value": "Please provide a short description for this region: [0.7, 0.57, 0.83, 0.62]."}, {"from": "gpt", "value": "The green grass of the tennis court."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A lady wears white sneakers."}, {"from": "gpt", "value": "[0.55, 0.57, 0.66, 0.64]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A man wears white shorts."}, {"from": "gpt", "value": "[0.24, 0.58, 0.43, 0.7]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Woman standing on green ground."}, {"from": "gpt", "value": "[0.53, 0.3, 0.74, 0.63]"}, {"from": "human", "value": "Please provide a short description for this region: [0.18, 0.02, 0.83, 0.25]."}, {"from": "gpt", "value": "Fenced in tennis court."}, {"from": "human", "value": "Please provide a short description for this region: [0.17, 0.91, 0.42, 1.0]."}, {"from": "gpt", "value": "Pair of black and white adidas sneakers."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: patch of green grass."}, {"from": "gpt", "value": "[0.69, 0.58, 0.78, 0.62]"}, {"from": "human", "value": "Please provide a short description for this region: [0.36, 0.37, 0.63, 0.54]."}, {"from": "gpt", "value": "Tennis racket is white and black."}]}, {"id": "VG_100K_2/2396761", "image": "vg/VG_100K_2/2396761.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: antique carnival horse."}, {"from": "gpt", "value": "[0.34, 0.4, 0.72, 0.76]"}, {"from": "human", "value": "Please provide a short description for this region: [0.25, 0.46, 0.36, 0.61]."}, {"from": "gpt", "value": "The back end of a horse."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a section of a brick wall."}, {"from": "gpt", "value": "[0.0, 0.23, 0.2, 0.84]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A white rocking horse in the window."}, {"from": "gpt", "value": "[0.3, 0.38, 0.65, 0.74]"}, {"from": "human", "value": "Please provide a short description for this region: [0.08, 0.16, 0.92, 0.23]."}, {"from": "gpt", "value": "Green painted strip above the window."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.49, 0.17, 0.54]."}, {"from": "gpt", "value": "The brick is black."}, {"from": "human", "value": "Please provide a short description for this region: [0.24, 0.47, 0.46, 0.53]."}, {"from": "gpt", "value": "A small piece of wood."}, {"from": "human", "value": "Please provide a short description for this region: [0.3, 0.41, 0.66, 0.72]."}, {"from": "gpt", "value": "White horse with multi-colored saddle."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The horse's saddle is blue, red, and yellow."}, {"from": "gpt", "value": "[0.29, 0.41, 0.71, 0.7]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Some of the white paint dripped onto the bricks."}, {"from": "gpt", "value": "[0.17, 0.78, 0.8, 0.85]"}]}, {"id": "VG_100K_2/2395956", "image": "vg/VG_100K_2/2395956.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.35, 0.68, 0.55, 0.87]."}, {"from": "gpt", "value": "White vase with flowers."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: handle of the vase."}, {"from": "gpt", "value": "[0.51, 0.65, 0.64, 0.74]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: green leaves on the stems."}, {"from": "gpt", "value": "[0.31, 0.45, 0.35, 0.49]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white textured wall in background."}, {"from": "gpt", "value": "[0.63, 0.76, 0.79, 0.86]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: two handles on the vase."}, {"from": "gpt", "value": "[0.25, 0.55, 0.59, 0.76]"}, {"from": "human", "value": "Please provide a short description for this region: [0.43, 0.83, 0.49, 0.86]."}, {"from": "gpt", "value": "Edge of a vase."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: edge of a vase."}, {"from": "gpt", "value": "[0.46, 0.8, 0.52, 0.84]"}, {"from": "human", "value": "Please provide a short description for this region: [0.24, 0.57, 0.64, 0.72]."}, {"from": "gpt", "value": "Two handles of the vase."}]}, {"id": "VG_100K_2/2394823", "image": "vg/VG_100K_2/2394823.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.04, 0.6, 0.16, 0.75]."}, {"from": "gpt", "value": "The steps."}, {"from": "human", "value": "Please provide a short description for this region: [0.36, 0.6, 0.48, 0.65]."}, {"from": "gpt", "value": "Immaculate green lawn in front of houses."}, {"from": "human", "value": "Please provide a short description for this region: [0.66, 0.55, 0.72, 0.6]."}, {"from": "gpt", "value": "A round trimmed hedge."}, {"from": "human", "value": "Please provide a short description for this region: [0.22, 0.23, 0.99, 0.39]."}, {"from": "gpt", "value": "The sky is dark."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the steps."}, {"from": "gpt", "value": "[0.09, 0.51, 0.19, 0.74]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: very tall bare tree."}, {"from": "gpt", "value": "[0.56, 0.34, 0.72, 0.51]"}, {"from": "human", "value": "Please provide a short description for this region: [0.31, 0.68, 0.49, 0.78]."}, {"from": "gpt", "value": "A metal bench."}, {"from": "human", "value": "Please provide a short description for this region: [0.1, 0.64, 0.21, 0.77]."}, {"from": "gpt", "value": "A iron gate."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white cloud peeking through the storm cloud."}, {"from": "gpt", "value": "[0.25, 0.24, 0.32, 0.26]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a clock on a building."}, {"from": "gpt", "value": "[0.42, 0.42, 0.47, 0.5]"}]}, {"id": "VG_100K_2/2394712", "image": "vg/VG_100K_2/2394712.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: A black shower curtain."}, {"from": "gpt", "value": "[0.05, 0.18, 0.3, 0.77]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Cabinets are under the sink."}, {"from": "gpt", "value": "[0.37, 0.61, 0.98, 0.83]"}, {"from": "human", "value": "Please provide a short description for this region: [0.21, 0.56, 0.36, 0.82]."}, {"from": "gpt", "value": "This is a commode."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a bathroom mirror."}, {"from": "gpt", "value": "[0.45, 0.26, 0.94, 0.56]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: silver handle on drawer."}, {"from": "gpt", "value": "[0.61, 0.66, 0.69, 0.7]"}, {"from": "human", "value": "Please provide a short description for this region: [0.64, 0.51, 0.71, 0.59]."}, {"from": "gpt", "value": "Soap dispencer on the counter."}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.38, 0.57, 0.57]."}, {"from": "gpt", "value": "Flowers in the garden pot."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: This is a shower curtain."}, {"from": "gpt", "value": "[0.07, 0.18, 0.29, 0.74]"}, {"from": "human", "value": "Please provide a short description for this region: [0.63, 0.28, 0.88, 0.54]."}, {"from": "gpt", "value": "Mirror on wall over sink."}]}, {"id": "VG_100K_2/2394148", "image": "vg/VG_100K_2/2394148.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.02, 0.52, 0.15, 0.65]."}, {"from": "gpt", "value": "Black sheep on a hillside."}, {"from": "human", "value": "Please provide a short description for this region: [0.67, 0.38, 0.88, 0.73]."}, {"from": "gpt", "value": "White water of the waterfall."}, {"from": "human", "value": "Please provide a short description for this region: [0.04, 0.53, 0.38, 0.75]."}, {"from": "gpt", "value": "Sheep climb rocky hill."}, {"from": "human", "value": "Please provide a short description for this region: [0.36, 0.63, 0.65, 0.77]."}, {"from": "gpt", "value": "Grey rocks with moss growing on them."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a black sheep with a white sheep."}, {"from": "gpt", "value": "[0.03, 0.53, 0.39, 0.74]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a white sky above a hill."}, {"from": "gpt", "value": "[0.18, 0.24, 0.62, 0.4]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: sheep is white and gray."}, {"from": "gpt", "value": "[0.13, 0.59, 0.38, 0.73]"}, {"from": "human", "value": "Please provide a short description for this region: [0.12, 0.61, 0.19, 0.68]."}, {"from": "gpt", "value": "The head of a goat."}, {"from": "human", "value": "Please provide a short description for this region: [0.67, 0.36, 0.87, 0.75]."}, {"from": "gpt", "value": "Waterfall on the side of a hill."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A waterfalls."}, {"from": "gpt", "value": "[0.64, 0.43, 0.78, 0.77]"}]}, {"id": "VG_100K_2/2393193", "image": "vg/VG_100K_2/2393193.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.74, 0.58, 0.84, 0.64]."}, {"from": "gpt", "value": "Basket on front of bike."}, {"from": "human", "value": "Please provide a short description for this region: [0.68, 0.48, 0.85, 0.73]."}, {"from": "gpt", "value": "Man riding bicycle with basket."}, {"from": "human", "value": "Please provide a short description for this region: [0.92, 0.51, 0.96, 0.56]."}, {"from": "gpt", "value": "A person wearing a red hat."}, {"from": "human", "value": "Please provide a short description for this region: [0.51, 0.51, 0.57, 0.62]."}, {"from": "gpt", "value": "A young boy riding a bike."}, {"from": "human", "value": "Please provide a short description for this region: [0.13, 0.53, 0.16, 0.58]."}, {"from": "gpt", "value": "Bicyclist riding down busy city street."}, {"from": "human", "value": "Please provide a short description for this region: [0.83, 0.36, 1.0, 0.5]."}, {"from": "gpt", "value": "Palm trees beside parking garage."}, {"from": "human", "value": "Please provide a short description for this region: [0.79, 0.55, 1.0, 0.58]."}, {"from": "gpt", "value": "Patch of grass along busy street."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the man is riding bike."}, {"from": "gpt", "value": "[0.64, 0.45, 0.95, 0.82]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: people walking down the street."}, {"from": "gpt", "value": "[0.28, 0.47, 0.59, 0.59]"}]}, {"id": "VG_100K_2/2392717", "image": "vg/VG_100K_2/2392717.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.63, 0.09, 0.72, 0.43]."}, {"from": "gpt", "value": "The pole is white."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The bush is green."}, {"from": "gpt", "value": "[0.09, 0.64, 0.34, 0.77]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: grey stone tower cone."}, {"from": "gpt", "value": "[0.75, 0.27, 0.78, 0.35]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Building made of brick."}, {"from": "gpt", "value": "[0.55, 0.25, 0.78, 0.82]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The clock is black and gold."}, {"from": "gpt", "value": "[0.63, 0.47, 0.74, 0.56]"}, {"from": "human", "value": "Please provide a short description for this region: [0.33, 0.57, 0.51, 0.77]."}, {"from": "gpt", "value": "The fog is allover the place."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Silver pole."}, {"from": "gpt", "value": "[0.63, 0.12, 0.7, 0.36]"}, {"from": "human", "value": "Please provide a short description for this region: [0.63, 0.49, 0.72, 0.59]."}, {"from": "gpt", "value": "Clock on a building."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: tree with green leaves."}, {"from": "gpt", "value": "[0.08, 0.65, 0.31, 0.76]"}, {"from": "human", "value": "Please provide a short description for this region: [0.42, 0.64, 0.77, 0.99]."}, {"from": "gpt", "value": "The fog is allover the place."}]}, {"id": "VG_100K_2/2392170", "image": "vg/VG_100K_2/2392170.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: ocean with one sailboat."}, {"from": "gpt", "value": "[0.13, 0.24, 1.0, 0.35]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Hair being blown in the wind."}, {"from": "gpt", "value": "[0.66, 0.35, 0.74, 0.4]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: person has a big smile on their face."}, {"from": "gpt", "value": "[0.5, 0.31, 0.88, 0.67]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A brown paper bag."}, {"from": "gpt", "value": "[0.4, 0.78, 0.56, 0.97]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Woman has short hair."}, {"from": "gpt", "value": "[0.49, 0.33, 0.85, 0.68]"}, {"from": "human", "value": "Please provide a short description for this region: [0.6, 0.48, 0.82, 0.53]."}, {"from": "gpt", "value": "Dark wire rim sunglasses."}, {"from": "human", "value": "Please provide a short description for this region: [0.56, 0.27, 0.74, 0.66]."}, {"from": "gpt", "value": "She has short hair."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a banner going accross her chest."}, {"from": "gpt", "value": "[0.52, 0.62, 0.67, 0.94]"}, {"from": "human", "value": "Please provide a short description for this region: [0.28, 0.62, 0.48, 0.81]."}, {"from": "gpt", "value": "Person holding hamburger."}, {"from": "human", "value": "Please provide a short description for this region: [0.54, 0.38, 0.85, 0.67]."}, {"from": "gpt", "value": "She is wearing sunglasses."}]}, {"id": "VG_100K_2/2391335", "image": "vg/VG_100K_2/2391335.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: paw is in the mud."}, {"from": "gpt", "value": "[0.61, 0.7, 0.68, 0.78]"}, {"from": "human", "value": "Please provide a short description for this region: [0.42, 0.62, 0.79, 0.99]."}, {"from": "gpt", "value": "A barbed wire."}, {"from": "human", "value": "Please provide a short description for this region: [0.53, 0.79, 0.62, 0.95]."}, {"from": "gpt", "value": "A barbed wire."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a long white bull horn."}, {"from": "gpt", "value": "[0.46, 0.06, 0.75, 0.29]"}, {"from": "human", "value": "Please provide a short description for this region: [0.51, 0.37, 0.73, 0.77]."}, {"from": "gpt", "value": "Young cow with tan fur."}, {"from": "human", "value": "Please provide a short description for this region: [0.48, 0.34, 0.55, 0.41]."}, {"from": "gpt", "value": "Tag on cow's ear."}, {"from": "human", "value": "Please provide a short description for this region: [0.02, 0.17, 0.24, 0.29]."}, {"from": "gpt", "value": "A long white bull horn."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: fence in middle of pasture."}, {"from": "gpt", "value": "[0.26, 0.11, 0.57, 0.18]"}, {"from": "human", "value": "Please provide a short description for this region: [0.34, 0.02, 0.37, 0.13]."}, {"from": "gpt", "value": "The pillar of a wind turbine."}, {"from": "human", "value": "Please provide a short description for this region: [0.79, 0.34, 0.9, 0.54]."}, {"from": "gpt", "value": "Green grass."}]}, {"id": "VG_100K_2/2390906", "image": "vg/VG_100K_2/2390906.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.56, 0.2, 0.67, 0.24]."}, {"from": "gpt", "value": "Lights are in the ceiling."}, {"from": "human", "value": "Please provide a short description for this region: [0.53, 0.37, 0.72, 0.47]."}, {"from": "gpt", "value": "Logo on side of cycle."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man looks at bike."}, {"from": "gpt", "value": "[0.87, 0.17, 0.91, 0.22]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: inside of rim is orange."}, {"from": "gpt", "value": "[0.26, 0.59, 0.35, 0.69]"}, {"from": "human", "value": "Please provide a short description for this region: [0.28, 0.25, 0.76, 0.4]."}, {"from": "gpt", "value": "Handles bars on cycle."}, {"from": "human", "value": "Please provide a short description for this region: [0.37, 0.37, 0.56, 0.5]."}, {"from": "gpt", "value": "Small white paper on cycle."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: back tail end of cycle."}, {"from": "gpt", "value": "[0.05, 0.42, 0.3, 0.6]"}, {"from": "human", "value": "Please provide a short description for this region: [0.22, 0.61, 0.74, 0.82]."}, {"from": "gpt", "value": "Long silver exhaust of cycle."}, {"from": "human", "value": "Please provide a short description for this region: [0.09, 0.42, 0.38, 0.57]."}, {"from": "gpt", "value": "Back end of cycle."}, {"from": "human", "value": "Please provide a short description for this region: [0.01, 0.29, 0.16, 0.7]."}, {"from": "gpt", "value": "Man wearing denim blue jeans."}]}, {"id": "VG_100K_2/2390245", "image": "vg/VG_100K_2/2390245.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.18, 0.34, 0.26, 0.52]."}, {"from": "gpt", "value": "Black apple iphone."}, {"from": "human", "value": "Please provide a short description for this region: [0.57, 0.71, 0.63, 0.77]."}, {"from": "gpt", "value": "White button on shirt."}, {"from": "human", "value": "Please provide a short description for this region: [0.62, 0.34, 0.8, 0.51]."}, {"from": "gpt", "value": "Green ear flap of knit hat."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Green knitting on hat."}, {"from": "gpt", "value": "[0.65, 0.38, 0.77, 0.49]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: White button."}, {"from": "gpt", "value": "[0.59, 0.73, 0.61, 0.75]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man's hand holding black cell phone."}, {"from": "gpt", "value": "[0.11, 0.32, 0.28, 0.71]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Man wears plaid jacket."}, {"from": "gpt", "value": "[0.37, 0.69, 0.44, 0.78]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the background picture is bluur."}, {"from": "gpt", "value": "[0.38, 0.55, 0.52, 0.65]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A black cell phone."}, {"from": "gpt", "value": "[0.16, 0.31, 0.27, 0.52]"}]}, {"id": "VG_100K_2/2390084", "image": "vg/VG_100K_2/2390084.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.07, 0.32, 0.27, 0.35]."}, {"from": "gpt", "value": "Head lights on front of vehicle."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: brown shoe and white sock."}, {"from": "gpt", "value": "[0.53, 0.65, 0.64, 0.74]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bus is mainly blue."}, {"from": "gpt", "value": "[0.69, 0.17, 0.99, 0.41]"}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.22, 0.53, 0.3]."}, {"from": "gpt", "value": "Man wears silver helmet."}, {"from": "human", "value": "Please provide a short description for this region: [0.31, 0.46, 0.5, 0.53]."}, {"from": "gpt", "value": "Black curved bicycle handles."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: small orange rectangular light."}, {"from": "gpt", "value": "[0.79, 0.46, 0.86, 0.51]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white painting on road."}, {"from": "gpt", "value": "[0.13, 0.69, 0.85, 0.83]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: back end of delivery truck."}, {"from": "gpt", "value": "[0.01, 0.2, 0.12, 0.4]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man wears white shirt."}, {"from": "gpt", "value": "[0.51, 0.31, 0.69, 0.42]"}, {"from": "human", "value": "Please provide a short description for this region: [0.7, 0.32, 0.75, 0.42]."}, {"from": "gpt", "value": "Blue handicapped sign on bus."}]}, {"id": "VG_100K_2/2389979", "image": "vg/VG_100K_2/2389979.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.27, 0.24, 0.66, 0.45]."}, {"from": "gpt", "value": "Red and black leather jacket."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a black motorcycle helmet."}, {"from": "gpt", "value": "[0.34, 0.14, 0.54, 0.3]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: blurry black paved tarmac."}, {"from": "gpt", "value": "[0.0, 0.74, 0.99, 0.87]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a red glove on the man."}, {"from": "gpt", "value": "[0.58, 0.32, 0.66, 0.4]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: rearview mirror on handle bar."}, {"from": "gpt", "value": "[0.61, 0.21, 0.67, 0.35]"}, {"from": "human", "value": "Please provide a short description for this region: [0.26, 0.36, 0.6, 0.55]."}, {"from": "gpt", "value": "Black leather pants."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: red and black leather glove."}, {"from": "gpt", "value": "[0.57, 0.31, 0.66, 0.39]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: red and black gloves."}, {"from": "gpt", "value": "[0.57, 0.32, 0.66, 0.4]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: black motorcycle tire."}, {"from": "gpt", "value": "[0.08, 0.53, 0.4, 0.82]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: an asphalt road."}, {"from": "gpt", "value": "[0.02, 0.76, 0.99, 0.87]"}]}, {"id": "VG_100K_2/2389771", "image": "vg/VG_100K_2/2389771.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: white plastic shelving pole."}, {"from": "gpt", "value": "[0.87, 0.35, 0.96, 0.87]"}, {"from": "human", "value": "Please provide a short description for this region: [0.48, 0.5, 0.62, 0.59]."}, {"from": "gpt", "value": "Fuzzy black beard on the face."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: this is the color black."}, {"from": "gpt", "value": "[0.4, 0.78, 0.43, 0.81]"}, {"from": "human", "value": "Please provide a short description for this region: [0.75, 0.44, 0.84, 0.64]."}, {"from": "gpt", "value": "This is a stem."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: silver clasp of the window."}, {"from": "gpt", "value": "[0.21, 0.52, 0.29, 0.55]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white plastic shelf holding several plants."}, {"from": "gpt", "value": "[0.73, 0.34, 1.0, 0.86]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: light reflecting off the metal."}, {"from": "gpt", "value": "[0.57, 0.64, 0.65, 0.71]"}, {"from": "human", "value": "Please provide a short description for this region: [0.84, 0.58, 0.91, 0.82]."}, {"from": "gpt", "value": "Purple leaves on potted plant."}, {"from": "human", "value": "Please provide a short description for this region: [0.8, 0.54, 0.98, 0.87]."}, {"from": "gpt", "value": "Dark purple leaves."}, {"from": "human", "value": "Please provide a short description for this region: [0.76, 0.67, 0.8, 0.73]."}, {"from": "gpt", "value": "This is the color yellow."}]}, {"id": "VG_100K_2/2389566", "image": "vg/VG_100K_2/2389566.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: boy's leg is crossed."}, {"from": "gpt", "value": "[0.42, 0.52, 0.56, 0.63]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Dressed for cool weather."}, {"from": "gpt", "value": "[0.05, 0.22, 0.63, 0.43]"}, {"from": "human", "value": "Please provide a short description for this region: [0.65, 0.34, 0.67, 0.39]."}, {"from": "gpt", "value": "Water bottle on the picnic table."}, {"from": "human", "value": "Please provide a short description for this region: [0.36, 0.28, 0.44, 0.41]."}, {"from": "gpt", "value": "Girl sitting by the picnic table."}, {"from": "human", "value": "Please provide a short description for this region: [0.67, 0.44, 0.76, 0.54]."}, {"from": "gpt", "value": "A coat draped over bench."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a man at table eating."}, {"from": "gpt", "value": "[0.48, 0.27, 0.6, 0.39]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Old fashioned black hat."}, {"from": "gpt", "value": "[0.46, 0.24, 0.61, 0.39]"}, {"from": "human", "value": "Please provide a short description for this region: [0.4, 0.36, 0.55, 0.66]."}, {"from": "gpt", "value": "A boy sitting on bench."}, {"from": "human", "value": "Please provide a short description for this region: [0.41, 0.36, 0.55, 0.66]."}, {"from": "gpt", "value": "Boy sitting on the bench."}, {"from": "human", "value": "Please provide a short description for this region: [0.53, 0.39, 0.64, 0.54]."}, {"from": "gpt", "value": "Blue cooler on the picnic bench."}]}, {"id": "VG_100K_2/2389375", "image": "vg/VG_100K_2/2389375.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: blue snowpants on a man."}, {"from": "gpt", "value": "[0.49, 0.6, 0.59, 0.71]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: there is some line in the snow."}, {"from": "gpt", "value": "[0.2, 0.27, 0.31, 0.46]"}, {"from": "human", "value": "Please provide a short description for this region: [0.35, 0.49, 0.69, 0.68]."}, {"from": "gpt", "value": "Person holding 2 poles."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the snow is white."}, {"from": "gpt", "value": "[0.78, 0.74, 0.83, 0.83]"}, {"from": "human", "value": "Please provide a short description for this region: [0.04, 0.51, 0.29, 0.8]."}, {"from": "gpt", "value": "White snow on the ground."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Moutain rock with dirt and snow."}, {"from": "gpt", "value": "[0.06, 0.18, 0.37, 0.27]"}, {"from": "human", "value": "Please provide a short description for this region: [0.35, 0.76, 0.42, 0.81]."}, {"from": "gpt", "value": "The snow is white."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the snow is white."}, {"from": "gpt", "value": "[0.75, 0.69, 0.79, 0.83]"}, {"from": "human", "value": "Please provide a short description for this region: [0.51, 0.46, 0.58, 0.5]."}, {"from": "gpt", "value": "Person wearing gray hat."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: more rocks on the slope."}, {"from": "gpt", "value": "[0.79, 0.24, 1.0, 0.61]"}]}, {"id": "VG_100K_2/2389010", "image": "vg/VG_100K_2/2389010.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: THE Window is white."}, {"from": "gpt", "value": "[0.47, 0.76, 0.49, 0.81]"}, {"from": "human", "value": "Please provide a short description for this region: [0.03, 0.74, 0.08, 0.8]."}, {"from": "gpt", "value": "Black mark is spotted."}, {"from": "human", "value": "Please provide a short description for this region: [0.49, 0.78, 0.51, 0.83]."}, {"from": "gpt", "value": "The window is white."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Window on the building."}, {"from": "gpt", "value": "[0.81, 0.38, 0.89, 0.51]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: hand on the clock."}, {"from": "gpt", "value": "[0.56, 0.33, 0.63, 0.42]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white window frames."}, {"from": "gpt", "value": "[0.0, 0.12, 0.17, 0.86]"}, {"from": "human", "value": "Please provide a short description for this region: [0.03, 0.73, 0.06, 0.76]."}, {"from": "gpt", "value": "Black mark is spotted."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: window on the building."}, {"from": "gpt", "value": "[0.43, 0.14, 0.6, 0.25]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: number on the clock."}, {"from": "gpt", "value": "[0.6, 0.46, 0.64, 0.52]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.73, 0.06, 0.77]."}, {"from": "gpt", "value": "Black mark is spotted."}]}, {"id": "VG_100K_2/2388682", "image": "vg/VG_100K_2/2388682.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: The glove is leather."}, {"from": "gpt", "value": "[0.37, 0.5, 0.45, 0.62]"}, {"from": "human", "value": "Please provide a short description for this region: [0.56, 0.2, 0.67, 0.32]."}, {"from": "gpt", "value": "The helmet is blue."}, {"from": "human", "value": "Please provide a short description for this region: [0.05, 0.23, 0.29, 0.73]."}, {"from": "gpt", "value": "An umpire."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: brim on the cap is orange."}, {"from": "gpt", "value": "[0.28, 0.38, 0.35, 0.45]"}, {"from": "human", "value": "Please provide a short description for this region: [0.56, 0.28, 0.77, 0.69]."}, {"from": "gpt", "value": "Baseball player wearing a gray and blue uniform."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a blue hard hat."}, {"from": "gpt", "value": "[0.57, 0.2, 0.66, 0.27]"}, {"from": "human", "value": "Please provide a short description for this region: [0.5, 0.33, 0.59, 0.45]."}, {"from": "gpt", "value": "Baseball player wearing blue and white gloves."}, {"from": "human", "value": "Please provide a short description for this region: [0.56, 0.72, 0.63, 0.76]."}, {"from": "gpt", "value": "Cleat on player's foot."}, {"from": "human", "value": "Please provide a short description for this region: [0.19, 0.73, 0.28, 0.82]."}, {"from": "gpt", "value": "Orange sole of a shoe."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: number 23 on sleeve."}, {"from": "gpt", "value": "[0.14, 0.37, 0.2, 0.41]"}]}, {"id": "VG_100K_2/2388381", "image": "vg/VG_100K_2/2388381.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: the player out in the field."}, {"from": "gpt", "value": "[0.89, 0.47, 0.93, 0.58]"}, {"from": "human", "value": "Please provide a short description for this region: [0.11, 0.64, 0.31, 0.72]."}, {"from": "gpt", "value": "Catcher wears white pants."}, {"from": "human", "value": "Please provide a short description for this region: [0.16, 0.73, 0.26, 0.8]."}, {"from": "gpt", "value": "Catcher wears white shoes."}, {"from": "human", "value": "Please provide a short description for this region: [0.43, 0.53, 0.63, 0.72]."}, {"from": "gpt", "value": "Man wears grey slacks."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: catcher wears red shirt."}, {"from": "gpt", "value": "[0.15, 0.53, 0.24, 0.66]"}, {"from": "human", "value": "Please provide a short description for this region: [0.46, 0.39, 0.63, 0.52]."}, {"from": "gpt", "value": "Man wears red shirt."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the fading white lines on the field."}, {"from": "gpt", "value": "[0.78, 0.61, 1.0, 0.8]"}, {"from": "human", "value": "Please provide a short description for this region: [0.5, 0.33, 0.7, 0.65]."}, {"from": "gpt", "value": "Man on red shirt."}]}, {"id": "VG_100K_2/2387915", "image": "vg/VG_100K_2/2387915.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: glasses on the woman's face."}, {"from": "gpt", "value": "[0.67, 0.26, 0.78, 0.29]"}, {"from": "human", "value": "Please provide a short description for this region: [0.19, 0.44, 0.27, 0.85]."}, {"from": "gpt", "value": "A wine bottle with a red label."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the glasses on the woman."}, {"from": "gpt", "value": "[0.65, 0.25, 0.77, 0.29]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a bottle of wine."}, {"from": "gpt", "value": "[0.18, 0.44, 0.29, 0.84]"}, {"from": "human", "value": "Please provide a short description for this region: [0.06, 0.5, 0.25, 0.95]."}, {"from": "gpt", "value": "The wine glass on the left."}, {"from": "human", "value": "Please provide a short description for this region: [0.2, 0.26, 0.32, 0.34]."}, {"from": "gpt", "value": "The name tag on the man."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: lady with glasses on."}, {"from": "gpt", "value": "[0.59, 0.19, 0.86, 0.42]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a long curtain rod."}, {"from": "gpt", "value": "[0.0, 0.04, 0.98, 0.07]"}, {"from": "human", "value": "Please provide a short description for this region: [0.6, 0.2, 0.85, 0.36]."}, {"from": "gpt", "value": "A woman wearing glasses."}, {"from": "human", "value": "Please provide a short description for this region: [0.64, 0.65, 0.98, 0.82]."}, {"from": "gpt", "value": "A plate of food."}]}, {"id": "VG_100K_2/2387549", "image": "vg/VG_100K_2/2387549.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.51, 0.45, 0.72, 0.55]."}, {"from": "gpt", "value": "People in the background."}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.28, 0.53, 0.35]."}, {"from": "gpt", "value": "Person wearing googles."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The man is wearing a hat."}, {"from": "gpt", "value": "[0.44, 0.25, 0.51, 0.31]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: three skilifts in the background."}, {"from": "gpt", "value": "[0.61, 0.17, 0.99, 0.46]"}, {"from": "human", "value": "Please provide a short description for this region: [0.51, 0.65, 0.72, 0.71]."}, {"from": "gpt", "value": "Sun shining on the snow."}, {"from": "human", "value": "Please provide a short description for this region: [0.52, 0.47, 0.73, 0.56]."}, {"from": "gpt", "value": "A group of skiiers in the background."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: 2 pine trees in distance."}, {"from": "gpt", "value": "[0.03, 0.42, 0.17, 0.53]"}, {"from": "human", "value": "Please provide a short description for this region: [0.25, 0.59, 0.83, 0.82]."}, {"from": "gpt", "value": "Sunlight on the snow."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a crowd of people."}, {"from": "gpt", "value": "[0.5, 0.44, 0.78, 0.57]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man jumping on skis."}, {"from": "gpt", "value": "[0.38, 0.29, 0.58, 0.63]"}]}, {"id": "VG_100K_2/2386890", "image": "vg/VG_100K_2/2386890.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.01, 0.58, 0.12, 0.74]."}, {"from": "gpt", "value": "Calculator on table."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: THE PEN IS BLUE."}, {"from": "gpt", "value": "[0.55, 0.64, 0.66, 0.68]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: THE TOP OF THE BOTTLE IS RED."}, {"from": "gpt", "value": "[0.08, 0.31, 0.12, 0.35]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a grey plastic bowl."}, {"from": "gpt", "value": "[0.08, 0.57, 0.22, 0.67]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A beige colored electrical outlet, with one thing plugged in."}, {"from": "gpt", "value": "[0.19, 0.27, 0.29, 0.32]"}, {"from": "human", "value": "Please provide a short description for this region: [0.69, 0.22, 0.77, 0.33]."}, {"from": "gpt", "value": "A piece of paper tacked to the wall."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a square piece of paper."}, {"from": "gpt", "value": "[0.5, 0.65, 0.59, 0.73]"}, {"from": "human", "value": "Please provide a short description for this region: [0.51, 0.56, 0.58, 0.62]."}, {"from": "gpt", "value": "The silver track pad on the laptop."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the white mouse."}, {"from": "gpt", "value": "[0.66, 0.54, 0.75, 0.61]"}, {"from": "human", "value": "Please provide a short description for this region: [0.07, 0.3, 0.15, 0.51]."}, {"from": "gpt", "value": "The bottle is on the desk."}]}, {"id": "VG_100K_2/2386556", "image": "vg/VG_100K_2/2386556.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.06, 0.17, 0.68, 0.41]."}, {"from": "gpt", "value": "Paw prints on wooden table."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: What remains of the far pizza."}, {"from": "gpt", "value": "[0.53, 0.05, 0.9, 0.28]"}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.02, 0.9, 0.31]."}, {"from": "gpt", "value": "Four slices of pizza on a pan."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: pile of forks on the table."}, {"from": "gpt", "value": "[0.0, 0.33, 0.32, 0.5]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: an empty white container on a table."}, {"from": "gpt", "value": "[0.82, 0.35, 0.97, 0.49]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a bunch of utensils on a table."}, {"from": "gpt", "value": "[0.0, 0.33, 0.3, 0.47]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a mug of beer in a glass."}, {"from": "gpt", "value": "[0.32, 0.1, 0.53, 0.37]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: small empty plastic cup on the table."}, {"from": "gpt", "value": "[0.79, 0.35, 0.96, 0.5]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.21, 0.21, 0.42]."}, {"from": "gpt", "value": "The napkins are white."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A stack of paper napkins."}, {"from": "gpt", "value": "[0.0, 0.21, 0.21, 0.4]"}]}, {"id": "VG_100K_2/2385750", "image": "vg/VG_100K_2/2385750.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.54, 0.29, 0.56, 0.33]."}, {"from": "gpt", "value": "The right hand of the skater."}, {"from": "human", "value": "Please provide a short description for this region: [0.56, 0.23, 0.84, 0.5]."}, {"from": "gpt", "value": "A man above a skateboard."}, {"from": "human", "value": "Please provide a short description for this region: [0.58, 0.33, 0.75, 0.4]."}, {"from": "gpt", "value": "The shorts are tan."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The wheels are red."}, {"from": "gpt", "value": "[0.64, 0.51, 0.7, 0.56]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The person is wearing a white top."}, {"from": "gpt", "value": "[0.58, 0.25, 0.73, 0.35]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Gray clouds in the sky."}, {"from": "gpt", "value": "[0.32, 0.39, 0.54, 0.57]"}, {"from": "human", "value": "Please provide a short description for this region: [0.64, 0.5, 0.73, 0.62]."}, {"from": "gpt", "value": "Black skateboard in mid air."}, {"from": "human", "value": "Please provide a short description for this region: [0.13, 0.3, 0.33, 0.32]."}, {"from": "gpt", "value": "The sky is cloudy."}, {"from": "human", "value": "Please provide a short description for this region: [0.59, 0.44, 0.74, 0.5]."}, {"from": "gpt", "value": "The person is wearing black shoes."}]}, {"id": "VG_100K_2/2385732", "image": "vg/VG_100K_2/2385732.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: this is the wall."}, {"from": "gpt", "value": "[0.35, 0.13, 0.58, 0.27]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the toilet is dirty."}, {"from": "gpt", "value": "[0.41, 0.55, 0.61, 0.99]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: this is the ground."}, {"from": "gpt", "value": "[0.24, 0.76, 0.38, 0.94]"}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.66, 0.54, 0.73]."}, {"from": "gpt", "value": "Toilet has water in it."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the toilet is dirty."}, {"from": "gpt", "value": "[0.37, 0.51, 0.73, 0.84]"}, {"from": "human", "value": "Please provide a short description for this region: [0.39, 0.58, 0.62, 0.85]."}, {"from": "gpt", "value": "Toilet is white color."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the floor is dirty."}, {"from": "gpt", "value": "[0.26, 0.74, 0.42, 0.94]"}, {"from": "human", "value": "Please provide a short description for this region: [0.39, 0.19, 0.57, 0.32]."}, {"from": "gpt", "value": "The wall is green in color."}, {"from": "human", "value": "Please provide a short description for this region: [0.23, 0.16, 0.74, 0.43]."}, {"from": "gpt", "value": "White lines are in wall."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Water outlet is closed."}, {"from": "gpt", "value": "[0.31, 0.44, 0.38, 0.5]"}]}, {"id": "VG_100K_2/2385400", "image": "vg/VG_100K_2/2385400.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.7, 0.31, 0.98, 0.74]."}, {"from": "gpt", "value": "Three ties on their side."}, {"from": "human", "value": "Please provide a short description for this region: [0.64, 0.34, 0.72, 0.71]."}, {"from": "gpt", "value": "The tie has red and blue stripes."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the tie has red and blue circles."}, {"from": "gpt", "value": "[0.15, 0.38, 0.26, 0.71]"}, {"from": "human", "value": "Please provide a short description for this region: [0.42, 0.26, 0.51, 0.73]."}, {"from": "gpt", "value": "A green red and yellow neck tie."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: paisley colored tie."}, {"from": "gpt", "value": "[0.44, 0.25, 0.5, 0.74]"}, {"from": "human", "value": "Please provide a short description for this region: [0.63, 0.26, 0.71, 0.73]."}, {"from": "gpt", "value": "A red, blue and yellow striped neck tie."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a red white and blue tie."}, {"from": "gpt", "value": "[0.11, 0.24, 0.27, 0.74]"}, {"from": "human", "value": "Please provide a short description for this region: [0.72, 0.45, 0.99, 0.74]."}, {"from": "gpt", "value": "Two blue and black ties."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the tie has blue and black stripes."}, {"from": "gpt", "value": "[0.74, 0.62, 1.0, 0.74]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a green and blue striped neck tie."}, {"from": "gpt", "value": "[0.7, 0.44, 0.95, 0.52]"}]}, {"id": "VG_100K_2/2384949", "image": "vg/VG_100K_2/2384949.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a large rock boulder in the watering hole."}, {"from": "gpt", "value": "[0.73, 0.54, 0.84, 0.57]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Group of trees in the background."}, {"from": "gpt", "value": "[0.1, 0.32, 0.73, 0.44]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Rock inside the water."}, {"from": "gpt", "value": "[0.72, 0.49, 0.88, 0.6]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: an elephant's trunk."}, {"from": "gpt", "value": "[0.53, 0.62, 0.65, 0.77]"}, {"from": "human", "value": "Please provide a short description for this region: [0.2, 0.52, 0.65, 0.76]."}, {"from": "gpt", "value": "Two elephants."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Small tree on the bank."}, {"from": "gpt", "value": "[0.03, 0.4, 0.16, 0.61]"}, {"from": "human", "value": "Please provide a short description for this region: [0.2, 0.53, 0.27, 0.58]."}, {"from": "gpt", "value": "Small elephant near watering hole."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Elephant has a long trunk."}, {"from": "gpt", "value": "[0.57, 0.62, 0.66, 0.73]"}, {"from": "human", "value": "Please provide a short description for this region: [0.73, 0.54, 0.84, 0.56]."}, {"from": "gpt", "value": "Large brown rock in watering hole."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.38, 0.99, 0.41]."}, {"from": "gpt", "value": "Thick green forest in the distance."}]}, {"id": "VG_100K_2/2384662", "image": "vg/VG_100K_2/2384662.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: A clear, blue sky."}, {"from": "gpt", "value": "[0.15, 0.0, 0.4, 0.05]"}, {"from": "human", "value": "Please provide a short description for this region: [0.67, 0.78, 0.8, 0.92]."}, {"from": "gpt", "value": "The soccer ball is blue and white."}, {"from": "human", "value": "Please provide a short description for this region: [0.44, 0.27, 0.62, 0.53]."}, {"from": "gpt", "value": "The boy has on a green and white striped shirt."}, {"from": "human", "value": "Please provide a short description for this region: [0.67, 0.78, 0.81, 0.93]."}, {"from": "gpt", "value": "Soccer ball with blue spots."}, {"from": "human", "value": "Please provide a short description for this region: [0.14, 0.26, 0.35, 0.41]."}, {"from": "gpt", "value": "Blue car behind fence."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white garage door with decorative windows."}, {"from": "gpt", "value": "[0.26, 0.08, 0.8, 0.37]"}, {"from": "human", "value": "Please provide a short description for this region: [0.67, 0.78, 0.8, 0.91]."}, {"from": "gpt", "value": "White and blue ball."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A parked white truck."}, {"from": "gpt", "value": "[0.66, 0.17, 0.85, 0.38]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: burgundy soccer cleats on female player."}, {"from": "gpt", "value": "[0.16, 0.71, 0.44, 0.82]"}, {"from": "human", "value": "Please provide a short description for this region: [0.66, 0.17, 0.86, 0.38]."}, {"from": "gpt", "value": "White truck behind fence."}]}, {"id": "VG_100K_2/2384265", "image": "vg/VG_100K_2/2384265.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.0, 0.55, 0.26, 0.87]."}, {"from": "gpt", "value": "The girl sitting."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A tan pitcher on the table."}, {"from": "gpt", "value": "[0.76, 0.69, 0.89, 0.86]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.56, 0.26, 0.87]."}, {"from": "gpt", "value": "Girl smiling."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Part of a window."}, {"from": "gpt", "value": "[0.34, 0.12, 0.43, 0.42]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the picture on the wall."}, {"from": "gpt", "value": "[0.23, 0.17, 0.32, 0.35]"}, {"from": "human", "value": "Please provide a short description for this region: [0.33, 0.27, 0.49, 0.47]."}, {"from": "gpt", "value": "A controller in the girl's hand."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the picture on the wall."}, {"from": "gpt", "value": "[0.73, 0.17, 0.9, 0.32]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: wii controller in woman's hand."}, {"from": "gpt", "value": "[0.38, 0.31, 0.45, 0.44]"}, {"from": "human", "value": "Please provide a short description for this region: [0.91, 0.81, 0.98, 0.87]."}, {"from": "gpt", "value": "A small white cup on the table."}, {"from": "human", "value": "Please provide a short description for this region: [0.67, 0.77, 0.99, 0.87]."}, {"from": "gpt", "value": "Dable with drink items on it."}]}, {"id": "VG_100K_2/2384220", "image": "vg/VG_100K_2/2384220.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.8, 0.15, 1.0, 0.51]."}, {"from": "gpt", "value": "Light green window curtains."}, {"from": "human", "value": "Please provide a short description for this region: [0.48, 0.29, 0.56, 0.46]."}, {"from": "gpt", "value": "Structure seen through the window."}, {"from": "human", "value": "Please provide a short description for this region: [0.12, 0.25, 0.25, 0.46]."}, {"from": "gpt", "value": "Painting on the wall of a hotel room."}, {"from": "human", "value": "Please provide a short description for this region: [0.47, 0.22, 0.79, 0.48]."}, {"from": "gpt", "value": "Hotel room window."}, {"from": "human", "value": "Please provide a short description for this region: [0.47, 0.19, 0.81, 0.5]."}, {"from": "gpt", "value": "Open window with view of roof top."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: trees and grass visible outside window."}, {"from": "gpt", "value": "[0.58, 0.38, 0.78, 0.48]"}, {"from": "human", "value": "Please provide a short description for this region: [0.76, 0.57, 0.84, 0.71]."}, {"from": "gpt", "value": "A pillow on the bed."}, {"from": "human", "value": "Please provide a short description for this region: [0.18, 0.43, 0.44, 0.64]."}, {"from": "gpt", "value": "Green and wood bedroom chair."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Light green pillow on a white bed."}, {"from": "gpt", "value": "[0.76, 0.55, 0.88, 0.74]"}]}, {"id": "VG_100K_2/2383857", "image": "vg/VG_100K_2/2383857.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.41, 0.86, 0.45, 0.91]."}, {"from": "gpt", "value": "Square illumation light."}, {"from": "human", "value": "Please provide a short description for this region: [0.62, 0.58, 0.83, 0.93]."}, {"from": "gpt", "value": "The glass doors."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a long gray pole."}, {"from": "gpt", "value": "[0.17, 0.73, 0.58, 0.78]"}, {"from": "human", "value": "Please provide a short description for this region: [0.2, 0.6, 0.34, 0.69]."}, {"from": "gpt", "value": "Part of a window."}, {"from": "human", "value": "Please provide a short description for this region: [0.2, 0.12, 0.31, 0.26]."}, {"from": "gpt", "value": "Edge of an overhang."}, {"from": "human", "value": "Please provide a short description for this region: [0.18, 0.73, 0.63, 0.82]."}, {"from": "gpt", "value": "Small metal railing on concrete wall."}, {"from": "human", "value": "Please provide a short description for this region: [0.41, 0.86, 0.46, 0.91]."}, {"from": "gpt", "value": "A small outdoor light."}, {"from": "human", "value": "Please provide a short description for this region: [0.41, 0.01, 0.8, 0.36]."}, {"from": "gpt", "value": "Boy with arm extended, looking down."}, {"from": "human", "value": "Please provide a short description for this region: [0.19, 0.33, 0.56, 0.53]."}, {"from": "gpt", "value": "Printing on the bottom of a slightly worn skateboard."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the greenery near the glass doors."}, {"from": "gpt", "value": "[0.21, 0.64, 0.57, 0.93]"}]}, {"id": "VG_100K_2/2383676", "image": "vg/VG_100K_2/2383676.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.0, 0.26, 0.09, 0.63]."}, {"from": "gpt", "value": "A cup color blue."}, {"from": "human", "value": "Please provide a short description for this region: [0.39, 0.17, 0.61, 0.83]."}, {"from": "gpt", "value": "The tie is long."}, {"from": "human", "value": "Please provide a short description for this region: [0.01, 0.17, 0.12, 0.32]."}, {"from": "gpt", "value": "Man has a white beard."}, {"from": "human", "value": "Please provide a short description for this region: [0.67, 0.66, 0.81, 0.82]."}, {"from": "gpt", "value": "Light green and white checked shirt."}, {"from": "human", "value": "Please provide a short description for this region: [0.01, 0.28, 0.07, 0.6]."}, {"from": "gpt", "value": "The cup is made of plastic."}, {"from": "human", "value": "Please provide a short description for this region: [0.04, 0.24, 0.15, 0.33]."}, {"from": "gpt", "value": "Man with  a mustache on face."}, {"from": "human", "value": "Please provide a short description for this region: [0.59, 0.18, 0.86, 0.47]."}, {"from": "gpt", "value": "A pocket on a mans shirt."}, {"from": "human", "value": "Please provide a short description for this region: [0.41, 0.42, 0.54, 0.8]."}, {"from": "gpt", "value": "The tie has christmas trees on it."}, {"from": "human", "value": "Please provide a short description for this region: [0.62, 0.18, 0.89, 0.49]."}, {"from": "gpt", "value": "Pocket on front of the shirt."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Man wearing a tie."}, {"from": "gpt", "value": "[0.39, 0.27, 0.54, 0.67]"}]}, {"id": "VG_100K_2/2383674", "image": "vg/VG_100K_2/2383674.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.33, 0.25, 0.66, 0.39]."}, {"from": "gpt", "value": "The word stop on the sign."}, {"from": "human", "value": "Please provide a short description for this region: [0.18, 0.65, 0.83, 0.87]."}, {"from": "gpt", "value": "Paved road behind a stop sign."}, {"from": "human", "value": "Please provide a short description for this region: [0.61, 0.28, 0.64, 0.32]."}, {"from": "gpt", "value": "Red d inside a white p."}, {"from": "human", "value": "Please provide a short description for this region: [0.58, 0.26, 0.65, 0.38]."}, {"from": "gpt", "value": "A white letter p."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: dirt on the sign."}, {"from": "gpt", "value": "[0.34, 0.39, 0.63, 0.53]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the letter P."}, {"from": "gpt", "value": "[0.58, 0.25, 0.66, 0.4]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: dark green leaves on the branches."}, {"from": "gpt", "value": "[0.17, 0.36, 0.52, 0.73]"}, {"from": "human", "value": "Please provide a short description for this region: [0.24, 0.67, 0.33, 0.89]."}, {"from": "gpt", "value": "Limb of a tree under a stop sign."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: White STOP letters on a sign."}, {"from": "gpt", "value": "[0.33, 0.25, 0.66, 0.39]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Green branch in front of sign."}, {"from": "gpt", "value": "[0.19, 0.37, 0.5, 0.68]"}]}, {"id": "VG_100K_2/2383182", "image": "vg/VG_100K_2/2383182.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.2, 0.39, 0.26, 0.59]."}, {"from": "gpt", "value": "Person with blue pants standing."}, {"from": "human", "value": "Please provide a short description for this region: [0.35, 0.73, 0.76, 0.98]."}, {"from": "gpt", "value": "Black asphalt walkway."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a line of people."}, {"from": "gpt", "value": "[0.19, 0.39, 0.43, 0.58]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: side rear view mirror on a vehicle."}, {"from": "gpt", "value": "[0.85, 0.34, 0.92, 0.51]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: windshield wiper on a vehicle."}, {"from": "gpt", "value": "[0.68, 0.45, 0.78, 0.5]"}, {"from": "human", "value": "Please provide a short description for this region: [0.61, 0.51, 0.7, 0.63]."}, {"from": "gpt", "value": "Front wheel of a vehicle."}, {"from": "human", "value": "Please provide a short description for this region: [0.2, 0.41, 0.26, 0.57]."}, {"from": "gpt", "value": "Man standing in line."}, {"from": "human", "value": "Please provide a short description for this region: [0.39, 0.44, 0.72, 0.55]."}, {"from": "gpt", "value": "Red painted stripe on truck."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white truck with yellow spots."}, {"from": "gpt", "value": "[0.39, 0.33, 0.84, 0.6]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: low hanging tree branches."}, {"from": "gpt", "value": "[0.16, 0.06, 0.76, 0.23]"}]}, {"id": "VG_100K_2/2382654", "image": "vg/VG_100K_2/2382654.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: siding on house is white."}, {"from": "gpt", "value": "[0.16, 0.27, 0.24, 0.41]"}, {"from": "human", "value": "Please provide a short description for this region: [0.35, 0.19, 0.68, 0.6]."}, {"from": "gpt", "value": "Black rectangle on white door."}, {"from": "human", "value": "Please provide a short description for this region: [0.34, 0.64, 0.7, 0.73]."}, {"from": "gpt", "value": "The numbers 5001 on a white door."}, {"from": "human", "value": "Please provide a short description for this region: [0.26, 0.64, 0.31, 0.68]."}, {"from": "gpt", "value": "Handle has keyhole."}, {"from": "human", "value": "Please provide a short description for this region: [0.33, 0.64, 0.69, 0.79]."}, {"from": "gpt", "value": "Address is 5001 brooklyn."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The word Brooklyn on a white door."}, {"from": "gpt", "value": "[0.34, 0.72, 0.68, 0.8]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the numbers on the door."}, {"from": "gpt", "value": "[0.33, 0.64, 0.68, 0.72]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a gray metal key slot."}, {"from": "gpt", "value": "[0.27, 0.35, 0.31, 0.39]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: light shining on the wall."}, {"from": "gpt", "value": "[0.8, 0.14, 0.87, 0.18]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The top edging of a white door."}, {"from": "gpt", "value": "[0.2, 0.02, 0.82, 0.09]"}]}, {"id": "VG_100K_2/2382407", "image": "vg/VG_100K_2/2382407.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a log is in the pond."}, {"from": "gpt", "value": "[0.51, 0.6, 0.6, 0.75]"}, {"from": "human", "value": "Please provide a short description for this region: [0.15, 0.29, 0.78, 0.47]."}, {"from": "gpt", "value": "Long brown tree branch."}, {"from": "human", "value": "Please provide a short description for this region: [0.39, 0.81, 0.52, 0.99]."}, {"from": "gpt", "value": "The giraffe has white legs."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the giraffe has a mouth."}, {"from": "gpt", "value": "[0.48, 0.35, 0.56, 0.4]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a pond is behind the giraffe."}, {"from": "gpt", "value": "[0.28, 0.59, 0.63, 0.7]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Trees behind the fence."}, {"from": "gpt", "value": "[0.62, 0.25, 0.86, 0.55]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the giraffe has front legs."}, {"from": "gpt", "value": "[0.39, 0.84, 0.53, 0.98]"}, {"from": "human", "value": "Please provide a short description for this region: [0.14, 0.29, 0.42, 0.52]."}, {"from": "gpt", "value": "Large beige stone building."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The giraffe is standing."}, {"from": "gpt", "value": "[0.38, 0.35, 0.52, 0.96]"}, {"from": "human", "value": "Please provide a short description for this region: [0.54, 0.55, 0.86, 0.89]."}, {"from": "gpt", "value": "Rocks next to the water."}]}, {"id": "VG_100K_2/2382207", "image": "vg/VG_100K_2/2382207.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: grey minivan with logo and artwork."}, {"from": "gpt", "value": "[0.0, 0.36, 0.51, 0.56]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white fabric with toothed edge."}, {"from": "gpt", "value": "[0.4, 0.17, 0.55, 0.21]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a red and white fence."}, {"from": "gpt", "value": "[0.0, 0.49, 0.05, 0.66]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.33, 0.52, 0.6]."}, {"from": "gpt", "value": "A parked silver minivan."}, {"from": "human", "value": "Please provide a short description for this region: [0.22, 0.27, 0.42, 0.54]."}, {"from": "gpt", "value": "A car."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: road is wet."}, {"from": "gpt", "value": "[0.17, 0.72, 0.43, 0.8]"}, {"from": "human", "value": "Please provide a short description for this region: [0.47, 0.27, 0.66, 0.39]."}, {"from": "gpt", "value": "Purplish pink open umbrella."}, {"from": "human", "value": "Please provide a short description for this region: [0.7, 0.4, 0.9, 0.55]."}, {"from": "gpt", "value": "Car has a cover."}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.24, 0.68, 0.41]."}, {"from": "gpt", "value": "The umbrella is purple."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Sign attached to a pole."}, {"from": "gpt", "value": "[0.7, 0.3, 0.95, 0.38]"}]}, {"id": "VG_100K_2/2382025", "image": "vg/VG_100K_2/2382025.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.63, 0.57, 0.7, 0.66]."}, {"from": "gpt", "value": "Black wheel on plane."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Plane is mostly gray in color."}, {"from": "gpt", "value": "[0.2, 0.42, 0.83, 0.57]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: BLUE TIPPED AIRPLANE WING."}, {"from": "gpt", "value": "[0.11, 0.48, 0.49, 0.53]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Man piloting the plane."}, {"from": "gpt", "value": "[0.67, 0.39, 0.73, 0.43]"}, {"from": "human", "value": "Please provide a short description for this region: [0.14, 0.44, 0.58, 0.61]."}, {"from": "gpt", "value": "Wing on side of plane."}, {"from": "human", "value": "Please provide a short description for this region: [0.49, 0.61, 0.53, 0.67]."}, {"from": "gpt", "value": "Small round airplane wheel."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Window on top of plane."}, {"from": "gpt", "value": "[0.62, 0.36, 0.8, 0.48]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: small round airplane wheel."}, {"from": "gpt", "value": "[0.48, 0.62, 0.54, 0.66]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Small wheel on front."}, {"from": "gpt", "value": "[0.63, 0.6, 0.69, 0.63]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: IDENTIFICATION OF AIRPLANE."}, {"from": "gpt", "value": "[0.26, 0.44, 0.34, 0.49]"}]}, {"id": "VG_100K_2/2381776", "image": "vg/VG_100K_2/2381776.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.69, 0.35, 0.74, 0.46]."}, {"from": "gpt", "value": "Black line."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Papers are in the desk."}, {"from": "gpt", "value": "[0.53, 0.4, 0.65, 0.58]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: black line."}, {"from": "gpt", "value": "[0.69, 0.38, 0.82, 0.51]"}, {"from": "human", "value": "Please provide a short description for this region: [0.65, 0.39, 0.75, 0.44]."}, {"from": "gpt", "value": "Black line."}, {"from": "human", "value": "Please provide a short description for this region: [0.14, 0.35, 0.46, 0.84]."}, {"from": "gpt", "value": "Boy is wearing white shirt."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the folder on th etable is green."}, {"from": "gpt", "value": "[0.82, 0.72, 0.94, 0.86]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the door is brown."}, {"from": "gpt", "value": "[0.08, 0.13, 0.18, 0.22]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Rail is black color."}, {"from": "gpt", "value": "[0.65, 0.35, 0.8, 0.45]"}, {"from": "human", "value": "Please provide a short description for this region: [0.67, 0.31, 0.85, 0.45]."}, {"from": "gpt", "value": "Black line."}, {"from": "human", "value": "Please provide a short description for this region: [0.68, 0.39, 0.76, 0.5]."}, {"from": "gpt", "value": "Black line."}]}, {"id": "VG_100K_2/2381175", "image": "vg/VG_100K_2/2381175.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: Blue colored S sign."}, {"from": "gpt", "value": "[0.18, 0.13, 0.21, 0.16]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: snow in the background."}, {"from": "gpt", "value": "[0.5, 0.16, 0.63, 0.26]"}, {"from": "human", "value": "Please provide a short description for this region: [0.72, 0.12, 0.79, 0.28]."}, {"from": "gpt", "value": "A cement base holding pole up."}, {"from": "human", "value": "Please provide a short description for this region: [0.76, 0.7, 0.85, 0.76]."}, {"from": "gpt", "value": "Board track in snow."}, {"from": "human", "value": "Please provide a short description for this region: [0.22, 0.13, 0.25, 0.17]."}, {"from": "gpt", "value": "White colored s on snow."}, {"from": "human", "value": "Please provide a short description for this region: [0.16, 0.24, 0.28, 0.28]."}, {"from": "gpt", "value": "Line connected to pole."}, {"from": "human", "value": "Please provide a short description for this region: [0.1, 0.13, 0.36, 0.19]."}, {"from": "gpt", "value": "Large e and f blue and red sign in snow."}, {"from": "human", "value": "Please provide a short description for this region: [0.36, 0.36, 0.44, 0.43]."}, {"from": "gpt", "value": "Arm of the man."}, {"from": "human", "value": "Please provide a short description for this region: [0.88, 0.15, 0.94, 0.42]."}, {"from": "gpt", "value": "Yellow tall pole with a light on top."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Black snowboard of snowboarder."}, {"from": "gpt", "value": "[0.25, 0.43, 0.37, 0.47]"}]}, {"id": "VG_100K_2/2381083", "image": "vg/VG_100K_2/2381083.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.04, 0.6, 0.22, 0.73]."}, {"from": "gpt", "value": "Black car parked on road."}, {"from": "human", "value": "Please provide a short description for this region: [0.62, 0.65, 0.99, 0.85]."}, {"from": "gpt", "value": "A brick paved street."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: an electric traffic signal."}, {"from": "gpt", "value": "[0.08, 0.34, 0.13, 0.42]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: large beautiful green tree."}, {"from": "gpt", "value": "[0.23, 0.43, 0.6, 0.65]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the light is showing red."}, {"from": "gpt", "value": "[0.43, 0.26, 0.58, 0.31]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the light is showing red."}, {"from": "gpt", "value": "[0.46, 0.25, 0.58, 0.38]"}, {"from": "human", "value": "Please provide a short description for this region: [0.07, 0.42, 0.65, 0.6]."}, {"from": "gpt", "value": "Trees along the road."}, {"from": "human", "value": "Please provide a short description for this region: [0.01, 0.61, 0.31, 0.71]."}, {"from": "gpt", "value": "Cars stopped at red light."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: caution sign on power pole."}, {"from": "gpt", "value": "[0.01, 0.54, 0.1, 0.71]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: beautiful white church steeple."}, {"from": "gpt", "value": "[0.16, 0.23, 0.36, 0.59]"}]}, {"id": "VG_100K_2/2379505", "image": "vg/VG_100K_2/2379505.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: the cord is black."}, {"from": "gpt", "value": "[0.3, 0.63, 0.33, 0.78]"}, {"from": "human", "value": "Please provide a short description for this region: [0.58, 0.67, 0.86, 0.87]."}, {"from": "gpt", "value": "A lack back on a rug."}, {"from": "human", "value": "Please provide a short description for this region: [0.57, 0.17, 0.69, 0.31]."}, {"from": "gpt", "value": "Woman with laptop on her lap."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Checkered rug on the floor."}, {"from": "gpt", "value": "[0.37, 0.73, 0.45, 0.83]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the cord is white."}, {"from": "gpt", "value": "[0.79, 0.63, 0.83, 0.78]"}, {"from": "human", "value": "Please provide a short description for this region: [0.57, 0.66, 0.84, 0.87]."}, {"from": "gpt", "value": "The black bag on the ground."}, {"from": "human", "value": "Please provide a short description for this region: [0.59, 0.24, 0.65, 0.28]."}, {"from": "gpt", "value": "Black laptop on woman's lap."}, {"from": "human", "value": "Please provide a short description for this region: [0.5, 0.35, 0.75, 0.52]."}, {"from": "gpt", "value": "The man's opened laptop."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Black and white tennis shoes on the person's feet."}, {"from": "gpt", "value": "[0.86, 0.79, 0.94, 0.84]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: green lid of a laptop."}, {"from": "gpt", "value": "[0.57, 0.35, 0.75, 0.51]"}]}, {"id": "VG_100K_2/2378989", "image": "vg/VG_100K_2/2378989.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.32, 0.37, 0.39, 0.41]."}, {"from": "gpt", "value": "A car along the road."}, {"from": "human", "value": "Please provide a short description for this region: [0.69, 0.42, 0.89, 0.65]."}, {"from": "gpt", "value": "The motorcycle is black."}, {"from": "human", "value": "Please provide a short description for this region: [0.44, 0.49, 0.83, 0.82]."}, {"from": "gpt", "value": "The motorcycle is black."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: red rear motorcycle brake light."}, {"from": "gpt", "value": "[0.74, 0.74, 0.78, 0.79]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: motorcycle parked on the pavement."}, {"from": "gpt", "value": "[0.4, 0.4, 0.58, 0.55]"}, {"from": "human", "value": "Please provide a short description for this region: [0.89, 0.31, 1.0, 0.58]."}, {"from": "gpt", "value": "Men on the sidewalk."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the person is standing."}, {"from": "gpt", "value": "[0.15, 0.32, 0.28, 0.64]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Sign by the highway."}, {"from": "gpt", "value": "[0.66, 0.23, 0.88, 0.4]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a person on a  motorbike."}, {"from": "gpt", "value": "[0.27, 0.39, 0.33, 0.46]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: small motorcycle rear view mirror."}, {"from": "gpt", "value": "[0.23, 0.48, 0.27, 0.52]"}]}, {"id": "VG_100K_2/2378676", "image": "vg/VG_100K_2/2378676.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: back of a chair."}, {"from": "gpt", "value": "[0.0, 0.89, 0.16, 1.0]"}, {"from": "human", "value": "Please provide a short description for this region: [0.15, 0.28, 0.21, 0.33]."}, {"from": "gpt", "value": "The thumbnail is clean."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the hand has fingers."}, {"from": "gpt", "value": "[0.16, 0.42, 0.41, 0.67]"}, {"from": "human", "value": "Please provide a short description for this region: [0.56, 0.28, 0.87, 0.46]."}, {"from": "gpt", "value": "These are left handed scissors."}, {"from": "human", "value": "Please provide a short description for this region: [0.59, 0.21, 0.88, 0.44]."}, {"from": "gpt", "value": "A pair of scissors."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the palm of a hand."}, {"from": "gpt", "value": "[0.04, 0.44, 0.2, 0.63]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: this is a gold ring."}, {"from": "gpt", "value": "[0.18, 0.54, 0.24, 0.6]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the shiny ring on the finger."}, {"from": "gpt", "value": "[0.19, 0.53, 0.22, 0.58]"}, {"from": "human", "value": "Please provide a short description for this region: [0.62, 0.22, 0.75, 0.36]."}, {"from": "gpt", "value": "Black and white plastic scissors."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the scissors are plastic."}, {"from": "gpt", "value": "[0.53, 0.2, 0.88, 0.44]"}]}, {"id": "VG_100K_2/2378509", "image": "vg/VG_100K_2/2378509.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.65, 0.48, 0.75, 1.0]."}, {"from": "gpt", "value": "A dark metal pole."}, {"from": "human", "value": "Please provide a short description for this region: [0.54, 0.16, 0.8, 0.44]."}, {"from": "gpt", "value": "Sign about bicycles."}, {"from": "human", "value": "Please provide a short description for this region: [0.25, 0.63, 0.32, 0.66]."}, {"from": "gpt", "value": "Boy wearing sneakers."}, {"from": "human", "value": "Please provide a short description for this region: [0.79, 0.59, 0.81, 0.71]."}, {"from": "gpt", "value": "A stone pillar."}, {"from": "human", "value": "Please provide a short description for this region: [0.26, 0.47, 0.34, 0.66]."}, {"from": "gpt", "value": "Young man on a skateboard."}, {"from": "human", "value": "Please provide a short description for this region: [0.38, 0.5, 0.58, 0.62]."}, {"from": "gpt", "value": "Posts on side of the road."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: green leaves on a tree."}, {"from": "gpt", "value": "[0.2, 0.18, 0.51, 0.48]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a boy riding a skateboard."}, {"from": "gpt", "value": "[0.25, 0.46, 0.37, 0.68]"}, {"from": "human", "value": "Please provide a short description for this region: [0.18, 0.7, 0.57, 0.94]."}, {"from": "gpt", "value": "Black paved road of a street."}, {"from": "human", "value": "Please provide a short description for this region: [0.63, 0.49, 0.77, 1.0]."}, {"from": "gpt", "value": "Pole where sign is attached."}]}, {"id": "VG_100K/2376308", "image": "vg/VG_100K/2376308.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: This is a man splashing water."}, {"from": "gpt", "value": "[0.56, 0.64, 0.87, 0.78]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Dirt in front of the tree."}, {"from": "gpt", "value": "[0.07, 0.68, 0.16, 0.72]"}, {"from": "human", "value": "Please provide a short description for this region: [0.11, 0.69, 0.58, 0.77]."}, {"from": "gpt", "value": "White waves on the water."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Water in the air."}, {"from": "gpt", "value": "[0.56, 0.66, 0.83, 0.73]"}, {"from": "human", "value": "Please provide a short description for this region: [0.26, 0.79, 0.31, 0.83]."}, {"from": "gpt", "value": "Ripple in the water."}, {"from": "human", "value": "Please provide a short description for this region: [0.67, 0.72, 0.75, 0.76]."}, {"from": "gpt", "value": "Part of the ski is sticking up."}, {"from": "human", "value": "Please provide a short description for this region: [0.25, 0.72, 0.57, 0.75]."}, {"from": "gpt", "value": "The water is white."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.31, 0.51, 0.49]."}, {"from": "gpt", "value": "Clear sky over the trees."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the wake caused by the waterskiier."}, {"from": "gpt", "value": "[0.01, 0.72, 0.66, 0.74]"}]}, {"id": "VG_100K/2376029", "image": "vg/VG_100K/2376029.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.27, 0.62, 0.37, 0.71]."}, {"from": "gpt", "value": "Blue nametag of man."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Man has blue colored eyes."}, {"from": "gpt", "value": "[0.32, 0.37, 0.46, 0.43]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: name tag of man giving presentation."}, {"from": "gpt", "value": "[0.28, 0.63, 0.34, 0.67]"}, {"from": "human", "value": "Please provide a short description for this region: [0.53, 0.46, 0.76, 0.66]."}, {"from": "gpt", "value": "Man's hand is in air."}, {"from": "human", "value": "Please provide a short description for this region: [0.25, 0.29, 0.47, 0.41]."}, {"from": "gpt", "value": "Salt and pepper hair."}, {"from": "human", "value": "Please provide a short description for this region: [0.55, 0.6, 0.98, 0.83]."}, {"from": "gpt", "value": "Black podium in front of man."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Piano black podium."}, {"from": "gpt", "value": "[0.58, 0.65, 0.99, 0.82]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man wearing a ring."}, {"from": "gpt", "value": "[0.64, 0.51, 0.67, 0.56]"}, {"from": "human", "value": "Please provide a short description for this region: [0.64, 0.53, 0.66, 0.55]."}, {"from": "gpt", "value": "Gold wedding ring on the left ring finger."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man's tie is black and yellow."}, {"from": "gpt", "value": "[0.36, 0.54, 0.5, 0.76]"}]}, {"id": "VG_100K/2375876", "image": "vg/VG_100K/2375876.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.78, 0.28, 0.98, 0.53]."}, {"from": "gpt", "value": "Bowl is white color."}, {"from": "human", "value": "Please provide a short description for this region: [0.27, 0.32, 0.35, 0.39]."}, {"from": "gpt", "value": "White paw of cat."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: counter top next to the cat."}, {"from": "gpt", "value": "[0.06, 0.74, 0.24, 0.82]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: head of cat under paw."}, {"from": "gpt", "value": "[0.26, 0.46, 0.44, 0.71]"}, {"from": "human", "value": "Please provide a short description for this region: [0.01, 0.64, 0.16, 0.8]."}, {"from": "gpt", "value": "Floor is white color."}, {"from": "human", "value": "Please provide a short description for this region: [0.78, 0.28, 0.92, 0.42]."}, {"from": "gpt", "value": "White porcelain sink."}, {"from": "human", "value": "Please provide a short description for this region: [0.1, 0.39, 0.26, 0.64]."}, {"from": "gpt", "value": "Orange cat tail."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a paw white and orange."}, {"from": "gpt", "value": "[0.2, 0.41, 0.3, 0.51]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: left whiskers of cat."}, {"from": "gpt", "value": "[0.29, 0.5, 0.36, 0.6]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: tail of fluffy orange cat."}, {"from": "gpt", "value": "[0.1, 0.26, 0.37, 0.68]"}]}, {"id": "VG_100K/2375240", "image": "vg/VG_100K/2375240.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: The clock's hour hand."}, {"from": "gpt", "value": "[0.53, 0.51, 0.61, 0.54]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The clock says 3:05."}, {"from": "gpt", "value": "[0.45, 0.41, 0.68, 0.63]"}, {"from": "human", "value": "Please provide a short description for this region: [0.09, 0.77, 0.28, 0.87]."}, {"from": "gpt", "value": "Shadows on pavement."}, {"from": "human", "value": "Please provide a short description for this region: [0.03, 0.36, 0.2, 0.6]."}, {"from": "gpt", "value": "Statue beside the fence."}, {"from": "human", "value": "Please provide a short description for this region: [0.51, 0.57, 0.55, 0.61]."}, {"from": "gpt", "value": "A pink diamond under the 6."}, {"from": "human", "value": "Please provide a short description for this region: [0.51, 0.44, 0.61, 0.53]."}, {"from": "gpt", "value": "Hands on the clock."}, {"from": "human", "value": "Please provide a short description for this region: [0.23, 0.72, 0.81, 0.76]."}, {"from": "gpt", "value": "Rocks underneath the fence."}, {"from": "human", "value": "Please provide a short description for this region: [0.05, 0.78, 0.07, 0.84]."}, {"from": "gpt", "value": "Part of a graphic."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: This is a wooden bar."}, {"from": "gpt", "value": "[0.15, 0.6, 0.17, 0.73]"}]}, {"id": "VG_100K/2375218", "image": "vg/VG_100K/2375218.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.3, 0.43, 0.37, 0.5]."}, {"from": "gpt", "value": "The helmet on the skier is black."}, {"from": "human", "value": "Please provide a short description for this region: [0.3, 0.56, 0.38, 0.64]."}, {"from": "gpt", "value": "Multicolored snow pants."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A long skatting stick."}, {"from": "gpt", "value": "[0.28, 0.51, 0.34, 0.64]"}, {"from": "human", "value": "Please provide a short description for this region: [0.64, 0.41, 0.72, 0.52]."}, {"from": "gpt", "value": "Person dressed in black ski outfit trimmed in white."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the skis are black."}, {"from": "gpt", "value": "[0.25, 0.62, 0.49, 0.68]"}, {"from": "human", "value": "Please provide a short description for this region: [0.26, 0.45, 0.5, 0.69]."}, {"from": "gpt", "value": "The skiers jacket is blue."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: person leaning to the side."}, {"from": "gpt", "value": "[0.64, 0.41, 0.73, 0.53]"}, {"from": "human", "value": "Please provide a short description for this region: [0.61, 0.39, 0.76, 0.55]."}, {"from": "gpt", "value": "A skier in black and white."}, {"from": "human", "value": "Please provide a short description for this region: [0.61, 0.41, 0.75, 0.53]."}, {"from": "gpt", "value": "The skier is dressed in black."}, {"from": "human", "value": "Please provide a short description for this region: [0.3, 0.48, 0.37, 0.58]."}, {"from": "gpt", "value": "Skier dressed in light blue jacket."}]}, {"id": "VG_100K/2374873", "image": "vg/VG_100K/2374873.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.58, 0.36, 0.78, 0.7]."}, {"from": "gpt", "value": "Man on a scooter."}, {"from": "human", "value": "Please provide a short description for this region: [0.01, 0.41, 0.27, 0.63]."}, {"from": "gpt", "value": "Bicycles parked in the sidewalk."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: parked bicycles on the sidewalk."}, {"from": "gpt", "value": "[0.0, 0.35, 0.35, 0.71]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A bicycle basket."}, {"from": "gpt", "value": "[0.49, 0.56, 0.6, 0.64]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A younge guy riding a scooter."}, {"from": "gpt", "value": "[0.57, 0.36, 0.78, 0.71]"}, {"from": "human", "value": "Please provide a short description for this region: [0.87, 0.33, 0.96, 0.46]."}, {"from": "gpt", "value": "A person wearing a reflective vest."}, {"from": "human", "value": "Please provide a short description for this region: [0.24, 0.13, 0.3, 0.58]."}, {"from": "gpt", "value": "Traffic light posted on metal post."}, {"from": "human", "value": "Please provide a short description for this region: [0.56, 0.32, 0.82, 0.73]."}, {"from": "gpt", "value": "Man looking forward."}, {"from": "human", "value": "Please provide a short description for this region: [0.4, 0.34, 0.62, 0.84]."}, {"from": "gpt", "value": "Man wearing glasses riding a bike."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man wearing glasses."}, {"from": "gpt", "value": "[0.46, 0.37, 0.51, 0.39]"}]}, {"id": "VG_100K/2374806", "image": "vg/VG_100K/2374806.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.89, 0.32, 0.94, 0.76]."}, {"from": "gpt", "value": "The text is yellow."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a very blue sky."}, {"from": "gpt", "value": "[0.0, 0.17, 0.99, 0.31]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: contrail coming off the back of the plane."}, {"from": "gpt", "value": "[0.0, 0.4, 0.78, 0.57]"}, {"from": "human", "value": "Please provide a short description for this region: [0.67, 0.33, 0.99, 0.79]."}, {"from": "gpt", "value": "The plane is blue and yellow."}, {"from": "human", "value": "Please provide a short description for this region: [0.75, 0.48, 0.78, 0.54]."}, {"from": "gpt", "value": "Airplane tale lights."}, {"from": "human", "value": "Please provide a short description for this region: [0.85, 0.32, 0.98, 0.48]."}, {"from": "gpt", "value": "Top airplane wing."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: plane flying in the sky."}, {"from": "gpt", "value": "[0.69, 0.31, 1.0, 0.74]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the starboard exhaust nozzle."}, {"from": "gpt", "value": "[0.74, 0.47, 0.79, 0.5]"}, {"from": "human", "value": "Please provide a short description for this region: [0.67, 0.31, 1.0, 0.73]."}, {"from": "gpt", "value": "Yellow and blue plane."}, {"from": "human", "value": "Please provide a short description for this region: [0.74, 0.48, 1.0, 0.56]."}, {"from": "gpt", "value": "The body of blue plane."}]}, {"id": "VG_100K/2374695", "image": "vg/VG_100K/2374695.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.02, 0.16, 0.47, 0.48]."}, {"from": "gpt", "value": "Black sheep grazing in the field."}, {"from": "human", "value": "Please provide a short description for this region: [0.71, 0.51, 0.8, 0.67]."}, {"from": "gpt", "value": "Light brown wooden fence post."}, {"from": "human", "value": "Please provide a short description for this region: [0.73, 0.64, 0.98, 0.86]."}, {"from": "gpt", "value": "Cat laying in the grass."}, {"from": "human", "value": "Please provide a short description for this region: [0.02, 0.15, 0.38, 0.5]."}, {"from": "gpt", "value": "Black sheep walking in the grass."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: gray black and white striped cat."}, {"from": "gpt", "value": "[0.74, 0.32, 0.97, 0.45]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a black sheep inside a pen."}, {"from": "gpt", "value": "[0.02, 0.15, 0.39, 0.48]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.52, 0.29, 0.79]."}, {"from": "gpt", "value": "A goat looking at a cat."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a bell on a sheep's collar."}, {"from": "gpt", "value": "[0.01, 0.66, 0.06, 0.71]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Light brown wooden fence post."}, {"from": "gpt", "value": "[0.24, 0.51, 0.34, 0.82]"}, {"from": "human", "value": "Please provide a short description for this region: [0.16, 0.6, 0.18, 0.66]."}, {"from": "gpt", "value": "A bell around a goat's neck."}]}, {"id": "VG_100K/2374512", "image": "vg/VG_100K/2374512.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.78, 0.43, 0.98, 0.71]."}, {"from": "gpt", "value": "Tomatoes near the broccoli."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: black beans next to broccoli on plate."}, {"from": "gpt", "value": "[0.0, 0.3, 0.26, 0.69]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the counter top is white."}, {"from": "gpt", "value": "[0.54, 0.06, 0.79, 0.42]"}, {"from": "human", "value": "Please provide a short description for this region: [0.76, 0.39, 0.98, 0.57]."}, {"from": "gpt", "value": "The tomato has been cut."}, {"from": "human", "value": "Please provide a short description for this region: [0.29, 0.24, 0.53, 0.54]."}, {"from": "gpt", "value": "Broccoli near some tomatoes."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the bowl is white."}, {"from": "gpt", "value": "[0.49, 0.53, 0.73, 0.85]"}, {"from": "human", "value": "Please provide a short description for this region: [0.15, 0.66, 0.45, 0.88]."}, {"from": "gpt", "value": "Lettuce by the broccoli."}, {"from": "human", "value": "Please provide a short description for this region: [0.25, 0.33, 0.53, 0.6]."}, {"from": "gpt", "value": "The broccoli is green."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Cut tomatoes on a plate."}, {"from": "gpt", "value": "[0.78, 0.29, 1.0, 0.69]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: tip of knife next to white plate."}, {"from": "gpt", "value": "[0.69, 0.83, 0.88, 1.0]"}]}, {"id": "VG_100K/2374146", "image": "vg/VG_100K/2374146.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a dark brown chest of drawers."}, {"from": "gpt", "value": "[0.63, 0.19, 0.79, 0.5]"}, {"from": "human", "value": "Please provide a short description for this region: [0.72, 0.49, 1.0, 0.83]."}, {"from": "gpt", "value": "A black coffee table."}, {"from": "human", "value": "Please provide a short description for this region: [0.56, 0.59, 0.69, 0.86]."}, {"from": "gpt", "value": "White tiles on floor in room."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the glass on the coffee table."}, {"from": "gpt", "value": "[0.77, 0.58, 1.0, 0.75]"}, {"from": "human", "value": "Please provide a short description for this region: [0.64, 0.23, 0.71, 0.45]."}, {"from": "gpt", "value": "Brown shelving unit in corner of room."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Brown curtains in room."}, {"from": "gpt", "value": "[0.32, 0.21, 0.6, 0.39]"}, {"from": "human", "value": "Please provide a short description for this region: [0.87, 0.23, 0.91, 0.33]."}, {"from": "gpt", "value": "A yellow cylinder."}, {"from": "human", "value": "Please provide a short description for this region: [0.14, 0.13, 0.22, 0.24]."}, {"from": "gpt", "value": "A light on a wall."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: window is cover with a curtain."}, {"from": "gpt", "value": "[0.29, 0.17, 0.57, 0.38]"}, {"from": "human", "value": "Please provide a short description for this region: [0.13, 0.12, 0.19, 0.18]."}, {"from": "gpt", "value": "The light on the wall."}]}, {"id": "VG_100K/2374055", "image": "vg/VG_100K/2374055.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: sign post is black."}, {"from": "gpt", "value": "[0.35, 0.71, 0.59, 0.9]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: edge of a window."}, {"from": "gpt", "value": "[0.8, 0.85, 0.82, 0.94]"}, {"from": "human", "value": "Please provide a short description for this region: [0.37, 0.24, 0.62, 0.55]."}, {"from": "gpt", "value": "Green steeple of building."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: window frame is black."}, {"from": "gpt", "value": "[0.73, 0.75, 0.83, 0.98]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: black sign with white lettering."}, {"from": "gpt", "value": "[0.39, 0.79, 0.5, 0.89]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Clocks above the building."}, {"from": "gpt", "value": "[0.42, 0.33, 0.58, 0.43]"}, {"from": "human", "value": "Please provide a short description for this region: [0.74, 0.77, 0.83, 0.99]."}, {"from": "gpt", "value": "White window with black window frame."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: discolored spot on green steeple."}, {"from": "gpt", "value": "[0.52, 0.23, 0.56, 0.29]"}]}, {"id": "VG_100K/2372937", "image": "vg/VG_100K/2372937.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.93, 0.72, 1.0, 0.8]."}, {"from": "gpt", "value": "Left headlight of van in intersection."}, {"from": "human", "value": "Please provide a short description for this region: [0.85, 0.64, 1.0, 0.83]."}, {"from": "gpt", "value": "Front nose of red vehicle."}, {"from": "human", "value": "Please provide a short description for this region: [0.1, 0.18, 0.36, 0.45]."}, {"from": "gpt", "value": "Beige building in the background."}, {"from": "human", "value": "Please provide a short description for this region: [0.16, 0.4, 0.98, 0.47]."}, {"from": "gpt", "value": "Passengers sitting on top of double decker bus."}, {"from": "human", "value": "Please provide a short description for this region: [0.05, 0.58, 0.12, 0.61]."}, {"from": "gpt", "value": "A small section of grass."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: passengers riding on the bus."}, {"from": "gpt", "value": "[0.49, 0.38, 0.61, 0.49]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a long building window."}, {"from": "gpt", "value": "[0.28, 0.24, 0.31, 0.33]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Passenger wearing blue top."}, {"from": "gpt", "value": "[0.86, 0.42, 0.89, 0.44]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: part of a red van."}, {"from": "gpt", "value": "[0.83, 0.66, 1.0, 0.83]"}, {"from": "human", "value": "Please provide a short description for this region: [0.13, 0.44, 0.98, 0.53]."}, {"from": "gpt", "value": "Arrows inside circles above bus windows."}]}, {"id": "VG_100K/2372717", "image": "vg/VG_100K/2372717.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: long fence in the background."}, {"from": "gpt", "value": "[0.01, 0.17, 0.99, 0.22]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The poles holding the gate up."}, {"from": "gpt", "value": "[0.05, 0.22, 0.1, 0.68]"}, {"from": "human", "value": "Please provide a short description for this region: [0.24, 0.64, 0.82, 0.72]."}, {"from": "gpt", "value": "The color of the grass is green."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The tail of the zebra."}, {"from": "gpt", "value": "[0.19, 0.34, 0.24, 0.49]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The leg of the zebra."}, {"from": "gpt", "value": "[0.16, 0.46, 0.27, 0.64]"}, {"from": "human", "value": "Please provide a short description for this region: [0.19, 0.45, 0.55, 0.63]."}, {"from": "gpt", "value": "The zebra legs."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The head of the zebra."}, {"from": "gpt", "value": "[0.57, 0.5, 0.69, 0.61]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a fence."}, {"from": "gpt", "value": "[0.78, 0.2, 0.99, 0.55]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the zebra neck and head."}, {"from": "gpt", "value": "[0.55, 0.37, 0.69, 0.6]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: brown grass patches in the grass."}, {"from": "gpt", "value": "[0.91, 0.71, 0.99, 0.76]"}]}, {"id": "VG_100K/2372673", "image": "vg/VG_100K/2372673.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.71, 0.33, 0.81, 0.4]."}, {"from": "gpt", "value": "Two pointy ears of a horse."}, {"from": "human", "value": "Please provide a short description for this region: [0.34, 0.17, 0.42, 0.21]."}, {"from": "gpt", "value": "The person is wearing a hat."}, {"from": "human", "value": "Please provide a short description for this region: [0.71, 0.33, 0.8, 0.54]."}, {"from": "gpt", "value": "A head of a horse."}, {"from": "human", "value": "Please provide a short description for this region: [0.93, 0.45, 1.0, 0.71]."}, {"from": "gpt", "value": "Man wearing all black."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white bumper on the car."}, {"from": "gpt", "value": "[0.78, 0.57, 0.92, 0.6]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the ear of a horse."}, {"from": "gpt", "value": "[0.56, 0.35, 0.6, 0.41]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the front leg of a horse."}, {"from": "gpt", "value": "[0.64, 0.63, 0.7, 0.8]"}, {"from": "human", "value": "Please provide a short description for this region: [0.93, 0.44, 1.0, 0.72]."}, {"from": "gpt", "value": "A policeman wears black cloths."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: mane of horse is black."}, {"from": "gpt", "value": "[0.49, 0.37, 0.57, 0.45]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: black straps around the body."}, {"from": "gpt", "value": "[0.31, 0.44, 0.49, 0.63]"}]}, {"id": "VG_100K/2372503", "image": "vg/VG_100K/2372503.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.53, 0.43, 0.84, 0.75]."}, {"from": "gpt", "value": "Macaroni and cheese on plate."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a bun."}, {"from": "gpt", "value": "[0.31, 0.55, 0.39, 0.64]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: yellow box macaroni and cheese."}, {"from": "gpt", "value": "[0.53, 0.43, 0.8, 0.76]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white plastic fork."}, {"from": "gpt", "value": "[0.39, 0.69, 0.96, 0.81]"}, {"from": "human", "value": "Please provide a short description for this region: [0.95, 0.34, 1.0, 0.4]."}, {"from": "gpt", "value": "Stray macaroni noodle on table."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: side of macaroni and cheese."}, {"from": "gpt", "value": "[0.54, 0.39, 0.82, 0.77]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: corn on the cob on plate."}, {"from": "gpt", "value": "[0.42, 0.25, 0.7, 0.41]"}, {"from": "human", "value": "Please provide a short description for this region: [0.42, 0.24, 0.75, 0.43]."}, {"from": "gpt", "value": "Half piece of corn on the cob."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a clean fork."}, {"from": "gpt", "value": "[0.39, 0.69, 0.98, 0.81]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: seasoning on the corn."}, {"from": "gpt", "value": "[0.64, 0.27, 0.68, 0.34]"}]}, {"id": "VG_100K/2372002", "image": "vg/VG_100K/2372002.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.01, 0.61, 0.12, 0.87]."}, {"from": "gpt", "value": "Glass door with white lettering."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: utility wires attached to a wooden pole."}, {"from": "gpt", "value": "[0.0, 0.19, 0.21, 0.3]"}, {"from": "human", "value": "Please provide a short description for this region: [0.35, 0.73, 0.41, 0.87]."}, {"from": "gpt", "value": "Silver metal pole attached to stop sign."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a white and glass door."}, {"from": "gpt", "value": "[0.0, 0.62, 0.09, 0.87]"}, {"from": "human", "value": "Please provide a short description for this region: [0.29, 0.41, 0.38, 0.6]."}, {"from": "gpt", "value": "White \"t\" on sign."}, {"from": "human", "value": "Please provide a short description for this region: [0.19, 0.12, 0.34, 0.87]."}, {"from": "gpt", "value": "Tall wooden electrical pole."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: White \"P\" on sign."}, {"from": "gpt", "value": "[0.48, 0.43, 0.58, 0.6]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.5, 0.18, 0.63]."}, {"from": "gpt", "value": "Striped overhang on building."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: teal and white overhang."}, {"from": "gpt", "value": "[0.0, 0.49, 0.22, 0.65]"}]}, {"id": "VG_100K/2371597", "image": "vg/VG_100K/2371597.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: white flower in a garden."}, {"from": "gpt", "value": "[0.29, 0.28, 0.36, 0.41]"}, {"from": "human", "value": "Please provide a short description for this region: [0.05, 0.3, 0.26, 0.68]."}, {"from": "gpt", "value": "Woman on bench itching her back."}, {"from": "human", "value": "Please provide a short description for this region: [0.7, 0.42, 0.85, 0.5]."}, {"from": "gpt", "value": "Group of purple flowers."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A blue button down shirt."}, {"from": "gpt", "value": "[0.43, 0.35, 0.65, 0.54]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a concrete bench."}, {"from": "gpt", "value": "[0.48, 0.54, 0.63, 0.79]"}, {"from": "human", "value": "Please provide a short description for this region: [0.32, 0.31, 0.66, 0.71]."}, {"from": "gpt", "value": "Man seated on bench reading a book."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: girl sitting on a bench."}, {"from": "gpt", "value": "[0.06, 0.27, 0.32, 0.68]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a woman's pink shoe."}, {"from": "gpt", "value": "[0.05, 0.62, 0.1, 0.65]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Bright pink sneakers the woman is wearing."}, {"from": "gpt", "value": "[0.05, 0.61, 0.11, 0.65]"}, {"from": "human", "value": "Please provide a short description for this region: [0.57, 0.68, 0.99, 0.83]."}, {"from": "gpt", "value": "Part of a paved patio."}]}, {"id": "VG_100K/2371147", "image": "vg/VG_100K/2371147.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: sheep is wearing a tag."}, {"from": "gpt", "value": "[0.24, 0.38, 0.4, 0.47]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: brown and black sheep standing in snow."}, {"from": "gpt", "value": "[0.41, 0.34, 0.72, 0.54]"}, {"from": "human", "value": "Please provide a short description for this region: [0.26, 0.28, 0.38, 0.35]."}, {"from": "gpt", "value": "The eyes are open."}, {"from": "human", "value": "Please provide a short description for this region: [0.34, 0.12, 0.81, 0.3]."}, {"from": "gpt", "value": "The snow is on the trees."}, {"from": "human", "value": "Please provide a short description for this region: [0.78, 0.33, 0.94, 0.58]."}, {"from": "gpt", "value": "Brown and black sheep standing in snow."}, {"from": "human", "value": "Please provide a short description for this region: [0.16, 0.29, 0.4, 0.64]."}, {"from": "gpt", "value": "Brown sheep."}, {"from": "human", "value": "Please provide a short description for this region: [0.29, 0.38, 0.37, 0.41]."}, {"from": "gpt", "value": "Collar of sheep around it's neck."}, {"from": "human", "value": "Please provide a short description for this region: [0.43, 0.35, 0.72, 0.53]."}, {"from": "gpt", "value": "Black and brown sheep standing in white snow."}, {"from": "human", "value": "Please provide a short description for this region: [0.23, 0.29, 0.4, 0.58]."}, {"from": "gpt", "value": "Black and brown sheep standing in white snow."}, {"from": "human", "value": "Please provide a short description for this region: [0.22, 0.29, 0.4, 0.6]."}, {"from": "gpt", "value": "Brown and black sheep standing in white snow."}]}, {"id": "VG_100K/2370792", "image": "vg/VG_100K/2370792.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.29, 0.17, 0.99, 0.22]."}, {"from": "gpt", "value": "The fans by the court."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the sponsor is lexus."}, {"from": "gpt", "value": "[0.64, 0.2, 0.8, 0.25]"}, {"from": "human", "value": "Please provide a short description for this region: [0.26, 0.4, 0.48, 0.8]."}, {"from": "gpt", "value": "The cort is blue."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: this is a referee box."}, {"from": "gpt", "value": "[0.1, 0.55, 0.24, 0.81]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: he looks like he won the match."}, {"from": "gpt", "value": "[0.43, 0.32, 0.54, 0.59]"}, {"from": "human", "value": "Please provide a short description for this region: [0.08, 0.17, 0.15, 0.25]."}, {"from": "gpt", "value": "Television camera."}, {"from": "human", "value": "Please provide a short description for this region: [0.62, 0.2, 0.85, 0.25]."}, {"from": "gpt", "value": "The lexus logo on the wall."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A man operating a camera."}, {"from": "gpt", "value": "[0.05, 0.17, 0.15, 0.26]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A bunch of spectators in the stands."}, {"from": "gpt", "value": "[0.22, 0.17, 1.0, 0.22]"}, {"from": "human", "value": "Please provide a short description for this region: [0.12, 0.55, 0.24, 0.82]."}, {"from": "gpt", "value": "Announcer tower on the side of a tennis court."}]}, {"id": "VG_100K/2370531", "image": "vg/VG_100K/2370531.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.36, 0.26, 0.53, 0.48]."}, {"from": "gpt", "value": "A black and white shirt."}, {"from": "human", "value": "Please provide a short description for this region: [0.32, 0.67, 0.36, 0.7]."}, {"from": "gpt", "value": "White plastic wheel on skateboard."}, {"from": "human", "value": "Please provide a short description for this region: [0.17, 0.55, 0.21, 0.63]."}, {"from": "gpt", "value": "An embankment within a city park."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white plastic wheel on skateboard."}, {"from": "gpt", "value": "[0.32, 0.59, 0.36, 0.63]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a tall brown telephone pole."}, {"from": "gpt", "value": "[0.79, 0.46, 0.82, 0.57]"}, {"from": "human", "value": "Please provide a short description for this region: [0.66, 0.57, 0.73, 0.67]."}, {"from": "gpt", "value": "A boy riding a bike."}, {"from": "human", "value": "Please provide a short description for this region: [0.43, 0.22, 0.45, 0.24]."}, {"from": "gpt", "value": "The eye of a man."}, {"from": "human", "value": "Please provide a short description for this region: [0.24, 0.57, 0.65, 0.71]."}, {"from": "gpt", "value": "Underneath of a skate board."}, {"from": "human", "value": "Please provide a short description for this region: [0.67, 0.59, 0.7, 0.62]."}, {"from": "gpt", "value": "A boy wearing a yellow shirt."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: someone's old and battered skateboard."}, {"from": "gpt", "value": "[0.24, 0.58, 0.64, 0.71]"}]}, {"id": "VG_100K/2369612", "image": "vg/VG_100K/2369612.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.4, 0.61, 0.51, 0.74]."}, {"from": "gpt", "value": "Black and white clock with no numbers."}, {"from": "human", "value": "Please provide a short description for this region: [0.65, 0.51, 0.83, 0.56]."}, {"from": "gpt", "value": "Reflection of dark colored device with red light."}, {"from": "human", "value": "Please provide a short description for this region: [0.24, 0.85, 0.45, 0.97]."}, {"from": "gpt", "value": "Black toggle switch for night mode."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: back corner of a red car."}, {"from": "gpt", "value": "[0.1, 0.84, 0.19, 0.94]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white car parked on curb."}, {"from": "gpt", "value": "[0.72, 0.84, 0.89, 0.99]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: eyebrows on man's face."}, {"from": "gpt", "value": "[0.19, 0.77, 0.36, 0.81]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white parked vehicle."}, {"from": "gpt", "value": "[0.74, 0.87, 0.9, 0.97]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: top of mans head in rear view mirror."}, {"from": "gpt", "value": "[0.17, 0.66, 0.36, 0.81]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: late model white coupe."}, {"from": "gpt", "value": "[0.73, 0.85, 0.88, 0.98]"}, {"from": "human", "value": "Please provide a short description for this region: [0.1, 0.86, 0.9, 1.0]."}, {"from": "gpt", "value": "Street is shiny from water."}]}, {"id": "VG_100K/2369036", "image": "vg/VG_100K/2369036.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: black and white shoes of jumper."}, {"from": "gpt", "value": "[0.13, 0.66, 0.23, 0.76]"}, {"from": "human", "value": "Please provide a short description for this region: [0.54, 0.44, 0.59, 0.65]."}, {"from": "gpt", "value": "Lights on a pole."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: black shirt of man jumping."}, {"from": "gpt", "value": "[0.1, 0.27, 0.25, 0.42]"}, {"from": "human", "value": "Please provide a short description for this region: [0.3, 0.27, 0.44, 0.38]."}, {"from": "gpt", "value": "White clouds in blue sky."}, {"from": "human", "value": "Please provide a short description for this region: [0.73, 0.29, 0.98, 0.76]."}, {"from": "gpt", "value": "Man in white shirt and shorts."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man with arms spread out."}, {"from": "gpt", "value": "[0.07, 0.19, 0.33, 0.77]"}, {"from": "human", "value": "Please provide a short description for this region: [0.75, 0.38, 0.88, 0.56]."}, {"from": "gpt", "value": "White shirt of man with frisbee."}, {"from": "human", "value": "Please provide a short description for this region: [0.52, 0.42, 0.59, 0.68]."}, {"from": "gpt", "value": "Bright lights to light field up at night."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a person walking."}, {"from": "gpt", "value": "[0.49, 0.61, 0.57, 0.7]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white clouds in blue sky."}, {"from": "gpt", "value": "[0.37, 0.16, 0.56, 0.26]"}]}, {"id": "VG_100K/2369011", "image": "vg/VG_100K/2369011.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: red shirt of person on horse."}, {"from": "gpt", "value": "[0.31, 0.29, 0.37, 0.35]"}, {"from": "human", "value": "Please provide a short description for this region: [0.29, 0.62, 0.35, 0.65]."}, {"from": "gpt", "value": "The shoe of a woman."}, {"from": "human", "value": "Please provide a short description for this region: [0.85, 0.53, 0.98, 0.81]."}, {"from": "gpt", "value": "Green grass by the tree."}, {"from": "human", "value": "Please provide a short description for this region: [0.07, 0.67, 0.23, 0.87]."}, {"from": "gpt", "value": "Crutch on a  woman."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A dirt road in the photo."}, {"from": "gpt", "value": "[0.34, 0.53, 0.69, 0.79]"}, {"from": "human", "value": "Please provide a short description for this region: [0.33, 0.76, 0.47, 0.84]."}, {"from": "gpt", "value": "Brown leaves."}, {"from": "human", "value": "Please provide a short description for this region: [0.35, 0.12, 0.42, 0.43]."}, {"from": "gpt", "value": "A tall tree branch."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: person standing behind horse."}, {"from": "gpt", "value": "[0.23, 0.38, 0.35, 0.65]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A forest in the picture."}, {"from": "gpt", "value": "[0.64, 0.21, 0.98, 0.46]"}, {"from": "human", "value": "Please provide a short description for this region: [0.25, 0.25, 0.42, 0.52]."}, {"from": "gpt", "value": "Person riding horse."}]}, {"id": "VG_100K/2368266", "image": "vg/VG_100K/2368266.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: this is an identification number."}, {"from": "gpt", "value": "[0.91, 0.57, 0.99, 0.82]"}, {"from": "human", "value": "Please provide a short description for this region: [0.07, 0.15, 0.6, 0.35]."}, {"from": "gpt", "value": "Scissors' handles are purple."}, {"from": "human", "value": "Please provide a short description for this region: [0.66, 0.45, 0.96, 0.61]."}, {"from": "gpt", "value": "A crown on the princess."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the blades on these scissors are dirty."}, {"from": "gpt", "value": "[0.36, 0.29, 0.58, 0.58]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: crown on the queen's head."}, {"from": "gpt", "value": "[0.63, 0.43, 0.92, 0.59]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Bolt on the scissors."}, {"from": "gpt", "value": "[0.39, 0.32, 0.51, 0.4]"}, {"from": "human", "value": "Please provide a short description for this region: [0.8, 0.69, 0.86, 0.75]."}, {"from": "gpt", "value": "The queen is wearing earrings."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Necklace on the queen."}, {"from": "gpt", "value": "[0.75, 0.81, 0.88, 0.87]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a signature in brown ink."}, {"from": "gpt", "value": "[0.22, 0.54, 0.34, 0.62]"}, {"from": "human", "value": "Please provide a short description for this region: [0.25, 0.38, 0.64, 0.72]."}, {"from": "gpt", "value": "This money is backed by the bank of england."}]}, {"id": "VG_100K/2367600", "image": "vg/VG_100K/2367600.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: man sitting on couch."}, {"from": "gpt", "value": "[0.12, 0.44, 0.37, 0.74]"}, {"from": "human", "value": "Please provide a short description for this region: [0.41, 0.54, 0.64, 0.75]."}, {"from": "gpt", "value": "Man sitting on the floor."}, {"from": "human", "value": "Please provide a short description for this region: [0.41, 0.59, 0.53, 0.71]."}, {"from": "gpt", "value": "Man wearing a red tee shirt."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Man standing wearing brown pants."}, {"from": "gpt", "value": "[0.63, 0.44, 0.77, 0.67]"}, {"from": "human", "value": "Please provide a short description for this region: [0.64, 0.2, 0.74, 0.32]."}, {"from": "gpt", "value": "A man with a short hair cut."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Man standing near the steps."}, {"from": "gpt", "value": "[0.58, 0.23, 0.77, 0.7]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a set of silver remote controls on table."}, {"from": "gpt", "value": "[0.5, 0.78, 0.6, 0.84]"}, {"from": "human", "value": "Please provide a short description for this region: [0.41, 0.54, 0.67, 0.77]."}, {"from": "gpt", "value": "Man sitting on the floor."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Light blue striped shirt."}, {"from": "gpt", "value": "[0.13, 0.51, 0.29, 0.66]"}, {"from": "human", "value": "Please provide a short description for this region: [0.83, 0.24, 0.95, 0.32]."}, {"from": "gpt", "value": "A picture in a frame on a wall."}]}, {"id": "VG_100K/2367295", "image": "vg/VG_100K/2367295.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: Stuffed Snowman is wearing a red hat."}, {"from": "gpt", "value": "[0.07, 0.41, 0.33, 0.57]"}, {"from": "human", "value": "Please provide a short description for this region: [0.55, 0.16, 0.6, 0.75]."}, {"from": "gpt", "value": "A square metal pole."}, {"from": "human", "value": "Please provide a short description for this region: [0.12, 0.62, 0.35, 0.87]."}, {"from": "gpt", "value": "The candle is red in color."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: glass with stand."}, {"from": "gpt", "value": "[0.32, 0.44, 0.55, 0.87]"}, {"from": "human", "value": "Please provide a short description for this region: [0.7, 0.15, 0.96, 0.23]."}, {"from": "gpt", "value": "Curtains hanging in the window."}, {"from": "human", "value": "Please provide a short description for this region: [0.3, 0.39, 0.56, 0.69]."}, {"from": "gpt", "value": "Milk is inside the glass cup."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a toy with red color cap."}, {"from": "gpt", "value": "[0.11, 0.43, 0.36, 0.65]"}, {"from": "human", "value": "Please provide a short description for this region: [0.56, 0.55, 0.73, 0.85]."}, {"from": "gpt", "value": "Leg of the cat."}, {"from": "human", "value": "Please provide a short description for this region: [0.12, 0.42, 0.35, 0.67]."}, {"from": "gpt", "value": "The head of a snowman."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Green house plant in back ground."}, {"from": "gpt", "value": "[0.72, 0.71, 0.97, 0.86]"}]}, {"id": "VG_100K/2366884", "image": "vg/VG_100K/2366884.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.74, 0.61, 0.89, 0.77]."}, {"from": "gpt", "value": "A little girl's knee."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: her hair is blonde."}, {"from": "gpt", "value": "[0.31, 0.21, 0.63, 0.54]"}, {"from": "human", "value": "Please provide a short description for this region: [0.06, 0.17, 0.32, 0.43]."}, {"from": "gpt", "value": "A white wooden wall behind the girl."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a red wood rail."}, {"from": "gpt", "value": "[0.33, 0.73, 0.53, 0.85]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a drak colored chair."}, {"from": "gpt", "value": "[0.66, 0.43, 0.97, 0.66]"}, {"from": "human", "value": "Please provide a short description for this region: [0.22, 0.5, 0.72, 0.63]."}, {"from": "gpt", "value": "A ruffle white shirt."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A girl's blue eyes."}, {"from": "gpt", "value": "[0.41, 0.37, 0.55, 0.43]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a blue and white dress."}, {"from": "gpt", "value": "[0.36, 0.58, 0.75, 0.85]"}, {"from": "human", "value": "Please provide a short description for this region: [0.26, 0.78, 0.29, 0.85]."}, {"from": "gpt", "value": "The thumb on the girl."}, {"from": "human", "value": "Please provide a short description for this region: [0.43, 0.45, 0.5, 0.5]."}, {"from": "gpt", "value": "A little girl's smile."}]}, {"id": "VG_100K/2366798", "image": "vg/VG_100K/2366798.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: the ground is wooden."}, {"from": "gpt", "value": "[0.42, 0.34, 0.61, 0.48]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a plant in a planter."}, {"from": "gpt", "value": "[0.91, 0.54, 1.0, 0.65]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: an ear on the cat."}, {"from": "gpt", "value": "[0.51, 0.49, 0.54, 0.53]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: black spots on fur."}, {"from": "gpt", "value": "[0.55, 0.62, 0.58, 0.67]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a large window sill."}, {"from": "gpt", "value": "[0.0, 0.63, 1.0, 0.78]"}, {"from": "human", "value": "Please provide a short description for this region: [0.44, 0.46, 0.74, 0.77]."}, {"from": "gpt", "value": "Small cat looking outside."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a small spotted cat."}, {"from": "gpt", "value": "[0.5, 0.48, 0.72, 0.75]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the fence is wooden."}, {"from": "gpt", "value": "[0.15, 0.22, 0.3, 0.37]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the tail on the cat."}, {"from": "gpt", "value": "[0.61, 0.68, 0.72, 0.75]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: tha cat is looking outside."}, {"from": "gpt", "value": "[0.44, 0.49, 0.76, 0.74]"}]}, {"id": "VG_100K/2366423", "image": "vg/VG_100K/2366423.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: Plaid cloth tied to luggage."}, {"from": "gpt", "value": "[0.25, 0.57, 0.38, 0.76]"}, {"from": "human", "value": "Please provide a short description for this region: [0.31, 0.69, 0.59, 0.85]."}, {"from": "gpt", "value": "Strap on the bag."}, {"from": "human", "value": "Please provide a short description for this region: [0.71, 0.0, 0.87, 0.09]."}, {"from": "gpt", "value": "The pillow is pink and brown."}, {"from": "human", "value": "Please provide a short description for this region: [0.12, 0.66, 0.35, 0.99]."}, {"from": "gpt", "value": "A person is standing beside the bags."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Black rubber handle of a backpack."}, {"from": "gpt", "value": "[0.55, 0.0, 0.75, 0.14]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Lint remover in the pocket of the blue bag."}, {"from": "gpt", "value": "[0.67, 0.26, 0.78, 0.47]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Woman is wearing tennis shoes."}, {"from": "gpt", "value": "[0.19, 0.67, 0.38, 0.79]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The tile is patterned."}, {"from": "gpt", "value": "[0.32, 0.86, 0.53, 1.0]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Let brown and white shoe."}, {"from": "gpt", "value": "[0.24, 0.67, 0.35, 0.8]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: black and white lint roller."}, {"from": "gpt", "value": "[0.66, 0.26, 0.79, 0.51]"}]}, {"id": "VG_100K/2366028", "image": "vg/VG_100K/2366028.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.42, 0.25, 0.57, 0.56]."}, {"from": "gpt", "value": "The lighthouse has seven stripes."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: TALL MAST OF A SAIL BOAT."}, {"from": "gpt", "value": "[0.81, 0.3, 0.87, 0.61]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: TWO BOATS DOCKED IN THE HARBOR."}, {"from": "gpt", "value": "[0.0, 0.56, 0.18, 0.87]"}, {"from": "human", "value": "Please provide a short description for this region: [0.14, 0.48, 0.4, 0.56]."}, {"from": "gpt", "value": "A building sitting in the background of the marina."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: LIGHTHOUSE WITH RED AND WHITE STRIPES."}, {"from": "gpt", "value": "[0.45, 0.25, 0.57, 0.57]"}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.24, 0.57, 0.59]."}, {"from": "gpt", "value": "A lighthouse to guide ships to the marina."}, {"from": "human", "value": "Please provide a short description for this region: [0.2, 0.55, 0.44, 0.72]."}, {"from": "gpt", "value": "White boat docked in water."}, {"from": "human", "value": "Please provide a short description for this region: [0.27, 0.46, 0.32, 0.49]."}, {"from": "gpt", "value": "There is a palm tree behind the building."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: White stripe on tower."}, {"from": "gpt", "value": "[0.45, 0.35, 0.62, 0.42]"}, {"from": "human", "value": "Please provide a short description for this region: [0.38, 0.23, 0.61, 0.56]."}, {"from": "gpt", "value": "The lighthouse has red and white stripes."}]}, {"id": "VG_100K/2365862", "image": "vg/VG_100K/2365862.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: wooden slats of the outhouse wall."}, {"from": "gpt", "value": "[0.52, 0.05, 0.68, 0.26]"}, {"from": "human", "value": "Please provide a short description for this region: [0.26, 0.25, 0.54, 0.46]."}, {"from": "gpt", "value": "Pot floating in the water."}, {"from": "human", "value": "Please provide a short description for this region: [0.63, 0.88, 0.69, 0.93]."}, {"from": "gpt", "value": "Dirty water in the bottom of the toilet basin."}, {"from": "human", "value": "Please provide a short description for this region: [0.53, 0.75, 0.69, 0.92]."}, {"from": "gpt", "value": "The toilet is white."}, {"from": "human", "value": "Please provide a short description for this region: [0.55, 0.32, 0.76, 0.51]."}, {"from": "gpt", "value": "Dirt on the ground."}, {"from": "human", "value": "Please provide a short description for this region: [0.24, 0.23, 0.55, 0.49]."}, {"from": "gpt", "value": "This is a black basin."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: an empty black bucket in the corner."}, {"from": "gpt", "value": "[0.74, 0.27, 0.87, 0.55]"}, {"from": "human", "value": "Please provide a short description for this region: [0.26, 0.26, 0.46, 0.39]."}, {"from": "gpt", "value": "This is a pink bowl."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a white procelain toilet laid in the ground."}, {"from": "gpt", "value": "[0.39, 0.7, 0.82, 0.98]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: silver pole running along the ground."}, {"from": "gpt", "value": "[0.13, 0.46, 0.39, 0.75]"}]}, {"id": "VG_100K/2365545", "image": "vg/VG_100K/2365545.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: Cat has black ear."}, {"from": "gpt", "value": "[0.77, 0.2, 0.89, 0.29]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Black fur section on cat."}, {"from": "gpt", "value": "[0.0, 0.2, 0.09, 0.47]"}, {"from": "human", "value": "Please provide a short description for this region: [0.62, 0.22, 0.79, 0.37]."}, {"from": "gpt", "value": "The cat has her eyes closed."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Cat has white paw."}, {"from": "gpt", "value": "[0.45, 0.48, 0.59, 0.61]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: kittys right ear on head."}, {"from": "gpt", "value": "[0.79, 0.17, 0.92, 0.29]"}, {"from": "human", "value": "Please provide a short description for this region: [0.34, 0.53, 0.48, 0.66]."}, {"from": "gpt", "value": "Cat has black leg."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: carpet on the ground."}, {"from": "gpt", "value": "[0.0, 0.63, 0.14, 0.82]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Cat has stripes on shoulder."}, {"from": "gpt", "value": "[0.17, 0.22, 0.3, 0.38]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Cat has pink nose."}, {"from": "gpt", "value": "[0.65, 0.35, 0.68, 0.39]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Very pink tip of a cat's nose."}, {"from": "gpt", "value": "[0.65, 0.35, 0.7, 0.4]"}]}, {"id": "VG_100K/2365458", "image": "vg/VG_100K/2365458.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: Side of car reflecting light."}, {"from": "gpt", "value": "[0.49, 0.48, 0.53, 0.52]"}, {"from": "human", "value": "Please provide a short description for this region: [0.6, 0.23, 1.0, 0.48]."}, {"from": "gpt", "value": "Red smashed in hood of a vehicle."}, {"from": "human", "value": "Please provide a short description for this region: [0.62, 0.5, 0.81, 0.69]."}, {"from": "gpt", "value": "Metal of a light."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Green grassy area to the left of a smashed up car."}, {"from": "gpt", "value": "[0.02, 0.65, 0.45, 0.83]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Broken front light."}, {"from": "gpt", "value": "[0.66, 0.54, 0.77, 0.66]"}, {"from": "human", "value": "Please provide a short description for this region: [0.43, 0.17, 0.59, 0.29]."}, {"from": "gpt", "value": "Back of a sideview mirror."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a windshield wiper on a car."}, {"from": "gpt", "value": "[0.7, 0.17, 1.0, 0.22]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A black wheel of a blurry motorcycle."}, {"from": "gpt", "value": "[0.06, 0.42, 0.24, 0.65]"}, {"from": "human", "value": "Please provide a short description for this region: [0.06, 0.41, 0.25, 0.65]."}, {"from": "gpt", "value": "Black wheel of a motorcycle that is blurry."}, {"from": "human", "value": "Please provide a short description for this region: [0.06, 0.43, 0.24, 0.65]."}, {"from": "gpt", "value": "Rear wheel of a motorcycle."}]}, {"id": "VG_100K/2365377", "image": "vg/VG_100K/2365377.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: A green baseball playing field."}, {"from": "gpt", "value": "[0.01, 0.54, 0.5, 0.83]"}, {"from": "human", "value": "Please provide a short description for this region: [0.44, 0.62, 0.73, 0.83]."}, {"from": "gpt", "value": "This is a baseball player."}, {"from": "human", "value": "Please provide a short description for this region: [0.52, 0.29, 0.58, 0.35]."}, {"from": "gpt", "value": "Metal rails along stairs."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: wooden bat held by batter."}, {"from": "gpt", "value": "[0.43, 0.39, 0.52, 0.49]"}, {"from": "human", "value": "Please provide a short description for this region: [0.46, 0.39, 0.52, 0.47]."}, {"from": "gpt", "value": "Wooden base ball bat."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: black triangle advertising sign."}, {"from": "gpt", "value": "[0.75, 0.48, 0.81, 0.55]"}, {"from": "human", "value": "Please provide a short description for this region: [0.49, 0.65, 0.71, 0.83]."}, {"from": "gpt", "value": "An athlete in a gray and orange uniform."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: hard blue batters helmet."}, {"from": "gpt", "value": "[0.48, 0.44, 0.52, 0.47]"}, {"from": "human", "value": "Please provide a short description for this region: [0.54, 0.69, 0.67, 0.82]."}, {"from": "gpt", "value": "The shirt is grey."}, {"from": "human", "value": "Please provide a short description for this region: [0.16, 0.45, 0.45, 0.54]."}, {"from": "gpt", "value": "Blue sign behind a batter."}]}, {"id": "VG_100K/2364880", "image": "vg/VG_100K/2364880.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: A light green cone on the ground."}, {"from": "gpt", "value": "[0.94, 0.56, 0.98, 0.61]"}, {"from": "human", "value": "Please provide a short description for this region: [0.26, 0.3, 1.0, 0.41]."}, {"from": "gpt", "value": "Group of nets in the tennis field."}, {"from": "human", "value": "Please provide a short description for this region: [0.72, 0.29, 1.0, 0.37]."}, {"from": "gpt", "value": "A tennis court net."}, {"from": "human", "value": "Please provide a short description for this region: [0.43, 0.39, 0.52, 0.53]."}, {"from": "gpt", "value": "The pants are grey."}, {"from": "human", "value": "Please provide a short description for this region: [0.67, 0.44, 0.8, 0.73]."}, {"from": "gpt", "value": "Little boy dressed in grey holding a baseball bat."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A man wearing a blue cap and a gray sweater."}, {"from": "gpt", "value": "[0.03, 0.18, 0.27, 0.82]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A toddler with a baseball bat in hand."}, {"from": "gpt", "value": "[0.27, 0.33, 0.3, 0.48]"}, {"from": "human", "value": "Please provide a short description for this region: [0.64, 0.37, 0.83, 0.73]."}, {"from": "gpt", "value": "A young boy holding a baseball bat."}, {"from": "human", "value": "Please provide a short description for this region: [0.65, 0.37, 0.81, 0.73]."}, {"from": "gpt", "value": "Small child with a baseball bat."}]}, {"id": "VG_100K/2364513", "image": "vg/VG_100K/2364513.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: The light is on."}, {"from": "gpt", "value": "[0.65, 0.53, 0.69, 0.57]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Wheel of a train."}, {"from": "gpt", "value": "[0.29, 0.5, 0.34, 0.58]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Wheel of a train."}, {"from": "gpt", "value": "[0.25, 0.47, 0.37, 0.59]"}, {"from": "human", "value": "Please provide a short description for this region: [0.62, 0.74, 0.82, 0.82]."}, {"from": "gpt", "value": "Parts of a track."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Smoke is coming out of the train."}, {"from": "gpt", "value": "[0.23, 0.18, 0.47, 0.37]"}, {"from": "human", "value": "Please provide a short description for this region: [0.07, 0.3, 0.19, 0.5]."}, {"from": "gpt", "value": "Parts of a track."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: green trees with trunks."}, {"from": "gpt", "value": "[0.85, 0.41, 0.97, 0.53]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Grey smoke coming out the back of a train."}, {"from": "gpt", "value": "[0.29, 0.21, 0.44, 0.35]"}, {"from": "human", "value": "Please provide a short description for this region: [0.43, 0.58, 0.53, 0.7]."}, {"from": "gpt", "value": "Wheel of a train."}, {"from": "human", "value": "Please provide a short description for this region: [0.23, 0.31, 0.71, 0.48]."}, {"from": "gpt", "value": "The roof is black."}]}, {"id": "VG_100K/2364468", "image": "vg/VG_100K/2364468.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: Wooden bleachers behind the rider."}, {"from": "gpt", "value": "[0.04, 0.19, 0.22, 0.45]"}, {"from": "human", "value": "Please provide a short description for this region: [0.59, 0.64, 0.75, 0.75]."}, {"from": "gpt", "value": "Orange wheels on skateboard."}, {"from": "human", "value": "Please provide a short description for this region: [0.9, 0.74, 0.99, 0.82]."}, {"from": "gpt", "value": "The brand name sponser in corner."}, {"from": "human", "value": "Please provide a short description for this region: [0.68, 0.17, 0.85, 0.44]."}, {"from": "gpt", "value": "The legs of a spectator on the bleachers."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: gray and black helmet."}, {"from": "gpt", "value": "[0.84, 0.34, 0.94, 0.42]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: blue and white baseball cap."}, {"from": "gpt", "value": "[0.32, 0.21, 0.69, 0.43]"}, {"from": "human", "value": "Please provide a short description for this region: [0.88, 0.79, 0.96, 0.83]."}, {"from": "gpt", "value": "Logo for photgrapher on picture."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A skateboard being ridden."}, {"from": "gpt", "value": "[0.13, 0.54, 0.77, 0.73]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: black skateboard on pavement."}, {"from": "gpt", "value": "[0.11, 0.53, 0.77, 0.72]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man with cap and glasses."}, {"from": "gpt", "value": "[0.35, 0.19, 0.55, 0.32]"}]}, {"id": "VG_100K/2363647", "image": "vg/VG_100K/2363647.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: The horses mane is long."}, {"from": "gpt", "value": "[0.27, 0.36, 0.3, 0.52]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The horses mane is brown."}, {"from": "gpt", "value": "[0.28, 0.36, 0.3, 0.53]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: girl wearing a helmet."}, {"from": "gpt", "value": "[0.61, 0.24, 0.88, 0.44]"}, {"from": "human", "value": "Please provide a short description for this region: [0.73, 0.7, 0.8, 0.87]."}, {"from": "gpt", "value": "Cream colored tail of horse."}, {"from": "human", "value": "Please provide a short description for this region: [0.23, 0.47, 0.28, 0.5]."}, {"from": "gpt", "value": "Horse's eyes are closed."}, {"from": "human", "value": "Please provide a short description for this region: [0.71, 0.22, 0.8, 0.34]."}, {"from": "gpt", "value": "The girl is wearing a helmet."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The dirt is brown."}, {"from": "gpt", "value": "[0.09, 0.74, 0.31, 0.84]"}, {"from": "human", "value": "Please provide a short description for this region: [0.03, 0.54, 0.25, 0.68]."}, {"from": "gpt", "value": "Horses riding mouth bit."}, {"from": "human", "value": "Please provide a short description for this region: [0.62, 0.65, 0.7, 0.87]."}, {"from": "gpt", "value": "Red leather piee to horse saddle."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: gray with black trim horse's saddle blanket."}, {"from": "gpt", "value": "[0.59, 0.44, 0.83, 0.65]"}]}, {"id": "VG_100K/2363538", "image": "vg/VG_100K/2363538.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: slice of banana cooking."}, {"from": "gpt", "value": "[0.39, 0.43, 0.48, 0.48]"}, {"from": "human", "value": "Please provide a short description for this region: [0.01, 0.36, 0.58, 0.62]."}, {"from": "gpt", "value": "Carmalized bananas in a frying pan."}, {"from": "human", "value": "Please provide a short description for this region: [0.53, 0.55, 0.63, 0.6]."}, {"from": "gpt", "value": "Slice of banana cooking."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: slice of banana cooking."}, {"from": "gpt", "value": "[0.23, 0.52, 0.37, 0.6]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: slice of banana cooking."}, {"from": "gpt", "value": "[0.27, 0.37, 0.4, 0.42]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the slice of food in the pan."}, {"from": "gpt", "value": "[0.26, 0.36, 0.39, 0.44]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: slice of banana cooking."}, {"from": "gpt", "value": "[0.41, 0.48, 0.51, 0.55]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the slice of food in the pan."}, {"from": "gpt", "value": "[0.46, 0.46, 0.56, 0.52]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the bubbles are brown in color."}, {"from": "gpt", "value": "[0.01, 0.54, 0.55, 0.67]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: slice of banana cooking."}, {"from": "gpt", "value": "[0.08, 0.45, 0.17, 0.48]"}]}, {"id": "VG_100K/2363222", "image": "vg/VG_100K/2363222.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.31, 0.02, 0.62, 0.22]."}, {"from": "gpt", "value": "The man's hair is brown."}, {"from": "human", "value": "Please provide a short description for this region: [0.56, 0.74, 0.79, 0.93]."}, {"from": "gpt", "value": "A mobile hand set."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a red and black cell phone."}, {"from": "gpt", "value": "[0.17, 0.73, 0.45, 0.81]"}, {"from": "human", "value": "Please provide a short description for this region: [0.54, 0.87, 0.63, 0.95]."}, {"from": "gpt", "value": "Paper under the phones."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: phone on the table."}, {"from": "gpt", "value": "[0.35, 0.82, 0.51, 0.91]"}, {"from": "human", "value": "Please provide a short description for this region: [0.34, 0.29, 0.63, 0.43]."}, {"from": "gpt", "value": "The man has a thin beard."}, {"from": "human", "value": "Please provide a short description for this region: [0.35, 0.09, 0.58, 0.41]."}, {"from": "gpt", "value": "Face of a person."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The man's hair is straight."}, {"from": "gpt", "value": "[0.27, 0.01, 0.63, 0.22]"}, {"from": "human", "value": "Please provide a short description for this region: [0.31, 0.16, 0.61, 0.27]."}, {"from": "gpt", "value": "The man is wearing glasses."}, {"from": "human", "value": "Please provide a short description for this region: [0.37, 0.18, 0.46, 0.29]."}, {"from": "gpt", "value": "Eye of a person."}]}, {"id": "VG_100K/2361589", "image": "vg/VG_100K/2361589.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.39, 0.5, 0.49, 0.64]."}, {"from": "gpt", "value": "Tennis ball in hand."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: strings on tennis racket."}, {"from": "gpt", "value": "[0.43, 0.68, 0.55, 0.76]"}, {"from": "human", "value": "Please provide a short description for this region: [0.24, 0.48, 0.3, 0.54]."}, {"from": "gpt", "value": "White wrist band on woman."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: nike logo on front of white tank top."}, {"from": "gpt", "value": "[0.29, 0.33, 0.35, 0.36]"}, {"from": "human", "value": "Please provide a short description for this region: [0.27, 0.04, 0.39, 0.13]."}, {"from": "gpt", "value": "Hat on tennis players head."}, {"from": "human", "value": "Please provide a short description for this region: [0.23, 0.49, 0.3, 0.54]."}, {"from": "gpt", "value": "White wrist band."}, {"from": "human", "value": "Please provide a short description for this region: [0.27, 0.05, 0.39, 0.12]."}, {"from": "gpt", "value": "Girl wearing visor for protection against sun."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white sweat band on tennis player."}, {"from": "gpt", "value": "[0.24, 0.48, 0.3, 0.53]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: sweat glistening on woman."}, {"from": "gpt", "value": "[0.19, 0.19, 0.45, 0.37]"}, {"from": "human", "value": "Please provide a short description for this region: [0.28, 0.19, 0.37, 0.29]."}, {"from": "gpt", "value": "Necklace on tennis player."}]}, {"id": "VG_100K/2361390", "image": "vg/VG_100K/2361390.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.07, 0.57, 1.0, 0.7]."}, {"from": "gpt", "value": "Water puddling on sand."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: red and white motorbike."}, {"from": "gpt", "value": "[0.28, 0.53, 0.51, 0.65]"}, {"from": "human", "value": "Please provide a short description for this region: [0.29, 0.63, 0.54, 0.69]."}, {"from": "gpt", "value": "Reflection of a red and white bike."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Reflection of motorcyclist in the water."}, {"from": "gpt", "value": "[0.62, 0.64, 0.82, 0.69]"}, {"from": "human", "value": "Please provide a short description for this region: [0.28, 0.49, 0.54, 0.73]."}, {"from": "gpt", "value": "This is a red and white motorcycle."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: tire on the bike."}, {"from": "gpt", "value": "[0.44, 0.57, 0.51, 0.64]"}, {"from": "human", "value": "Please provide a short description for this region: [0.29, 0.64, 0.52, 0.69]."}, {"from": "gpt", "value": "Reflection of bike's tires."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: yellow on the back of bike."}, {"from": "gpt", "value": "[0.63, 0.49, 0.68, 0.52]"}, {"from": "human", "value": "Please provide a short description for this region: [0.35, 0.47, 0.44, 0.58]."}, {"from": "gpt", "value": "Man hunched over on bike."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Red and yellow dirt bike."}, {"from": "gpt", "value": "[0.58, 0.47, 0.81, 0.57]"}]}, {"id": "VG_100K/2360537", "image": "vg/VG_100K/2360537.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.2, 0.5, 0.62, 0.79]."}, {"from": "gpt", "value": "Croissant next to croissant."}, {"from": "human", "value": "Please provide a short description for this region: [0.59, 0.43, 0.63, 0.48]."}, {"from": "gpt", "value": "Sausage inside of croissant."}, {"from": "human", "value": "Please provide a short description for this region: [0.17, 0.73, 0.51, 0.83]."}, {"from": "gpt", "value": "Sign on the table."}, {"from": "human", "value": "Please provide a short description for this region: [0.34, 0.17, 0.45, 0.28]."}, {"from": "gpt", "value": "Woman in brown jacket standing in background."}, {"from": "human", "value": "Please provide a short description for this region: [0.6, 0.4, 0.77, 0.6]."}, {"from": "gpt", "value": "Browned part of the croissant."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Croissant next to croissant."}, {"from": "gpt", "value": "[0.52, 0.49, 0.9, 0.74]"}, {"from": "human", "value": "Please provide a short description for this region: [0.07, 0.71, 0.14, 0.77]."}, {"from": "gpt", "value": "Sausage inside of croissant."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Plastic sign in front of croissants."}, {"from": "gpt", "value": "[0.14, 0.73, 0.52, 0.83]"}, {"from": "human", "value": "Please provide a short description for this region: [0.49, 0.18, 0.95, 0.35]."}, {"from": "gpt", "value": "Shelf with food in the background."}, {"from": "human", "value": "Please provide a short description for this region: [0.59, 0.3, 0.96, 0.47]."}, {"from": "gpt", "value": "This is a pie."}]}, {"id": "VG_100K/2360003", "image": "vg/VG_100K/2360003.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.64, 0.23, 0.7, 0.44]."}, {"from": "gpt", "value": "A street light."}, {"from": "human", "value": "Please provide a short description for this region: [0.54, 0.36, 0.59, 0.38]."}, {"from": "gpt", "value": "A blue and white umbrella."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: person on the bike."}, {"from": "gpt", "value": "[0.46, 0.43, 0.5, 0.47]"}, {"from": "human", "value": "Please provide a short description for this region: [0.21, 0.94, 0.31, 0.99]."}, {"from": "gpt", "value": "Purple motor scooter."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Black jeep parked on street."}, {"from": "gpt", "value": "[0.75, 0.51, 0.83, 0.6]"}, {"from": "human", "value": "Please provide a short description for this region: [0.16, 0.1, 0.53, 0.33]."}, {"from": "gpt", "value": "Colorful hotel rooms with balconies."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The colors of a motorcycle are red, white, and black."}, {"from": "gpt", "value": "[0.61, 0.89, 0.73, 1.0]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: scooter riders at festival."}, {"from": "gpt", "value": "[0.34, 0.39, 0.6, 0.48]"}]}, {"id": "VG_100K/2359897", "image": "vg/VG_100K/2359897.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.72, 0.32, 0.78, 0.37]."}, {"from": "gpt", "value": "A street light."}, {"from": "human", "value": "Please provide a short description for this region: [0.87, 0.37, 0.97, 0.51]."}, {"from": "gpt", "value": "Lighted front of a building at night."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.49, 0.47, 0.73]."}, {"from": "gpt", "value": "Two streaks of white light."}, {"from": "human", "value": "Please provide a short description for this region: [0.75, 0.25, 0.91, 0.42]."}, {"from": "gpt", "value": "A multi story building."}, {"from": "human", "value": "Please provide a short description for this region: [0.35, 0.28, 0.43, 0.36]."}, {"from": "gpt", "value": "The street light."}, {"from": "human", "value": "Please provide a short description for this region: [0.25, 0.59, 0.36, 0.67]."}, {"from": "gpt", "value": "A white arrow on the street."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a red brick building."}, {"from": "gpt", "value": "[0.87, 0.36, 0.99, 0.49]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bright white lights reflecting on pavement."}, {"from": "gpt", "value": "[0.4, 0.46, 0.48, 0.67]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a tall white building."}, {"from": "gpt", "value": "[0.77, 0.27, 0.95, 0.5]"}, {"from": "human", "value": "Please provide a short description for this region: [0.91, 0.47, 0.99, 0.51]."}, {"from": "gpt", "value": "Cars parked."}]}, {"id": "VG_100K/2359813", "image": "vg/VG_100K/2359813.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a white bath towel."}, {"from": "gpt", "value": "[0.61, 0.42, 0.66, 0.5]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a white porcelain bathroom sink."}, {"from": "gpt", "value": "[0.42, 0.55, 0.58, 0.65]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a double sink in the bathroom."}, {"from": "gpt", "value": "[0.43, 0.52, 0.96, 0.76]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a bathtub for the owners."}, {"from": "gpt", "value": "[0.0, 0.59, 0.37, 0.78]"}, {"from": "human", "value": "Please provide a short description for this region: [0.44, 0.29, 0.53, 0.38]."}, {"from": "gpt", "value": "A red wall light."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.58, 0.45, 0.78]."}, {"from": "gpt", "value": "White ceramic tub in bathroom."}, {"from": "human", "value": "Please provide a short description for this region: [0.57, 0.57, 0.77, 0.66]."}, {"from": "gpt", "value": "Two small baskets in between sinks."}, {"from": "human", "value": "Please provide a short description for this region: [0.34, 0.56, 0.99, 0.78]."}, {"from": "gpt", "value": "A rich wooden paneled vanity holds the sinks."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: two tubs full of bathroom items."}, {"from": "gpt", "value": "[0.58, 0.57, 0.75, 0.65]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a green wall light."}, {"from": "gpt", "value": "[0.64, 0.34, 0.68, 0.38]"}]}, {"id": "VG_100K/2359450", "image": "vg/VG_100K/2359450.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a large parked Greyhound bus."}, {"from": "gpt", "value": "[0.1, 0.53, 0.13, 0.64]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.62, 0.06, 0.71]."}, {"from": "gpt", "value": "The yellow lines on the ground."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.58, 0.04, 0.63]."}, {"from": "gpt", "value": "A black suv in road."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.58, 0.05, 0.63]."}, {"from": "gpt", "value": "It is a black car in the road."}, {"from": "human", "value": "Please provide a short description for this region: [0.53, 0.26, 0.82, 0.44]."}, {"from": "gpt", "value": "Green trees beside the bus."}, {"from": "human", "value": "Please provide a short description for this region: [0.53, 0.56, 0.55, 0.59]."}, {"from": "gpt", "value": "The mirror on the bus."}, {"from": "human", "value": "Please provide a short description for this region: [0.38, 0.48, 0.56, 0.66]."}, {"from": "gpt", "value": "A large parked greyhound bus."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: large building in distance."}, {"from": "gpt", "value": "[0.35, 0.17, 0.48, 0.38]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a large parked Greyhound bus."}, {"from": "gpt", "value": "[0.28, 0.48, 0.44, 0.67]"}]}, {"id": "VG_100K/2359291", "image": "vg/VG_100K/2359291.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a person wearing a green shirt."}, {"from": "gpt", "value": "[0.11, 0.42, 0.31, 0.67]"}, {"from": "human", "value": "Please provide a short description for this region: [0.7, 0.47, 0.77, 0.62]."}, {"from": "gpt", "value": "Man is wearing red gloves."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the blond hair on the woman."}, {"from": "gpt", "value": "[0.4, 0.35, 0.54, 0.56]"}, {"from": "human", "value": "Please provide a short description for this region: [0.6, 0.33, 0.73, 0.5]."}, {"from": "gpt", "value": "A man wearing a red hat."}, {"from": "human", "value": "Please provide a short description for this region: [0.74, 0.38, 0.79, 0.49]."}, {"from": "gpt", "value": "A man holding a red bag."}, {"from": "human", "value": "Please provide a short description for this region: [0.04, 0.17, 0.4, 0.31]."}, {"from": "gpt", "value": "The lights in the ceiling."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the green minecraft shirt."}, {"from": "gpt", "value": "[0.08, 0.45, 0.36, 0.81]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the man is wearing gloves."}, {"from": "gpt", "value": "[0.7, 0.47, 0.76, 0.6]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man wearing a red beret."}, {"from": "gpt", "value": "[0.59, 0.31, 0.73, 0.41]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Man is wearing gloves."}, {"from": "gpt", "value": "[0.69, 0.47, 0.76, 0.61]"}]}, {"id": "VG_100K/2358853", "image": "vg/VG_100K/2358853.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.63, 0.03, 1.0, 0.41]."}, {"from": "gpt", "value": "Square tile on floor."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the plate's green trim has lines."}, {"from": "gpt", "value": "[0.12, 0.86, 0.21, 0.92]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the green trim on the plate has half circles."}, {"from": "gpt", "value": "[0.18, 0.89, 0.24, 0.94]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the floor in the kitchen is tiled."}, {"from": "gpt", "value": "[0.62, 0.06, 1.0, 0.4]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Missing tile on the floor."}, {"from": "gpt", "value": "[0.84, 0.05, 0.95, 0.12]"}, {"from": "human", "value": "Please provide a short description for this region: [0.63, 0.02, 1.0, 0.42]."}, {"from": "gpt", "value": "Brown tiled floor."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Hole in the middle of a cake."}, {"from": "gpt", "value": "[0.33, 0.23, 0.68, 0.41]"}, {"from": "human", "value": "Please provide a short description for this region: [0.23, 0.92, 0.3, 0.97]."}, {"from": "gpt", "value": "Five green stripes."}, {"from": "human", "value": "Please provide a short description for this region: [0.44, 0.03, 0.52, 0.07]."}, {"from": "gpt", "value": "Wooden handle of a drawer."}]}, {"id": "VG_100K/2358805", "image": "vg/VG_100K/2358805.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.46, 0.57, 0.95, 0.87]."}, {"from": "gpt", "value": "Man sits in red chair."}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.29, 0.57, 0.45]."}, {"from": "gpt", "value": "Man holding scissors in hand."}, {"from": "human", "value": "Please provide a short description for this region: [0.46, 0.74, 0.58, 0.82]."}, {"from": "gpt", "value": "Man's left hand."}, {"from": "human", "value": "Please provide a short description for this region: [0.85, 0.4, 0.99, 0.68]."}, {"from": "gpt", "value": "Red and white metal fence."}, {"from": "human", "value": "Please provide a short description for this region: [0.01, 0.49, 0.16, 0.86]."}, {"from": "gpt", "value": "Concrete ledge on the wall."}, {"from": "human", "value": "Please provide a short description for this region: [0.8, 0.38, 1.0, 0.64]."}, {"from": "gpt", "value": "Grey and red rails."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man has facial hair."}, {"from": "gpt", "value": "[0.65, 0.29, 0.79, 0.46]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man wears olive green shirt."}, {"from": "gpt", "value": "[0.61, 0.74, 0.88, 0.85]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A leaf filled tree."}, {"from": "gpt", "value": "[0.39, 0.24, 0.51, 0.38]"}, {"from": "human", "value": "Please provide a short description for this region: [0.44, 0.58, 0.94, 0.86]."}, {"from": "gpt", "value": "Red barber chair."}]}, {"id": "VG_100K/2358767", "image": "vg/VG_100K/2358767.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.61, 0.46, 0.66, 0.55]."}, {"from": "gpt", "value": "Sign for yoga school."}, {"from": "human", "value": "Please provide a short description for this region: [0.48, 0.48, 0.51, 0.57]."}, {"from": "gpt", "value": "A man standing on the sidewalk."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: person sitting down."}, {"from": "gpt", "value": "[0.16, 0.31, 0.39, 0.64]"}, {"from": "human", "value": "Please provide a short description for this region: [0.18, 0.35, 0.34, 0.68]."}, {"from": "gpt", "value": "Man sitting on counter."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: blue wood under man's bare feet."}, {"from": "gpt", "value": "[0.2, 0.56, 0.36, 0.75]"}, {"from": "human", "value": "Please provide a short description for this region: [0.64, 0.52, 0.75, 0.65]."}, {"from": "gpt", "value": "White book with green writing."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man has grey hair."}, {"from": "gpt", "value": "[0.19, 0.33, 0.26, 0.39]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: pants on the person."}, {"from": "gpt", "value": "[0.2, 0.51, 0.35, 0.63]"}, {"from": "human", "value": "Please provide a short description for this region: [0.18, 0.37, 0.34, 0.67]."}, {"from": "gpt", "value": "Man sits on rail."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Metal green fence."}, {"from": "gpt", "value": "[0.78, 0.61, 0.99, 0.82]"}]}, {"id": "VG_100K/2357678", "image": "vg/VG_100K/2357678.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.61, 0.46, 0.97, 0.8]."}, {"from": "gpt", "value": "Wooden buggy hooked up to a horse statue."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: head of fake horse."}, {"from": "gpt", "value": "[0.29, 0.5, 0.39, 0.62]"}, {"from": "human", "value": "Please provide a short description for this region: [0.38, 0.2, 0.67, 0.29]."}, {"from": "gpt", "value": "Bright blue sky above the building."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the shadow is on the ground."}, {"from": "gpt", "value": "[0.43, 0.69, 0.78, 0.83]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the archway in the building."}, {"from": "gpt", "value": "[0.12, 0.4, 0.25, 0.61]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a leg on a statue of a horse."}, {"from": "gpt", "value": "[0.44, 0.68, 0.49, 0.81]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the wheel on the carriage."}, {"from": "gpt", "value": "[0.76, 0.67, 0.89, 0.81]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: brown wooden cargo cart."}, {"from": "gpt", "value": "[0.65, 0.48, 0.99, 0.81]"}, {"from": "human", "value": "Please provide a short description for this region: [0.76, 0.67, 0.92, 0.82]."}, {"from": "gpt", "value": "Wheel on the wooden cart."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the power lines behind the building."}, {"from": "gpt", "value": "[0.29, 0.35, 0.7, 0.41]"}]}, {"id": "VG_100K/2357095", "image": "vg/VG_100K/2357095.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: A purple onion on a pizza."}, {"from": "gpt", "value": "[0.48, 0.7, 0.59, 0.83]"}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.24, 0.6, 0.38]."}, {"from": "gpt", "value": "A purple onion on a pizza."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Table cloth under the table."}, {"from": "gpt", "value": "[0.69, 0.05, 0.99, 0.35]"}, {"from": "human", "value": "Please provide a short description for this region: [0.17, 0.52, 0.31, 0.62]."}, {"from": "gpt", "value": "Small, round, whole red tomato."}, {"from": "human", "value": "Please provide a short description for this region: [0.4, 0.53, 0.57, 0.69]."}, {"from": "gpt", "value": "Slice of pepperoni topping on pizza."}, {"from": "human", "value": "Please provide a short description for this region: [0.69, 0.04, 0.96, 0.36]."}, {"from": "gpt", "value": "Drawing of whole onion on tablecloth."}, {"from": "human", "value": "Please provide a short description for this region: [0.76, 0.54, 0.92, 0.66]."}, {"from": "gpt", "value": "A fresh green vegitable."}, {"from": "human", "value": "Please provide a short description for this region: [0.07, 0.27, 0.22, 0.4]."}, {"from": "gpt", "value": "A fresh green vegitable."}, {"from": "human", "value": "Please provide a short description for this region: [0.56, 0.36, 0.65, 0.52]."}, {"from": "gpt", "value": "A purple onion on a pizza."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Tomatoes on the pizza."}, {"from": "gpt", "value": "[0.68, 0.3, 0.88, 0.5]"}]}, {"id": "VG_100K/2356566", "image": "vg/VG_100K/2356566.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.32, 0.37, 0.51, 0.55]."}, {"from": "gpt", "value": "A person laying down talking on a cellphone."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a monitor of a laptop."}, {"from": "gpt", "value": "[0.49, 0.49, 0.74, 0.71]"}, {"from": "human", "value": "Please provide a short description for this region: [0.51, 0.53, 0.92, 0.75]."}, {"from": "gpt", "value": "Grey laptop on table."}, {"from": "human", "value": "Please provide a short description for this region: [0.21, 0.58, 0.29, 0.68]."}, {"from": "gpt", "value": "Picture on screen with boy making a hawaiian symbol."}, {"from": "human", "value": "Please provide a short description for this region: [0.21, 0.41, 0.45, 0.59]."}, {"from": "gpt", "value": "Person is holding phone."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: keys on a lap top."}, {"from": "gpt", "value": "[0.7, 0.63, 0.79, 0.69]"}, {"from": "human", "value": "Please provide a short description for this region: [0.43, 0.34, 0.61, 0.47]."}, {"from": "gpt", "value": "Brown throw pillow."}, {"from": "human", "value": "Please provide a short description for this region: [0.27, 0.57, 0.58, 0.8]."}, {"from": "gpt", "value": "Black laptop on table."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: screen on a lap top."}, {"from": "gpt", "value": "[0.51, 0.52, 0.69, 0.68]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: black laptop with screen on."}, {"from": "gpt", "value": "[0.28, 0.55, 0.57, 0.78]"}]}, {"id": "VG_100K/2356203", "image": "vg/VG_100K/2356203.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.21, 0.53, 0.68, 0.76]."}, {"from": "gpt", "value": "A man near a truck."}, {"from": "human", "value": "Please provide a short description for this region: [0.83, 0.61, 0.95, 0.71]."}, {"from": "gpt", "value": "The man is wearing an orange suit."}, {"from": "human", "value": "Please provide a short description for this region: [0.46, 0.75, 0.85, 0.88]."}, {"from": "gpt", "value": "Brown leaves on the ground."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the truck is red."}, {"from": "gpt", "value": "[0.03, 0.45, 0.33, 0.84]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The water is frozen behind the tree."}, {"from": "gpt", "value": "[0.35, 0.58, 0.75, 0.85]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a man in orange jumpsuit."}, {"from": "gpt", "value": "[0.86, 0.58, 0.96, 0.74]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: red dump truck."}, {"from": "gpt", "value": "[0.02, 0.45, 0.32, 0.77]"}, {"from": "human", "value": "Please provide a short description for this region: [0.8, 0.34, 0.95, 0.69]."}, {"from": "gpt", "value": "Two tall pine trees."}, {"from": "human", "value": "Please provide a short description for this region: [0.84, 0.6, 0.93, 0.73]."}, {"from": "gpt", "value": "A man in orange jumpsuit."}, {"from": "human", "value": "Please provide a short description for this region: [0.32, 0.61, 0.37, 0.76]."}, {"from": "gpt", "value": "Man wearing tan pants."}]}, {"id": "VG_100K/2355215", "image": "vg/VG_100K/2355215.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: this is a pole."}, {"from": "gpt", "value": "[0.84, 0.2, 0.86, 0.3]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: cement pole in ground."}, {"from": "gpt", "value": "[0.33, 0.58, 0.45, 0.97]"}, {"from": "human", "value": "Please provide a short description for this region: [0.6, 0.64, 0.64, 0.76]."}, {"from": "gpt", "value": "The pants are black."}, {"from": "human", "value": "Please provide a short description for this region: [0.6, 0.19, 0.74, 0.28]."}, {"from": "gpt", "value": "The helmet on the motorcycle rider."}, {"from": "human", "value": "Please provide a short description for this region: [0.24, 0.24, 0.39, 0.57]."}, {"from": "gpt", "value": "The windshield on the motorcycle."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The white semi truck."}, {"from": "gpt", "value": "[0.04, 0.16, 0.33, 0.31]"}, {"from": "human", "value": "Please provide a short description for this region: [0.7, 0.12, 0.81, 0.17]."}, {"from": "gpt", "value": "Street sign on pole."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the sign is green."}, {"from": "gpt", "value": "[0.74, 0.09, 0.77, 0.12]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: street sign on pole."}, {"from": "gpt", "value": "[0.69, 0.08, 0.81, 0.14]"}, {"from": "human", "value": "Please provide a short description for this region: [0.64, 0.42, 0.76, 0.67]."}, {"from": "gpt", "value": "The man is sitting on the motorcycle."}]}, {"id": "VG_100K/2354876", "image": "vg/VG_100K/2354876.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.24, 0.38, 0.35, 0.56]."}, {"from": "gpt", "value": "A lamp in the background."}, {"from": "human", "value": "Please provide a short description for this region: [0.13, 0.21, 0.22, 0.26]."}, {"from": "gpt", "value": "Black tea pot on top of shelf."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a glass is on the table."}, {"from": "gpt", "value": "[0.28, 0.51, 0.45, 0.72]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: wall decoration of a sun on a green background."}, {"from": "gpt", "value": "[0.5, 0.02, 0.53, 0.06]"}, {"from": "human", "value": "Please provide a short description for this region: [0.64, 0.42, 0.74, 0.5]."}, {"from": "gpt", "value": "Silver pots in the background."}, {"from": "human", "value": "Please provide a short description for this region: [0.47, 0.59, 0.65, 0.99]."}, {"from": "gpt", "value": "This is a chair."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: this is a table cloth."}, {"from": "gpt", "value": "[0.22, 0.78, 0.26, 0.84]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A glass jug on the table."}, {"from": "gpt", "value": "[0.34, 0.58, 0.41, 0.68]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: yellow and blue towel on the counter."}, {"from": "gpt", "value": "[0.45, 0.5, 0.56, 0.55]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a blue cup is on the table."}, {"from": "gpt", "value": "[0.43, 0.6, 0.53, 0.71]"}]}, {"id": "VG_100K/2354830", "image": "vg/VG_100K/2354830.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.48, 0.56, 0.55, 0.76]."}, {"from": "gpt", "value": "Yellow stand of bananas in the store."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bunch of bananas in a store."}, {"from": "gpt", "value": "[0.49, 0.5, 0.57, 0.82]"}, {"from": "human", "value": "Please provide a short description for this region: [0.38, 0.7, 0.48, 0.75]."}, {"from": "gpt", "value": "The bananas hanging under the counter."}, {"from": "human", "value": "Please provide a short description for this region: [0.65, 0.57, 0.7, 0.6]."}, {"from": "gpt", "value": "The hat the mannequin is wearing."}, {"from": "human", "value": "Please provide a short description for this region: [0.03, 0.62, 0.16, 0.78]."}, {"from": "gpt", "value": "Yellow stand of bananas in the store."}, {"from": "human", "value": "Please provide a short description for this region: [0.2, 0.74, 0.37, 0.83]."}, {"from": "gpt", "value": "Yellow stand of bananas in the store."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: neon letters on a building."}, {"from": "gpt", "value": "[0.1, 0.42, 0.17, 0.46]"}, {"from": "human", "value": "Please provide a short description for this region: [0.02, 0.63, 0.08, 0.71]."}, {"from": "gpt", "value": "Bunch of bananas in a store."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A blue sign with white writing."}, {"from": "gpt", "value": "[0.0, 0.42, 0.18, 0.46]"}, {"from": "human", "value": "Please provide a short description for this region: [0.49, 0.59, 0.57, 0.81]."}, {"from": "gpt", "value": "These are some bananas."}]}, {"id": "VG_100K/2354173", "image": "vg/VG_100K/2354173.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.39, 0.57, 0.53, 0.87]."}, {"from": "gpt", "value": "Empty train rails between trains."}, {"from": "human", "value": "Please provide a short description for this region: [0.76, 0.12, 0.99, 0.32]."}, {"from": "gpt", "value": "Bright spot in the hazy sky."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a line of buildings to the right."}, {"from": "gpt", "value": "[0.65, 0.46, 1.0, 0.64]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a tree near the train tracks."}, {"from": "gpt", "value": "[0.09, 0.48, 0.16, 0.55]"}, {"from": "human", "value": "Please provide a short description for this region: [0.8, 0.42, 0.92, 0.58]."}, {"from": "gpt", "value": "A material processing plant."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: an empty train track in the middle."}, {"from": "gpt", "value": "[0.38, 0.53, 0.53, 0.87]"}, {"from": "human", "value": "Please provide a short description for this region: [0.59, 0.53, 0.87, 0.83]."}, {"from": "gpt", "value": "Several maroon train cars."}, {"from": "human", "value": "Please provide a short description for this region: [0.1, 0.64, 0.23, 0.72]."}, {"from": "gpt", "value": "One blue oil tank."}, {"from": "human", "value": "Please provide a short description for this region: [0.52, 0.54, 0.61, 0.87]."}, {"from": "gpt", "value": "White train between cargo trains."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: green grass to the right of the trains."}, {"from": "gpt", "value": "[0.81, 0.58, 1.0, 0.65]"}]}, {"id": "VG_100K/2352610", "image": "vg/VG_100K/2352610.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: legs of the cat."}, {"from": "gpt", "value": "[0.35, 0.71, 0.51, 0.77]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: front legs of cat are white."}, {"from": "gpt", "value": "[0.37, 0.68, 0.53, 0.78]"}, {"from": "human", "value": "Please provide a short description for this region: [0.4, 0.59, 0.46, 0.65]."}, {"from": "gpt", "value": "Eye of the cat lightening."}, {"from": "human", "value": "Please provide a short description for this region: [0.54, 0.17, 0.8, 0.32]."}, {"from": "gpt", "value": "Tail of the cat in blue cover."}, {"from": "human", "value": "Please provide a short description for this region: [0.41, 0.62, 0.5, 0.64]."}, {"from": "gpt", "value": "Eyes of cat are orange."}, {"from": "human", "value": "Please provide a short description for this region: [0.33, 0.49, 0.57, 0.6]."}, {"from": "gpt", "value": "Black ears of cat."}, {"from": "human", "value": "Please provide a short description for this region: [0.05, 0.66, 0.27, 0.81]."}, {"from": "gpt", "value": "The sheet is blue."}, {"from": "human", "value": "Please provide a short description for this region: [0.42, 0.66, 0.49, 0.7]."}, {"from": "gpt", "value": "The cats whtie muzzle."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the cat has black ears."}, {"from": "gpt", "value": "[0.35, 0.54, 0.78, 0.79]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the cat has a white nose."}, {"from": "gpt", "value": "[0.33, 0.62, 0.74, 0.71]"}]}, {"id": "VG_100K/2351830", "image": "vg/VG_100K/2351830.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.72, 0.71, 0.79, 0.78]."}, {"from": "gpt", "value": "The bird is standing."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a tree pith with exposed trunks."}, {"from": "gpt", "value": "[0.38, 0.34, 0.5, 0.44]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the waves are crashing."}, {"from": "gpt", "value": "[0.07, 0.27, 0.35, 0.38]"}, {"from": "human", "value": "Please provide a short description for this region: [0.01, 0.47, 0.32, 0.51]."}, {"from": "gpt", "value": "Water hititing the shoreline."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: base of the tree debris."}, {"from": "gpt", "value": "[0.52, 0.46, 0.9, 0.51]"}, {"from": "human", "value": "Please provide a short description for this region: [0.34, 0.7, 0.43, 0.76]."}, {"from": "gpt", "value": "Second seagull looking in the same direction as the first."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: sand birds are walking on."}, {"from": "gpt", "value": "[0.0, 0.71, 1.0, 0.77]"}, {"from": "human", "value": "Please provide a short description for this region: [0.02, 0.32, 0.12, 0.37]."}, {"from": "gpt", "value": "A wave."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the oceans water."}, {"from": "gpt", "value": "[0.32, 0.53, 0.58, 0.62]"}, {"from": "human", "value": "Please provide a short description for this region: [0.34, 0.69, 0.43, 0.76]."}, {"from": "gpt", "value": "Grey and white seagull in center front."}]}, {"id": "VG_100K/2350884", "image": "vg/VG_100K/2350884.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.66, 0.67, 0.82, 0.71]."}, {"from": "gpt", "value": "Zebra laying on the floor."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the zebra eating grass."}, {"from": "gpt", "value": "[0.32, 0.62, 0.41, 0.7]"}, {"from": "human", "value": "Please provide a short description for this region: [0.06, 0.17, 0.22, 0.3]."}, {"from": "gpt", "value": "White clouds in blue sky."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the zebra is eating grass."}, {"from": "gpt", "value": "[0.3, 0.61, 0.41, 0.7]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: grass in front of the zebras."}, {"from": "gpt", "value": "[0.41, 0.72, 1.0, 0.86]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: zebra laying down on grass."}, {"from": "gpt", "value": "[0.22, 0.7, 0.36, 0.79]"}, {"from": "human", "value": "Please provide a short description for this region: [0.13, 0.23, 0.29, 0.31]."}, {"from": "gpt", "value": "Cloud in the sky."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: zebra."}, {"from": "gpt", "value": "[0.02, 0.64, 0.16, 0.74]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: clouds in the sky."}, {"from": "gpt", "value": "[0.11, 0.19, 0.35, 0.32]"}, {"from": "human", "value": "Please provide a short description for this region: [0.01, 0.64, 0.17, 0.76]."}, {"from": "gpt", "value": "The zebra is standing."}]}, {"id": "VG_100K/2350806", "image": "vg/VG_100K/2350806.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.42, 0.04, 0.77, 0.47]."}, {"from": "gpt", "value": "The child's hair is straight."}, {"from": "human", "value": "Please provide a short description for this region: [0.17, 0.35, 0.27, 0.76]."}, {"from": "gpt", "value": "A bottle of coca cola sitting on table."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: wooden tray to hold the hot dish."}, {"from": "gpt", "value": "[0.27, 0.66, 0.7, 0.95]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: reflective table."}, {"from": "gpt", "value": "[0.31, 0.89, 0.68, 1.0]"}, {"from": "human", "value": "Please provide a short description for this region: [0.49, 0.44, 0.58, 0.47]."}, {"from": "gpt", "value": "Food on the spoon."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the girl is holding a spoon."}, {"from": "gpt", "value": "[0.22, 0.41, 0.32, 0.5]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: woman in a blue dress."}, {"from": "gpt", "value": "[0.4, 0.0, 0.52, 0.22]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The spoon is silver."}, {"from": "gpt", "value": "[0.17, 0.37, 0.6, 0.57]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a floral tapestry pillow."}, {"from": "gpt", "value": "[0.72, 0.25, 0.81, 0.44]"}, {"from": "human", "value": "Please provide a short description for this region: [0.59, 0.83, 0.62, 0.85]."}, {"from": "gpt", "value": "The rim of the pan."}]}, {"id": "VG_100K/2350527", "image": "vg/VG_100K/2350527.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.65, 0.24, 0.75, 0.29]."}, {"from": "gpt", "value": "Display on a parking meter."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: key lock on meter."}, {"from": "gpt", "value": "[0.35, 0.53, 0.39, 0.57]"}, {"from": "human", "value": "Please provide a short description for this region: [0.3, 0.25, 0.36, 0.3]."}, {"from": "gpt", "value": "Dried bird popp on the parking meter."}, {"from": "human", "value": "Please provide a short description for this region: [0.71, 0.51, 0.75, 0.55]."}, {"from": "gpt", "value": "Lock on a parking meter."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: yellow tag on a parking meter."}, {"from": "gpt", "value": "[0.66, 0.31, 0.82, 0.35]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: plastic cover on meter."}, {"from": "gpt", "value": "[0.62, 0.21, 0.81, 0.31]"}, {"from": "human", "value": "Please provide a short description for this region: [0.27, 0.36, 0.46, 0.5]."}, {"from": "gpt", "value": "Yellow sticker on a grey parking meter."}]}, {"id": "VG_100K/2350219", "image": "vg/VG_100K/2350219.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.06, 0.46, 0.38, 0.79]."}, {"from": "gpt", "value": "The pieces of pizza are cut into squares."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: pizzas over a table."}, {"from": "gpt", "value": "[0.56, 0.3, 0.97, 0.51]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: handle of spatula."}, {"from": "gpt", "value": "[0.04, 0.83, 0.44, 0.96]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A person is holding a hand up."}, {"from": "gpt", "value": "[0.63, 0.19, 0.72, 0.34]"}, {"from": "human", "value": "Please provide a short description for this region: [0.1, 0.51, 0.36, 0.77]."}, {"from": "gpt", "value": "Square slices of pizza."}, {"from": "human", "value": "Please provide a short description for this region: [0.52, 0.38, 0.62, 0.54]."}, {"from": "gpt", "value": "A drinking glass on a tabel."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a square cut piece of pizza."}, {"from": "gpt", "value": "[0.06, 0.6, 0.32, 0.76]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a stack of plates."}, {"from": "gpt", "value": "[0.9, 0.69, 0.96, 0.88]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: spatula color silver."}, {"from": "gpt", "value": "[0.37, 0.7, 0.72, 0.92]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: large metal trey for pizza."}, {"from": "gpt", "value": "[0.84, 0.77, 0.93, 0.91]"}]}, {"id": "VG_100K/2349873", "image": "vg/VG_100K/2349873.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.09, 0.47, 0.47, 0.85]."}, {"from": "gpt", "value": "Folded gray blanket draped on bed."}, {"from": "human", "value": "Please provide a short description for this region: [0.52, 0.32, 0.7, 0.44]."}, {"from": "gpt", "value": "Wooden nightstand next to bed."}, {"from": "human", "value": "Please provide a short description for this region: [0.89, 0.12, 1.0, 0.87]."}, {"from": "gpt", "value": "A rounded wall next to the bed."}, {"from": "human", "value": "Please provide a short description for this region: [0.52, 0.28, 0.71, 0.44]."}, {"from": "gpt", "value": "Rotary telephone on a white side table."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the black and clear light."}, {"from": "gpt", "value": "[0.81, 0.21, 0.86, 0.27]"}, {"from": "human", "value": "Please provide a short description for this region: [0.51, 0.13, 0.61, 0.35]."}, {"from": "gpt", "value": "The mirror on the wall."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Telephone on a side table."}, {"from": "gpt", "value": "[0.58, 0.28, 0.68, 0.34]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Plastic moulding on wall."}, {"from": "gpt", "value": "[0.0, 0.41, 0.53, 0.54]"}, {"from": "human", "value": "Please provide a short description for this region: [0.58, 0.28, 0.68, 0.35]."}, {"from": "gpt", "value": "Phone on a side table."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the white table."}, {"from": "gpt", "value": "[0.52, 0.31, 0.69, 0.45]"}]}, {"id": "VG_100K/2349177", "image": "vg/VG_100K/2349177.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.16, 0.36, 0.23, 0.51]."}, {"from": "gpt", "value": "This is a fence pole."}, {"from": "human", "value": "Please provide a short description for this region: [0.3, 0.57, 0.39, 0.7]."}, {"from": "gpt", "value": "White snow on the ground."}, {"from": "human", "value": "Please provide a short description for this region: [0.67, 0.29, 0.82, 0.43]."}, {"from": "gpt", "value": "White snow on the ground."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: this is a fence pole."}, {"from": "gpt", "value": "[0.3, 0.25, 0.39, 0.39]"}, {"from": "human", "value": "Please provide a short description for this region: [0.79, 0.54, 0.84, 0.61]."}, {"from": "gpt", "value": "Small pile of white snow on the ground."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: red post is supporting the fence."}, {"from": "gpt", "value": "[0.02, 0.38, 0.06, 0.54]"}, {"from": "human", "value": "Please provide a short description for this region: [0.01, 0.4, 0.11, 0.54]."}, {"from": "gpt", "value": "This is a fence pole."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: rocky mountain behind fence."}, {"from": "gpt", "value": "[0.0, 0.17, 0.29, 0.56]"}]}, {"id": "VG_100K/2349117", "image": "vg/VG_100K/2349117.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: This is a train."}, {"from": "gpt", "value": "[0.54, 0.43, 0.71, 0.64]"}, {"from": "human", "value": "Please provide a short description for this region: [0.2, 0.4, 0.34, 0.44]."}, {"from": "gpt", "value": "An old brown train car alone."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: This is a train."}, {"from": "gpt", "value": "[0.69, 0.42, 0.87, 0.67]"}, {"from": "human", "value": "Please provide a short description for this region: [0.63, 0.38, 0.82, 0.51]."}, {"from": "gpt", "value": "This is a bullet train."}, {"from": "human", "value": "Please provide a short description for this region: [0.57, 0.38, 1.0, 0.65]."}, {"from": "gpt", "value": "Rows of long blue trains."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a row of red and white trains."}, {"from": "gpt", "value": "[0.03, 0.39, 0.79, 0.58]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a row of houses in the distance."}, {"from": "gpt", "value": "[0.5, 0.31, 0.57, 0.37]"}, {"from": "human", "value": "Please provide a short description for this region: [0.85, 0.42, 1.0, 0.67]."}, {"from": "gpt", "value": "The first blue and white train on the right."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a white train car."}, {"from": "gpt", "value": "[0.02, 0.45, 0.18, 0.55]"}, {"from": "human", "value": "Please provide a short description for this region: [0.65, 0.26, 0.99, 0.38]."}, {"from": "gpt", "value": "Large group of tall leafy green trees."}]}, {"id": "VG_100K/2348818", "image": "vg/VG_100K/2348818.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.84, 0.49, 0.95, 0.7]."}, {"from": "gpt", "value": "Marble table top the dish is on."}, {"from": "human", "value": "Please provide a short description for this region: [0.59, 0.12, 0.93, 0.43]."}, {"from": "gpt", "value": "Syrup next to the plate."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Butter is on waffles."}, {"from": "gpt", "value": "[0.35, 0.43, 0.54, 0.59]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a bunch of red grapes drawn on a plate."}, {"from": "gpt", "value": "[0.53, 0.82, 0.57, 0.85]"}, {"from": "human", "value": "Please provide a short description for this region: [0.61, 0.12, 0.91, 0.45]."}, {"from": "gpt", "value": "A jar of maple syrup."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Syrup on the counter."}, {"from": "gpt", "value": "[0.59, 0.13, 0.92, 0.44]"}, {"from": "human", "value": "Please provide a short description for this region: [0.2, 0.77, 0.24, 0.81]."}, {"from": "gpt", "value": "A bunch of blue grapes drawn on a plate."}, {"from": "human", "value": "Please provide a short description for this region: [0.28, 0.43, 0.63, 0.81]."}, {"from": "gpt", "value": "A affle with butter on it."}, {"from": "human", "value": "Please provide a short description for this region: [0.42, 0.63, 0.5, 0.71]."}, {"from": "gpt", "value": "Square in the waffle."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: berry design on the plate."}, {"from": "gpt", "value": "[0.66, 0.55, 0.73, 0.73]"}]}, {"id": "VG_100K/2348510", "image": "vg/VG_100K/2348510.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.07, 0.22, 0.18, 0.25]."}, {"from": "gpt", "value": "Thin cloud in the sky."}, {"from": "human", "value": "Please provide a short description for this region: [0.17, 0.41, 0.49, 0.53]."}, {"from": "gpt", "value": "Blue and yellow color on jet."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white clouds in blue sky."}, {"from": "gpt", "value": "[0.01, 0.22, 0.14, 0.28]"}, {"from": "human", "value": "Please provide a short description for this region: [0.06, 0.18, 0.93, 0.27]."}, {"from": "gpt", "value": "The sky is clear."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Jet in front of bridge."}, {"from": "gpt", "value": "[0.17, 0.4, 0.49, 0.53]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the plane is blue and yellow."}, {"from": "gpt", "value": "[0.18, 0.39, 0.5, 0.55]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: frame of red bridge."}, {"from": "gpt", "value": "[0.21, 0.29, 0.44, 0.83]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: military plane in flight."}, {"from": "gpt", "value": "[0.17, 0.42, 0.49, 0.52]"}]}, {"id": "VG_100K/2347619", "image": "vg/VG_100K/2347619.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.38, 0.38, 0.76, 0.68]."}, {"from": "gpt", "value": "Red bus on a street."}, {"from": "human", "value": "Please provide a short description for this region: [0.48, 0.58, 0.57, 0.62]."}, {"from": "gpt", "value": "The manufacturer is arriva."}, {"from": "human", "value": "Please provide a short description for this region: [0.79, 0.55, 0.82, 0.66]."}, {"from": "gpt", "value": "Black and white pole."}, {"from": "human", "value": "Please provide a short description for this region: [0.38, 0.38, 0.63, 0.46]."}, {"from": "gpt", "value": "The display on the bus."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: this is the bus's route number."}, {"from": "gpt", "value": "[0.35, 0.38, 0.64, 0.45]"}, {"from": "human", "value": "Please provide a short description for this region: [0.54, 0.37, 0.63, 0.46]."}, {"from": "gpt", "value": "The bus is number 286."}, {"from": "human", "value": "Please provide a short description for this region: [0.41, 0.39, 0.61, 0.44]."}, {"from": "gpt", "value": "Digital text on a bus."}, {"from": "human", "value": "Please provide a short description for this region: [0.5, 0.3, 0.61, 0.36]."}, {"from": "gpt", "value": "Light over the street."}, {"from": "human", "value": "Please provide a short description for this region: [0.55, 0.39, 0.61, 0.44]."}, {"from": "gpt", "value": "Numbers 286 on bus."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bus on the street."}, {"from": "gpt", "value": "[0.38, 0.36, 0.76, 0.66]"}]}, {"id": "VG_100K/2347398", "image": "vg/VG_100K/2347398.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: part of a grass."}, {"from": "gpt", "value": "[0.51, 0.73, 0.59, 0.81]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the man is sitting on the ground."}, {"from": "gpt", "value": "[0.14, 0.36, 0.34, 0.49]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a pink frisbee flying in the air."}, {"from": "gpt", "value": "[0.48, 0.38, 0.55, 0.41]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: part of a ground."}, {"from": "gpt", "value": "[0.44, 0.69, 0.5, 0.76]"}, {"from": "human", "value": "Please provide a short description for this region: [0.77, 0.51, 0.98, 0.73]."}, {"from": "gpt", "value": "Woman wearing blue jeans."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the man is sitting on the ground."}, {"from": "gpt", "value": "[0.1, 0.32, 0.37, 0.53]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: sandals on the woman."}, {"from": "gpt", "value": "[0.76, 0.7, 0.99, 0.74]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: pants on a woman."}, {"from": "gpt", "value": "[0.78, 0.49, 0.97, 0.71]"}, {"from": "human", "value": "Please provide a short description for this region: [0.02, 0.6, 0.95, 0.71]."}, {"from": "gpt", "value": "Path of concrete in park."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: vehicle on the road."}, {"from": "gpt", "value": "[0.02, 0.29, 0.36, 0.46]"}]}, {"id": "VG_100K/2346399", "image": "vg/VG_100K/2346399.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: white lines on a tennis court."}, {"from": "gpt", "value": "[0.0, 0.42, 0.11, 0.66]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Shadow falling on the pitch."}, {"from": "gpt", "value": "[0.0, 0.17, 1.0, 0.3]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.49, 0.03, 0.53]."}, {"from": "gpt", "value": "The floor is blue in color."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: White short sleeved sports shirt."}, {"from": "gpt", "value": "[0.38, 0.27, 0.6, 0.55]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a man wearing a cap backwards."}, {"from": "gpt", "value": "[0.41, 0.21, 0.56, 0.28]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Edge markings of a playing field."}, {"from": "gpt", "value": "[0.0, 0.44, 0.13, 0.75]"}, {"from": "human", "value": "Please provide a short description for this region: [0.38, 0.8, 0.76, 0.83]."}, {"from": "gpt", "value": "Feet in white pair of socks."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Tennis racket in the hand."}, {"from": "gpt", "value": "[0.21, 0.5, 0.3, 0.77]"}, {"from": "human", "value": "Please provide a short description for this region: [0.42, 0.56, 0.57, 0.71]."}, {"from": "gpt", "value": "Pants are white in color."}]}, {"id": "VG_100K/2345153", "image": "vg/VG_100K/2345153.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.41, 0.35, 0.46, 0.39]."}, {"from": "gpt", "value": "The black band on the wrist."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the racquet is black and white."}, {"from": "gpt", "value": "[0.42, 0.17, 0.57, 0.33]"}, {"from": "human", "value": "Please provide a short description for this region: [0.75, 0.35, 0.81, 0.38]."}, {"from": "gpt", "value": "The white watch on the wrist."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: White shoes in the grass."}, {"from": "gpt", "value": "[0.6, 0.54, 0.69, 0.59]"}, {"from": "human", "value": "Please provide a short description for this region: [0.4, 0.75, 0.52, 0.82]."}, {"from": "gpt", "value": "Red, white, and blue shoe on man tennis player."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the man wearing white polo shirt."}, {"from": "gpt", "value": "[0.24, 0.34, 0.44, 0.53]"}, {"from": "human", "value": "Please provide a short description for this region: [0.78, 0.55, 0.85, 0.58]."}, {"from": "gpt", "value": "Black and white shoe on tennis linesperson."}, {"from": "human", "value": "Please provide a short description for this region: [0.07, 0.52, 0.52, 0.8]."}, {"from": "gpt", "value": "Bent knees with a flat foot and a pointed toe."}, {"from": "human", "value": "Please provide a short description for this region: [0.94, 0.45, 0.99, 0.52]."}, {"from": "gpt", "value": "Yellow ball in air close to player."}]}, {"id": "VG_100K/2344847", "image": "vg/VG_100K/2344847.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: The lettuce is green."}, {"from": "gpt", "value": "[0.01, 0.12, 0.2, 0.24]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The plate is white."}, {"from": "gpt", "value": "[0.11, 0.74, 0.25, 0.81]"}, {"from": "human", "value": "Please provide a short description for this region: [0.01, 0.77, 0.07, 0.87]."}, {"from": "gpt", "value": "The table is brown."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The sandwich is small."}, {"from": "gpt", "value": "[0.46, 0.6, 0.66, 0.82]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a stack of plates."}, {"from": "gpt", "value": "[0.76, 0.12, 0.99, 0.2]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a pair of silver tongs."}, {"from": "gpt", "value": "[0.71, 0.13, 0.97, 0.47]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a stack of white plates."}, {"from": "gpt", "value": "[0.76, 0.13, 1.0, 0.2]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Shiny silver tongs on plate."}, {"from": "gpt", "value": "[0.7, 0.12, 0.98, 0.48]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bread covered in seseame seeds."}, {"from": "gpt", "value": "[0.52, 0.34, 0.7, 0.53]"}, {"from": "human", "value": "Please provide a short description for this region: [0.27, 0.21, 0.33, 0.28]."}, {"from": "gpt", "value": "The cheese is orange."}]}, {"id": "VG_100K/2344610", "image": "vg/VG_100K/2344610.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a spatula."}, {"from": "gpt", "value": "[0.61, 0.46, 0.8, 0.55]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: handle of the spatcula on the pan."}, {"from": "gpt", "value": "[0.94, 0.4, 0.99, 0.45]"}, {"from": "human", "value": "Please provide a short description for this region: [0.25, 0.04, 0.37, 0.11]."}, {"from": "gpt", "value": "A watch on the persons hand."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: chicke on the pizza."}, {"from": "gpt", "value": "[0.38, 0.24, 0.47, 0.3]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: tomato sauce on a pizza."}, {"from": "gpt", "value": "[0.38, 0.67, 0.65, 0.79]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: glass salt shaker."}, {"from": "gpt", "value": "[0.0, 0.91, 0.09, 0.99]"}, {"from": "human", "value": "Please provide a short description for this region: [0.24, 0.02, 0.4, 0.13]."}, {"from": "gpt", "value": "Wrist watch on a wrist."}, {"from": "human", "value": "Please provide a short description for this region: [0.17, 0.53, 0.31, 0.61]."}, {"from": "gpt", "value": "Black olives on a pizza."}, {"from": "human", "value": "Please provide a short description for this region: [0.09, 0.28, 0.16, 0.33]."}, {"from": "gpt", "value": "The crust is brown."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.19, 0.2, 0.36]."}, {"from": "gpt", "value": "Blue, white and red table cloth."}]}, {"id": "VG_100K/2344556", "image": "vg/VG_100K/2344556.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a phone on the wal."}, {"from": "gpt", "value": "[0.51, 0.19, 0.79, 0.49]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: top of red office chair."}, {"from": "gpt", "value": "[0.42, 0.35, 0.54, 0.56]"}, {"from": "human", "value": "Please provide a short description for this region: [0.73, 0.33, 0.83, 0.43]."}, {"from": "gpt", "value": "A laptop screen."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: phone with red light on it."}, {"from": "gpt", "value": "[0.52, 0.26, 0.67, 0.41]"}, {"from": "human", "value": "Please provide a short description for this region: [0.69, 0.48, 0.75, 0.51]."}, {"from": "gpt", "value": "A mouse."}, {"from": "human", "value": "Please provide a short description for this region: [0.58, 0.35, 0.81, 0.55]."}, {"from": "gpt", "value": "A keybaord on the desk."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: black computer keyboard."}, {"from": "gpt", "value": "[0.54, 0.38, 0.72, 0.43]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the desk is brown."}, {"from": "gpt", "value": "[0.47, 0.57, 0.61, 0.68]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a telephone that is black and grey."}, {"from": "gpt", "value": "[0.57, 0.25, 0.65, 0.34]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a black cord."}, {"from": "gpt", "value": "[0.85, 0.48, 0.94, 0.53]"}]}, {"id": "VG_100K/2344374", "image": "vg/VG_100K/2344374.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.55, 0.45, 0.66, 0.67]."}, {"from": "gpt", "value": "The woman has black hair."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Brick pavers in the walkway."}, {"from": "gpt", "value": "[0.0, 0.72, 0.84, 0.81]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.2, 0.17, 0.46]."}, {"from": "gpt", "value": "Trees with long straight branches in front of buildings."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.43, 0.43, 0.53]."}, {"from": "gpt", "value": "Cars on both sides of the street."}, {"from": "human", "value": "Please provide a short description for this region: [0.11, 0.46, 0.36, 0.81]."}, {"from": "gpt", "value": "Person in a black coat."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: chairs setting on the patio."}, {"from": "gpt", "value": "[0.59, 0.67, 0.9, 0.81]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: green and white street sign on pole."}, {"from": "gpt", "value": "[0.32, 0.19, 0.43, 0.26]"}, {"from": "human", "value": "Please provide a short description for this region: [0.11, 0.55, 0.35, 0.81]."}, {"from": "gpt", "value": "Black coat woman is wearing."}, {"from": "human", "value": "Please provide a short description for this region: [0.53, 0.43, 0.66, 0.65]."}, {"from": "gpt", "value": "Woman in red coat."}, {"from": "human", "value": "Please provide a short description for this region: [0.58, 0.58, 0.63, 0.64]."}, {"from": "gpt", "value": "Brown pants the woman is wearing."}]}, {"id": "VG_100K/2344362", "image": "vg/VG_100K/2344362.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: Part of black digital camera."}, {"from": "gpt", "value": "[0.77, 0.58, 0.87, 0.81]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Woman wearing shoes."}, {"from": "gpt", "value": "[0.38, 0.89, 0.54, 1.0]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a plastic fork on the plate."}, {"from": "gpt", "value": "[0.19, 0.75, 0.23, 0.82]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: woman wearing a blue dress."}, {"from": "gpt", "value": "[0.15, 0.16, 0.25, 0.44]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the bracelt on the girls wrist."}, {"from": "gpt", "value": "[0.59, 0.5, 0.62, 0.56]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the girl licking the carrot."}, {"from": "gpt", "value": "[0.33, 0.31, 0.41, 0.42]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Woman wearing a skirt."}, {"from": "gpt", "value": "[0.57, 0.67, 0.73, 0.85]"}, {"from": "human", "value": "Please provide a short description for this region: [0.36, 0.9, 0.55, 0.99]."}, {"from": "gpt", "value": "Woman is wearing green shoes."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: pink cup the lady are holding."}, {"from": "gpt", "value": "[0.45, 0.56, 0.52, 0.64]"}]}, {"id": "VG_100K/2344282", "image": "vg/VG_100K/2344282.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.71, 0.55, 0.76, 0.62]."}, {"from": "gpt", "value": "A tall green tree."}, {"from": "human", "value": "Please provide a short description for this region: [0.7, 0.52, 0.75, 0.62]."}, {"from": "gpt", "value": "A green tall tree."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A tall green tree."}, {"from": "gpt", "value": "[0.64, 0.54, 0.71, 0.61]"}, {"from": "human", "value": "Please provide a short description for this region: [0.13, 0.61, 0.83, 0.67]."}, {"from": "gpt", "value": "Water with boat in it."}, {"from": "human", "value": "Please provide a short description for this region: [0.19, 0.56, 0.87, 0.62]."}, {"from": "gpt", "value": "Trees on the side of the water."}, {"from": "human", "value": "Please provide a short description for this region: [0.22, 0.59, 0.32, 0.63]."}, {"from": "gpt", "value": "A big white boat."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A rough ground surface."}, {"from": "gpt", "value": "[0.15, 0.76, 0.38, 0.82]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A green tall tree."}, {"from": "gpt", "value": "[0.53, 0.57, 0.57, 0.61]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A rough ground surface."}, {"from": "gpt", "value": "[0.51, 0.78, 0.74, 0.89]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A tall green tree."}, {"from": "gpt", "value": "[0.58, 0.54, 0.63, 0.62]"}]}, {"id": "VG_100K/2344263", "image": "vg/VG_100K/2344263.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: pole on the concrete."}, {"from": "gpt", "value": "[0.41, 0.3, 0.43, 0.53]"}, {"from": "human", "value": "Please provide a short description for this region: [0.34, 0.53, 0.57, 0.64]."}, {"from": "gpt", "value": "The cement under the bench."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: pole on the concrete."}, {"from": "gpt", "value": "[0.13, 0.32, 0.19, 0.6]"}, {"from": "human", "value": "Please provide a short description for this region: [0.02, 0.19, 0.51, 0.26]."}, {"from": "gpt", "value": "Clouds in the sky."}, {"from": "human", "value": "Please provide a short description for this region: [0.5, 0.37, 0.81, 0.61]."}, {"from": "gpt", "value": "The bench near the water."}, {"from": "human", "value": "Please provide a short description for this region: [0.51, 0.45, 0.6, 0.49]."}, {"from": "gpt", "value": "The arm rest on the bench."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the shadow of the bench."}, {"from": "gpt", "value": "[0.54, 0.51, 0.94, 0.66]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.12, 1.0, 0.26]."}, {"from": "gpt", "value": "The blue sky above the ocean."}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.13, 0.54, 0.17]."}, {"from": "gpt", "value": "This is the sky."}, {"from": "human", "value": "Please provide a short description for this region: [0.02, 0.59, 0.34, 0.74]."}, {"from": "gpt", "value": "Rocks around the water."}]}, {"id": "VG_100K/2343321", "image": "vg/VG_100K/2343321.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.44, 0.31, 0.46, 0.36]."}, {"from": "gpt", "value": "The letter s from a stop sign."}, {"from": "human", "value": "Please provide a short description for this region: [0.69, 0.14, 0.91, 0.24]."}, {"from": "gpt", "value": "Distant tree branches."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The sign is round."}, {"from": "gpt", "value": "[0.4, 0.24, 0.59, 0.44]"}, {"from": "human", "value": "Please provide a short description for this region: [0.46, 0.42, 0.51, 0.82]."}, {"from": "gpt", "value": "The sign pole is black and white."}, {"from": "human", "value": "Please provide a short description for this region: [0.55, 0.6, 0.9, 0.79]."}, {"from": "gpt", "value": "A white car on the road."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the fence is black."}, {"from": "gpt", "value": "[0.6, 0.54, 0.96, 0.65]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a car rear view mirror."}, {"from": "gpt", "value": "[0.76, 0.23, 1.0, 0.39]"}, {"from": "human", "value": "Please provide a short description for this region: [0.14, 0.71, 0.64, 0.81]."}, {"from": "gpt", "value": "Green grass of a lawn."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A round stop sign."}, {"from": "gpt", "value": "[0.4, 0.24, 0.59, 0.42]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A distant street lamp."}, {"from": "gpt", "value": "[0.11, 0.5, 0.18, 0.66]"}]}, {"id": "VG_100K/2342826", "image": "vg/VG_100K/2342826.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.85, 0.66, 0.88, 0.76]."}, {"from": "gpt", "value": "Red and white canteen in a person's hand."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white shorts on the man."}, {"from": "gpt", "value": "[0.08, 0.64, 0.29, 0.87]"}, {"from": "human", "value": "Please provide a short description for this region: [0.82, 0.64, 0.93, 0.82]."}, {"from": "gpt", "value": "White and red cooler in the man's hand."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white shirt with purple logo."}, {"from": "gpt", "value": "[0.64, 0.37, 0.86, 0.61]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Red and white canteen in a person's hand."}, {"from": "gpt", "value": "[0.35, 0.54, 0.43, 0.83]"}, {"from": "human", "value": "Please provide a short description for this region: [0.25, 0.55, 0.38, 0.8]."}, {"from": "gpt", "value": "A black back pack."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A white strap on a thermos."}, {"from": "gpt", "value": "[0.85, 0.65, 0.93, 0.82]"}, {"from": "human", "value": "Please provide a short description for this region: [0.01, 0.67, 0.05, 0.87]."}, {"from": "gpt", "value": "Red and white canteen in a person's hand."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Red and white canteen in a person's hand."}, {"from": "gpt", "value": "[0.24, 0.65, 0.28, 0.73]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: black bag in the man's hand."}, {"from": "gpt", "value": "[0.24, 0.54, 0.38, 0.8]"}]}, {"id": "VG_100K/2341849", "image": "vg/VG_100K/2341849.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.43, 0.71, 0.48, 0.99]."}, {"from": "gpt", "value": "Whtie bar in the fridge for food."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white cap on the bottle."}, {"from": "gpt", "value": "[0.34, 0.14, 0.37, 0.16]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Whtie bar in the fridge for food."}, {"from": "gpt", "value": "[0.57, 0.92, 0.61, 0.97]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a carton of milk in the fridge."}, {"from": "gpt", "value": "[0.21, 0.06, 0.31, 0.37]"}, {"from": "human", "value": "Please provide a short description for this region: [0.21, 0.75, 0.76, 0.87]."}, {"from": "gpt", "value": "Glass shelf in the bottom of the fridge."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a red and white carton."}, {"from": "gpt", "value": "[0.61, 0.14, 0.73, 0.45]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a green cap on the milk."}, {"from": "gpt", "value": "[0.24, 0.07, 0.28, 0.1]"}]}, {"id": "VG_100K/2341323", "image": "vg/VG_100K/2341323.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.35, 0.53, 0.45, 0.69]."}, {"from": "gpt", "value": "Black metal bars on window."}, {"from": "human", "value": "Please provide a short description for this region: [0.35, 0.53, 0.45, 0.69]."}, {"from": "gpt", "value": "Caging over a set of windows."}, {"from": "human", "value": "Please provide a short description for this region: [0.35, 0.53, 0.46, 0.7]."}, {"from": "gpt", "value": "Rod iron window."}, {"from": "human", "value": "Please provide a short description for this region: [0.21, 0.57, 0.26, 0.61]."}, {"from": "gpt", "value": "Blue and white sign on side of corner building."}, {"from": "human", "value": "Please provide a short description for this region: [0.51, 0.7, 0.96, 0.77]."}, {"from": "gpt", "value": "Black metal poles on city sidewalk."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: traffic lights on pole."}, {"from": "gpt", "value": "[0.65, 0.24, 0.77, 0.62]"}, {"from": "human", "value": "Please provide a short description for this region: [0.5, 0.31, 0.62, 0.56]."}, {"from": "gpt", "value": "A sign hanging on the side of a building."}, {"from": "human", "value": "Please provide a short description for this region: [0.54, 0.62, 0.6, 0.71]."}, {"from": "gpt", "value": "Red and white poster."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Black lantern attached to wall of building."}, {"from": "gpt", "value": "[0.86, 0.38, 0.94, 0.45]"}]}, {"id": "VG_100K/2340476", "image": "vg/VG_100K/2340476.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.27, 0.19, 0.49, 0.78]."}, {"from": "gpt", "value": "Baseball player in blue hoodie."}, {"from": "human", "value": "Please provide a short description for this region: [0.71, 0.24, 0.74, 0.28]."}, {"from": "gpt", "value": "Player is wearing sunglasses."}, {"from": "human", "value": "Please provide a short description for this region: [0.15, 0.28, 0.31, 0.43]."}, {"from": "gpt", "value": "Black baseball bat."}, {"from": "human", "value": "Please provide a short description for this region: [0.66, 0.3, 0.7, 0.38]."}, {"from": "gpt", "value": "Team logo on the shirt."}, {"from": "human", "value": "Please provide a short description for this region: [0.39, 0.67, 0.49, 0.78]."}, {"from": "gpt", "value": "Pair of blue nike sneakers."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: baseball bat in hand."}, {"from": "gpt", "value": "[0.13, 0.27, 0.32, 0.46]"}, {"from": "human", "value": "Please provide a short description for this region: [0.3, 0.24, 0.48, 0.53]."}, {"from": "gpt", "value": "Blue cubs sweat shirt."}, {"from": "human", "value": "Please provide a short description for this region: [0.71, 0.65, 0.76, 0.78]."}, {"from": "gpt", "value": "Tall blue baseball sock on leg."}, {"from": "human", "value": "Please provide a short description for this region: [0.03, 0.51, 0.31, 0.78]."}, {"from": "gpt", "value": "Green grass of a baseball field."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: player is wearing a sweatshirt."}, {"from": "gpt", "value": "[0.31, 0.26, 0.47, 0.54]"}]}, {"id": "VG_100K/2340270", "image": "vg/VG_100K/2340270.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: trash can."}, {"from": "gpt", "value": "[0.96, 0.81, 1.0, 0.86]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: light switch reflected in mirror."}, {"from": "gpt", "value": "[0.96, 0.37, 0.99, 0.4]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: dark mirror over sink."}, {"from": "gpt", "value": "[0.65, 0.43, 0.74, 0.47]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: black framed mirrors above each sink."}, {"from": "gpt", "value": "[0.66, 0.23, 0.99, 0.47]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: racks for clothes."}, {"from": "gpt", "value": "[0.22, 0.29, 0.28, 0.37]"}, {"from": "human", "value": "Please provide a short description for this region: [0.6, 0.48, 0.97, 0.63]."}, {"from": "gpt", "value": "Vanity has two sinks."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: long throw rug on floor in front of sink."}, {"from": "gpt", "value": "[0.45, 0.7, 0.67, 0.86]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: hand soap in plastic bottle."}, {"from": "gpt", "value": "[0.95, 0.52, 0.99, 0.6]"}, {"from": "human", "value": "Please provide a short description for this region: [0.19, 0.65, 0.33, 0.72]."}, {"from": "gpt", "value": "A small floor rug in front of the shower."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: black frame around a mirror."}, {"from": "gpt", "value": "[0.66, 0.24, 0.79, 0.47]"}]}, {"id": "VG_100K/2340132", "image": "vg/VG_100K/2340132.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: stretch of a dirt road."}, {"from": "gpt", "value": "[0.71, 0.49, 0.83, 0.55]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a big paper below a scissor."}, {"from": "gpt", "value": "[0.22, 0.25, 0.55, 0.59]"}, {"from": "human", "value": "Please provide a short description for this region: [0.48, 0.72, 0.82, 0.84]."}, {"from": "gpt", "value": "A shadow on grass."}, {"from": "human", "value": "Please provide a short description for this region: [0.47, 0.27, 0.49, 0.41]."}, {"from": "gpt", "value": "Blade of a scissor."}, {"from": "human", "value": "Please provide a short description for this region: [0.32, 0.81, 0.34, 0.85]."}, {"from": "gpt", "value": "Circle piece of granite."}, {"from": "human", "value": "Please provide a short description for this region: [0.23, 0.26, 0.54, 0.57]."}, {"from": "gpt", "value": "A piece of paper."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: concrete base under statue."}, {"from": "gpt", "value": "[0.23, 0.85, 0.27, 0.88]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a piece of paper statue."}, {"from": "gpt", "value": "[0.23, 0.26, 0.55, 0.56]"}, {"from": "human", "value": "Please provide a short description for this region: [0.41, 0.04, 0.5, 0.1]."}, {"from": "gpt", "value": "White clouds in blue sky."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white clouds in blue sky."}, {"from": "gpt", "value": "[0.62, 0.06, 0.7, 0.11]"}]}, {"id": "VG_100K/2339713", "image": "vg/VG_100K/2339713.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: Window of the train."}, {"from": "gpt", "value": "[0.39, 0.11, 0.51, 0.17]"}, {"from": "human", "value": "Please provide a short description for this region: [0.26, 0.19, 0.69, 0.44]."}, {"from": "gpt", "value": "Yellow stripes and design on engine."}, {"from": "human", "value": "Please provide a short description for this region: [0.43, 0.51, 0.51, 0.79]."}, {"from": "gpt", "value": "Excited child watching train."}, {"from": "human", "value": "Please provide a short description for this region: [0.27, 0.16, 0.33, 0.21]."}, {"from": "gpt", "value": "Train driver waving at onlookers."}, {"from": "human", "value": "Please provide a short description for this region: [0.6, 0.56, 0.71, 0.86]."}, {"from": "gpt", "value": "Boy wearing blue shorts."}, {"from": "human", "value": "Please provide a short description for this region: [0.25, 0.5, 0.35, 0.75]."}, {"from": "gpt", "value": "Boy wearing red shorts."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Right hand of the train driver."}, {"from": "gpt", "value": "[0.27, 0.16, 0.3, 0.19]"}, {"from": "human", "value": "Please provide a short description for this region: [0.26, 0.5, 0.35, 0.75]."}, {"from": "gpt", "value": "Boy wearing a striped shirt and red shorts."}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.76, 0.48, 0.78]."}, {"from": "gpt", "value": "Foot of child watching train."}, {"from": "human", "value": "Please provide a short description for this region: [0.25, 0.3, 0.7, 0.41]."}, {"from": "gpt", "value": "Black stripes and design on engine."}]}, {"id": "VG_100K/2339681", "image": "vg/VG_100K/2339681.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a chair."}, {"from": "gpt", "value": "[0.0, 0.54, 0.13, 0.78]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: head of a person."}, {"from": "gpt", "value": "[0.33, 0.15, 0.57, 0.44]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: eye of a person."}, {"from": "gpt", "value": "[0.39, 0.27, 0.44, 0.3]"}, {"from": "human", "value": "Please provide a short description for this region: [0.75, 0.76, 0.8, 0.82]."}, {"from": "gpt", "value": "Silver spoon on oval plate."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: White oval plate sitting on table."}, {"from": "gpt", "value": "[0.43, 0.77, 0.58, 0.86]"}, {"from": "human", "value": "Please provide a short description for this region: [0.8, 0.74, 0.88, 0.81]."}, {"from": "gpt", "value": "A table."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: jaw of a person."}, {"from": "gpt", "value": "[0.37, 0.39, 0.52, 0.44]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man is smiling."}, {"from": "gpt", "value": "[0.41, 0.34, 0.49, 0.37]"}, {"from": "human", "value": "Please provide a short description for this region: [0.34, 0.16, 0.55, 0.43]."}, {"from": "gpt", "value": "The person has a smile on his face."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: sunlight on the wall."}, {"from": "gpt", "value": "[0.59, 0.18, 0.79, 0.24]"}]}, {"id": "VG_100K/2338401", "image": "vg/VG_100K/2338401.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.33, 0.33, 0.64, 0.77]."}, {"from": "gpt", "value": "A little girl skiing."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the jacket is red."}, {"from": "gpt", "value": "[0.4, 0.41, 0.57, 0.65]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: skiis being worn by child."}, {"from": "gpt", "value": "[0.39, 0.64, 0.61, 0.79]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: trees are in the background."}, {"from": "gpt", "value": "[0.45, 0.2, 0.8, 0.3]"}, {"from": "human", "value": "Please provide a short description for this region: [0.39, 0.34, 0.6, 0.76]."}, {"from": "gpt", "value": "The child dressed to be out in the snow."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: this is a person."}, {"from": "gpt", "value": "[0.95, 0.31, 1.0, 0.4]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: child in red suit skiing."}, {"from": "gpt", "value": "[0.39, 0.33, 0.61, 0.78]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the glove is black."}, {"from": "gpt", "value": "[0.52, 0.54, 0.56, 0.59]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the smalll kid is asian."}, {"from": "gpt", "value": "[0.4, 0.33, 0.64, 0.77]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the child on the skis."}, {"from": "gpt", "value": "[0.39, 0.34, 0.6, 0.76]"}]}, {"id": "VG_100K/2337662", "image": "vg/VG_100K/2337662.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: A small piece of paper on the table."}, {"from": "gpt", "value": "[0.1, 0.79, 0.18, 0.84]"}, {"from": "human", "value": "Please provide a short description for this region: [0.5, 0.3, 0.53, 0.33]."}, {"from": "gpt", "value": "The brown ear of a cat."}, {"from": "human", "value": "Please provide a short description for this region: [0.43, 0.36, 0.58, 0.53]."}, {"from": "gpt", "value": "These are two cats."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Three cables are plugged into the TV>."}, {"from": "gpt", "value": "[0.62, 0.57, 0.68, 0.61]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A black shelf above the TV."}, {"from": "gpt", "value": "[0.48, 0.13, 0.97, 0.19]"}, {"from": "human", "value": "Please provide a short description for this region: [0.19, 0.32, 0.46, 0.85]."}, {"from": "gpt", "value": "This is a cat."}, {"from": "human", "value": "Please provide a short description for this region: [0.65, 0.33, 0.67, 0.35]."}, {"from": "gpt", "value": "The eye of a cat."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A small container on a table."}, {"from": "gpt", "value": "[0.01, 0.66, 0.1, 0.77]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: this is a table."}, {"from": "gpt", "value": "[0.14, 0.73, 0.23, 0.87]"}]}, {"id": "VG_100K/2337069", "image": "vg/VG_100K/2337069.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.42, 0.37, 0.56, 0.49]."}, {"from": "gpt", "value": "The glare from the flash of a camera."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: shadows on the wall."}, {"from": "gpt", "value": "[0.75, 0.41, 0.95, 0.52]"}, {"from": "human", "value": "Please provide a short description for this region: [0.34, 0.68, 0.8, 0.82]."}, {"from": "gpt", "value": "Black computer keyboard on table."}, {"from": "human", "value": "Please provide a short description for this region: [0.77, 0.55, 0.9, 0.64]."}, {"from": "gpt", "value": "Black calculator on table."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: black cords under table."}, {"from": "gpt", "value": "[0.44, 0.56, 0.64, 0.69]"}, {"from": "human", "value": "Please provide a short description for this region: [0.35, 0.22, 0.74, 0.55]."}, {"from": "gpt", "value": "Monitor on a desk."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Lit up apple sign on back of the laptop."}, {"from": "gpt", "value": "[0.54, 0.71, 0.6, 0.79]"}, {"from": "human", "value": "Please provide a short description for this region: [0.94, 0.39, 1.0, 0.57]."}, {"from": "gpt", "value": "Can on a desk."}, {"from": "human", "value": "Please provide a short description for this region: [0.94, 0.42, 0.99, 0.54]."}, {"from": "gpt", "value": "Black writing on the side of the can."}]}, {"id": "VG_100K/2337030", "image": "vg/VG_100K/2337030.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.11, 0.67, 0.99, 0.7]."}, {"from": "gpt", "value": "White dotted lines on the street."}, {"from": "human", "value": "Please provide a short description for this region: [0.11, 0.35, 0.86, 0.53]."}, {"from": "gpt", "value": "Blue plane sitting on the tar mac."}, {"from": "human", "value": "Please provide a short description for this region: [0.83, 0.64, 0.86, 0.66]."}, {"from": "gpt", "value": "Painted black colored square."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Tail on commercial plane."}, {"from": "gpt", "value": "[0.11, 0.35, 0.26, 0.46]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The tail fen has KLM Asia sign on it."}, {"from": "gpt", "value": "[0.11, 0.35, 0.26, 0.46]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: KLM asia in white letters."}, {"from": "gpt", "value": "[0.69, 0.46, 0.75, 0.49]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: painted black colored square."}, {"from": "gpt", "value": "[0.46, 0.62, 0.49, 0.66]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Commercial plane is blue and white."}, {"from": "gpt", "value": "[0.1, 0.35, 0.85, 0.55]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: painted black colored square."}, {"from": "gpt", "value": "[0.72, 0.63, 0.75, 0.66]"}]}, {"id": "VG_100K/2336973", "image": "vg/VG_100K/2336973.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.33, 0.44, 0.49, 0.6]."}, {"from": "gpt", "value": "Flat bottom of vase."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a flower engraved on vase."}, {"from": "gpt", "value": "[0.65, 0.42, 0.85, 0.62]"}, {"from": "human", "value": "Please provide a short description for this region: [0.76, 0.59, 0.84, 0.64]."}, {"from": "gpt", "value": "A picture of a leaf carved into the vase."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: reflection of light in the vase."}, {"from": "gpt", "value": "[0.73, 0.8, 0.78, 0.86]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a vase color brown."}, {"from": "gpt", "value": "[0.4, 0.13, 0.77, 0.38]"}, {"from": "human", "value": "Please provide a short description for this region: [0.36, 0.77, 0.46, 0.87]."}, {"from": "gpt", "value": "Bottom of a vase."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: holes in a small brass vase."}, {"from": "gpt", "value": "[0.67, 0.43, 0.84, 0.6]"}, {"from": "human", "value": "Please provide a short description for this region: [0.07, 0.71, 0.16, 0.77]."}, {"from": "gpt", "value": "Small gap in pot."}, {"from": "human", "value": "Please provide a short description for this region: [0.78, 0.55, 0.81, 0.59]."}, {"from": "gpt", "value": "Whole in silver pot."}, {"from": "human", "value": "Please provide a short description for this region: [0.09, 0.29, 0.3, 0.48]."}, {"from": "gpt", "value": "Vase is shining on surface."}]}, {"id": "VG_100K/2336731", "image": "vg/VG_100K/2336731.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.43, 0.64, 0.67, 0.7]."}, {"from": "gpt", "value": "Surfboard in the water."}, {"from": "human", "value": "Please provide a short description for this region: [0.25, 0.59, 0.3, 0.65]."}, {"from": "gpt", "value": "Wave in the ocean."}, {"from": "human", "value": "Please provide a short description for this region: [0.29, 0.37, 0.69, 0.74]."}, {"from": "gpt", "value": "Man is surfing in the ocean."}, {"from": "human", "value": "Please provide a short description for this region: [0.37, 0.64, 0.69, 0.72]."}, {"from": "gpt", "value": "White surfboard in the ocean."}, {"from": "human", "value": "Please provide a short description for this region: [0.4, 0.47, 0.45, 0.5]."}, {"from": "gpt", "value": "White writing on the man's wetsuit."}, {"from": "human", "value": "Please provide a short description for this region: [0.36, 0.39, 0.54, 0.66]."}, {"from": "gpt", "value": "Man is wearing a wet suit."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Man with black hair."}, {"from": "gpt", "value": "[0.42, 0.37, 0.5, 0.47]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: wave in the water."}, {"from": "gpt", "value": "[0.77, 0.65, 0.83, 0.71]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.77, 0.36, 0.82]."}, {"from": "gpt", "value": "Photo tag on the picture."}, {"from": "human", "value": "Please provide a short description for this region: [0.3, 0.37, 0.54, 0.68]."}, {"from": "gpt", "value": "Man is standing on the surfboard."}]}, {"id": "VG_100K/2336709", "image": "vg/VG_100K/2336709.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a tree near a sidewalk."}, {"from": "gpt", "value": "[0.0, 0.17, 0.26, 0.57]"}, {"from": "human", "value": "Please provide a short description for this region: [0.37, 0.36, 0.75, 0.73]."}, {"from": "gpt", "value": "Girls riding skateboards on the road."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a white line in the road."}, {"from": "gpt", "value": "[0.41, 0.62, 0.6, 0.75]"}, {"from": "human", "value": "Please provide a short description for this region: [0.41, 0.39, 0.65, 0.64]."}, {"from": "gpt", "value": "Two girls skateboarding in a park."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: tree leaves are bare."}, {"from": "gpt", "value": "[0.82, 0.32, 0.99, 0.52]"}, {"from": "human", "value": "Please provide a short description for this region: [0.8, 0.48, 0.84, 0.5]."}, {"from": "gpt", "value": "Red and blue sign."}, {"from": "human", "value": "Please provide a short description for this region: [0.39, 0.34, 0.7, 0.78]."}, {"from": "gpt", "value": "Girls riding skateboards on the street."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: girl has yellow jacket."}, {"from": "gpt", "value": "[0.46, 0.42, 0.5, 0.5]"}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.42, 0.5, 0.49]."}, {"from": "gpt", "value": "Yellow jacket on girl."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: blue jeans on a girl."}, {"from": "gpt", "value": "[0.47, 0.5, 0.52, 0.6]"}]}, {"id": "VG_100K/2336486", "image": "vg/VG_100K/2336486.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.19, 0.26, 0.25, 0.33]."}, {"from": "gpt", "value": "An ear on the boy."}, {"from": "human", "value": "Please provide a short description for this region: [0.3, 0.33, 0.4, 0.36]."}, {"from": "gpt", "value": "Closed lip smile on the face."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Pink chair beside the child."}, {"from": "gpt", "value": "[0.61, 0.43, 0.94, 0.7]"}, {"from": "human", "value": "Please provide a short description for this region: [0.59, 0.61, 0.99, 0.82]."}, {"from": "gpt", "value": "A plate on the table."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the chin of a boy."}, {"from": "gpt", "value": "[0.24, 0.36, 0.44, 0.46]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a nose on the boy."}, {"from": "gpt", "value": "[0.3, 0.27, 0.4, 0.35]"}, {"from": "human", "value": "Please provide a short description for this region: [0.41, 0.55, 0.6, 0.75]."}, {"from": "gpt", "value": "Desert bar in the hand."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a mouth on the nose."}, {"from": "gpt", "value": "[0.32, 0.31, 0.4, 0.38]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: arm in the air."}, {"from": "gpt", "value": "[0.46, 0.26, 0.68, 0.53]"}, {"from": "human", "value": "Please provide a short description for this region: [0.64, 0.45, 0.92, 0.73]."}, {"from": "gpt", "value": "A pink wooden chair."}]}, {"id": "VG_100K/2336343", "image": "vg/VG_100K/2336343.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.09, 0.7, 0.3, 0.75]."}, {"from": "gpt", "value": "A metalic railway line."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.48, 0.36, 0.69]."}, {"from": "gpt", "value": "Dark brown metal train tracks."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: segment of a train."}, {"from": "gpt", "value": "[0.83, 0.5, 0.89, 0.53]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: this is the train track."}, {"from": "gpt", "value": "[0.24, 0.71, 0.32, 0.74]"}, {"from": "human", "value": "Please provide a short description for this region: [0.7, 0.53, 0.76, 0.55]."}, {"from": "gpt", "value": "Windows on the train."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the train tracks."}, {"from": "gpt", "value": "[0.19, 0.71, 0.21, 0.73]"}, {"from": "human", "value": "Please provide a short description for this region: [0.9, 0.32, 0.95, 0.43]."}, {"from": "gpt", "value": "Big parachute in the sky being pulled."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: green grass on the stuck side."}, {"from": "gpt", "value": "[0.92, 0.52, 1.0, 0.71]"}, {"from": "human", "value": "Please provide a short description for this region: [0.06, 0.26, 0.34, 0.32]."}, {"from": "gpt", "value": "The clouds are white in the sky."}]}, {"id": "VG_100K/2336051", "image": "vg/VG_100K/2336051.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.54, 0.2, 0.64, 0.33]."}, {"from": "gpt", "value": "A smiling man's face."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Black and white insignia on the surfboard."}, {"from": "gpt", "value": "[0.43, 0.41, 0.47, 0.46]"}, {"from": "human", "value": "Please provide a short description for this region: [0.7, 0.58, 0.83, 0.71]."}, {"from": "gpt", "value": "Strap on a surf board."}, {"from": "human", "value": "Please provide a short description for this region: [0.42, 0.38, 0.48, 0.48]."}, {"from": "gpt", "value": "Sticker on a surf board."}, {"from": "human", "value": "Please provide a short description for this region: [0.41, 0.6, 0.51, 0.67]."}, {"from": "gpt", "value": "Logo on a surf board."}, {"from": "human", "value": "Please provide a short description for this region: [0.53, 0.28, 0.63, 0.33]."}, {"from": "gpt", "value": "Man wearing a beard."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: water washing up ashore."}, {"from": "gpt", "value": "[0.1, 0.25, 0.54, 0.41]"}, {"from": "human", "value": "Please provide a short description for this region: [0.08, 0.13, 0.58, 0.21]."}, {"from": "gpt", "value": "Mountains near the ocean."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Surfboard is blue and white."}, {"from": "gpt", "value": "[0.29, 0.34, 0.55, 0.62]"}]}, {"id": "VG_100K/2335774", "image": "vg/VG_100K/2335774.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: snow on top of signal, support and pole."}, {"from": "gpt", "value": "[0.75, 0.22, 0.93, 0.34]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: blue street sign with white letters."}, {"from": "gpt", "value": "[0.82, 0.42, 0.85, 0.54]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: this is a street sign."}, {"from": "gpt", "value": "[0.79, 0.39, 0.9, 0.59]"}, {"from": "human", "value": "Please provide a short description for this region: [0.72, 0.7, 0.75, 0.79]."}, {"from": "gpt", "value": "The yellow traffic light on a pole."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: three yellow stoplights hanging from black pole."}, {"from": "gpt", "value": "[0.72, 0.17, 0.95, 0.8]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: street sign between two traffic signals."}, {"from": "gpt", "value": "[0.73, 0.27, 0.88, 0.64]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a white and blue street sign."}, {"from": "gpt", "value": "[0.78, 0.38, 0.9, 0.57]"}, {"from": "human", "value": "Please provide a short description for this region: [0.78, 0.49, 0.84, 0.63]."}, {"from": "gpt", "value": "Bars and supports behind signals."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a blue street sign."}, {"from": "gpt", "value": "[0.82, 0.41, 0.85, 0.54]"}, {"from": "human", "value": "Please provide a short description for this region: [0.75, 0.26, 0.86, 0.41]."}, {"from": "gpt", "value": "White snow covering traffic light."}]}, {"id": "VG_100K/2335647", "image": "vg/VG_100K/2335647.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: the leaf is green."}, {"from": "gpt", "value": "[0.26, 0.66, 0.34, 0.8]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: shiny green leaf on a bush."}, {"from": "gpt", "value": "[0.77, 0.57, 0.83, 0.67]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the beak is pointy."}, {"from": "gpt", "value": "[0.54, 0.36, 0.59, 0.39]"}, {"from": "human", "value": "Please provide a short description for this region: [0.64, 0.23, 0.81, 0.5]."}, {"from": "gpt", "value": "Blurry green background."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: black leg of bird clutching bush."}, {"from": "gpt", "value": "[0.37, 0.58, 0.48, 0.7]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: green plant with thick stem."}, {"from": "gpt", "value": "[0.73, 0.31, 0.96, 0.8]"}, {"from": "human", "value": "Please provide a short description for this region: [0.17, 0.33, 0.59, 0.69]."}, {"from": "gpt", "value": "Small bird with black shiny feathers."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the leaf is green."}, {"from": "gpt", "value": "[0.81, 0.52, 0.89, 0.64]"}, {"from": "human", "value": "Please provide a short description for this region: [0.41, 0.73, 0.46, 0.81]."}, {"from": "gpt", "value": "Green leaf on plant."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: green leaf on plant."}, {"from": "gpt", "value": "[0.82, 0.52, 0.88, 0.64]"}]}, {"id": "VG_100K/2335217", "image": "vg/VG_100K/2335217.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: crumb on white plate."}, {"from": "gpt", "value": "[0.19, 0.67, 0.27, 0.73]"}, {"from": "human", "value": "Please provide a short description for this region: [0.21, 0.7, 0.23, 0.72]."}, {"from": "gpt", "value": "Brown bread crumb on plate."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Paper with prints on it."}, {"from": "gpt", "value": "[0.58, 0.34, 0.7, 0.59]"}, {"from": "human", "value": "Please provide a short description for this region: [0.32, 0.57, 0.35, 0.62]."}, {"from": "gpt", "value": "Crumb on white plate."}, {"from": "human", "value": "Please provide a short description for this region: [0.13, 0.37, 0.38, 0.53]."}, {"from": "gpt", "value": "Tines of plastic fork."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a wrinkled piece of paper."}, {"from": "gpt", "value": "[0.41, 0.61, 0.68, 0.8]"}, {"from": "human", "value": "Please provide a short description for this region: [0.23, 0.55, 0.26, 0.57]."}, {"from": "gpt", "value": "Brown bread crumb on plate."}, {"from": "human", "value": "Please provide a short description for this region: [0.48, 0.46, 0.55, 0.52]."}, {"from": "gpt", "value": "Reflection on plastic fork."}, {"from": "human", "value": "Please provide a short description for this region: [0.13, 0.38, 0.36, 0.56]."}, {"from": "gpt", "value": "Prongs of a fork."}, {"from": "human", "value": "Please provide a short description for this region: [0.62, 0.48, 0.94, 0.69]."}, {"from": "gpt", "value": "Used teabag on plate."}]}, {"id": "VG_100K/2334690", "image": "vg/VG_100K/2334690.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: skateboard in the air."}, {"from": "gpt", "value": "[0.35, 0.34, 0.47, 0.4]"}, {"from": "human", "value": "Please provide a short description for this region: [0.3, 0.12, 0.6, 0.44]."}, {"from": "gpt", "value": "A man riding a skateboard."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white clouds in blue sky."}, {"from": "gpt", "value": "[0.56, 0.5, 0.61, 0.6]"}, {"from": "human", "value": "Please provide a short description for this region: [0.36, 0.37, 0.4, 0.4]."}, {"from": "gpt", "value": "Back wheels of a skateboard."}, {"from": "human", "value": "Please provide a short description for this region: [0.31, 0.13, 0.56, 0.41]."}, {"from": "gpt", "value": "Skater in the air."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: short sleeved strip shirt."}, {"from": "gpt", "value": "[0.29, 0.15, 0.41, 0.27]"}, {"from": "human", "value": "Please provide a short description for this region: [0.18, 0.18, 0.25, 0.3]."}, {"from": "gpt", "value": "White clouds in blue sky."}, {"from": "human", "value": "Please provide a short description for this region: [0.51, 0.4, 0.65, 0.59]."}, {"from": "gpt", "value": "White clouds in blue sky."}, {"from": "human", "value": "Please provide a short description for this region: [0.26, 0.08, 0.63, 0.49]."}, {"from": "gpt", "value": "A man jumping a skateboard."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white clouds in blue sky."}, {"from": "gpt", "value": "[0.5, 0.56, 0.59, 0.63]"}]}, {"id": "VG_100K/2334557", "image": "vg/VG_100K/2334557.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: bear's nails are long."}, {"from": "gpt", "value": "[0.21, 0.61, 0.71, 0.79]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bamboo sticks near platform."}, {"from": "gpt", "value": "[0.87, 0.53, 0.97, 0.58]"}, {"from": "human", "value": "Please provide a short description for this region: [0.25, 0.68, 0.71, 0.8]."}, {"from": "gpt", "value": "Nails on the wood."}, {"from": "human", "value": "Please provide a short description for this region: [0.19, 0.65, 0.61, 0.7]."}, {"from": "gpt", "value": "Long nails on bear's feet."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: bear's nails are long."}, {"from": "gpt", "value": "[0.19, 0.62, 0.66, 0.76]"}, {"from": "human", "value": "Please provide a short description for this region: [0.02, 0.12, 0.7, 0.26]."}, {"from": "gpt", "value": "Two wooden trees."}, {"from": "human", "value": "Please provide a short description for this region: [0.84, 0.5, 0.91, 0.59]."}, {"from": "gpt", "value": "Green leaves on bush."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: nails on the wood."}, {"from": "gpt", "value": "[0.24, 0.7, 0.76, 0.8]"}]}, {"id": "VG_100K/2334288", "image": "vg/VG_100K/2334288.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.21, 0.64, 0.37, 0.81]."}, {"from": "gpt", "value": "The tire is black."}, {"from": "human", "value": "Please provide a short description for this region: [0.29, 0.46, 0.53, 0.65]."}, {"from": "gpt", "value": "A red and white campaign 2008 image."}, {"from": "human", "value": "Please provide a short description for this region: [0.86, 0.58, 0.94, 0.66]."}, {"from": "gpt", "value": "Four white stars are on a blue surface."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.25, 0.05, 0.34]."}, {"from": "gpt", "value": "Part of a tree."}, {"from": "human", "value": "Please provide a short description for this region: [0.88, 0.58, 0.92, 0.63]."}, {"from": "gpt", "value": "Star on a bus."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A large building window."}, {"from": "gpt", "value": "[0.32, 0.21, 0.47, 0.4]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Picture of people on side of bus."}, {"from": "gpt", "value": "[0.7, 0.48, 0.8, 0.66]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Three tires are on the ground."}, {"from": "gpt", "value": "[0.22, 0.63, 0.87, 0.75]"}, {"from": "human", "value": "Please provide a short description for this region: [0.87, 0.61, 0.91, 0.66]."}, {"from": "gpt", "value": "Star on a bus."}, {"from": "human", "value": "Please provide a short description for this region: [0.11, 0.43, 0.22, 0.66]."}, {"from": "gpt", "value": "Mirrors are making a shadow."}]}, {"id": "VG_100K/2333322", "image": "vg/VG_100K/2333322.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.26, 0.04, 0.3, 0.07]."}, {"from": "gpt", "value": "People standing in the background."}, {"from": "human", "value": "Please provide a short description for this region: [0.17, 0.01, 0.19, 0.03]."}, {"from": "gpt", "value": "Sky with clouds."}, {"from": "human", "value": "Please provide a short description for this region: [0.37, 0.57, 0.45, 0.77]."}, {"from": "gpt", "value": "White ski poles."}, {"from": "human", "value": "Please provide a short description for this region: [0.26, 0.08, 0.47, 0.33]."}, {"from": "gpt", "value": "Ski tracks in the snow."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A person holding the skipole."}, {"from": "gpt", "value": "[0.33, 0.47, 0.46, 0.77]"}, {"from": "human", "value": "Please provide a short description for this region: [0.13, 0.0, 0.32, 0.04]."}, {"from": "gpt", "value": "Trees with branches."}, {"from": "human", "value": "Please provide a short description for this region: [0.23, 0.72, 0.42, 0.89]."}, {"from": "gpt", "value": "Section of the ice."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: weeds in the snow."}, {"from": "gpt", "value": "[0.32, 0.02, 0.87, 0.13]"}, {"from": "human", "value": "Please provide a short description for this region: [0.15, 0.63, 0.28, 0.71]."}, {"from": "gpt", "value": "White color snow."}, {"from": "human", "value": "Please provide a short description for this region: [0.53, 0.83, 0.58, 0.87]."}, {"from": "gpt", "value": "This part of the ski is red."}]}, {"id": "VG_100K/2332252", "image": "vg/VG_100K/2332252.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: yellow tennis ball in hand."}, {"from": "gpt", "value": "[0.66, 0.84, 0.76, 0.98]"}, {"from": "human", "value": "Please provide a short description for this region: [0.29, 0.83, 0.48, 0.94]."}, {"from": "gpt", "value": "Woman wearing black shorts."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: this is a person."}, {"from": "gpt", "value": "[0.11, 0.09, 0.26, 0.47]"}, {"from": "human", "value": "Please provide a short description for this region: [0.7, 0.93, 0.75, 0.98]."}, {"from": "gpt", "value": "Yellow tennis ball in the player's hand."}, {"from": "human", "value": "Please provide a short description for this region: [0.5, 0.33, 0.77, 0.9]."}, {"from": "gpt", "value": "A blue and white shirt."}, {"from": "human", "value": "Please provide a short description for this region: [0.25, 0.7, 0.58, 1.0]."}, {"from": "gpt", "value": "Red and white tennis racket in right hand."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: black visor on the woman's head."}, {"from": "gpt", "value": "[0.32, 0.47, 0.42, 0.53]"}, {"from": "human", "value": "Please provide a short description for this region: [0.35, 0.89, 0.54, 1.0]."}, {"from": "gpt", "value": "White tape on the tennis court net."}, {"from": "human", "value": "Please provide a short description for this region: [0.54, 0.0, 0.86, 0.22]."}, {"from": "gpt", "value": "A woman in the background standing."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white shirt with blue stripes on the sleeve."}, {"from": "gpt", "value": "[0.51, 0.33, 0.78, 0.9]"}]}, {"id": "VG_100K/2332192", "image": "vg/VG_100K/2332192.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.43, 0.37, 0.47, 0.39]."}, {"from": "gpt", "value": "The hand of a man."}, {"from": "human", "value": "Please provide a short description for this region: [0.54, 0.1, 0.79, 0.17]."}, {"from": "gpt", "value": "Sky is covered in clear blue color."}, {"from": "human", "value": "Please provide a short description for this region: [0.46, 0.34, 0.52, 0.42]."}, {"from": "gpt", "value": "A person skiing down the slope."}, {"from": "human", "value": "Please provide a short description for this region: [0.41, 0.33, 0.58, 0.49]."}, {"from": "gpt", "value": "A man holding ski sticks."}, {"from": "human", "value": "Please provide a short description for this region: [0.81, 0.19, 0.87, 0.32]."}, {"from": "gpt", "value": "Snow on the tree."}, {"from": "human", "value": "Please provide a short description for this region: [0.71, 0.19, 0.75, 0.22]."}, {"from": "gpt", "value": "Empty chair on the ski lift."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a gondola lift with people."}, {"from": "gpt", "value": "[0.81, 0.13, 0.86, 0.19]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: snow on the tree."}, {"from": "gpt", "value": "[0.82, 0.2, 0.84, 0.27]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a person skiing."}, {"from": "gpt", "value": "[0.45, 0.35, 0.53, 0.43]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a gondola lift for the snow."}, {"from": "gpt", "value": "[0.71, 0.19, 0.75, 0.21]"}]}, {"id": "VG_100K/2332091", "image": "vg/VG_100K/2332091.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: fork in the hand."}, {"from": "gpt", "value": "[0.25, 0.12, 0.47, 0.26]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: fork with food on it."}, {"from": "gpt", "value": "[0.29, 0.12, 0.58, 0.22]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.72, 0.09, 0.87]."}, {"from": "gpt", "value": "Glass kept on table."}, {"from": "human", "value": "Please provide a short description for this region: [0.18, 0.27, 0.3, 0.3]."}, {"from": "gpt", "value": "Brown wooden table top."}, {"from": "human", "value": "Please provide a short description for this region: [0.17, 0.7, 0.29, 0.77]."}, {"from": "gpt", "value": "Black spot on the crust."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man holding fork in hand."}, {"from": "gpt", "value": "[0.25, 0.14, 0.55, 0.21]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: triangle slice of pizza."}, {"from": "gpt", "value": "[0.42, 0.24, 0.47, 0.42]"}, {"from": "human", "value": "Please provide a short description for this region: [0.07, 0.31, 0.3, 0.53]."}, {"from": "gpt", "value": "A burnt slice of pizza."}, {"from": "human", "value": "Please provide a short description for this region: [0.35, 0.74, 0.61, 0.85]."}, {"from": "gpt", "value": "Red sauce sticking out of the cheese."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white color plate."}, {"from": "gpt", "value": "[0.03, 0.5, 0.13, 0.6]"}]}, {"id": "VG_100K/2331682", "image": "vg/VG_100K/2331682.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: window on the building."}, {"from": "gpt", "value": "[0.79, 0.17, 1.0, 0.49]"}, {"from": "human", "value": "Please provide a short description for this region: [0.59, 0.5, 0.65, 0.54]."}, {"from": "gpt", "value": "Red lettering on sign."}, {"from": "human", "value": "Please provide a short description for this region: [0.8, 0.17, 0.86, 0.56]."}, {"from": "gpt", "value": "Edge of window painted beige."}, {"from": "human", "value": "Please provide a short description for this region: [0.05, 0.25, 0.21, 0.53]."}, {"from": "gpt", "value": "The clouds are white in color."}, {"from": "human", "value": "Please provide a short description for this region: [0.03, 0.25, 0.19, 0.4]."}, {"from": "gpt", "value": "This is the sky."}, {"from": "human", "value": "Please provide a short description for this region: [0.97, 0.3, 1.0, 0.48]."}, {"from": "gpt", "value": "A small glass window pane."}, {"from": "human", "value": "Please provide a short description for this region: [0.35, 0.49, 0.67, 0.57]."}, {"from": "gpt", "value": "This is a street sign."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: building made of brick."}, {"from": "gpt", "value": "[0.31, 0.17, 0.71, 0.4]"}, {"from": "human", "value": "Please provide a short description for this region: [0.84, 0.27, 0.97, 0.4]."}, {"from": "gpt", "value": "A small glass window pane."}]}, {"id": "VG_100K/2331596", "image": "vg/VG_100K/2331596.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.42, 0.4, 0.51, 0.49]."}, {"from": "gpt", "value": "This is a t shirt."}, {"from": "human", "value": "Please provide a short description for this region: [0.35, 0.33, 0.54, 0.54]."}, {"from": "gpt", "value": "A light grey shirt on a boy."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: this is a knee pad."}, {"from": "gpt", "value": "[0.39, 0.57, 0.43, 0.65]"}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.3, 0.48, 0.32]."}, {"from": "gpt", "value": "The helmet is blue in color."}, {"from": "human", "value": "Please provide a short description for this region: [0.37, 0.58, 0.43, 0.66]."}, {"from": "gpt", "value": "A black knee pad."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the shadow of a skateboard."}, {"from": "gpt", "value": "[0.17, 0.81, 0.45, 0.84]"}, {"from": "human", "value": "Please provide a short description for this region: [0.38, 0.75, 0.44, 0.78]."}, {"from": "gpt", "value": "A black sandal on a boy's foot."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Wheels on the skateboard."}, {"from": "gpt", "value": "[0.26, 0.78, 0.45, 0.84]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: shadow on the ground."}, {"from": "gpt", "value": "[0.17, 0.8, 0.43, 0.84]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The boy is wearing knee pads."}, {"from": "gpt", "value": "[0.31, 0.58, 0.42, 0.64]"}]}, {"id": "VG_100K/2331535", "image": "vg/VG_100K/2331535.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.3, 0.19, 0.39, 0.28]."}, {"from": "gpt", "value": "The wall is white in color."}, {"from": "human", "value": "Please provide a short description for this region: [0.34, 0.25, 0.68, 0.44]."}, {"from": "gpt", "value": "The device is on."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: this is the hair."}, {"from": "gpt", "value": "[0.05, 0.43, 0.29, 0.78]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The thumb on the person's left hand."}, {"from": "gpt", "value": "[0.33, 0.57, 0.49, 0.75]"}, {"from": "human", "value": "Please provide a short description for this region: [0.7, 0.35, 0.79, 0.53]."}, {"from": "gpt", "value": "The index finger on the right hand."}, {"from": "human", "value": "Please provide a short description for this region: [0.05, 0.37, 0.29, 0.75]."}, {"from": "gpt", "value": "Long brown hair."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: person has brown hair."}, {"from": "gpt", "value": "[0.01, 0.23, 0.25, 0.85]"}, {"from": "human", "value": "Please provide a short description for this region: [0.76, 0.61, 0.87, 0.74]."}, {"from": "gpt", "value": "The hand is light skinned."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: these are the keyboards."}, {"from": "gpt", "value": "[0.41, 0.46, 0.59, 0.57]"}, {"from": "human", "value": "Please provide a short description for this region: [0.39, 0.46, 0.64, 0.59]."}, {"from": "gpt", "value": "The keys are black."}]}, {"id": "VG_100K/2331140", "image": "vg/VG_100K/2331140.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: shadow from bike and rider."}, {"from": "gpt", "value": "[0.35, 0.67, 0.99, 0.83]"}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.4, 0.57, 0.5]."}, {"from": "gpt", "value": "Number 40 on bike."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man wearing a black helmet."}, {"from": "gpt", "value": "[0.74, 0.18, 0.84, 0.29]"}, {"from": "human", "value": "Please provide a short description for this region: [0.63, 0.2, 0.91, 0.59]."}, {"from": "gpt", "value": "A white and black outfit."}, {"from": "human", "value": "Please provide a short description for this region: [0.29, 0.58, 0.51, 0.79]."}, {"from": "gpt", "value": "Front tire of bike."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: number 40 on bike."}, {"from": "gpt", "value": "[0.49, 0.38, 0.6, 0.53]"}, {"from": "human", "value": "Please provide a short description for this region: [0.48, 0.18, 0.61, 0.3]."}, {"from": "gpt", "value": "White helmet with blue accents."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: jacket on the rider."}, {"from": "gpt", "value": "[0.64, 0.24, 0.83, 0.38]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: black 40 on the yellow motorcycle."}, {"from": "gpt", "value": "[0.47, 0.42, 0.55, 0.48]"}, {"from": "human", "value": "Please provide a short description for this region: [0.58, 0.51, 0.65, 0.68]."}, {"from": "gpt", "value": "Front tire of the bike."}]}, {"id": "VG_100K/2330334", "image": "vg/VG_100K/2330334.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: A red sign with the numbers 140 on it."}, {"from": "gpt", "value": "[0.12, 0.38, 0.39, 0.42]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A green garden hose on the wall."}, {"from": "gpt", "value": "[0.82, 0.43, 0.93, 0.54]"}, {"from": "human", "value": "Please provide a short description for this region: [0.15, 0.36, 0.35, 0.45]."}, {"from": "gpt", "value": "Words and numbers be read."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the clock says it is 2 o'clock."}, {"from": "gpt", "value": "[0.7, 0.31, 0.75, 0.36]"}, {"from": "human", "value": "Please provide a short description for this region: [0.84, 0.44, 0.92, 0.52]."}, {"from": "gpt", "value": "A blue water hose holder."}, {"from": "human", "value": "Please provide a short description for this region: [0.35, 0.39, 0.39, 0.43]."}, {"from": "gpt", "value": "A fire hazard warning on the sign."}, {"from": "human", "value": "Please provide a short description for this region: [0.78, 0.71, 0.86, 0.81]."}, {"from": "gpt", "value": "Trash in a black trash-bag."}, {"from": "human", "value": "Please provide a short description for this region: [0.19, 0.48, 0.25, 0.57]."}, {"from": "gpt", "value": "A motorcycle in the distance."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a green garden hose."}, {"from": "gpt", "value": "[0.82, 0.42, 0.93, 0.53]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a clock on the wall."}, {"from": "gpt", "value": "[0.68, 0.32, 0.75, 0.38]"}]}, {"id": "VG_100K/2329356", "image": "vg/VG_100K/2329356.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.43, 0.18, 0.61, 0.39]."}, {"from": "gpt", "value": "The head of a man."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: black metal pole on the ground."}, {"from": "gpt", "value": "[0.88, 0.38, 0.94, 0.48]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the mouth of a man."}, {"from": "gpt", "value": "[0.55, 0.33, 0.59, 0.35]"}, {"from": "human", "value": "Please provide a short description for this region: [0.72, 0.18, 0.9, 0.51]."}, {"from": "gpt", "value": "A flower pot with a plant on it."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a pure white baseball cap."}, {"from": "gpt", "value": "[0.45, 0.2, 0.61, 0.3]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a man wearing a white hat."}, {"from": "gpt", "value": "[0.39, 0.2, 0.62, 0.44]"}, {"from": "human", "value": "Please provide a short description for this region: [0.34, 0.65, 0.42, 0.74]."}, {"from": "gpt", "value": "Gray sweatband on right wrist."}, {"from": "human", "value": "Please provide a short description for this region: [0.33, 0.64, 0.42, 0.73]."}, {"from": "gpt", "value": "Grey wrist band on right arm."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the adams apple of a man."}, {"from": "gpt", "value": "[0.47, 0.35, 0.53, 0.43]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a tan flower pot."}, {"from": "gpt", "value": "[0.73, 0.27, 0.89, 0.5]"}]}, {"id": "VG_100K/2328176", "image": "vg/VG_100K/2328176.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.21, 0.02, 0.44, 0.5]."}, {"from": "gpt", "value": "The sky is the color gray."}, {"from": "human", "value": "Please provide a short description for this region: [0.53, 0.34, 0.63, 0.44]."}, {"from": "gpt", "value": "A clock on a tower."}, {"from": "human", "value": "Please provide a short description for this region: [0.53, 0.34, 0.62, 0.42]."}, {"from": "gpt", "value": "A clock on builidng."}, {"from": "human", "value": "Please provide a short description for this region: [0.18, 0.91, 0.22, 0.97]."}, {"from": "gpt", "value": "Window of a building."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the small hand on a clock."}, {"from": "gpt", "value": "[0.53, 0.36, 0.59, 0.41]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a bell in a tower."}, {"from": "gpt", "value": "[0.57, 0.22, 0.6, 0.25]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the hands on a clock."}, {"from": "gpt", "value": "[0.54, 0.34, 0.65, 0.43]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: window of a building."}, {"from": "gpt", "value": "[0.26, 0.72, 0.31, 0.81]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a big clock on a building."}, {"from": "gpt", "value": "[0.51, 0.28, 0.7, 0.45]"}, {"from": "human", "value": "Please provide a short description for this region: [0.52, 0.34, 0.64, 0.43]."}, {"from": "gpt", "value": "Arms on the clock."}]}, {"id": "VG_100K/2327967", "image": "vg/VG_100K/2327967.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a window on a building."}, {"from": "gpt", "value": "[0.38, 0.19, 0.42, 0.25]"}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.56, 0.61, 0.75]."}, {"from": "gpt", "value": "The boy wears a jean jacket."}, {"from": "human", "value": "Please provide a short description for this region: [0.15, 0.64, 0.5, 0.83]."}, {"from": "gpt", "value": "Two bikes right next to each other."}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.56, 0.6, 0.74]."}, {"from": "gpt", "value": "A blue jean jacket."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a letter on a sign."}, {"from": "gpt", "value": "[0.5, 0.35, 0.54, 0.4]"}, {"from": "human", "value": "Please provide a short description for this region: [0.3, 0.34, 0.71, 0.41]."}, {"from": "gpt", "value": "The name of a store."}, {"from": "human", "value": "Please provide a short description for this region: [0.01, 0.71, 0.17, 0.83]."}, {"from": "gpt", "value": "Part of a sidewalk."}, {"from": "human", "value": "Please provide a short description for this region: [0.48, 0.56, 0.55, 0.74]."}, {"from": "gpt", "value": "Black tshirt on the boy."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: gray, black, and yellow writing."}, {"from": "gpt", "value": "[0.28, 0.33, 0.75, 0.42]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: glasses on the face."}, {"from": "gpt", "value": "[0.49, 0.51, 0.55, 0.54]"}]}, {"id": "VG_100K/2327639", "image": "vg/VG_100K/2327639.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.42, 0.68, 0.5, 0.78]."}, {"from": "gpt", "value": "This is a window."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a row of windows."}, {"from": "gpt", "value": "[0.14, 0.71, 0.27, 0.82]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: 2 lit up lights."}, {"from": "gpt", "value": "[0.52, 0.35, 0.65, 0.53]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a bright yellow light."}, {"from": "gpt", "value": "[0.6, 0.93, 0.64, 0.98]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: traffic lights are yellow."}, {"from": "gpt", "value": "[0.5, 0.34, 0.63, 0.58]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: this is a window."}, {"from": "gpt", "value": "[0.2, 0.24, 0.29, 0.3]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: grey side of building."}, {"from": "gpt", "value": "[0.41, 0.14, 0.68, 0.46]"}, {"from": "human", "value": "Please provide a short description for this region: [0.14, 0.35, 0.24, 0.56]."}, {"from": "gpt", "value": "White sign on building."}, {"from": "human", "value": "Please provide a short description for this region: [0.29, 0.35, 0.65, 0.61]."}, {"from": "gpt", "value": "The traffic light is big."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: window of a building."}, {"from": "gpt", "value": "[0.3, 0.39, 0.36, 0.43]"}]}, {"id": "VG_100K/2327195", "image": "vg/VG_100K/2327195.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.08, 0.12, 0.23, 0.41]."}, {"from": "gpt", "value": "Metal pipes along wall."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a hair on a chest."}, {"from": "gpt", "value": "[0.7, 0.6, 0.72, 0.62]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: White snow with trees in it."}, {"from": "gpt", "value": "[0.49, 0.78, 0.92, 0.87]"}, {"from": "human", "value": "Please provide a short description for this region: [0.27, 0.46, 0.58, 0.73]."}, {"from": "gpt", "value": "Three fingers grasp pizza."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: White snow with trees in it."}, {"from": "gpt", "value": "[0.57, 0.13, 0.61, 0.25]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: man is wearing eye glasses."}, {"from": "gpt", "value": "[0.5, 0.29, 0.59, 0.35]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: this is a slice of pizza."}, {"from": "gpt", "value": "[0.25, 0.34, 0.58, 0.75]"}, {"from": "human", "value": "Please provide a short description for this region: [0.31, 0.46, 0.59, 0.71]."}, {"from": "gpt", "value": "A slice of pizza."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: this is his shirt collar."}, {"from": "gpt", "value": "[0.8, 0.44, 0.93, 0.65]"}]}, {"id": "VG_100K/2326874", "image": "vg/VG_100K/2326874.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: this is a tree trunk."}, {"from": "gpt", "value": "[0.17, 0.18, 0.23, 0.45]"}, {"from": "human", "value": "Please provide a short description for this region: [0.53, 0.27, 0.66, 0.45]."}, {"from": "gpt", "value": "Long neck of the giraffe."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: floor is covered of sand and dirt."}, {"from": "gpt", "value": "[0.21, 0.67, 0.42, 0.82]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: two animals are graxzing nect to the giraffe."}, {"from": "gpt", "value": "[0.41, 0.68, 0.56, 0.81]"}, {"from": "human", "value": "Please provide a short description for this region: [0.87, 0.47, 0.99, 0.56]."}, {"from": "gpt", "value": "Piece of log lying on the ground."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The giraffe is standing on the side of the road."}, {"from": "gpt", "value": "[0.48, 0.23, 0.75, 0.69]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: brushy tail of the giraffe."}, {"from": "gpt", "value": "[0.69, 0.49, 0.77, 0.67]"}, {"from": "human", "value": "Please provide a short description for this region: [0.34, 0.22, 0.55, 0.66]."}, {"from": "gpt", "value": "The road is made of dirt."}, {"from": "human", "value": "Please provide a short description for this region: [0.34, 0.56, 0.47, 0.63]."}, {"from": "gpt", "value": "Small patch of grass."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: long black hair on the tail."}, {"from": "gpt", "value": "[0.69, 0.5, 0.77, 0.65]"}]}, {"id": "VG_100K/2326479", "image": "vg/VG_100K/2326479.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.0, 0.52, 0.98, 0.59]."}, {"from": "gpt", "value": "Green field of airport."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: air traffic control tower."}, {"from": "gpt", "value": "[0.13, 0.44, 0.17, 0.52]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: vehicle used at airport."}, {"from": "gpt", "value": "[0.59, 0.63, 0.62, 0.67]"}, {"from": "human", "value": "Please provide a short description for this region: [0.02, 0.49, 0.67, 0.64]."}, {"from": "gpt", "value": "Four lights on poles."}, {"from": "human", "value": "Please provide a short description for this region: [0.56, 0.51, 0.91, 0.62]."}, {"from": "gpt", "value": "Gray airplane parked at the airport."}, {"from": "human", "value": "Please provide a short description for this region: [0.7, 0.7, 0.74, 0.74]."}, {"from": "gpt", "value": "Windows on the cockpit of white airplane."}, {"from": "human", "value": "Please provide a short description for this region: [0.01, 0.48, 0.99, 0.53]."}, {"from": "gpt", "value": "Hazy horizon of airport."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: airplane lifting off into the sky."}, {"from": "gpt", "value": "[0.3, 0.38, 0.47, 0.48]"}, {"from": "human", "value": "Please provide a short description for this region: [0.3, 0.39, 0.46, 0.45]."}, {"from": "gpt", "value": "Commercial plane taking off."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: vehicle used at airport."}, {"from": "gpt", "value": "[0.86, 0.75, 0.91, 0.78]"}]}, {"id": "VG_100K/2326247", "image": "vg/VG_100K/2326247.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: outdoor patio umbrella."}, {"from": "gpt", "value": "[0.88, 0.47, 0.98, 0.58]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: backpack on the woman's back."}, {"from": "gpt", "value": "[0.38, 0.55, 0.43, 0.65]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a man with empty body."}, {"from": "gpt", "value": "[0.52, 0.42, 0.85, 0.71]"}, {"from": "human", "value": "Please provide a short description for this region: [0.55, 0.43, 0.58, 0.49]."}, {"from": "gpt", "value": "Small chineese lettering on a sign."}, {"from": "human", "value": "Please provide a short description for this region: [0.48, 0.17, 0.77, 0.35]."}, {"from": "gpt", "value": "Overhead power lines."}, {"from": "human", "value": "Please provide a short description for this region: [0.32, 0.26, 0.35, 0.35]."}, {"from": "gpt", "value": "Small chineese lettering on a sign."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: signage above store front."}, {"from": "gpt", "value": "[0.2, 0.2, 0.46, 0.4]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: towel draped over man's shoulder."}, {"from": "gpt", "value": "[0.56, 0.45, 0.69, 0.64]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a towel on body."}, {"from": "gpt", "value": "[0.57, 0.46, 0.71, 0.67]"}, {"from": "human", "value": "Please provide a short description for this region: [0.37, 0.41, 0.42, 0.46]."}, {"from": "gpt", "value": "Small chineese lettering on a sign."}]}, {"id": "VG_100K/2325805", "image": "vg/VG_100K/2325805.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: A man in a white shirt."}, {"from": "gpt", "value": "[0.28, 0.45, 0.61, 0.87]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white clouds in blue sky."}, {"from": "gpt", "value": "[0.73, 0.2, 0.79, 0.29]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Green canopy of an umbrella."}, {"from": "gpt", "value": "[0.32, 0.29, 0.77, 0.53]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Striped pants on a man."}, {"from": "gpt", "value": "[0.31, 0.76, 0.56, 0.87]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a green umbrella."}, {"from": "gpt", "value": "[0.32, 0.3, 0.78, 0.62]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A man with a green umbrella."}, {"from": "gpt", "value": "[0.32, 0.29, 0.78, 0.52]"}, {"from": "human", "value": "Please provide a short description for this region: [0.36, 0.35, 0.74, 0.58]."}, {"from": "gpt", "value": "The umbrella has characters on it."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a right hand holding the umbrella."}, {"from": "gpt", "value": "[0.56, 0.58, 0.61, 0.63]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Leaves of palm trees."}, {"from": "gpt", "value": "[0.69, 0.8, 0.89, 0.87]"}, {"from": "human", "value": "Please provide a short description for this region: [0.51, 0.42, 0.64, 0.7]."}, {"from": "gpt", "value": "The man is holding an umbrella."}]}, {"id": "VG_100K/2325540", "image": "vg/VG_100K/2325540.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.13, 0.13, 0.74, 0.34]."}, {"from": "gpt", "value": "Umbrella with floral print."}, {"from": "human", "value": "Please provide a short description for this region: [0.22, 0.13, 0.52, 0.3]."}, {"from": "gpt", "value": "Fine detail in umbrella with flowers."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: fordable chair about to fall over."}, {"from": "gpt", "value": "[0.71, 0.45, 0.99, 0.85]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the man has a mullet."}, {"from": "gpt", "value": "[0.58, 0.17, 0.85, 0.38]"}, {"from": "human", "value": "Please provide a short description for this region: [0.75, 0.26, 0.94, 0.51]."}, {"from": "gpt", "value": "Man wearing a black jacket."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Blue logo on back of shoe."}, {"from": "gpt", "value": "[0.4, 0.64, 0.55, 0.73]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: suit and tie on white man."}, {"from": "gpt", "value": "[0.73, 0.23, 0.94, 0.4]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: dress pants no crinkles."}, {"from": "gpt", "value": "[0.52, 0.39, 0.78, 0.64]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: red and white floral print umbrella."}, {"from": "gpt", "value": "[0.14, 0.13, 0.72, 0.33]"}, {"from": "human", "value": "Please provide a short description for this region: [0.01, 0.59, 0.33, 0.85]."}, {"from": "gpt", "value": "Green grass growing on a lawn."}]}, {"id": "VG_100K/2325441", "image": "vg/VG_100K/2325441.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.37, 0.36, 0.45, 0.44]."}, {"from": "gpt", "value": "White glob oftoothpaste."}, {"from": "human", "value": "Please provide a short description for this region: [0.34, 0.68, 0.49, 0.89]."}, {"from": "gpt", "value": "Faucet on a sink."}, {"from": "human", "value": "Please provide a short description for this region: [0.55, 0.65, 0.86, 0.83]."}, {"from": "gpt", "value": "Thumb of a person."}, {"from": "human", "value": "Please provide a short description for this region: [0.68, 0.87, 0.75, 0.92]."}, {"from": "gpt", "value": "Nail of a person."}, {"from": "human", "value": "Please provide a short description for this region: [0.58, 0.66, 0.65, 0.74]."}, {"from": "gpt", "value": "Nail of a person."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Toothbrush head with toothpaste."}, {"from": "gpt", "value": "[0.36, 0.32, 0.46, 0.45]"}, {"from": "human", "value": "Please provide a short description for this region: [0.57, 0.66, 0.65, 0.72]."}, {"from": "gpt", "value": "A thumb nail of a person."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: nail of a person."}, {"from": "gpt", "value": "[0.57, 0.65, 0.65, 0.74]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a finger of a person."}, {"from": "gpt", "value": "[0.5, 0.74, 0.61, 0.81]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: palm of a person."}, {"from": "gpt", "value": "[0.74, 0.8, 0.87, 0.96]"}]}, {"id": "VG_100K/2325431", "image": "vg/VG_100K/2325431.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: wall painted white."}, {"from": "gpt", "value": "[0.33, 0.12, 0.36, 0.19]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: label inside of suitcase."}, {"from": "gpt", "value": "[0.77, 0.29, 0.81, 0.35]"}, {"from": "human", "value": "Please provide a short description for this region: [0.33, 0.12, 0.85, 0.41]."}, {"from": "gpt", "value": "Inside storage pockets in top of suitcase."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: an eye of a dog."}, {"from": "gpt", "value": "[0.54, 0.37, 0.62, 0.46]"}, {"from": "human", "value": "Please provide a short description for this region: [0.28, 0.67, 0.34, 0.75]."}, {"from": "gpt", "value": "Dog's sharp claws hanging down."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: handle of suitcase with dog's paws."}, {"from": "gpt", "value": "[0.25, 0.67, 0.56, 0.77]"}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.12, 0.32, 0.38]."}, {"from": "gpt", "value": "Powder blue curtains."}, {"from": "human", "value": "Please provide a short description for this region: [0.89, 0.52, 1.0, 0.63]."}, {"from": "gpt", "value": "White shoe strings in the shoe."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: blue jeans for wearing on the legs."}, {"from": "gpt", "value": "[0.76, 0.46, 0.9, 0.68]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: tag on the interior of the suitcase."}, {"from": "gpt", "value": "[0.77, 0.29, 0.79, 0.34]"}]}, {"id": "VG_100K/2325239", "image": "vg/VG_100K/2325239.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: Blue, cloudless sky."}, {"from": "gpt", "value": "[0.0, 0.13, 0.3, 0.35]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: yellow traffic light."}, {"from": "gpt", "value": "[0.42, 0.34, 0.53, 0.58]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: traffic light is yellow."}, {"from": "gpt", "value": "[0.44, 0.31, 0.52, 0.57]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white clouds in blue sky."}, {"from": "gpt", "value": "[0.11, 0.23, 0.19, 0.32]"}, {"from": "human", "value": "Please provide a short description for this region: [0.41, 0.33, 0.54, 0.62]."}, {"from": "gpt", "value": "Yellow signal light."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Pine tree at the edge of the road."}, {"from": "gpt", "value": "[0.86, 0.59, 0.95, 0.87]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white clouds in blue sky."}, {"from": "gpt", "value": "[0.83, 0.21, 0.93, 0.33]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white clouds in blue sky."}, {"from": "gpt", "value": "[0.1, 0.22, 0.24, 0.33]"}, {"from": "human", "value": "Please provide a short description for this region: [0.09, 0.21, 0.27, 0.37]."}, {"from": "gpt", "value": "White clouds in blue sky."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white clouds in blue sky."}, {"from": "gpt", "value": "[0.56, 0.15, 0.61, 0.23]"}]}, {"id": "VG_100K/2325025", "image": "vg/VG_100K/2325025.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.57, 0.5, 0.62, 0.61]."}, {"from": "gpt", "value": "Cow grazing on grass."}, {"from": "human", "value": "Please provide a short description for this region: [0.53, 0.36, 0.56, 0.4]."}, {"from": "gpt", "value": "Window on the building."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a house is in the distance."}, {"from": "gpt", "value": "[0.77, 0.24, 0.91, 0.32]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the horns are white in color."}, {"from": "gpt", "value": "[0.6, 0.55, 0.62, 0.58]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: leaves on a tree."}, {"from": "gpt", "value": "[0.04, 0.23, 0.28, 0.39]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: cows walking near a barn."}, {"from": "gpt", "value": "[0.78, 0.37, 0.88, 0.45]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: back of cow butt."}, {"from": "gpt", "value": "[0.39, 0.47, 0.43, 0.54]"}]}, {"id": "VG_100K/2324781", "image": "vg/VG_100K/2324781.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: arm of a person."}, {"from": "gpt", "value": "[0.72, 0.41, 0.77, 0.5]"}, {"from": "human", "value": "Please provide a short description for this region: [0.22, 0.82, 0.6, 1.0]."}, {"from": "gpt", "value": "A bundle of oranges."}, {"from": "human", "value": "Please provide a short description for this region: [0.49, 0.03, 0.67, 0.25]."}, {"from": "gpt", "value": "Light blue is the color of the sky."}, {"from": "human", "value": "Please provide a short description for this region: [0.41, 0.33, 0.51, 0.39]."}, {"from": "gpt", "value": "The hair is short."}, {"from": "human", "value": "Please provide a short description for this region: [0.32, 0.34, 0.71, 0.59]."}, {"from": "gpt", "value": "Both women are wearing coats."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a blue hand dolly."}, {"from": "gpt", "value": "[0.23, 0.36, 0.36, 0.69]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The oranges are in the bags."}, {"from": "gpt", "value": "[0.23, 0.81, 0.63, 0.99]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Black bag on the hand truck."}, {"from": "gpt", "value": "[0.26, 0.42, 0.34, 0.52]"}, {"from": "human", "value": "Please provide a short description for this region: [0.23, 0.36, 0.38, 0.66]."}, {"from": "gpt", "value": "This is a blue carrier."}, {"from": "human", "value": "Please provide a short description for this region: [0.58, 0.4, 0.6, 0.43]."}, {"from": "gpt", "value": "Hand of a person."}]}, {"id": "VG_100K/2324722", "image": "vg/VG_100K/2324722.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: A clock on the wall."}, {"from": "gpt", "value": "[0.96, 0.17, 1.0, 0.24]"}, {"from": "human", "value": "Please provide a short description for this region: [0.53, 0.36, 0.76, 0.83]."}, {"from": "gpt", "value": "A man cooking food."}, {"from": "human", "value": "Please provide a short description for this region: [0.31, 0.6, 0.54, 0.67]."}, {"from": "gpt", "value": "Food on a grill."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a backwards baseball cap."}, {"from": "gpt", "value": "[0.6, 0.34, 0.73, 0.44]"}, {"from": "human", "value": "Please provide a short description for this region: [0.18, 0.72, 0.25, 0.79]."}, {"from": "gpt", "value": "A little stack of condiments."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: arm of a person."}, {"from": "gpt", "value": "[0.55, 0.52, 0.68, 0.61]"}, {"from": "human", "value": "Please provide a short description for this region: [0.01, 0.34, 0.11, 0.42]."}, {"from": "gpt", "value": "Papers on a shelf."}, {"from": "human", "value": "Please provide a short description for this region: [0.6, 0.35, 1.0, 0.47]."}, {"from": "gpt", "value": "Three hats on heads."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.33, 0.11, 0.45]."}, {"from": "gpt", "value": "A pile of napkins on a shelf."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: hand of a person."}, {"from": "gpt", "value": "[0.95, 0.56, 1.0, 0.62]"}]}, {"id": "VG_100K/2323733", "image": "vg/VG_100K/2323733.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.15, 0.39, 0.3, 0.48]."}, {"from": "gpt", "value": "Horse with brown and white patches."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the t shirt is balck in color."}, {"from": "gpt", "value": "[0.39, 0.37, 0.44, 0.4]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a body of calm water."}, {"from": "gpt", "value": "[0.53, 0.35, 0.99, 0.55]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a brown horse walking in the water."}, {"from": "gpt", "value": "[0.36, 0.34, 0.54, 0.51]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the water is colorles."}, {"from": "gpt", "value": "[0.36, 0.58, 0.5, 0.77]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the cape is red in color."}, {"from": "gpt", "value": "[0.2, 0.35, 0.24, 0.39]"}, {"from": "human", "value": "Please provide a short description for this region: [0.22, 0.52, 0.57, 0.61]."}, {"from": "gpt", "value": "The horses reflection are in water."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a body of calm water."}, {"from": "gpt", "value": "[0.54, 0.24, 0.94, 0.5]"}, {"from": "human", "value": "Please provide a short description for this region: [0.14, 0.36, 0.29, 0.5]."}, {"from": "gpt", "value": "Boy sitting on a horse."}, {"from": "human", "value": "Please provide a short description for this region: [0.57, 0.29, 0.83, 0.51]."}, {"from": "gpt", "value": "A body of calm water."}]}, {"id": "VG_100K/2323563", "image": "vg/VG_100K/2323563.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: Shadow from the yellow tape."}, {"from": "gpt", "value": "[0.67, 0.65, 0.87, 0.71]"}, {"from": "human", "value": "Please provide a short description for this region: [0.13, 0.1, 0.22, 0.3]."}, {"from": "gpt", "value": "Tree with green leaves and its branches."}, {"from": "human", "value": "Please provide a short description for this region: [0.37, 0.25, 0.5, 0.37]."}, {"from": "gpt", "value": "Bicycle being walked."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: cracks in the concrete."}, {"from": "gpt", "value": "[0.15, 0.34, 0.31, 0.44]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a building with a shingled roof."}, {"from": "gpt", "value": "[0.24, 0.15, 0.4, 0.21]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: White van parked behind service station."}, {"from": "gpt", "value": "[0.35, 0.24, 0.43, 0.29]"}, {"from": "human", "value": "Please provide a short description for this region: [0.33, 0.24, 0.38, 0.29]."}, {"from": "gpt", "value": "White color car parked near the building."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Clear blue color sky."}, {"from": "gpt", "value": "[0.14, 0.02, 0.22, 0.11]"}]}, {"id": "VG_100K/2322298", "image": "vg/VG_100K/2322298.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.4, 0.27, 0.6, 0.42]."}, {"from": "gpt", "value": "This is a crosswalk sign."}, {"from": "human", "value": "Please provide a short description for this region: [0.62, 0.8, 0.65, 0.89]."}, {"from": "gpt", "value": "Orange and yellow banner."}, {"from": "human", "value": "Please provide a short description for this region: [0.51, 0.6, 0.72, 0.83]."}, {"from": "gpt", "value": "A blue sign on the pole."}, {"from": "human", "value": "Please provide a short description for this region: [0.3, 0.11, 0.44, 0.3]."}, {"from": "gpt", "value": "Sky is dark blue."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a street sign on a metal pole."}, {"from": "gpt", "value": "[0.41, 0.26, 0.64, 0.51]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a tall sky scraper."}, {"from": "gpt", "value": "[0.41, 0.23, 0.61, 0.95]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: there are lights on the edge of the building."}, {"from": "gpt", "value": "[0.42, 0.2, 0.61, 0.97]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: HEADLIGHT OF SMALL CAR."}, {"from": "gpt", "value": "[0.16, 0.95, 0.19, 0.98]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white and black banner."}, {"from": "gpt", "value": "[0.64, 0.77, 0.69, 0.86]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: OVERHEAD HIGH STREET LIGHT."}, {"from": "gpt", "value": "[0.21, 0.72, 0.25, 0.75]"}]}, {"id": "VG_100K/2321462", "image": "vg/VG_100K/2321462.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: this is a blue top."}, {"from": "gpt", "value": "[0.46, 0.37, 0.66, 0.61]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: This is a person."}, {"from": "gpt", "value": "[0.29, 0.24, 0.4, 0.39]"}, {"from": "human", "value": "Please provide a short description for this region: [0.26, 0.26, 0.39, 0.39]."}, {"from": "gpt", "value": "The woman plays tennis."}, {"from": "human", "value": "Please provide a short description for this region: [0.02, 0.55, 0.21, 0.81]."}, {"from": "gpt", "value": "A large crack in cement."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.4, 0.23, 0.79]."}, {"from": "gpt", "value": "Large crack in tennis court."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: red vehicle parked behind a woman."}, {"from": "gpt", "value": "[0.21, 0.29, 0.38, 0.37]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: woman's purple colored top."}, {"from": "gpt", "value": "[0.29, 0.28, 0.35, 0.33]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: woman playing game of tennis."}, {"from": "gpt", "value": "[0.3, 0.26, 0.39, 0.38]"}, {"from": "human", "value": "Please provide a short description for this region: [0.6, 0.61, 0.77, 0.83]."}, {"from": "gpt", "value": "The leg of a girl."}, {"from": "human", "value": "Please provide a short description for this region: [0.33, 0.28, 0.36, 0.31]."}, {"from": "gpt", "value": "Racket woman is using."}]}, {"id": "VG_100K/2321193", "image": "vg/VG_100K/2321193.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: The tip of a knife with food on it."}, {"from": "gpt", "value": "[0.0, 0.21, 0.2, 0.29]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Knife and fork are silver."}, {"from": "gpt", "value": "[0.0, 0.17, 1.0, 0.29]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: egg on the end of knife."}, {"from": "gpt", "value": "[0.0, 0.21, 0.18, 0.29]"}, {"from": "human", "value": "Please provide a short description for this region: [0.32, 0.16, 1.0, 0.23]."}, {"from": "gpt", "value": "A fork on a plate."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: egg yolk on serrated knife."}, {"from": "gpt", "value": "[0.0, 0.2, 0.2, 0.29]"}, {"from": "human", "value": "Please provide a short description for this region: [0.33, 0.17, 1.0, 0.24]."}, {"from": "gpt", "value": "Silver fork on plate."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A silver fork on a plate."}, {"from": "gpt", "value": "[0.32, 0.17, 1.0, 0.24]"}, {"from": "human", "value": "Please provide a short description for this region: [0.32, 0.66, 0.84, 0.86]."}, {"from": "gpt", "value": "A runny yellow yolk."}, {"from": "human", "value": "Please provide a short description for this region: [0.0, 0.2, 0.19, 0.29]."}, {"from": "gpt", "value": "Sharp top of a knife."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: egg white on fork prong."}, {"from": "gpt", "value": "[0.32, 0.17, 0.38, 0.23]"}]}, {"id": "VG_100K/2320430", "image": "vg/VG_100K/2320430.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.39, 0.26, 0.72, 0.39]."}, {"from": "gpt", "value": "A white airplane."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a plane in midair."}, {"from": "gpt", "value": "[0.41, 0.28, 0.68, 0.4]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: an airplane in the sky."}, {"from": "gpt", "value": "[0.43, 0.25, 0.67, 0.39]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white clouds in blue sky."}, {"from": "gpt", "value": "[0.54, 0.14, 0.61, 0.19]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white clouds in gray sky."}, {"from": "gpt", "value": "[0.59, 0.63, 0.7, 0.72]"}, {"from": "human", "value": "Please provide a short description for this region: [0.39, 0.22, 0.75, 0.41]."}, {"from": "gpt", "value": "Plane flyng in overcast sky."}, {"from": "human", "value": "Please provide a short description for this region: [0.43, 0.29, 0.67, 0.4]."}, {"from": "gpt", "value": "Plane in the sky."}, {"from": "human", "value": "Please provide a short description for this region: [0.34, 0.24, 0.71, 0.45]."}, {"from": "gpt", "value": "One plane above the land."}, {"from": "human", "value": "Please provide a short description for this region: [0.52, 0.35, 0.56, 0.38]."}, {"from": "gpt", "value": "White engine of plane."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: wing of plane."}, {"from": "gpt", "value": "[0.46, 0.28, 0.51, 0.34]"}]}, {"id": "VG_100K/2319916", "image": "vg/VG_100K/2319916.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: block wall behind sign."}, {"from": "gpt", "value": "[0.0, 0.51, 0.14, 0.7]"}, {"from": "human", "value": "Please provide a short description for this region: [0.55, 0.35, 0.99, 0.69]."}, {"from": "gpt", "value": "A pole with street sign."}, {"from": "human", "value": "Please provide a short description for this region: [0.58, 0.46, 0.62, 0.51]."}, {"from": "gpt", "value": "R letter on green signboard."}, {"from": "human", "value": "Please provide a short description for this region: [0.24, 0.47, 0.28, 0.5]."}, {"from": "gpt", "value": "Blue numbers on sign."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: red and blue symbol on green signboard."}, {"from": "gpt", "value": "[0.17, 0.41, 0.29, 0.49]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: logo for the city."}, {"from": "gpt", "value": "[0.16, 0.39, 0.3, 0.51]"}, {"from": "human", "value": "Please provide a short description for this region: [0.17, 0.47, 0.24, 0.5]."}, {"from": "gpt", "value": "Blue letters on sign."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: c letter on green signboard."}, {"from": "gpt", "value": "[0.4, 0.42, 0.46, 0.5]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: large red and blue star."}, {"from": "gpt", "value": "[0.18, 0.41, 0.26, 0.48]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: green clark signboard."}, {"from": "gpt", "value": "[0.14, 0.36, 0.84, 0.57]"}]}, {"id": "VG_100K/2319593", "image": "vg/VG_100K/2319593.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a green fence in the distance."}, {"from": "gpt", "value": "[0.03, 0.19, 0.29, 0.34]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a silver watch."}, {"from": "gpt", "value": "[0.24, 0.85, 0.35, 0.92]"}, {"from": "human", "value": "Please provide a short description for this region: [0.7, 0.59, 0.98, 0.76]."}, {"from": "gpt", "value": "A black fence."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a water bottle."}, {"from": "gpt", "value": "[0.05, 0.31, 0.32, 0.4]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: strings in the racket."}, {"from": "gpt", "value": "[0.66, 0.72, 0.88, 0.9]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a section of empty seating."}, {"from": "gpt", "value": "[0.01, 0.38, 0.33, 0.74]"}, {"from": "human", "value": "Please provide a short description for this region: [0.6, 0.25, 0.74, 0.71]."}, {"from": "gpt", "value": "A brown ponytail."}, {"from": "human", "value": "Please provide a short description for this region: [0.44, 0.32, 0.5, 0.41]."}, {"from": "gpt", "value": "Round ear rings adorn her ears."}, {"from": "human", "value": "Please provide a short description for this region: [0.31, 0.47, 0.64, 0.92]."}, {"from": "gpt", "value": "A black and white tennis uniform."}, {"from": "human", "value": "Please provide a short description for this region: [0.8, 0.53, 0.95, 0.79]."}, {"from": "gpt", "value": "A lady sitting on a bench."}]}, {"id": "VG_100K/2319369", "image": "vg/VG_100K/2319369.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: The carrot is orange."}, {"from": "gpt", "value": "[0.34, 0.69, 0.65, 0.79]"}, {"from": "human", "value": "Please provide a short description for this region: [0.67, 0.46, 0.91, 0.69]."}, {"from": "gpt", "value": "The broccoli is steamed."}, {"from": "human", "value": "Please provide a short description for this region: [0.29, 0.28, 0.74, 0.47]."}, {"from": "gpt", "value": "The chicken has not been breaded."}, {"from": "human", "value": "Please provide a short description for this region: [0.62, 0.33, 0.91, 0.67]."}, {"from": "gpt", "value": "Cooked broccoli on a plate."}, {"from": "human", "value": "Please provide a short description for this region: [0.19, 0.18, 0.78, 0.44]."}, {"from": "gpt", "value": "Meat on a white plate."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The meat is cooked."}, {"from": "gpt", "value": "[0.07, 0.16, 0.65, 0.42]"}, {"from": "human", "value": "Please provide a short description for this region: [0.68, 0.46, 0.88, 0.69]."}, {"from": "gpt", "value": "The broccoli is green."}, {"from": "human", "value": "Please provide a short description for this region: [0.34, 0.29, 0.63, 0.5]."}, {"from": "gpt", "value": "Brown gravy."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A grilled chicken leg."}, {"from": "gpt", "value": "[0.11, 0.17, 0.59, 0.44]"}, {"from": "human", "value": "Please provide a short description for this region: [0.64, 0.31, 0.77, 0.48]."}, {"from": "gpt", "value": "The broccoli is steamed."}]}, {"id": "VG_100K/2318932", "image": "vg/VG_100K/2318932.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: slice of pepperoni on pizza."}, {"from": "gpt", "value": "[0.75, 0.14, 1.0, 0.33]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: White surf board in the water."}, {"from": "gpt", "value": "[0.39, 0.3, 0.59, 0.62]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The olives are black."}, {"from": "gpt", "value": "[0.1, 0.59, 0.22, 0.72]"}, {"from": "human", "value": "Please provide a short description for this region: [0.07, 0.59, 0.25, 0.74]."}, {"from": "gpt", "value": "A slice of olive."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: sauce on a pizza."}, {"from": "gpt", "value": "[0.2, 0.3, 0.28, 0.38]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Small black olive on pizza."}, {"from": "gpt", "value": "[0.15, 0.46, 0.24, 0.59]"}, {"from": "human", "value": "Please provide a short description for this region: [0.09, 0.6, 0.23, 0.71]."}, {"from": "gpt", "value": "Small black olive on pizza."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: slice of olive has a hole."}, {"from": "gpt", "value": "[0.05, 0.24, 0.2, 0.41]"}, {"from": "human", "value": "Please provide a short description for this region: [0.03, 0.36, 0.12, 0.46]."}, {"from": "gpt", "value": "Sauce on a pizza."}]}, {"id": "VG_100K/2318917", "image": "vg/VG_100K/2318917.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.3, 0.6, 0.36, 0.65]."}, {"from": "gpt", "value": "Ear of a cat."}, {"from": "human", "value": "Please provide a short description for this region: [0.24, 0.29, 0.39, 0.43]."}, {"from": "gpt", "value": "Body of a cat."}, {"from": "human", "value": "Please provide a short description for this region: [0.33, 0.38, 0.66, 0.74]."}, {"from": "gpt", "value": "The plates are white."}, {"from": "human", "value": "Please provide a short description for this region: [0.35, 0.39, 0.45, 0.48]."}, {"from": "gpt", "value": "Head of a cat."}, {"from": "human", "value": "Please provide a short description for this region: [0.78, 0.13, 0.93, 0.55]."}, {"from": "gpt", "value": "Black and white dishwasher."}, {"from": "human", "value": "Please provide a short description for this region: [0.8, 0.59, 0.93, 0.78]."}, {"from": "gpt", "value": "The bowls are silver."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: head of a cat."}, {"from": "gpt", "value": "[0.51, 0.36, 0.63, 0.44]"}, {"from": "human", "value": "Please provide a short description for this region: [0.31, 0.59, 0.39, 0.65]."}, {"from": "gpt", "value": "Ear of a cat."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the rug is many colors."}, {"from": "gpt", "value": "[0.54, 0.33, 0.76, 0.53]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Silver feeding and water dishes."}, {"from": "gpt", "value": "[0.79, 0.61, 0.95, 0.78]"}]}, {"id": "VG_100K/2318107", "image": "vg/VG_100K/2318107.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.13, 0.79, 0.87, 1.0]."}, {"from": "gpt", "value": "Table has yellow tiles."}, {"from": "human", "value": "Please provide a short description for this region: [0.36, 0.0, 0.47, 0.12]."}, {"from": "gpt", "value": "The candle is lit."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the folded white napkin."}, {"from": "gpt", "value": "[0.13, 0.01, 0.26, 0.14]"}, {"from": "human", "value": "Please provide a short description for this region: [0.42, 0.43, 0.5, 0.55]."}, {"from": "gpt", "value": "The white sauce on the middle hot dog."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The table is gold."}, {"from": "gpt", "value": "[0.2, 0.85, 0.78, 0.98]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The smaller plate is white."}, {"from": "gpt", "value": "[0.13, 0.14, 0.35, 0.33]"}, {"from": "human", "value": "Please provide a short description for this region: [0.13, 0.01, 0.27, 0.15]."}, {"from": "gpt", "value": "The napkin is folded."}, {"from": "human", "value": "Please provide a short description for this region: [0.43, 0.43, 0.51, 0.58]."}, {"from": "gpt", "value": "I see onions here."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: There are three mini dogs."}, {"from": "gpt", "value": "[0.23, 0.37, 0.73, 0.67]"}, {"from": "human", "value": "Please provide a short description for this region: [0.29, 0.33, 0.57, 0.5]."}, {"from": "gpt", "value": "The garnish is green."}]}, {"id": "VG_100K/2317374", "image": "vg/VG_100K/2317374.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.09, 0.46, 0.16, 0.63]."}, {"from": "gpt", "value": "Beige handbag on shoulder."}, {"from": "human", "value": "Please provide a short description for this region: [0.8, 0.15, 0.89, 0.33]."}, {"from": "gpt", "value": "Man walking wearing white t-shirt and blue jeans."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a leg of a person."}, {"from": "gpt", "value": "[0.17, 0.75, 0.21, 0.85]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: green sign with yellow highlights."}, {"from": "gpt", "value": "[0.79, 0.19, 0.87, 0.32]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: black and white checkerboard umbrella."}, {"from": "gpt", "value": "[0.09, 0.34, 0.42, 0.54]"}, {"from": "human", "value": "Please provide a short description for this region: [0.13, 0.42, 0.34, 0.87]."}, {"from": "gpt", "value": "Woman wearing vlue jeans holding a black and white umbrella."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: red umbrella covers face."}, {"from": "gpt", "value": "[0.29, 0.23, 0.56, 0.37]"}, {"from": "human", "value": "Please provide a short description for this region: [0.58, 0.18, 0.75, 0.26]."}, {"from": "gpt", "value": "Black umbrella appears to be falling apart."}, {"from": "human", "value": "Please provide a short description for this region: [0.38, 0.35, 0.49, 0.42]."}, {"from": "gpt", "value": "Red and white letters on dark gray sweatshirt."}, {"from": "human", "value": "Please provide a short description for this region: [0.21, 0.72, 0.32, 0.83]."}, {"from": "gpt", "value": "Leg of a person."}]}, {"id": "VG_100K/2317300", "image": "vg/VG_100K/2317300.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a black strap on a tree."}, {"from": "gpt", "value": "[0.32, 0.13, 0.69, 0.27]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Giraffe is curious about the limb of a tree."}, {"from": "gpt", "value": "[0.38, 0.33, 0.64, 0.56]"}, {"from": "human", "value": "Please provide a short description for this region: [0.39, 0.27, 0.63, 0.71]."}, {"from": "gpt", "value": "Giraffe is living in a zoo."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: trunk of tall tree."}, {"from": "gpt", "value": "[0.33, 0.14, 0.35, 0.4]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: one brown giraffe snout."}, {"from": "gpt", "value": "[0.55, 0.47, 0.6, 0.53]"}, {"from": "human", "value": "Please provide a short description for this region: [0.37, 0.38, 0.6, 0.7]."}, {"from": "gpt", "value": "Tall giraffe in zoo."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: one light colored giraffe ear."}, {"from": "gpt", "value": "[0.39, 0.41, 0.43, 0.48]"}, {"from": "human", "value": "Please provide a short description for this region: [0.76, 0.44, 0.94, 0.6]."}, {"from": "gpt", "value": "Green grass on a lawn."}, {"from": "human", "value": "Please provide a short description for this region: [0.71, 0.52, 0.82, 0.59]."}, {"from": "gpt", "value": "Small white flowers growing in the grass."}, {"from": "human", "value": "Please provide a short description for this region: [0.39, 0.36, 0.6, 0.55]."}, {"from": "gpt", "value": "Head of spotted giraffe."}]}, {"id": "VG_100K/2317264", "image": "vg/VG_100K/2317264.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: believing at the bottom."}, {"from": "gpt", "value": "[0.16, 0.68, 0.79, 0.82]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: UNDERLINE ADDED TO STOP SIGN."}, {"from": "gpt", "value": "[0.25, 0.82, 0.79, 0.87]"}, {"from": "human", "value": "Please provide a short description for this region: [0.07, 0.33, 0.29, 0.7]."}, {"from": "gpt", "value": "Letter s on red stop sign."}, {"from": "human", "value": "Please provide a short description for this region: [0.68, 0.34, 0.91, 0.71]."}, {"from": "gpt", "value": "Letter p on red stop sign."}, {"from": "human", "value": "Please provide a short description for this region: [0.24, 0.13, 0.75, 0.33]."}, {"from": "gpt", "value": "Don't is written above \"stop\"."}, {"from": "human", "value": "Please provide a short description for this region: [0.22, 0.48, 0.52, 0.6]."}, {"from": "gpt", "value": "Rectangular shaped mark on sign."}, {"from": "human", "value": "Please provide a short description for this region: [0.26, 0.35, 0.46, 0.7]."}, {"from": "gpt", "value": "Letter t on red stop sign."}, {"from": "human", "value": "Please provide a short description for this region: [0.76, 0.66, 0.84, 0.81]."}, {"from": "gpt", "value": "An exclamation point on a sign."}, {"from": "human", "value": "Please provide a short description for this region: [0.27, 0.15, 0.76, 0.32]."}, {"from": "gpt", "value": "Don't at the top."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: DONT ADDED TO STOP SIGN."}, {"from": "gpt", "value": "[0.26, 0.15, 0.77, 0.32]"}]}, {"id": "VG_100K/2316193", "image": "vg/VG_100K/2316193.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.0, 0.17, 0.43, 0.5]."}, {"from": "gpt", "value": "Green colored broccoli."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: seasoning on the food."}, {"from": "gpt", "value": "[0.2, 0.39, 0.79, 0.66]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A sort of meat on the plate."}, {"from": "gpt", "value": "[0.41, 0.46, 0.95, 0.68]"}, {"from": "human", "value": "Please provide a short description for this region: [0.39, 0.23, 0.65, 0.4]."}, {"from": "gpt", "value": "A small serving of mashed potatoes."}, {"from": "human", "value": "Please provide a short description for this region: [0.23, 0.52, 0.74, 0.71]."}, {"from": "gpt", "value": "A sort of dressing on the food."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: green broccoli steamed on plate."}, {"from": "gpt", "value": "[0.0, 0.17, 0.43, 0.5]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: edge of the plate."}, {"from": "gpt", "value": "[0.75, 0.65, 0.97, 0.78]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: mashed potatoes on a plate."}, {"from": "gpt", "value": "[0.4, 0.23, 0.66, 0.4]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Some slices of tomatos."}, {"from": "gpt", "value": "[0.12, 0.42, 0.37, 0.6]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: red meat sauce on plate."}, {"from": "gpt", "value": "[0.77, 0.39, 1.0, 0.58]"}]}, {"id": "VG_100K/2315503", "image": "vg/VG_100K/2315503.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.39, 0.26, 0.5, 0.33]."}, {"from": "gpt", "value": "Blue sky with white clouds."}, {"from": "human", "value": "Please provide a short description for this region: [0.25, 0.39, 0.62, 0.73]."}, {"from": "gpt", "value": "A horse standing in the grass."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: horse facing left."}, {"from": "gpt", "value": "[0.21, 0.38, 0.63, 0.74]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a view of sky."}, {"from": "gpt", "value": "[0.34, 0.23, 0.52, 0.37]"}, {"from": "human", "value": "Please provide a short description for this region: [0.19, 0.37, 0.38, 0.54]."}, {"from": "gpt", "value": "Head of the horse."}, {"from": "human", "value": "Please provide a short description for this region: [0.37, 0.61, 0.4, 0.68]."}, {"from": "gpt", "value": "Horse has a brown leg."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: blue sky with white clouds."}, {"from": "gpt", "value": "[0.41, 0.22, 0.5, 0.26]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: large brown horse."}, {"from": "gpt", "value": "[0.22, 0.4, 0.59, 0.68]"}, {"from": "human", "value": "Please provide a short description for this region: [0.25, 0.43, 0.29, 0.51]."}, {"from": "gpt", "value": "Red halter on the face of a horse."}, {"from": "human", "value": "Please provide a short description for this region: [0.47, 0.58, 0.55, 0.71]."}, {"from": "gpt", "value": "Back leg of horse."}]}, {"id": "VG_100K_2/2414507", "image": "vg/VG_100K_2/2414507.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: a cat tower in the room."}, {"from": "gpt", "value": "[0.01, 0.13, 0.17, 0.55]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: PILE OF DVDS."}, {"from": "gpt", "value": "[0.17, 0.5, 0.28, 0.64]"}, {"from": "human", "value": "Please provide a short description for this region: [0.61, 0.31, 0.72, 0.38]."}, {"from": "gpt", "value": "Black and white cat sitting on couch."}, {"from": "human", "value": "Please provide a short description for this region: [0.2, 0.38, 0.36, 0.47]."}, {"from": "gpt", "value": "Television on the entertainment stand."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: large black television with gray border."}, {"from": "gpt", "value": "[0.2, 0.36, 0.38, 0.47]"}, {"from": "human", "value": "Please provide a short description for this region: [0.52, 0.14, 0.87, 0.33]."}, {"from": "gpt", "value": "Venetian blinds on a door."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: BLACK SWIVEL OFFICE CHAIR."}, {"from": "gpt", "value": "[0.44, 0.37, 0.57, 0.56]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A cat climbing structure."}, {"from": "gpt", "value": "[0.01, 0.13, 0.16, 0.56]"}, {"from": "human", "value": "Please provide a short description for this region: [0.8, 0.34, 1.0, 0.52]."}, {"from": "gpt", "value": "Black shiny chair with deep line in seat."}, {"from": "human", "value": "Please provide a short description for this region: [0.04, 0.69, 0.15, 0.82]."}, {"from": "gpt", "value": "A playable game on a a shelf."}]}, {"id": "VG_100K_2/2413647", "image": "vg/VG_100K_2/2413647.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.17, 0.17, 0.6, 0.46]."}, {"from": "gpt", "value": "Steam coming from steam engine."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a two colored train car."}, {"from": "gpt", "value": "[0.42, 0.38, 0.87, 0.57]"}, {"from": "human", "value": "Please provide a short description for this region: [0.21, 0.21, 0.68, 0.41]."}, {"from": "gpt", "value": "A cloud of smoke drifting up."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a functioning train engine."}, {"from": "gpt", "value": "[0.14, 0.4, 0.37, 0.55]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a small leafy bush."}, {"from": "gpt", "value": "[0.58, 0.46, 0.78, 0.67]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Some of the windows on the passenger cars are open."}, {"from": "gpt", "value": "[0.85, 0.41, 0.98, 0.47]"}, {"from": "human", "value": "Please provide a short description for this region: [0.01, 0.13, 0.41, 0.4]."}, {"from": "gpt", "value": "An odd tree."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: railroad train car wheels."}, {"from": "gpt", "value": "[0.18, 0.48, 0.98, 0.58]"}, {"from": "human", "value": "Please provide a short description for this region: [0.44, 0.39, 0.84, 0.57]."}, {"from": "gpt", "value": "A dark and light passenger car."}, {"from": "human", "value": "Please provide a short description for this region: [0.36, 0.45, 0.42, 0.51]."}, {"from": "gpt", "value": "Logo of a train company."}]}, {"id": "VG_100K_2/2413206", "image": "vg/VG_100K_2/2413206.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: Buses are parked on the street."}, {"from": "gpt", "value": "[0.43, 0.35, 0.65, 0.5]"}, {"from": "human", "value": "Please provide a short description for this region: [0.01, 0.2, 0.13, 0.24]."}, {"from": "gpt", "value": "The street sign says cambie st."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: crosswalk has stencils of bicycles."}, {"from": "gpt", "value": "[0.4, 0.57, 0.73, 0.63]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: silver car parked on street."}, {"from": "gpt", "value": "[0.07, 0.42, 0.19, 0.5]"}, {"from": "human", "value": "Please provide a short description for this region: [0.51, 0.43, 0.54, 0.52]."}, {"from": "gpt", "value": "A yellow and black warning sign."}, {"from": "human", "value": "Please provide a short description for this region: [0.13, 0.21, 0.82, 0.36]."}, {"from": "gpt", "value": "Traffic lights that are yellow."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: The helmet is green."}, {"from": "gpt", "value": "[0.2, 0.35, 0.29, 0.42]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: stoplight is yellow."}, {"from": "gpt", "value": "[0.41, 0.2, 0.44, 0.29]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A woman rides a bicycle."}, {"from": "gpt", "value": "[0.16, 0.34, 0.39, 0.83]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: red banner advertisements on pole."}, {"from": "gpt", "value": "[0.75, 0.17, 0.86, 0.27]"}]}, {"id": "VG_100K_2/2412960", "image": "vg/VG_100K_2/2412960.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: an open door of a white double cabin."}, {"from": "gpt", "value": "[0.5, 0.59, 0.56, 0.69]"}, {"from": "human", "value": "Please provide a short description for this region: [0.49, 0.59, 0.91, 0.75]."}, {"from": "gpt", "value": "The truck is white in color."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a lady in blue jeans strolls across the beach."}, {"from": "gpt", "value": "[0.08, 0.6, 0.13, 0.68]"}, {"from": "human", "value": "Please provide a short description for this region: [0.63, 0.56, 0.9, 0.58]."}, {"from": "gpt", "value": "A yellow canoe sits on top of a truck."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the blue large water body."}, {"from": "gpt", "value": "[0.01, 0.5, 0.39, 0.61]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: green penisula judding into the ocean."}, {"from": "gpt", "value": "[0.55, 0.45, 0.98, 0.65]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a puddle of water is on the sand."}, {"from": "gpt", "value": "[0.01, 0.77, 0.17, 0.82]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: darke sandy beach filled with puddles during low tide."}, {"from": "gpt", "value": "[0.02, 0.62, 0.49, 0.85]"}, {"from": "human", "value": "Please provide a short description for this region: [0.48, 0.57, 0.63, 0.74]."}, {"from": "gpt", "value": "The driver's door of the truck is open."}]}, {"id": "VG_100K_2/2412360", "image": "vg/VG_100K_2/2412360.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: Roped off train."}, {"from": "gpt", "value": "[0.03, 0.64, 0.3, 0.86]"}, {"from": "human", "value": "Please provide a short description for this region: [0.03, 0.34, 0.14, 0.57]."}, {"from": "gpt", "value": "Orange,black, and red train."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: and orange post with yellow tied tape."}, {"from": "gpt", "value": "[0.13, 0.76, 0.2, 0.85]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: orange and white cone."}, {"from": "gpt", "value": "[0.14, 0.77, 0.18, 0.87]"}, {"from": "human", "value": "Please provide a short description for this region: [0.02, 0.2, 0.28, 0.26]."}, {"from": "gpt", "value": "Small portion of silver door."}, {"from": "human", "value": "Please provide a short description for this region: [0.14, 0.31, 0.53, 0.53]."}, {"from": "gpt", "value": "Train has many rivets."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: long tied yellow ribbon."}, {"from": "gpt", "value": "[0.1, 0.75, 0.34, 0.79]"}, {"from": "human", "value": "Please provide a short description for this region: [0.39, 0.66, 0.57, 0.87]."}, {"from": "gpt", "value": "The wheel of a train."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: grooves in shiny train wheel."}, {"from": "gpt", "value": "[0.42, 0.69, 0.5, 0.76]"}, {"from": "human", "value": "Please provide a short description for this region: [0.05, 0.4, 0.09, 0.47]."}, {"from": "gpt", "value": "A window on a train locomotive."}]}, {"id": "VG_100K_2/2415770", "image": "vg/VG_100K_2/2415770.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.14, 0.66, 0.5, 0.81]."}, {"from": "gpt", "value": "Counter with a sink on top."}, {"from": "human", "value": "Please provide a short description for this region: [0.55, 0.59, 0.7, 0.92]."}, {"from": "gpt", "value": "A white toilet in the room."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Mosaic of pebbles in the floor."}, {"from": "gpt", "value": "[0.56, 0.91, 0.87, 1.0]"}, {"from": "human", "value": "Please provide a short description for this region: [0.57, 0.54, 0.73, 0.86]."}, {"from": "gpt", "value": "A toilet seat upright."}, {"from": "human", "value": "Please provide a short description for this region: [0.45, 0.75, 0.52, 1.0]."}, {"from": "gpt", "value": "A pipe next to the wall by the sink."}, {"from": "human", "value": "Please provide a short description for this region: [0.57, 0.56, 0.74, 0.95]."}, {"from": "gpt", "value": "A toilet in the corner."}, {"from": "human", "value": "Please provide a short description for this region: [0.23, 0.57, 0.27, 0.66]."}, {"from": "gpt", "value": "Silver faucet in a white sink."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A green bottle sitting above the sink."}, {"from": "gpt", "value": "[0.32, 0.33, 0.41, 0.39]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: a towel on the rack."}, {"from": "gpt", "value": "[0.14, 0.8, 0.26, 1.0]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white sink attached to wall."}, {"from": "gpt", "value": "[0.12, 0.56, 0.43, 0.83]"}]}, {"id": "VG_100K_2/2415867", "image": "vg/VG_100K_2/2415867.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide a short description for this region: [0.25, 0.72, 0.41, 0.79]."}, {"from": "gpt", "value": "The shoes are white."}, {"from": "human", "value": "Please provide a short description for this region: [0.53, 0.43, 1.0, 0.47]."}, {"from": "gpt", "value": "White line on ground."}, {"from": "human", "value": "Please provide a short description for this region: [0.51, 0.19, 0.58, 0.34]."}, {"from": "gpt", "value": "This is a lady."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Tennis ball in the air."}, {"from": "gpt", "value": "[0.12, 0.2, 0.14, 0.22]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: white line on ground."}, {"from": "gpt", "value": "[0.53, 0.31, 0.74, 0.44]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: the visor is orange."}, {"from": "gpt", "value": "[0.28, 0.3, 0.3, 0.34]"}, {"from": "human", "value": "Please provide a short description for this region: [0.39, 0.19, 0.49, 0.36]."}, {"from": "gpt", "value": "A black tennis racket."}, {"from": "human", "value": "Please provide a short description for this region: [0.84, 0.69, 0.93, 0.8]."}, {"from": "gpt", "value": "This is a sports shoe."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Woman's left foot lifted off ground."}, {"from": "gpt", "value": "[0.86, 0.7, 0.91, 0.79]"}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A white tank top."}, {"from": "gpt", "value": "[0.22, 0.34, 0.35, 0.51]"}]}, {"id": "VG_100K_2/2417066", "image": "vg/VG_100K_2/2417066.jpg", "conversations": [{"from": "human", "value": "<image>\nPlease provide the bounding box coordinate of the region this sentence describes: person wearing gray shirt."}, {"from": "gpt", "value": "[0.11, 0.49, 0.5, 0.83]"}, {"from": "human", "value": "Please provide a short description for this region: [0.47, 0.31, 0.55, 0.34]."}, {"from": "gpt", "value": "Frisbee in air is orange."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Yellow flowers on the ground."}, {"from": "gpt", "value": "[0.77, 0.7, 0.94, 0.76]"}, {"from": "human", "value": "Please provide a short description for this region: [0.62, 0.56, 0.68, 0.6]."}, {"from": "gpt", "value": "Person wearing green shorts."}, {"from": "human", "value": "Please provide a short description for this region: [0.2, 0.39, 0.25, 0.45]."}, {"from": "gpt", "value": "The left ear of a young boy."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: girl wearing green shorts."}, {"from": "gpt", "value": "[0.56, 0.4, 0.7, 0.73]"}, {"from": "human", "value": "Please provide a short description for this region: [0.33, 0.41, 0.38, 0.46]."}, {"from": "gpt", "value": "The right ear of a young boy."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: A tree trunk."}, {"from": "gpt", "value": "[0.4, 0.21, 0.53, 0.57]"}, {"from": "human", "value": "Please provide a short description for this region: [0.56, 0.39, 0.71, 0.74]."}, {"from": "gpt", "value": "Person standing on grass."}, {"from": "human", "value": "Please provide the bounding box coordinate of the region this sentence describes: Grass in the field."}, {"from": "gpt", "value": "[0.71, 0.61, 0.84, 0.8]"}]}, {"id": 2345503, "image": "gqa/images/2345503.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the jacket yellow?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which color are the pants?"}, {"from": "gpt", "value": "Brown"}, {"from": "human", "value": "Who is walking?"}, {"from": "gpt", "value": "People"}, {"from": "human", "value": "Is there a plane in the image?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the man that is to the left of the person wearing?"}, {"from": "gpt", "value": "Hat"}, {"from": "human", "value": "What color are the vests?"}, {"from": "gpt", "value": "Yellow"}, {"from": "human", "value": "What color is the sky the clouds are in?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "Does the horse's tail look green?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there either any toilet papers or buses?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Who is wearing a hat?"}, {"from": "gpt", "value": "Man"}, {"from": "human", "value": "Is the tower white?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2358091, "image": "gqa/images/2358091.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the boy holding?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Sandwich"}, {"from": "human", "value": "Which kind of device is on the table?"}, {"from": "gpt", "value": "Computer monitor"}, {"from": "human", "value": "What is on the table?"}, {"from": "gpt", "value": "Computer monitor"}, {"from": "human", "value": "Are there any Xbox controllers to the right of the red tomatoes?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What device is on the desk?"}, {"from": "gpt", "value": "Headphones"}, {"from": "human", "value": "Are there either any desks or beds?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the cup to the right or to the left of the plate he is to the right of?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "What type of device is on the wall?"}, {"from": "gpt", "value": "Speaker"}, {"from": "human", "value": "Which color is the cup, blue or white?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "Who is holding the sandwich?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "Who is holding the sandwich to the left of the computer monitor?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "Is there a mirror on the wall?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the speaker different in color than the computer monitor?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "The speaker is on what?"}, {"from": "gpt", "value": "Wall"}, {"from": "human", "value": "What is the device to the right of the lettuce that is in the center?"}, {"from": "gpt", "value": "Computer monitor"}, {"from": "human", "value": "Is the plate to the right or to the left of the blue cup?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Which side of the photo is the bottle on?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Which kind of device is to the left of the bottle?"}, {"from": "gpt", "value": "Computer monitor"}, {"from": "human", "value": "Do you see computer monitors on the table?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What piece of furniture is the boy on?"}, {"from": "gpt", "value": "Chair"}, {"from": "human", "value": "What item of furniture is the boy on?"}, {"from": "gpt", "value": "Chair"}, {"from": "human", "value": "What is the boy on?"}, {"from": "gpt", "value": "Chair"}, {"from": "human", "value": "What is he on?"}, {"from": "gpt", "value": "Chair"}, {"from": "human", "value": "Who is on the chair?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "What length is the hair?"}, {"from": "gpt", "value": "Short"}, {"from": "human", "value": "On which side of the picture is the speaker?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "What is on the wall?"}, {"from": "gpt", "value": "Speaker"}, {"from": "human", "value": "Is the chair in the bottom?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2389438, "image": "gqa/images/2389438.jpg", "conversations": [{"from": "human", "value": "<image>\nHow is the weather?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Foggy"}, {"from": "human", "value": "What color is the grass?"}, {"from": "gpt", "value": "Brown"}]}, {"id": 2322737, "image": "gqa/images/2322737.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat does the girl in the ocean wear?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Shorts"}, {"from": "human", "value": "Is the girl on the left or on the right side?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Who do you think wears shorts?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "Which color is the hair, red or black?"}, {"from": "gpt", "value": "Red"}, {"from": "human", "value": "The tail is of what color?"}, {"from": "gpt", "value": "Red"}, {"from": "human", "value": "Who is wearing shorts?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "Where was the picture taken?"}, {"from": "gpt", "value": "Ocean"}, {"from": "human", "value": "What is the color of the trousers?"}, {"from": "gpt", "value": "Brown"}, {"from": "human", "value": "Are these people female?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Which side of the picture is the girl on?"}, {"from": "gpt", "value": "Right"}]}, {"id": 2326042, "image": "gqa/images/2326042.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich kind of vegetable is to the left of the lettuce?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Tomato"}, {"from": "human", "value": "What kind of vegetable is on the sandwich?"}, {"from": "gpt", "value": "Lettuce"}, {"from": "human", "value": "Is there a sandwich to the right of the white bowl?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which kind of food is the tomato on?"}, {"from": "gpt", "value": "Sandwich"}, {"from": "human", "value": "The tomato is on what?"}, {"from": "gpt", "value": "Sandwich"}, {"from": "human", "value": "Is the lettuce on the sandwich that is to the right of the cup?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "On which side is the spoon?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What type of food is on the food with the lettuce?"}, {"from": "gpt", "value": "Shrimp"}, {"from": "human", "value": "On which side is the shrimp?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Which kind of food is on the sandwich?"}, {"from": "gpt", "value": "Shrimp"}, {"from": "human", "value": "How is the food in the bowl to the right of the tomato called?"}, {"from": "gpt", "value": "Soup"}, {"from": "human", "value": "How is the food that the spoon is in called?"}, {"from": "gpt", "value": "Soup"}, {"from": "human", "value": "What kind of food is in the bowl?"}, {"from": "gpt", "value": "Soup"}, {"from": "human", "value": "What color is the liquid that is in the cup?"}, {"from": "gpt", "value": "Brown"}, {"from": "human", "value": "What is in the cup to the left of the sandwich?"}, {"from": "gpt", "value": "Liquid"}, {"from": "human", "value": "Does the lemon look yellow and small?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the sandwich to the left or to the right of the bowl?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "What do you think is the sandwich on?"}, {"from": "gpt", "value": "Plate"}, {"from": "human", "value": "What type of vegetable is to the left of the bowl?"}, {"from": "gpt", "value": "Tomato"}, {"from": "human", "value": "What type of food is not white, the bread or the tomato?"}, {"from": "gpt", "value": "Tomato"}, {"from": "human", "value": "Is the white food to the left of the cup on the left?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the food to the left of the vegetable that is to the left of the lettuce?"}, {"from": "gpt", "value": "Shrimp"}, {"from": "human", "value": "What kind of food is to the left of the bowl?"}, {"from": "gpt", "value": "Sandwich"}, {"from": "human", "value": "Is the bowl to the left or to the right of the tomato?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Is there any meat on the food with the lettuce?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What kind of food is the shrimp on?"}, {"from": "gpt", "value": "Sandwich"}, {"from": "human", "value": "What color is the soup?"}, {"from": "gpt", "value": "Orange"}, {"from": "human", "value": "Are there fruits in the bowl?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What kind of vegetable is to the right of the tomato?"}, {"from": "gpt", "value": "Lettuce"}, {"from": "human", "value": "Is the silver spoon to the right of a bread?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What vegetable is on the plate?"}, {"from": "gpt", "value": "Lemon"}, {"from": "human", "value": "What is the vegetable on the plate?"}, {"from": "gpt", "value": "Lemon"}, {"from": "human", "value": "Is there a bottle on the table?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the bread to the left or to the right of the spoon?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Do you see either any snacks or lemons?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Which kind of food is not white?"}, {"from": "gpt", "value": "Tomato"}, {"from": "human", "value": "Is the table different in color than the bowl?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is there a bread to the left of the orange food?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2332999, "image": "gqa/images/2332999.jpg", "conversations": [{"from": "human", "value": "<image>\nOn which side of the picture is the shelf, the right or the left?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is the shelf on the left or on the right side?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is the green bottle to the right or to the left of the man that is wearing a tie?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Where is the drawer, on the left or on the right of the image?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Who is wearing a tie?"}, {"from": "gpt", "value": "Man"}, {"from": "human", "value": "What is the item of furniture to the left of the man on the left?"}, {"from": "gpt", "value": "Shelf"}, {"from": "human", "value": "Is there a bottle to the right of the man that is wearing a tie?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there both glasses and ties in the photo?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the shelf on the right side?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there either mugs or juice boxes?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the piece of furniture to the left of the man that is wearing a shirt called?"}, {"from": "gpt", "value": "Drawer"}, {"from": "human", "value": "On which side of the image is the drawer?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "What piece of furniture is to the right of the man on the left side of the photo?"}, {"from": "gpt", "value": "Drawer"}, {"from": "human", "value": "Do you see drawers to the left of the man on the left?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color are the pants?"}, {"from": "gpt", "value": "Tan"}, {"from": "human", "value": "Do the trousers look long and tan?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there any shelves to the left of the drawer in the bottom?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the man to the right of the drawer wearing a coat?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there any bottles to the left of the man that is leaning on the counter?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2386182, "image": "gqa/images/2386182.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat's the bench made of?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Metal"}, {"from": "human", "value": "Which color is the bench made of metal?"}, {"from": "gpt", "value": "Silver"}, {"from": "human", "value": "Are the people to the left of the vehicle on the platform?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What vehicle is parked?"}, {"from": "gpt", "value": "Train"}, {"from": "human", "value": "Who is standing on the platform?"}, {"from": "gpt", "value": "People"}, {"from": "human", "value": "What are the people near the train standing on?"}, {"from": "gpt", "value": "Platform"}, {"from": "human", "value": "Are there elephants near the people on the right?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Does the wall have the same material as the bench?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there either any elbow pads or mirrors?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are the people to the left or to the right of the bench?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Who is boarding the train?"}, {"from": "gpt", "value": "People"}, {"from": "human", "value": "Who is boarding the parked train on the platform?"}, {"from": "gpt", "value": "People"}, {"from": "human", "value": "Which kind of vehicle are the people boarding?"}, {"from": "gpt", "value": "Train"}, {"from": "human", "value": "What are the people on?"}, {"from": "gpt", "value": "Platform"}, {"from": "human", "value": "The people are on what?"}, {"from": "gpt", "value": "Platform"}, {"from": "human", "value": "Are the people to the right of the bench boarding a bus?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there any blue bicycles or kites?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What's the train on?"}, {"from": "gpt", "value": "Platform"}, {"from": "human", "value": "The train is on what?"}, {"from": "gpt", "value": "Platform"}, {"from": "human", "value": "What color is the train?"}, {"from": "gpt", "value": "Silver"}, {"from": "human", "value": "Are there any doors or trains that are silver?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "On which side are the people?"}, {"from": "gpt", "value": "Right"}]}, {"id": 2403464, "image": "gqa/images/2403464.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat's in front of the tree?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Plants"}, {"from": "human", "value": "What is in front of the tree that is gray?"}, {"from": "gpt", "value": "Plants"}, {"from": "human", "value": "Are the green plants behind a fire hydrant?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "The hydrant has what color?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "What is in front of the plants that are not short?"}, {"from": "gpt", "value": "Fire hydrant"}, {"from": "human", "value": "That hydrant is in front of what?"}, {"from": "gpt", "value": "Plants"}, {"from": "human", "value": "What is the fire hydrant in front of?"}, {"from": "gpt", "value": "Plants"}, {"from": "human", "value": "Is the hydrant in front of the plants white and metallic?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the color of the chain next to the other chain?"}, {"from": "gpt", "value": "White"}]}, {"id": 2415572, "image": "gqa/images/2415572.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the color of the car on the road?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Tan"}, {"from": "human", "value": "What type of vehicle is behind the young person?"}, {"from": "gpt", "value": "Car"}, {"from": "human", "value": "Behind what vehicle is the tree?"}, {"from": "gpt", "value": "Car"}, {"from": "human", "value": "Are the shoes different in color than the trousers?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the black car behind the tree that is not large?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Who wears a coat?"}, {"from": "gpt", "value": "Man"}, {"from": "human", "value": "Do you see men in front of the tan car?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Of which color are the shoes?"}, {"from": "gpt", "value": "Black"}, {"from": "human", "value": "Is the small tree behind the black car?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are the pants red or black?"}, {"from": "gpt", "value": "Black"}, {"from": "human", "value": "What color is the coat he is wearing?"}, {"from": "gpt", "value": "Black"}, {"from": "human", "value": "What is on the pole?"}, {"from": "gpt", "value": "Sign"}, {"from": "human", "value": "What's on the pole?"}, {"from": "gpt", "value": "Sign"}, {"from": "human", "value": "What is in front of the tree?"}, {"from": "gpt", "value": "Car"}, {"from": "human", "value": "What vehicle is in front of the small tree?"}, {"from": "gpt", "value": "Car"}, {"from": "human", "value": "What vehicle is he in front of, a car or a bus?"}, {"from": "gpt", "value": "Car"}, {"from": "human", "value": "What vehicle is the man in front of?"}, {"from": "gpt", "value": "Car"}]}, {"id": 2319786, "image": "gqa/images/2319786.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat do both the kitchen and the shirt have in common?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Color"}, {"from": "human", "value": "What do both the crate and the bottle have in common?"}, {"from": "gpt", "value": "Material"}, {"from": "human", "value": "What is the clothing item that is white?"}, {"from": "gpt", "value": "Shirt"}, {"from": "human", "value": "What is the crate made of?"}, {"from": "gpt", "value": "Plastic"}, {"from": "human", "value": "Which side of the photo is the shelf on?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "What is the piece of furniture to the left of him?"}, {"from": "gpt", "value": "Shelf"}, {"from": "human", "value": "What is the bottle made of?"}, {"from": "gpt", "value": "Plastic"}, {"from": "human", "value": "What clothing item is not white?"}, {"from": "gpt", "value": "Cap"}, {"from": "human", "value": "Is the happy person to the left or to the right of the shelf on the left?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Is he to the right or to the left of the plastic bottle?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Who do you think is in front of the wall?"}, {"from": "gpt", "value": "Man"}, {"from": "human", "value": "What is the piece of furniture to the left of the crate?"}, {"from": "gpt", "value": "Shelf"}, {"from": "human", "value": "On which side of the picture is the plastic bottle?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Do you see either a mug or a bottle that are made of glass?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the item of furniture that is in the white kitchen?"}, {"from": "gpt", "value": "Table"}, {"from": "human", "value": "Are there any juice boxes or bottles in the scene?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2347783, "image": "gqa/images/2347783.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the pepperoni to the left of the cheese red and round?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is there either a black plate or cup?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there bottles or pizzas?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the mozzarella cheese on?"}, {"from": "gpt", "value": "Plate"}, {"from": "human", "value": "On which side of the photo is the cheese?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Are the peppers that are not thin green and large?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Does the pepperoni to the right of the pizza have round shape and red color?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How large are the peppers on the pizza?"}, {"from": "gpt", "value": "Small"}, {"from": "human", "value": "What are the vegetables that are on the pizza the pepperoni is to the left of?"}, {"from": "gpt", "value": "Peppers"}, {"from": "human", "value": "Is the cup in the bottom or in the top of the photo?"}, {"from": "gpt", "value": "Top"}, {"from": "human", "value": "Is the wood table on a plate?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is there pepperoni to the right of the cheese?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What type of meat is to the left of the small peppers?"}, {"from": "gpt", "value": "Pepperoni"}, {"from": "human", "value": "How thick is the pizza with the peppers?"}, {"from": "gpt", "value": "Thin"}, {"from": "human", "value": "Is the cheese to the right of a tomato?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there any crackers or carrots in the photo?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is there a pepper on the cheese pizza?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Does the plate to the right of the cup look green?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Do you see any bottles on the table that is made of wood?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the cup to the right or to the left of the plate in the top part of the photo?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "What is the color of the plate the pizza is on?"}, {"from": "gpt", "value": "Black"}, {"from": "human", "value": "Are there either any spoons or plates?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there any black bottles or plates?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there silver knives or cups?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Do you see both knives and cups?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which color is the cup?"}, {"from": "gpt", "value": "Silver"}]}, {"id": 2343006, "image": "gqa/images/2343006.jpg", "conversations": [{"from": "human", "value": "<image>\nDo you see both grass and sand there?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the train engine in front of?"}, {"from": "gpt", "value": "Train car"}, {"from": "human", "value": "What is on the bridge?"}, {"from": "gpt", "value": "Train car"}, {"from": "human", "value": "What vehicle is on the bridge?"}, {"from": "gpt", "value": "Train car"}, {"from": "human", "value": "What color is the cloudy sky?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "Is the locomotive to the left or to the right of the train car on the bridge?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Are there long fences or trains?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Does the train car to the right of the other train car look blue?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "On which side of the image are the animals, the left or the right?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What is the train in front of?"}, {"from": "gpt", "value": "Mountains"}, {"from": "human", "value": "Is the train engine in front of the train car that is on the bridge?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What's the train in front of?"}, {"from": "gpt", "value": "Mountains"}, {"from": "human", "value": "What vehicle are the mountains behind of?"}, {"from": "gpt", "value": "Train"}]}, {"id": 2364627, "image": "gqa/images/2364627.jpg", "conversations": [{"from": "human", "value": "<image>\nIs there a horse or a giraffe that is young?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Does the horse in front of the house seem to be jumping?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Does the horse that is standing look colorful?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the horse that is not old white and calm?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What's in the sky?"}, {"from": "gpt", "value": "Clouds"}, {"from": "human", "value": "What animal is white?"}, {"from": "gpt", "value": "Horse"}, {"from": "human", "value": "What is the young animal?"}, {"from": "gpt", "value": "Horse"}]}, {"id": 713148, "image": "gqa/images/713148.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is on the street?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Bus"}, {"from": "human", "value": "What is the color of the letters?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "Are there any doors?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there any cars or buses?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What kind of vehicle has the same color as the canopy?"}, {"from": "gpt", "value": "Bus"}, {"from": "human", "value": "Do you see white letters?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Does the bus on the street look large and red?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there taxis on the street?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there both doors and windows in the image?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there both a door and a window in the picture?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is this a bus or a train?"}, {"from": "gpt", "value": "Bus"}, {"from": "human", "value": "What place does this represent?"}, {"from": "gpt", "value": "Sidewalk"}]}, {"id": 2375525, "image": "gqa/images/2375525.jpg", "conversations": [{"from": "human", "value": "<image>\nHow is the aircraft that is to the left of the person on the right called?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Jet"}, {"from": "human", "value": "What type of place is shown?"}, {"from": "gpt", "value": "Runway"}, {"from": "human", "value": "Which place is it?"}, {"from": "gpt", "value": "Runway"}, {"from": "human", "value": "In which part of the image is the yellow vehicle, the top or the bottom?"}, {"from": "gpt", "value": "Top"}, {"from": "human", "value": "What is the grass beside the runway covering?"}, {"from": "gpt", "value": "Mound"}, {"from": "human", "value": "What is covered by the grass which is beside the runway?"}, {"from": "gpt", "value": "Mound"}, {"from": "human", "value": "Is there a bag to the left of the person in the top part of the image?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the covered mound covered by the grass beside the runway?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the vehicle yellow?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2393141, "image": "gqa/images/2393141.jpg", "conversations": [{"from": "human", "value": "<image>\nAre there women or drivers?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the catcher wearing?"}, {"from": "gpt", "value": "Uniform"}, {"from": "human", "value": "What is the person that is standing wearing?"}, {"from": "gpt", "value": "Helmet"}, {"from": "human", "value": "Does the shirt of the catcher look black?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a beach?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there either any black tennis rackets or bats?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Who is wearing a uniform?"}, {"from": "gpt", "value": "Catcher"}, {"from": "human", "value": "Who is wearing a helmet?"}, {"from": "gpt", "value": "Player"}, {"from": "human", "value": "Does the player seem to be walking?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Who is standing?"}, {"from": "gpt", "value": "Player"}, {"from": "human", "value": "Is the bat skinny and black?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What color are the pants the man is wearing?"}, {"from": "gpt", "value": "Gray"}, {"from": "human", "value": "Who is wearing pants?"}, {"from": "gpt", "value": "Man"}, {"from": "human", "value": "Who is wearing the pants?"}, {"from": "gpt", "value": "Man"}]}, {"id": 2360375, "image": "gqa/images/2360375.jpg", "conversations": [{"from": "human", "value": "<image>\nDo you see cows below the green trees?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How is the weather?"}, {"from": "gpt", "value": "Clear"}, {"from": "human", "value": "Is there a duck or a cow in the picture?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is in front of the cow on the left side?"}, {"from": "gpt", "value": "Trees"}, {"from": "human", "value": "Which color do you think the cows that are walking are?"}, {"from": "gpt", "value": "Black"}, {"from": "human", "value": "What is the animal in the forest called?"}, {"from": "gpt", "value": "Cow"}, {"from": "human", "value": "What kind of animal is below the green trees?"}, {"from": "gpt", "value": "Cow"}, {"from": "human", "value": "What animal is in the forest?"}, {"from": "gpt", "value": "Cow"}, {"from": "human", "value": "What are the leaves on?"}, {"from": "gpt", "value": "Trees"}, {"from": "human", "value": "Are there houses behind the green trees?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which place is it?"}, {"from": "gpt", "value": "Forest"}, {"from": "human", "value": "What color is the cow the trees are above?"}, {"from": "gpt", "value": "Brown"}, {"from": "human", "value": "What animal is under the green trees?"}, {"from": "gpt", "value": "Cow"}, {"from": "human", "value": "How thick are the leaves on the trees?"}, {"from": "gpt", "value": "Thick"}]}, {"id": 2376567, "image": "gqa/images/2376567.jpg", "conversations": [{"from": "human", "value": "<image>\nOn which side is the bear?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "On which side of the image is the car?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "How clean is the fence?"}, {"from": "gpt", "value": "Clean"}, {"from": "human", "value": "Is the fence clean and white?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What place is this image in?"}, {"from": "gpt", "value": "Yard"}, {"from": "human", "value": "Which place is it?"}, {"from": "gpt", "value": "Yard"}, {"from": "human", "value": "What is the bear on?"}, {"from": "gpt", "value": "Fence"}, {"from": "human", "value": "On which side of the picture is the white animal?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What is that bear on?"}, {"from": "gpt", "value": "Fence"}, {"from": "human", "value": "Is there a bag or a bicycle in the image?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Does the ground look leafy or bare?"}, {"from": "gpt", "value": "Leafy"}, {"from": "human", "value": "Which color is the fence?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "Are the animals of different types?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Do the dog and the van have a different colors?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "In which part is the bicycle?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Where is the bicycle?"}, {"from": "gpt", "value": "Porch"}, {"from": "human", "value": "Is there a bicycle on the porch?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What animal is on the white fence?"}, {"from": "gpt", "value": "Bear"}, {"from": "human", "value": "What is the animal that is on the fence that is not dirty?"}, {"from": "gpt", "value": "Bear"}, {"from": "human", "value": "Are there toilets or fences that are clean?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2417603, "image": "gqa/images/2417603.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich color is this couch?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Tan"}, {"from": "human", "value": "What are the denim clothing items?"}, {"from": "gpt", "value": "Jeans"}, {"from": "human", "value": "What item of furniture in this picture is tan?"}, {"from": "gpt", "value": "Couch"}, {"from": "human", "value": "Is this a cabinet or a couch?"}, {"from": "gpt", "value": "Couch"}, {"from": "human", "value": "What is the white item of furniture?"}, {"from": "gpt", "value": "Shelf"}, {"from": "human", "value": "Is the shelf on the right side?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the man to the left of the shelf wearing glasses?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What kind of furniture is white?"}, {"from": "gpt", "value": "Shelf"}, {"from": "human", "value": "What is the man to the left of the shelf wearing?"}, {"from": "gpt", "value": "Jeans"}]}, {"id": 2405353, "image": "gqa/images/2405353.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the chair on the left side?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is it indoors?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is there a chair to the right of the palm by the pool?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there any hotels or stores that are not white?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there either birds or kites in the picture?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How large is that pool?"}, {"from": "gpt", "value": "Small"}, {"from": "human", "value": "Does the hotel have white color?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the color of the sea different than the color of the sky?"}, {"from": "gpt", "value": "No"}]}, {"id": 2338020, "image": "gqa/images/2338020.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat vehicle is the girl inside of?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Bus"}, {"from": "human", "value": "Who is inside the bus?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "Who is standing in front of the bus?"}, {"from": "gpt", "value": "Man"}, {"from": "human", "value": "Is the man to the right of the soda standing in front of the bus that the girl is inside of?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Who is inside the vehicle that the man is standing in front of?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "What is the vehicle that the girl is inside of?"}, {"from": "gpt", "value": "Bus"}, {"from": "human", "value": "Which side is the woman on?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Are there any chalkboards or carts in this photo?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "The person in the kitchen is wearing what?"}, {"from": "gpt", "value": "Hat"}, {"from": "human", "value": "What's the girl wearing?"}, {"from": "gpt", "value": "Hat"}, {"from": "human", "value": "Which color is the bag the woman is holding?"}, {"from": "gpt", "value": "Orange"}, {"from": "human", "value": "What is the man wearing?"}, {"from": "gpt", "value": "Pants"}, {"from": "human", "value": "Are these people of the same gender?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Who is wearing a hat?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "Is the man to the left or to the right of the napkins?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Is the girl inside a train?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What vehicle is it?"}, {"from": "gpt", "value": "Bus"}, {"from": "human", "value": "Do you see either any bags or umbrellas?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What type of vehicle does the person to the right of the napkins look at?"}, {"from": "gpt", "value": "Bus"}, {"from": "human", "value": "What does the man look at?"}, {"from": "gpt", "value": "Bus"}, {"from": "human", "value": "What does the person that to the right of the utensils look at?"}, {"from": "gpt", "value": "Bus"}, {"from": "human", "value": "Is the man in front of a fence?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there girls in the kitchen?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the man to the left or to the right of the soda?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Do you see any orange letters or cones?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Who is wearing the hat?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "Who is in front of the bus?"}, {"from": "gpt", "value": "Man"}, {"from": "human", "value": "The man is in front of what?"}, {"from": "gpt", "value": "Bus"}, {"from": "human", "value": "Is the girl to the right of the soda wearing a hat?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Who is talking to the man?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "What vehicle is behind the man?"}, {"from": "gpt", "value": "Bus"}, {"from": "human", "value": "What vehicle do you think is behind the man the girl is talking to?"}, {"from": "gpt", "value": "Bus"}, {"from": "human", "value": "Do you see either a orange bag or chair?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2383334, "image": "gqa/images/2383334.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the parked vehicle in front of the truck bright and white?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What vehicle is white, the truck or the car?"}, {"from": "gpt", "value": "Truck"}, {"from": "human", "value": "Is the white vehicle behind the vehicle in the bottom of the photo?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What color is the shirt the man is wearing?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "Does the bus stop look blue?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Which kind of vehicle is in front of the truck?"}, {"from": "gpt", "value": "Car"}, {"from": "human", "value": "Is the blue vehicle in front of the truck?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Does the tire look gray and round?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is he wearing?"}, {"from": "gpt", "value": "Shirt"}, {"from": "human", "value": "What is that car in front of?"}, {"from": "gpt", "value": "Truck"}, {"from": "human", "value": "Is the truck to the left or to the right of him?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Does that truck look bright and white?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the color of the jeans?"}, {"from": "gpt", "value": "Gray"}, {"from": "human", "value": "What does the roof cover?"}, {"from": "gpt", "value": "Bus stop"}, {"from": "human", "value": "What is the bus stop covered by?"}, {"from": "gpt", "value": "Roof"}, {"from": "human", "value": "What is covered by the roof?"}, {"from": "gpt", "value": "Bus stop"}, {"from": "human", "value": "Is the tree above an animal?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which kind of clothing is blue?"}, {"from": "gpt", "value": "Shirt"}, {"from": "human", "value": "Is the color of the car different than the sign?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the car in front of, a bus or a truck?"}, {"from": "gpt", "value": "Truck"}, {"from": "human", "value": "Is the blue vehicle in front or behind the truck that is to the right of the man?"}, {"from": "gpt", "value": "Front"}, {"from": "human", "value": "Is the blue vehicle to the left of the truck?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2376319, "image": "gqa/images/2376319.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the person to the right of the garbage can wearing a watch?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Who is wearing an earring?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "Who is wearing the earring?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "Which kind of clothing is black?"}, {"from": "gpt", "value": "Apron"}, {"from": "human", "value": "Are the tongs to the right or to the left of the food in the middle?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Are there either pots or chefs in this image?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the black clothing item?"}, {"from": "gpt", "value": "Apron"}, {"from": "human", "value": "What's on the grill?"}, {"from": "gpt", "value": "Lid"}, {"from": "human", "value": "What is on the grill?"}, {"from": "gpt", "value": "Lid"}, {"from": "human", "value": "What kind of vehicle is to the right of the trash can?"}, {"from": "gpt", "value": "Truck"}, {"from": "human", "value": "What kind of fast food is to the right of the tongs on the left side of the image?"}, {"from": "gpt", "value": "Hot dog"}, {"from": "human", "value": "Who is wearing the apron?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "Is the garbage bin to the left or to the right of him?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "What cooking utensils are to the left of the hot dog?"}, {"from": "gpt", "value": "Tongs"}, {"from": "human", "value": "What is the boy doing?"}, {"from": "gpt", "value": "Cooking"}, {"from": "human", "value": "Who is cooking?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "What is the lid on?"}, {"from": "gpt", "value": "Grill"}, {"from": "human", "value": "On which side of the photo is the pan?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Who is wearing an apron?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "What's the boy using?"}, {"from": "gpt", "value": "Pan"}, {"from": "human", "value": "Who is using the pan?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "On which side is the garbage bin?"}, {"from": "gpt", "value": "Left"}]}, {"id": 2327520, "image": "gqa/images/2327520.jpg", "conversations": [{"from": "human", "value": "<image>\nAre there either white ostriches or bears?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What do you think is in front of the sky?"}, {"from": "gpt", "value": "Trees"}, {"from": "human", "value": "What are the trees in front of?"}, {"from": "gpt", "value": "Sky"}, {"from": "human", "value": "On which side is the lady?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Do all these people have the same gender?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the brown animal in the bottom or in the top of the picture?"}, {"from": "gpt", "value": "Top"}]}, {"id": 2332912, "image": "gqa/images/2332912.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the large bear sitting on?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Car"}, {"from": "human", "value": "What is the animal that is sitting on the car?"}, {"from": "gpt", "value": "Bear"}, {"from": "human", "value": "What is the black vehicle?"}, {"from": "gpt", "value": "Car"}, {"from": "human", "value": "On which side is the small flag?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What kind of animal is large?"}, {"from": "gpt", "value": "Bear"}, {"from": "human", "value": "What kind of animal is to the left of the flag?"}, {"from": "gpt", "value": "Bear"}, {"from": "human", "value": "Are there any large flags or balloons?"}, {"from": "gpt", "value": "No"}]}, {"id": 2389226, "image": "gqa/images/2389226.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the color of the ball on the grass?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "In which part of the photo is the ball, the top or the bottom?"}, {"from": "gpt", "value": "Bottom"}, {"from": "human", "value": "Does the woman that is sitting-down sit on a chair?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What bag does the woman to the right of the soccer ball carry?"}, {"from": "gpt", "value": "Backpack"}, {"from": "human", "value": "Is the soccer ball blue?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Does the jacket have the same color as the blanket?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the color of the grass?"}, {"from": "gpt", "value": "Light brown"}, {"from": "human", "value": "Is there any grass in the photo that is green?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the woman on the grass carrying a backpack?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Who is wearing shorts?"}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "Is the blanket striped and blue?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the pattern of the blanket?"}, {"from": "gpt", "value": "Checkered"}, {"from": "human", "value": "What is the man holding?"}, {"from": "gpt", "value": "Frisbee"}, {"from": "human", "value": "The man is holding what?"}, {"from": "gpt", "value": "Frisbee"}, {"from": "human", "value": "Who is wearing sneakers?"}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "Who wears the pants?"}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "Who wears pants?"}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "Are there both a bag and a woman in the picture?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the backpack to the left or to the right of the woman that is wearing trousers?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Which side is the backpack on?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Who is wearing the jacket?"}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "Which color is the tee shirt?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "Is there a fence or a bicycle in this scene?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the woman on the grass wearing a boot?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the blue blanket to the right or to the left of the woman that is wearing a jacket?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is the woman on the grass wearing a skirt?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Who do you think is wearing a boot?"}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "Is there a ball on the grass that looks light brown?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the plastic bag to the left of a football?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What does the woman that is sitting-down sit on?"}, {"from": "gpt", "value": "Blanket"}, {"from": "human", "value": "Who sits on the blanket?"}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "Who sits on the blue blanket?"}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "Is there a soccer ball that is not pink?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there any checkered blankets in this photo?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Who is sitting?"}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "Is the man wearing a hat?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What's the man wearing?"}, {"from": "gpt", "value": "Shirt"}, {"from": "human", "value": "Which side is the man on?"}, {"from": "gpt", "value": "Left"}]}, {"id": 2416820, "image": "gqa/images/2416820.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat are the pieces of furniture to the left of the glasses in the middle called?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Tables"}, {"from": "human", "value": "Which kind of furniture is to the left of the glasses?"}, {"from": "gpt", "value": "Tables"}, {"from": "human", "value": "What item of furniture is to the left of the glasses?"}, {"from": "gpt", "value": "Chair"}, {"from": "human", "value": "Is the blond woman to the right or to the left of the man who is to the right of the tables?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "How is the black clothing item called?"}, {"from": "gpt", "value": "Coat"}, {"from": "human", "value": "Is there a tie in the photograph?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Do the tables to the left of the glasses look white?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What clothing item is long?"}, {"from": "gpt", "value": "Coat"}, {"from": "human", "value": "Do you see either any white plates or tables?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What color is the coat?"}, {"from": "gpt", "value": "Black"}, {"from": "human", "value": "Are the man's lips black?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "On which side is the woman?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Is there any black coat or bag?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Does the woman's hair look brown?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the coat both long and black?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is there a chair to the left of the glasses the woman is to the right of?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What pieces of furniture are to the left of the glasses?"}, {"from": "gpt", "value": "Chairs"}, {"from": "human", "value": "Are all the people of the same gender?"}, {"from": "gpt", "value": "No"}]}, {"id": 558, "image": "gqa/images/558.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is on the table the curtain is to the left of?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Plant"}, {"from": "human", "value": "What color do you think is the house that the tree is behind of?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "Is the sky blue?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there couches in front of the curtain that looks white and black?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the mirror in front of?"}, {"from": "gpt", "value": "Curtain"}, {"from": "human", "value": "What is in front of the curtain that looks white and black?"}, {"from": "gpt", "value": "Mirror"}, {"from": "human", "value": "Is the curtain behind the mirror both white and striped?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Does the pillow have green color?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are the sky and the pillow the same color?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "On which side of the image is the mirror?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What is the house in front of?"}, {"from": "gpt", "value": "Tree"}, {"from": "human", "value": "Where is the rug?"}, {"from": "gpt", "value": "Ground"}, {"from": "human", "value": "Is the tall tree in front of a house?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which side is the house on?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "What color is the curtain that is in the top?"}, {"from": "gpt", "value": "Black"}, {"from": "human", "value": "Are there any curtains behind the mirror?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is there either a television or a chair in the image?"}, {"from": "gpt", "value": "No"}]}, {"id": 2402904, "image": "gqa/images/2402904.jpg", "conversations": [{"from": "human", "value": "<image>\nDoes the person that is to the left of the dog look Caucasian or Asian?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Asian"}, {"from": "human", "value": "What is the color of the tennis net?"}, {"from": "gpt", "value": "Black"}, {"from": "human", "value": "What is the color of the fence?"}, {"from": "gpt", "value": "Silver"}, {"from": "human", "value": "Are there either notebooks or lipsticks?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the shoe black?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Who is swinging the racket?"}, {"from": "gpt", "value": "Man"}, {"from": "human", "value": "Do the shorts look white or khaki?"}, {"from": "gpt", "value": "Khaki"}, {"from": "human", "value": "Is the tennis racket in the top or in the bottom of the picture?"}, {"from": "gpt", "value": "Top"}, {"from": "human", "value": "What is he wearing?"}, {"from": "gpt", "value": "Shirt"}, {"from": "human", "value": "Is the Asian man swinging a racket?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the dog on the right or on the left?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "How long is the brown hair?"}, {"from": "gpt", "value": "Short"}, {"from": "human", "value": "Are there any mailboxes or boys in the image?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is he playing?"}, {"from": "gpt", "value": "Tennis"}, {"from": "human", "value": "Who is playing tennis?"}, {"from": "gpt", "value": "Man"}, {"from": "human", "value": "Is the logo on a surfboard?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the animal that is to the right of the man doing?"}, {"from": "gpt", "value": "Playing"}]}, {"id": 2402209, "image": "gqa/images/2402209.jpg", "conversations": [{"from": "human", "value": "<image>\nDo you see trucks in this scene?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "On which side is the white vehicle?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is the happy woman in the top part or in the bottom of the image?"}, {"from": "gpt", "value": "Bottom"}, {"from": "human", "value": "Is the truck to the left or to the right of the man that the woman is to the right of?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "What color is the clock?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "Is the man to the left or to the right of the woman who is wearing a shirt?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Who is wearing the shirt?"}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "Do you see trucks that are white?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the vehicle to the left of the woman who wears a shirt called?"}, {"from": "gpt", "value": "Truck"}, {"from": "human", "value": "What is the happy woman wearing?"}, {"from": "gpt", "value": "Jacket"}, {"from": "human", "value": "In which part of the image is the woman, the top or the bottom?"}, {"from": "gpt", "value": "Bottom"}, {"from": "human", "value": "Is the man to the right or to the left of the woman that is wearing a jacket?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is the color of the clock the same as the truck?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Who is wearing a jacket?"}, {"from": "gpt", "value": "Woman"}]}, {"id": 150430, "image": "gqa/images/150430.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the snow board to the left of the person in the middle?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the blue fence on the left?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the snowboard blue?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Who is wearing a helmet?"}, {"from": "gpt", "value": "Snowboarder"}, {"from": "human", "value": "Are there both a fence and a helmet in this photo?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Do you see any black coats?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color do you think is the coat?"}, {"from": "gpt", "value": "Yellow"}, {"from": "human", "value": "What's the snowboarder doing?"}, {"from": "gpt", "value": "Resting"}, {"from": "human", "value": "Who is resting?"}, {"from": "gpt", "value": "Snowboarder"}, {"from": "human", "value": "Are there either umbrellas or shampoos?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the snowboard different in color than the sky?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the helmet to the left or to the right of the person that is to the left of the backpack?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is the backpack on the right side?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What color is that fence?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "Who is dressed in black?"}, {"from": "gpt", "value": "Snowboarder"}, {"from": "human", "value": "Does the snowboarder on top of the snow appear to be resting?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "In which part of the photo is the snowboarder, the bottom or the top?"}, {"from": "gpt", "value": "Bottom"}, {"from": "human", "value": "Who is sitting?"}, {"from": "gpt", "value": "Snowboarder"}, {"from": "human", "value": "Who is wearing the helmet?"}, {"from": "gpt", "value": "Snowboarder"}, {"from": "human", "value": "What is the person that is resting wearing?"}, {"from": "gpt", "value": "Helmet"}, {"from": "human", "value": "Is that snowboarder wearing a glove?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Do the jacket and the coat have a different colors?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the color of the helmet the snowboarder is wearing?"}, {"from": "gpt", "value": "Gray"}, {"from": "human", "value": "On which side is the helmet?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "What color is the bag which is to the right of the person?"}, {"from": "gpt", "value": "Green"}, {"from": "human", "value": "What color is the jacket?"}, {"from": "gpt", "value": "Yellow"}, {"from": "human", "value": "Are there green backpacks?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2338439, "image": "gqa/images/2338439.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the white vehicle in the bottom of the image?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which side of the image is the open umbrella on?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is the skirt yellow?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the color of the bananas that are to the right of the person?"}, {"from": "gpt", "value": "Green"}]}, {"id": 2390177, "image": "gqa/images/2390177.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat kind of animal is it?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Dog"}, {"from": "human", "value": "What is the white animal called?"}, {"from": "gpt", "value": "Dog"}, {"from": "human", "value": "Which kind of animal is white?"}, {"from": "gpt", "value": "Dog"}, {"from": "human", "value": "Does the fur look white?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What animal stands in the car?"}, {"from": "gpt", "value": "Dog"}, {"from": "human", "value": "Where does the white animal next to the window stand?"}, {"from": "gpt", "value": "Car"}, {"from": "human", "value": "Is the window shut or open?"}, {"from": "gpt", "value": "Open"}, {"from": "human", "value": "What is the dog sitting in?"}, {"from": "gpt", "value": "Car"}, {"from": "human", "value": "What vehicle is large?"}, {"from": "gpt", "value": "Car"}, {"from": "human", "value": "What is the vehicle that is large?"}, {"from": "gpt", "value": "Car"}, {"from": "human", "value": "What vehicle is red?"}, {"from": "gpt", "value": "Car"}, {"from": "human", "value": "What animal stands in the red car?"}, {"from": "gpt", "value": "Dog"}, {"from": "human", "value": "Which kind of animal is wearing the collar?"}, {"from": "gpt", "value": "Dog"}, {"from": "human", "value": "What animal is wearing a collar?"}, {"from": "gpt", "value": "Dog"}, {"from": "human", "value": "Is there a dog inside the large car?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Which type is the animal?"}, {"from": "gpt", "value": "Dog"}, {"from": "human", "value": "What is the vehicle that the white animal stands in?"}, {"from": "gpt", "value": "Car"}, {"from": "human", "value": "Where does the dog stand?"}, {"from": "gpt", "value": "Car"}, {"from": "human", "value": "What animal is sitting in the vehicle that is not small?"}, {"from": "gpt", "value": "Dog"}, {"from": "human", "value": "What vehicle is the same color as the door?"}, {"from": "gpt", "value": "Car"}, {"from": "human", "value": "Does the nose seem to be dry?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What size is the red vehicle?"}, {"from": "gpt", "value": "Large"}, {"from": "human", "value": "What color do you think the large vehicle is?"}, {"from": "gpt", "value": "Red"}, {"from": "human", "value": "Which kind of animal is hanging out of the window?"}, {"from": "gpt", "value": "Dog"}, {"from": "human", "value": "What animal is hanging out of the window?"}, {"from": "gpt", "value": "Dog"}]}, {"id": 2354640, "image": "gqa/images/2354640.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich color is the hair?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Brown"}, {"from": "human", "value": "On which side of the picture is the chair?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Are there chairs in this photo?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "On which side are the benches?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Which side is the frisbee on?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What is he wearing?"}, {"from": "gpt", "value": "T-shirt"}, {"from": "human", "value": "What is the man wearing?"}, {"from": "gpt", "value": "T-shirt"}, {"from": "human", "value": "What is the clothing item that is blue?"}, {"from": "gpt", "value": "T-shirt"}, {"from": "human", "value": "Are there any frisbees or toilets?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What kind of clothing is blue?"}, {"from": "gpt", "value": "T-shirt"}, {"from": "human", "value": "What color is the tee shirt the man is wearing?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "Is there a chair to the right of him?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What kind of furniture is the backpack on, a chair or a bed?"}, {"from": "gpt", "value": "Chair"}, {"from": "human", "value": "What is the backpack on?"}, {"from": "gpt", "value": "Chair"}, {"from": "human", "value": "In which part of the picture is the house?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Which kind of furniture is to the left of the man?"}, {"from": "gpt", "value": "Chair"}]}, {"id": 2410565, "image": "gqa/images/2410565.jpg", "conversations": [{"from": "human", "value": "<image>\nDoes the sky look white and cloudy?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What color is the arrow?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "What is on the wall?"}, {"from": "gpt", "value": "Character"}, {"from": "human", "value": "What is on the wall that is shown in the photo?"}, {"from": "gpt", "value": "Character"}, {"from": "human", "value": "Is the color of the jacket the same as the arrow?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is there a fire hydrant on the sidewalk?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the lamp on the left side?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Do you see both lamps and desks?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "On which side of the picture is the person?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What is the person on the sidewalk wearing?"}, {"from": "gpt", "value": "Jacket"}]}, {"id": 1159345, "image": "gqa/images/1159345.jpg", "conversations": [{"from": "human", "value": "<image>\nOn which side of the picture is the car?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "In which part of the photo is the person, the bottom or the top?"}, {"from": "gpt", "value": "Bottom"}, {"from": "human", "value": "Is the van maroon or white?"}, {"from": "gpt", "value": "White"}]}, {"id": 2375305, "image": "gqa/images/2375305.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the person to the left of the man wearing?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Hat"}, {"from": "human", "value": "What is the woman wearing?"}, {"from": "gpt", "value": "Hat"}, {"from": "human", "value": "Is the woman in the top of the photo?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the flag on the left or on the right?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What type of animal is on the poster which is on the street?"}, {"from": "gpt", "value": "Monkey"}, {"from": "human", "value": "Which kind of animal is on the poster?"}, {"from": "gpt", "value": "Monkey"}, {"from": "human", "value": "Does the bridge near the tree look small and metallic?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What's in front of the skyscraper?"}, {"from": "gpt", "value": "Bridge"}, {"from": "human", "value": "Is the bridge made of stone?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the bridge in front of?"}, {"from": "gpt", "value": "Skyscraper"}, {"from": "human", "value": "What is the animal on the poster?"}, {"from": "gpt", "value": "Monkey"}, {"from": "human", "value": "That poster is where?"}, {"from": "gpt", "value": "Street"}, {"from": "human", "value": "What is the name of the animal to the left of the flag on the right of the image?"}, {"from": "gpt", "value": "Monkey"}, {"from": "human", "value": "Is the person that is to the left of the man wearing a hat?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What animal do you think is on the poster that is on the street?"}, {"from": "gpt", "value": "Monkey"}, {"from": "human", "value": "What animal is on the poster?"}, {"from": "gpt", "value": "Monkey"}, {"from": "human", "value": "Are there both giraffes and monkeys in this photograph?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the man in the bottom or in the top part?"}, {"from": "gpt", "value": "Bottom"}, {"from": "human", "value": "How big is the bridge?"}, {"from": "gpt", "value": "Small"}, {"from": "human", "value": "Is the skyscraper behind a bridge?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Do you see any elephants on the poster that is on the street?"}, {"from": "gpt", "value": "No"}]}, {"id": 2384100, "image": "gqa/images/2384100.jpg", "conversations": [{"from": "human", "value": "<image>\nAre there either trains or windows in the picture?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the color of the door?"}, {"from": "gpt", "value": "Red"}, {"from": "human", "value": "Do you see pillows?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "On which side is the picture?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Is the picture on the right side?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Do you think the gate is pink?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "On which side of the image is the picture?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Which side of the image is the picture on?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Do you see a pillow in the image?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the picture on the left of the image?"}, {"from": "gpt", "value": "No"}]}, {"id": 2388586, "image": "gqa/images/2388586.jpg", "conversations": [{"from": "human", "value": "<image>\nAre there chefs or cowboys?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there carts to the right of the horse on the right?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "On which side is the brown horse?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Are there policemen to the left of the brown animal?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the wood cart to the left or to the right of the horse on the right?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "What do you think is the man to the left of the ribs sitting on?"}, {"from": "gpt", "value": "Cart"}, {"from": "human", "value": "Is the brown horse to the right or to the left of the cart the man is sitting on?"}, {"from": "gpt", "value": "Right"}]}, {"id": 2316687, "image": "gqa/images/2316687.jpg", "conversations": [{"from": "human", "value": "<image>\nIs that a bed or a cabinet?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Cabinet"}, {"from": "human", "value": "What piece of furniture is it?"}, {"from": "gpt", "value": "Cabinet"}, {"from": "human", "value": "What is the piece of furniture in the picture?"}, {"from": "gpt", "value": "Cabinet"}, {"from": "human", "value": "What shape is the metal tray?"}, {"from": "gpt", "value": "Round"}, {"from": "human", "value": "What is on the refrigerator?"}, {"from": "gpt", "value": "Magnet"}, {"from": "human", "value": "What is in the full sink?"}, {"from": "gpt", "value": "Pans"}, {"from": "human", "value": "What are the cooking utensils in the sink?"}, {"from": "gpt", "value": "Pans"}, {"from": "human", "value": "What is on the appliance that is on the right?"}, {"from": "gpt", "value": "Magnet"}, {"from": "human", "value": "Does the sink look full?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is in the sink?"}, {"from": "gpt", "value": "Pans"}, {"from": "human", "value": "What cooking utensils are in the sink?"}, {"from": "gpt", "value": "Pans"}, {"from": "human", "value": "What are the pans in?"}, {"from": "gpt", "value": "Sink"}, {"from": "human", "value": "On which side of the picture is the tray?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is the pot on the left side of the picture?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "On which side of the picture is the cabinet?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "On which side of the picture is the freezer?"}, {"from": "gpt", "value": "Right"}]}, {"id": 2351690, "image": "gqa/images/2351690.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat type of vehicle is on the street?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Car"}, {"from": "human", "value": "Which place is it?"}, {"from": "gpt", "value": "City"}, {"from": "human", "value": "The person on the sidewalk is wearing what?"}, {"from": "gpt", "value": "Shirt"}, {"from": "human", "value": "Is the woman wearing a necklace?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there any women?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the red car in the top part or in the bottom of the image?"}, {"from": "gpt", "value": "Bottom"}, {"from": "human", "value": "On which side of the picture is the woman?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What color is the car to the right of the woman?"}, {"from": "gpt", "value": "Red"}, {"from": "human", "value": "Is the woman to the left or to the right of the red car?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is the white car in the top or in the bottom of the picture?"}, {"from": "gpt", "value": "Bottom"}, {"from": "human", "value": "The car to the right of the person is what color?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "Do you see any women that are not walking?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which color is the sky?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "Is the white car to the right of a person?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2393030, "image": "gqa/images/2393030.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat kind of furniture is it?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Table"}, {"from": "human", "value": "What kind of fast food is pictured?"}, {"from": "gpt", "value": "Pizza"}, {"from": "human", "value": "What is the color of the table?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "Do the plate and the table have the same color?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there both utensils and plates?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there either buns or cones?"}, {"from": "gpt", "value": "No"}]}, {"id": 1159419, "image": "gqa/images/1159419.jpg", "conversations": [{"from": "human", "value": "<image>\nDoes the pillow that is to the right of the couch look blue?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the item of furniture that is not gray called?"}, {"from": "gpt", "value": "Table"}, {"from": "human", "value": "Which kind of furniture is gray?"}, {"from": "gpt", "value": "Couch"}, {"from": "human", "value": "Is this a couch or a mirror?"}, {"from": "gpt", "value": "Couch"}, {"from": "human", "value": "How big is the sink?"}, {"from": "gpt", "value": "Small"}, {"from": "human", "value": "Is the counter gray and small?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What type of furniture is the camera on?"}, {"from": "gpt", "value": "Couch"}, {"from": "human", "value": "What is the camera on?"}, {"from": "gpt", "value": "Couch"}, {"from": "human", "value": "Which kind of furniture is the camera on?"}, {"from": "gpt", "value": "Couch"}, {"from": "human", "value": "Are there any cameras on the couch the table is to the right of?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the tablet on the right side or on the left of the picture?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What is the item of furniture to the left of the blue pillow?"}, {"from": "gpt", "value": "Couch"}, {"from": "human", "value": "What is on the couch that looks gray?"}, {"from": "gpt", "value": "Pillows"}, {"from": "human", "value": "Is the gray couch to the left or to the right of the bottle that is on the left?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "In which part of the photo is the black camera, the bottom or the top?"}, {"from": "gpt", "value": "Bottom"}, {"from": "human", "value": "Are there cameras or tablets?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is there any cabinet or bottle in this photograph?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What device is on the table?"}, {"from": "gpt", "value": "Tablet"}, {"from": "human", "value": "What is on the table to the right of the couch?"}, {"from": "gpt", "value": "Tablet"}, {"from": "human", "value": "What is on the couch that the table is to the right of?"}, {"from": "gpt", "value": "Camera"}, {"from": "human", "value": "Are there any pictures or pillows in the picture?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the table to the left or to the right of the couch the camera is on?"}, {"from": "gpt", "value": "Right"}]}, {"id": 2376099, "image": "gqa/images/2376099.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the girl to the right or to the left of the tennis racket?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Who is swinging the racket?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "Do the shorts have pink color?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there spectators to the right of the man on the right?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the girl to the left of a racket?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the girl to the left or to the right of the ball?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Do you see either any armors or statues in this photo?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the spectator in the top part of the image?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the person that is to the right of the ball wearing a necklace?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which part of the image is the girl in, the left or the right?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Who is wearing a hat?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "Is the outfit purple or green?"}, {"from": "gpt", "value": "Green"}, {"from": "human", "value": "Is the person that is to the right of the ball swinging a tennis racket?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2401274, "image": "gqa/images/2401274.jpg", "conversations": [{"from": "human", "value": "<image>\nDo the broccoli to the right of the meat and the spinach to the right of the meat both look green?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there both meat and broccoli in the picture?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What vegetables are to the left of the spinach?"}, {"from": "gpt", "value": "Carrots"}, {"from": "human", "value": "Is the broccoli different in color than the spinach?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the spinach to the left or to the right of the green broccoli?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What is the table made of?"}, {"from": "gpt", "value": "Metal"}, {"from": "human", "value": "Are there carrots or peppers that are not green?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the vegetable that is to the left of the vegetable on the right side of the picture called?"}, {"from": "gpt", "value": "Broccoli"}, {"from": "human", "value": "Is the meat on the left side or on the right of the picture?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Which color is the meat that the spinach is to the right of?"}, {"from": "gpt", "value": "Beige"}, {"from": "human", "value": "Is there either a white table or bed?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the table made of metal?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the color of the carrots?"}, {"from": "gpt", "value": "Green"}, {"from": "human", "value": "Is there any cheese to the left of the vegetable on the right of the photo?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which side is the spinach on?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What type of food is to the left of the broccoli in the middle of the picture?"}, {"from": "gpt", "value": "Meat"}, {"from": "human", "value": "What kind of food is to the left of the broccoli?"}, {"from": "gpt", "value": "Meat"}]}, {"id": 2383556, "image": "gqa/images/2383556.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the chair made of metal?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color are the jeans that the kid is wearing?"}, {"from": "gpt", "value": "Khaki"}, {"from": "human", "value": "On which side of the picture is the white shelf?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Who seems to be younger, the woman or the kid?"}, {"from": "gpt", "value": "Child"}, {"from": "human", "value": "What is the child doing?"}, {"from": "gpt", "value": "Posing"}, {"from": "human", "value": "What is the person to the left of the picture wearing?"}, {"from": "gpt", "value": "Shirt"}, {"from": "human", "value": "Who is standing behind the woman?"}, {"from": "gpt", "value": "Man"}, {"from": "human", "value": "Who is wearing a shirt?"}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "How is the striped clothing item called?"}, {"from": "gpt", "value": "Jacket"}, {"from": "human", "value": "Is the white shelf to the left or to the right of the man that is in front of the wall?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is the picture on the right side?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the chair to the left of the person that is wearing a shirt?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which kind of clothing is khaki?"}, {"from": "gpt", "value": "Jeans"}, {"from": "human", "value": "What are the clothing items that are khaki called?"}, {"from": "gpt", "value": "Jeans"}, {"from": "human", "value": "What is the person to the left of the picture doing, posing or playing?"}, {"from": "gpt", "value": "Posing"}, {"from": "human", "value": "Who is the woman holding?"}, {"from": "gpt", "value": "Child"}, {"from": "human", "value": "What color is the hair, dark or blond?"}, {"from": "gpt", "value": "Dark"}, {"from": "human", "value": "On which side of the picture is the wood chair?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What hangs on the wall behind the man?"}, {"from": "gpt", "value": "Picture"}, {"from": "human", "value": "Who is in front of the clean wall?"}, {"from": "gpt", "value": "Man"}, {"from": "human", "value": "What is the child that looks little doing?"}, {"from": "gpt", "value": "Posing"}, {"from": "human", "value": "Is the woman holding the kid that is wearing jeans?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "The woman that is to the left of the chair is holding who?"}, {"from": "gpt", "value": "Child"}, {"from": "human", "value": "What's the man doing?"}, {"from": "gpt", "value": "Posing"}, {"from": "human", "value": "Is the man in front of the wall having meeting or posing?"}, {"from": "gpt", "value": "Posing"}, {"from": "human", "value": "What is that woman sitting on?"}, {"from": "gpt", "value": "Chair"}, {"from": "human", "value": "What is the woman wearing?"}, {"from": "gpt", "value": "Shirt"}, {"from": "human", "value": "Is the woman to the left or to the right of the wood chair?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Who is wearing the jeans?"}, {"from": "gpt", "value": "Child"}, {"from": "human", "value": "Who is wearing jeans?"}, {"from": "gpt", "value": "Child"}, {"from": "human", "value": "Who is wearing the jacket?"}, {"from": "gpt", "value": "Child"}, {"from": "human", "value": "Who is wearing a jacket?"}, {"from": "gpt", "value": "Child"}, {"from": "human", "value": "Which kind of clothing is striped?"}, {"from": "gpt", "value": "Jacket"}, {"from": "human", "value": "What is the pattern of the jacket?"}, {"from": "gpt", "value": "Striped"}, {"from": "human", "value": "Is there a woman in the picture that is not posing?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Who is posing?"}, {"from": "gpt", "value": "Woman"}]}, {"id": 2412227, "image": "gqa/images/2412227.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich kind of animal is not brown, the giraffe or the calf of the giraffe?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Calf"}, {"from": "human", "value": "What kind of animal is not brown?"}, {"from": "gpt", "value": "Calf"}, {"from": "human", "value": "Where does the giraffe that looks tan and brown stand on?"}, {"from": "gpt", "value": "Dirt"}, {"from": "human", "value": "Does the giraffe's tail have short length and brown color?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are the animals of different types?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How is the weather on this day?"}, {"from": "gpt", "value": "Overcast"}, {"from": "human", "value": "How's the weather?"}, {"from": "gpt", "value": "Overcast"}]}, {"id": 2380854, "image": "gqa/images/2380854.jpg", "conversations": [{"from": "human", "value": "<image>\nOn which side of the picture is the happy person, the right or the left?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Left"}]}, {"id": 2414638, "image": "gqa/images/2414638.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the blue clock on the building that looks gray?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Does the clock to the right of the other clock appear to be blue?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "In which part is the clock, the bottom or the top?"}, {"from": "gpt", "value": "Top"}, {"from": "human", "value": "Are there any clocks that are not white?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2370474, "image": "gqa/images/2370474.jpg", "conversations": [{"from": "human", "value": "<image>\nDo the drawers to the left of the bar stool look tan?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What kind of appliance is to the right of the cooking utensil that looks red?"}, {"from": "gpt", "value": "Refrigerator"}, {"from": "human", "value": "Is the fridge to the right or to the left of the appliance the kettle is on top of?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Is the fan made of plastic?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What type of furniture is to the right of the bar stool that is to the right of the drawers?"}, {"from": "gpt", "value": "Chairs"}, {"from": "human", "value": "Do the chairs look green?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the fridge to the right of the appliance in the center?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there any bar stools to the left of the chairs?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there bar stools to the right of the drawers that are on the left side of the photo?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the tap on the left side?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is in front of the window?"}, {"from": "gpt", "value": "Faucet"}, {"from": "human", "value": "On which side of the image are the black chairs?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Are there any boys in front of the window?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the appliance to the right of the stove that is to the right of the drawers called?"}, {"from": "gpt", "value": "Refrigerator"}]}, {"id": 2326201, "image": "gqa/images/2326201.jpg", "conversations": [{"from": "human", "value": "<image>\nHow thick are the leafy trees?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Thick"}, {"from": "human", "value": "Are the thick trees leafy or maybe bare?"}, {"from": "gpt", "value": "Leafy"}, {"from": "human", "value": "Which place is it?"}, {"from": "gpt", "value": "Skate park"}, {"from": "human", "value": "What is the image showing?"}, {"from": "gpt", "value": "Skate park"}, {"from": "human", "value": "Are there any men in the skate park?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the sky white or blue?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "What is the color of the pants?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "Is the person to the left of the fence watching a dog?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "The shirt has what color?"}, {"from": "gpt", "value": "White"}]}, {"id": 2412961, "image": "gqa/images/2412961.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is wearing the jacket?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "Which color is the cabinet that is to the left of the other cabinet, brown or white?"}, {"from": "gpt", "value": "Brown"}, {"from": "human", "value": "Does the cabinet to the left of the woman have beige color?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the yellow bottle on the right side or on the left?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "What is the oven door made of?"}, {"from": "gpt", "value": "Glass"}, {"from": "human", "value": "What color is the woman's hair?"}, {"from": "gpt", "value": "Dark"}, {"from": "human", "value": "Is the coffee pot on the oven?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there clocks in the scene?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Which side of the image is the bottle on?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is the bottle on the left?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What's the coffee pot made of?"}, {"from": "gpt", "value": "Glass"}, {"from": "human", "value": "What is the color of the cabinet to the right of the clock?"}, {"from": "gpt", "value": "Dark"}, {"from": "human", "value": "Is the oven to the left or to the right of the woman who is wearing jeans?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What is the cooking utensil to the right of the person that is wearing jeans?"}, {"from": "gpt", "value": "Coffee pot"}, {"from": "human", "value": "Was this image taken in the kitchen or in the bathroom?"}, {"from": "gpt", "value": "Kitchen"}, {"from": "human", "value": "Do you see any full coffee pots or bowls?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Which color is the stove, brown or silver?"}, {"from": "gpt", "value": "Brown"}, {"from": "human", "value": "Who is wearing the jeans?"}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "Is the red clock to the right or to the left of the cabinet that is dark and brown?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Do you see either any desks or cabinets?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there both men and women in the picture?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the piece of furniture that is brown?"}, {"from": "gpt", "value": "Cabinet"}, {"from": "human", "value": "Which kind of furniture is brown?"}, {"from": "gpt", "value": "Cabinet"}, {"from": "human", "value": "On which side of the photo is the coffee?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "On which side of the photo is the pot?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Is there any yellow bottle or bag?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Do you see plates or bottles in the image?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What cooking utensil is on the oven that is to the right of the woman?"}, {"from": "gpt", "value": "Coffee pot"}, {"from": "human", "value": "What is on the oven?"}, {"from": "gpt", "value": "Coffee pot"}, {"from": "human", "value": "What is the piece of furniture to the left of the person that is wearing a jacket?"}, {"from": "gpt", "value": "Cabinet"}, {"from": "human", "value": "Is there a bottle to the right of the cabinet that looks brown?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the liquid in?"}, {"from": "gpt", "value": "Glass"}, {"from": "human", "value": "What is the name of the gray clothing item?"}, {"from": "gpt", "value": "Jacket"}, {"from": "human", "value": "Which kind of clothing is gray?"}, {"from": "gpt", "value": "Jacket"}, {"from": "human", "value": "On which side of the picture is the coffee pot?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Is the oven white?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the oven to the left of the woman that is wearing jeans?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which side is the old appliance on?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What appliance is the coffee pot on?"}, {"from": "gpt", "value": "Oven"}, {"from": "human", "value": "Is it indoors?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the stove to the right of her old and brown?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What cooking utensil is on the oven?"}, {"from": "gpt", "value": "Coffee pot"}, {"from": "human", "value": "What is the coffee pot on?"}, {"from": "gpt", "value": "Oven"}, {"from": "human", "value": "Is the oven on the left side or on the right?"}, {"from": "gpt", "value": "Right"}]}, {"id": 2329592, "image": "gqa/images/2329592.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the umpire wearing?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Pants"}, {"from": "human", "value": "Does the baseball jersey have red color?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Where is the umpire?"}, {"from": "gpt", "value": "Game"}, {"from": "human", "value": "Is the man of the game wearing a tie?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "The trousers the man is wearing have which color?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "What is the person at the game wearing?"}, {"from": "gpt", "value": "Pants"}, {"from": "human", "value": "Is the man of the game wearing shorts?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which place is it?"}, {"from": "gpt", "value": "Field"}]}, {"id": 2348690, "image": "gqa/images/2348690.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat toy does the dog bite?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Stuffed animal"}, {"from": "human", "value": "What animal bites the stuffed animal that is orange?"}, {"from": "gpt", "value": "Dog"}, {"from": "human", "value": "What animal is chewing the stuffed animal?"}, {"from": "gpt", "value": "Dog"}, {"from": "human", "value": "What color is the stuffed animal?"}, {"from": "gpt", "value": "Orange"}, {"from": "human", "value": "The animal that looks black and white is chewing what?"}, {"from": "gpt", "value": "Stuffed animal"}, {"from": "human", "value": "Which kind of animal is white?"}, {"from": "gpt", "value": "Dog"}, {"from": "human", "value": "Which kind of animal is on top of the floor?"}, {"from": "gpt", "value": "Dog"}, {"from": "human", "value": "What is the animal on top of the floor?"}, {"from": "gpt", "value": "Dog"}, {"from": "human", "value": "What animal is on top of the floor?"}, {"from": "gpt", "value": "Dog"}, {"from": "human", "value": "What's the dog doing?"}, {"from": "gpt", "value": "Playing"}, {"from": "human", "value": "What is the white animal doing, looking up or playing?"}, {"from": "gpt", "value": "Playing"}, {"from": "human", "value": "What is the animal on top of the floor doing?"}, {"from": "gpt", "value": "Lying"}, {"from": "human", "value": "What toy is orange?"}, {"from": "gpt", "value": "Stuffed animal"}, {"from": "human", "value": "What is that animal called?"}, {"from": "gpt", "value": "Dog"}]}, {"id": 2393235, "image": "gqa/images/2393235.jpg", "conversations": [{"from": "human", "value": "<image>\nAre there clocks on the wall made of brick?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is on the wall made of brick?"}, {"from": "gpt", "value": "Clock"}, {"from": "human", "value": "How is the weather?"}, {"from": "gpt", "value": "Cloudy"}]}, {"id": 2343282, "image": "gqa/images/2343282.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is covered in the water?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Surfboard"}, {"from": "human", "value": "Who is surfing?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "Is the girl surfing?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Which color is the shirt?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "Are there boats in the water?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there either pilots or passengers in this photo?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the surfboard that looks white covered in?"}, {"from": "gpt", "value": "Water"}, {"from": "human", "value": "Who is wearing the shirt?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "Who is wearing a shirt?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "Who wears pants?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "Who wears the pants?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "Does the girl wear jeans?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Who is on the surfboard that is covered in water?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "Is the girl on the right?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "The girl is where?"}, {"from": "gpt", "value": "Water"}, {"from": "human", "value": "Who is on the surfboard?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "Who is riding on the surfboard?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "Who is riding on the surfboard that is covered in water?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "Is the young girl riding on the surfboard in the water?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2319605, "image": "gqa/images/2319605.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich color do you think is the shirt the man is wearing?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "Is it an indoors scene?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What kind of device is to the left of the man on the right?"}, {"from": "gpt", "value": "Wii"}, {"from": "human", "value": "Are there any boxes on the counter?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there shelves to the right of the man on the right?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the chair to the left or to the right of the man on the right?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Are there both computers and game controllers in this image?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How is the brown item of furniture called?"}, {"from": "gpt", "value": "Table"}, {"from": "human", "value": "What is the man to the left of the Wii holding?"}, {"from": "gpt", "value": "Game controller"}, {"from": "human", "value": "What is the device that the man that is to the left of the chair is holding?"}, {"from": "gpt", "value": "Game controller"}, {"from": "human", "value": "Is the man to the right of the game controller wearing a hat?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the man to the right of the Wii wearing?"}, {"from": "gpt", "value": "Shirt"}, {"from": "human", "value": "Are there any men to the left of the game controller in the bottom part of the picture?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color does the table have?"}, {"from": "gpt", "value": "Brown"}, {"from": "human", "value": "What device is on the counter?"}, {"from": "gpt", "value": "Wii"}, {"from": "human", "value": "What is the device on the counter called?"}, {"from": "gpt", "value": "Wii"}, {"from": "human", "value": "What is the piece of furniture to the right of the man that holds the drink?"}, {"from": "gpt", "value": "Shelf"}, {"from": "human", "value": "In which part of the photo is the chair, the bottom or the top?"}, {"from": "gpt", "value": "Bottom"}, {"from": "human", "value": "Where is the chair?"}, {"from": "gpt", "value": "Table"}, {"from": "human", "value": "Which kind of furniture is the chair at?"}, {"from": "gpt", "value": "Table"}, {"from": "human", "value": "What item of furniture is to the left of the man on the right side of the image?"}, {"from": "gpt", "value": "Chair"}, {"from": "human", "value": "Is there any chair to the left of the man on the right?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "In which part of the image is the game controller, the bottom or the top?"}, {"from": "gpt", "value": "Bottom"}, {"from": "human", "value": "Which color is the man's hair, blond or light brown?"}, {"from": "gpt", "value": "Blond"}, {"from": "human", "value": "What item of furniture is to the right of the man that is holding the game controller?"}, {"from": "gpt", "value": "Shelf"}, {"from": "human", "value": "Is the shelf to the right or to the left of the man that holds the game controller?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Is the shelf to the left of the man that is holding the game controller?"}, {"from": "gpt", "value": "No"}]}, {"id": 2387460, "image": "gqa/images/2387460.jpg", "conversations": [{"from": "human", "value": "<image>\nDo you see either yellow traffic lights or fire hydrants?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is it cloudy?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the street sign the same color as the pole?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is common to the pole and the street lamp?"}, {"from": "gpt", "value": "Material"}]}, {"id": 2358373, "image": "gqa/images/2358373.jpg", "conversations": [{"from": "human", "value": "<image>\nAre there couches in the picture?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is in front of the fireplace below the mirror?"}, {"from": "gpt", "value": "Flowers"}, {"from": "human", "value": "What is in the vase?"}, {"from": "gpt", "value": "Flowers"}, {"from": "human", "value": "What are the pieces of furniture that the books are on called?"}, {"from": "gpt", "value": "Shelves"}, {"from": "human", "value": "Which kind of furniture are the books on?"}, {"from": "gpt", "value": "Shelves"}, {"from": "human", "value": "The books are on what?"}, {"from": "gpt", "value": "Shelves"}, {"from": "human", "value": "What are the books on?"}, {"from": "gpt", "value": "Shelves"}, {"from": "human", "value": "Which side is the blanket on?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "How big is the picture?"}, {"from": "gpt", "value": "Small"}, {"from": "human", "value": "Where in this photo is the vase, in the bottom or in the top?"}, {"from": "gpt", "value": "Bottom"}, {"from": "human", "value": "In which part is the bowl?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Which kind of furniture is to the right of the radio?"}, {"from": "gpt", "value": "Shelves"}, {"from": "human", "value": "On which side is the picture, the right or the left?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "How large is the table to the left of the shelves?"}, {"from": "gpt", "value": "Small"}, {"from": "human", "value": "What are the pieces of furniture to the left of the drape that is reflected on the mirror?"}, {"from": "gpt", "value": "Shelves"}, {"from": "human", "value": "What is the drapery to the right of the picture reflected on?"}, {"from": "gpt", "value": "Mirror"}, {"from": "human", "value": "What's hanging above the fireplace?"}, {"from": "gpt", "value": "Mirror"}, {"from": "human", "value": "Does the lamp seem to be white and small?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Does the drape to the left of the shelves look short?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is there a television to the left of the picture?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there any drapes next to the window?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there footballs or trash cans in the scene?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What are the flowers in front of?"}, {"from": "gpt", "value": "Fireplace"}, {"from": "human", "value": "Are the flowers in front of the fireplace?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there mirrors in this image?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is in front of the fireplace?"}, {"from": "gpt", "value": "Flowers"}, {"from": "human", "value": "On which side are the shelves?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "What are the items of furniture to the right of the blue drape called?"}, {"from": "gpt", "value": "Shelves"}, {"from": "human", "value": "Are the books on the right?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is that picture to the left of a chair?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the small picture to the right or to the left of the candle in the image?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Which side is the radio on?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Do you see a chair or a cabinet?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How large do you think is the white lamp?"}, {"from": "gpt", "value": "Small"}, {"from": "human", "value": "Is there a chair to the right of the books?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Do you see girls to the right of the picture that is not large?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there white blankets in this image?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is reflected on the mirror?"}, {"from": "gpt", "value": "Drape"}, {"from": "human", "value": "What is the ornate mirror on the wall hanging above?"}, {"from": "gpt", "value": "Fireplace"}, {"from": "human", "value": "Are there any mirrors above the fireplace behind the flowers?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2343810, "image": "gqa/images/2343810.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the bus to the left of the blue car?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "On which side is the car?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Is the bus to the right or to the left of the large vehicle?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Which color is that sky?"}, {"from": "gpt", "value": "Light blue"}, {"from": "human", "value": "Is the blue vehicle to the right or to the left of the bus?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Does the truck to the left of the bus look white and large?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there vehicles to the right of the vehicle the letters are on the front of?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Which side is the large truck on?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is there any helmet or bike in the picture?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How tall is the grass that the car is parked on?"}, {"from": "gpt", "value": "Tall"}, {"from": "human", "value": "Is the large vehicle to the left or to the right of the mirror the car is to the right of?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Do you see both buses and cars?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Does the car have black color?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the vehicle that is not large?"}, {"from": "gpt", "value": "Bus"}, {"from": "human", "value": "What kind of vehicle is not large, the bus or the truck?"}, {"from": "gpt", "value": "Bus"}]}, {"id": 2405475, "image": "gqa/images/2405475.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat kind of vehicle is not dark?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Truck"}, {"from": "human", "value": "What vehicle isn't driving?"}, {"from": "gpt", "value": "Truck"}, {"from": "human", "value": "Is the car on the left?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the black SUV to the right or to the left of the dark vehicle?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Who is riding on a skateboard?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "Is the person to the right of the car riding on a skateboard?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Who is on top of the skateboard?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "Where are the stores?"}, {"from": "gpt", "value": "Road"}, {"from": "human", "value": "What vehicle is to the left of the boy?"}, {"from": "gpt", "value": "Car"}, {"from": "human", "value": "Which kind of vehicle isn't parked?"}, {"from": "gpt", "value": "Truck"}, {"from": "human", "value": "Which kind of vehicle is driving?"}, {"from": "gpt", "value": "Car"}, {"from": "human", "value": "Is the vehicle that is to the right of the car tan or black?"}, {"from": "gpt", "value": "Black"}, {"from": "human", "value": "Where is the sign?"}, {"from": "gpt", "value": "Road"}, {"from": "human", "value": "Which side of the image is the house on?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What is he wearing?"}, {"from": "gpt", "value": "Sneakers"}, {"from": "human", "value": "Are there both trucks and cars in the picture?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Who is wearing sneakers?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "What is the boy wearing?"}, {"from": "gpt", "value": "Sneakers"}]}, {"id": 2382427, "image": "gqa/images/2382427.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat material is the bench next to the pond made of?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Wood"}, {"from": "human", "value": "Does the pond look large and calm?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the pond in front of?"}, {"from": "gpt", "value": "Bench"}, {"from": "human", "value": "Does the bench next to the pond look pink?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is there a bench next to the small pond?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is in front of the bush?"}, {"from": "gpt", "value": "Bench"}, {"from": "human", "value": "Which color does the bench that is in front of the tree have?"}, {"from": "gpt", "value": "Black"}, {"from": "human", "value": "Which place is it?"}, {"from": "gpt", "value": "Pond"}]}, {"id": 2333459, "image": "gqa/images/2333459.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is the bench in the middle of the picture?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Orange"}, {"from": "human", "value": "What is the color of the countertop?"}, {"from": "gpt", "value": "Green"}, {"from": "human", "value": "What is the girl wearing?"}, {"from": "gpt", "value": "Scarf"}, {"from": "human", "value": "What color do you think the rug that is to the left of the fries has?"}, {"from": "gpt", "value": "Dark blue"}, {"from": "human", "value": "Are the French fries in the top part or in the bottom?"}, {"from": "gpt", "value": "Bottom"}, {"from": "human", "value": "What is the food to the right of the rug called?"}, {"from": "gpt", "value": "Fries"}, {"from": "human", "value": "Do you see fries to the right of the rug that looks dark blue?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the cash register on the left?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Who is preparing the food?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "On which side of the picture is the girl?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "What is the person to the left of the French fries wearing?"}, {"from": "gpt", "value": "Scarf"}, {"from": "human", "value": "What kind of fast food is the basket holding?"}, {"from": "gpt", "value": "Hot dog"}, {"from": "human", "value": "What is the basket holding?"}, {"from": "gpt", "value": "Hot dog"}, {"from": "human", "value": "On which side is the bun, the right or the left?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is the bench rectangular and gray?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the pot to the right or to the left of the bench?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is the pot that is to the left of the bench white or blue?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "What is the tree in?"}, {"from": "gpt", "value": "Pot"}, {"from": "human", "value": "What's in the pot?"}, {"from": "gpt", "value": "Tree"}, {"from": "human", "value": "What is in the pot?"}, {"from": "gpt", "value": "Tree"}, {"from": "human", "value": "Is there a bench that is white?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the hot dog on the right or on the left side?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is the basket holding a hot dog?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Which kind of fast food is the basket holding?"}, {"from": "gpt", "value": "Hot dog"}, {"from": "human", "value": "Is the cash register to the right of the rug that looks dark blue?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the bench to the right or to the left of the pot?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Are there blue pots or tents?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2410099, "image": "gqa/images/2410099.jpg", "conversations": [{"from": "human", "value": "<image>\nAre the chair and the pitcher made of the same material?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are the pitcher and the basket made of the same material?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is there a kettle to the right of the person that is not young?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is there a desk or a chair that is made out of wood?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the chair made of?"}, {"from": "gpt", "value": "Plastic"}, {"from": "human", "value": "What makes up the chair to the right of the box?"}, {"from": "gpt", "value": "Plastic"}, {"from": "human", "value": "What is the appliance that is to the right of the chair that is made of plastic called?"}, {"from": "gpt", "value": "Stove"}, {"from": "human", "value": "Is the cardboard box to the right or to the left of the old person?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "The pots are on what?"}, {"from": "gpt", "value": "Stove"}, {"from": "human", "value": "Is the box to the left of the chair white and long?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is on the stove?"}, {"from": "gpt", "value": "Pots"}, {"from": "human", "value": "What is on the appliance the chair is to the left of?"}, {"from": "gpt", "value": "Pots"}, {"from": "human", "value": "Which ethnic group is the woman?"}, {"from": "gpt", "value": "Asian"}, {"from": "human", "value": "Is the long box to the left of the chair?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the white box to the left or to the right of the chair?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Where in this picture are the eggs, in the bottom or in the top?"}, {"from": "gpt", "value": "Top"}, {"from": "human", "value": "Is the old person to the right of a stove?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are the pots on a shelf?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color is the pipe?"}, {"from": "gpt", "value": "Red"}, {"from": "human", "value": "Does the woman that looks old seem to be sitting?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "On which side are the napkins?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is there any donut in the white box that is to the left of the chair?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there either any women or men that are not old?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "The woman wears what?"}, {"from": "gpt", "value": "Dress"}, {"from": "human", "value": "What does the woman wear?"}, {"from": "gpt", "value": "Dress"}, {"from": "human", "value": "On which side are the plastic bags?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Are there any kettles?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "The bags are on what?"}, {"from": "gpt", "value": "Wall"}, {"from": "human", "value": "Are the large pots on the right side of the picture?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Which kind of furniture is on the left of the stove?"}, {"from": "gpt", "value": "Chair"}, {"from": "human", "value": "Does the newspaper appear to be lying?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What color are the fruits on the right?"}, {"from": "gpt", "value": "Brown"}, {"from": "human", "value": "What is the pitcher made of?"}, {"from": "gpt", "value": "Plastic"}, {"from": "human", "value": "On which side are the bananas?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Who is selling fruit?"}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "What kind of furniture is to the right of the napkins in the box?"}, {"from": "gpt", "value": "Chair"}, {"from": "human", "value": "Is there either a black kettle or pan?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How large is the dress?"}, {"from": "gpt", "value": "Small"}, {"from": "human", "value": "Are the pots to the right of a desk?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the woman to the left of the pots Asian and old?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Was glass used to make the pitcher?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the old person to the left of a box?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Who is sitting?"}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "Is the woman to the left or to the right of the pots on the stove?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "On which side of the photo is the kettle?"}, {"from": "gpt", "value": "Right"}]}, {"id": 1592770, "image": "gqa/images/1592770.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the man to the left of the backpack wearing?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Shirt"}, {"from": "human", "value": "In which part of the photo is the backpack, the bottom or the top?"}, {"from": "gpt", "value": "Top"}, {"from": "human", "value": "The man that to the right of the bottle picks up what?"}, {"from": "gpt", "value": "Camera"}, {"from": "human", "value": "What is the device that the man to the right of the bottle picks up?"}, {"from": "gpt", "value": "Camera"}, {"from": "human", "value": "What is the man to the right of the bottle wearing?"}, {"from": "gpt", "value": "Backpack"}, {"from": "human", "value": "Do you see boys to the left of the backpack?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the device to the right of the keyboard called?"}, {"from": "gpt", "value": "Camera"}, {"from": "human", "value": "What is the device to the left of the cellphone that is shown in the picture?"}, {"from": "gpt", "value": "Laptop"}, {"from": "human", "value": "Which side of the photo is the cell phone on?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Do you see a speaker or a calculator in this photo?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which color is that shirt, red or light blue?"}, {"from": "gpt", "value": "Red"}, {"from": "human", "value": "What is the device to the right of the bottle in the middle of the photo?"}, {"from": "gpt", "value": "Camera"}, {"from": "human", "value": "Which kind of device is to the right of the picture?"}, {"from": "gpt", "value": "Camera"}, {"from": "human", "value": "Are there bottles in the image?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the camera on the right side or on the left?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "On which side of the picture is the keyboard?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is it an indoors scene?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "On which side of the image is the camera?"}, {"from": "gpt", "value": "Right"}]}, {"id": 2321944, "image": "gqa/images/2321944.jpg", "conversations": [{"from": "human", "value": "<image>\nOn what is the person to the left of the painting standing?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Bed"}, {"from": "human", "value": "What type of furniture is this?"}, {"from": "gpt", "value": "Bed"}, {"from": "human", "value": "What kind of furniture is it?"}, {"from": "gpt", "value": "Bed"}, {"from": "human", "value": "On what is the child standing?"}, {"from": "gpt", "value": "Bed"}, {"from": "human", "value": "On which kind of furniture is the child standing?"}, {"from": "gpt", "value": "Bed"}, {"from": "human", "value": "Which side are the white pillows on?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Are there rugs or couches in the photograph?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Who is wearing a shirt?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "Are there both a bed and a lamp in the image?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the painting to the right or to the left of the lamp?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Who is standing on the bed?"}, {"from": "gpt", "value": "Child"}, {"from": "human", "value": "What items of clothing are dark?"}, {"from": "gpt", "value": "Pants"}, {"from": "human", "value": "What color are the pants?"}, {"from": "gpt", "value": "Dark"}, {"from": "human", "value": "Is the boy's hair brown?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the person to the right of the lamp wearing?"}, {"from": "gpt", "value": "Shirt"}]}, {"id": 2375959, "image": "gqa/images/2375959.jpg", "conversations": [{"from": "human", "value": "<image>\nIs there a bicycle or a toothbrush in this image?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color are the clouds in the sky?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "Do you see any trains?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the brown box in the top or in the bottom part of the picture?"}, {"from": "gpt", "value": "Bottom"}, {"from": "human", "value": "How big are the flowers?"}, {"from": "gpt", "value": "Small"}, {"from": "human", "value": "Is it outdoors?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Do the crates to the right of the box seem to be brown?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the snow on?"}, {"from": "gpt", "value": "Mountains"}, {"from": "human", "value": "Are the wood boxes on the right side of the picture?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Do you see boxes by the train that looks red and gray?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What's the snow on?"}, {"from": "gpt", "value": "Mountains"}]}, {"id": 2350187, "image": "gqa/images/2350187.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat animal is sitting on the floor?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Cat"}, {"from": "human", "value": "On which side of the image is the drawer?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Does the door look red and open?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the cat standing?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is there any table or nightstand?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which side of the image is the drawer on?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Are there any soap dispensers or pens in the image?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "On which side of the picture is the bed?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is the animal that is lying black and fat?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the fat animal sitting on?"}, {"from": "gpt", "value": "Floor"}, {"from": "human", "value": "On which side is the drawer?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is the black animal on the right or on the left side of the photo?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Is the door shut?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is on the wall?"}, {"from": "gpt", "value": "Mirror"}, {"from": "human", "value": "Do you see doors?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "On which side is the drawer, the right or the left?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Are there coffee tables or cabinets?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is it indoors or outdoors?"}, {"from": "gpt", "value": "Indoors"}]}, {"id": 2380056, "image": "gqa/images/2380056.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat device isn't white?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Cell phone"}, {"from": "human", "value": "Do you see either a silver cell phone or DVD player?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there men to the right of the keyboard that is to the right of the screen?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there laptops on the rectangular table?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What device is to the left of the man on the right of the image?"}, {"from": "gpt", "value": "Laptop"}, {"from": "human", "value": "Is there a cell phone or a laptop in the picture?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the laptop to the right of the screen open and white?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How large is the screen in the top of the image?"}, {"from": "gpt", "value": "Large"}, {"from": "human", "value": "What kind of device is white?"}, {"from": "gpt", "value": "Laptop"}, {"from": "human", "value": "Which kind of furniture is the cell phone on?"}, {"from": "gpt", "value": "Table"}, {"from": "human", "value": "Are there either any couches or tables that are light?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the device to the left of the computer mouse that is to the left of the man?"}, {"from": "gpt", "value": "Screen"}, {"from": "human", "value": "The open laptop on the table is of which color?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "Is the screen on the left of the picture?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "On which side of the photo is the large screen?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Does that mouse look black?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "On which side of the photo is the small cup?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Do you think the cellphone is black?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the cellphone in the bottom or in the top part?"}, {"from": "gpt", "value": "Bottom"}, {"from": "human", "value": "Is there a white computer mouse or Wii controller?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the tiny cup to the left or to the right of the laptop computer that looks white?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What color is the laptop computer that is to the right of the screen?"}, {"from": "gpt", "value": "Black"}, {"from": "human", "value": "What device is to the left of the man on the right?"}, {"from": "gpt", "value": "Computer mouse"}, {"from": "human", "value": "What do you think is the shape of the light table?"}, {"from": "gpt", "value": "Rectangular"}, {"from": "human", "value": "What color do the pants have?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "What color is the man's hair?"}, {"from": "gpt", "value": "Red"}, {"from": "human", "value": "What device is to the left of the computer mouse?"}, {"from": "gpt", "value": "Screen"}, {"from": "human", "value": "Is the mouse different in color than the cell phone?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the keyboard to the right or to the left of the man on the right of the photo?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is the tiny cup to the left of the laptop that is on the table?"}, {"from": "gpt", "value": "No"}]}, {"id": 2361722, "image": "gqa/images/2361722.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the ground snowy?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "The jacket is of what color?"}, {"from": "gpt", "value": "Green"}, {"from": "human", "value": "What is on the large tree?"}, {"from": "gpt", "value": "Snow"}, {"from": "human", "value": "Which color is the coat?"}, {"from": "gpt", "value": "Black"}, {"from": "human", "value": "Which color do the goggles have?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "Do you see a helmet that is black?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How's the weather?"}, {"from": "gpt", "value": "Overcast"}, {"from": "human", "value": "How is the weather?"}, {"from": "gpt", "value": "Overcast"}, {"from": "human", "value": "Who is wearing the helmet?"}, {"from": "gpt", "value": "Man"}, {"from": "human", "value": "Are there either white hats or gloves?"}, {"from": "gpt", "value": "No"}]}, {"id": 2390125, "image": "gqa/images/2390125.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the small tent black or blue?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "How thick is the bracelet?"}, {"from": "gpt", "value": "Thin"}, {"from": "human", "value": "Does the bracelet look orange and thin?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the blue tent large or small?"}, {"from": "gpt", "value": "Small"}, {"from": "human", "value": "Is that shirt long sleeved and white?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Does the shirt look short sleeved or long sleeved?"}, {"from": "gpt", "value": "Short sleeved"}, {"from": "human", "value": "Is the bracelet silver?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the tent small and blue?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2359710, "image": "gqa/images/2359710.jpg", "conversations": [{"from": "human", "value": "<image>\nHow is the animal called?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Bear"}, {"from": "human", "value": "Does that toy look white or green?"}, {"from": "gpt", "value": "Green"}, {"from": "human", "value": "The bear plays with what?"}, {"from": "gpt", "value": "Toy"}, {"from": "human", "value": "What animal plays with the toy?"}, {"from": "gpt", "value": "Bear"}]}, {"id": 2359446, "image": "gqa/images/2359446.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is that nose, yellow or red?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yellow"}, {"from": "human", "value": "Are there both windows and doors in the image?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there both doors and windows in the photo?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Which color do you think the door of the train is?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "Does that fence look blue?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How is the weather?"}, {"from": "gpt", "value": "Cloudy"}]}, {"id": 2404295, "image": "gqa/images/2404295.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the boy that is to the left of the cow using a skateboard?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Who is holding the animal that is above the grass?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "Who is standing?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "The boy is holding what?"}, {"from": "gpt", "value": "Rope"}, {"from": "human", "value": "Who is holding the rope?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "Is the boy to the left or to the right of the girl that is wearing a dress?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Who is wearing a jacket?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "Who is wearing the jacket?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "Does the girl to the left of the other girl have blond color?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Who wears a hat?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "What is the person to the left of the cow using?"}, {"from": "gpt", "value": "Rope"}, {"from": "human", "value": "What's the boy using?"}, {"from": "gpt", "value": "Rope"}, {"from": "human", "value": "Are there any helmets or bowls?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is there a cow above the grass?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Which kind of clothing is not closed, the sweater or the hat?"}, {"from": "gpt", "value": "Hat"}, {"from": "human", "value": "Who wears the hat?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "What is the boy holding?"}, {"from": "gpt", "value": "Rope"}, {"from": "human", "value": "What kind of clothing isn't closed?"}, {"from": "gpt", "value": "Hat"}, {"from": "human", "value": "Who is holding the rope that is black and white?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "Is the boy to the left or to the right of the girl that is wearing a jacket?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Who is using the rope?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "Does the girl to the right of the boy look brunette?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the girl to the left of the rope wearing?"}, {"from": "gpt", "value": "Dress"}, {"from": "human", "value": "What is the closed clothing item called?"}, {"from": "gpt", "value": "Sweater"}, {"from": "human", "value": "Does the sweater look open or closed?"}, {"from": "gpt", "value": "Closed"}, {"from": "human", "value": "Is the grass under a cow?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Who is holding the cow?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "The building is in front of what?"}, {"from": "gpt", "value": "Trees"}, {"from": "human", "value": "Is the building behind the trees?"}, {"from": "gpt", "value": "No"}]}, {"id": 2401646, "image": "gqa/images/2401646.jpg", "conversations": [{"from": "human", "value": "<image>\nDoes the happy person seem to be bending?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Of what color is the shirt the man is wearing?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "Do you see men to the left of the crate?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What's the woman wearing?"}, {"from": "gpt", "value": "Scarf"}, {"from": "human", "value": "What is the person to the right of the mat wearing?"}, {"from": "gpt", "value": "Scarf"}, {"from": "human", "value": "Is the house behind a fence?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "On which side is the crate?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What's the crate made of?"}, {"from": "gpt", "value": "Plastic"}, {"from": "human", "value": "What do the bag and the crate have in common?"}, {"from": "gpt", "value": "Material"}, {"from": "human", "value": "Are there animals on the skateboard?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How does the street look like, clean or dirty?"}, {"from": "gpt", "value": "Dirty"}, {"from": "human", "value": "What's in front of the house?"}, {"from": "gpt", "value": "Bag"}, {"from": "human", "value": "Is the plastic bag in front of a house?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Who in this scene is sitting?"}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "What's the bag in front of?"}, {"from": "gpt", "value": "House"}, {"from": "human", "value": "Who is riding an animal?"}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "Does the scarf look maroon?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Who sits on the blue animal that to the right of the mat?"}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "Are there men to the left of the bag that is in front of the house?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the bag to the right or to the left of the man the crate is to the left of?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Is the orange house on the right side or on the left of the picture?"}, {"from": "gpt", "value": "Right"}]}, {"id": 2348063, "image": "gqa/images/2348063.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the brown bottle on the right?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Which kind of fast food is on the plate?"}, {"from": "gpt", "value": "Pizza"}, {"from": "human", "value": "Is the stapler in the bottom part or in the top of the photo?"}, {"from": "gpt", "value": "Bottom"}, {"from": "human", "value": "Do the paper and the mug have a different colors?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is on the wall?"}, {"from": "gpt", "value": "Clock"}, {"from": "human", "value": "Is there either a blue cup or mug?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the bottle that is to the right of the mug brown or silver?"}, {"from": "gpt", "value": "Brown"}, {"from": "human", "value": "Is the brown bottle to the right or to the left of the computer that is not off?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is the brown bottle to the right of the computer on the right side?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "On which side of the image is the computer, the left or the right?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Are there both a plate and a bottle in this image?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the plate made of glass or paper?"}, {"from": "gpt", "value": "Paper"}, {"from": "human", "value": "Is the white mug to the right or to the left of the bottle on the right?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Are there any clocks or towers?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Do you see pictures on the wall?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the device to the right of the toy that is to the right of the bottle called?"}, {"from": "gpt", "value": "Computer"}, {"from": "human", "value": "What device is to the right of the clock on the wall?"}, {"from": "gpt", "value": "Computer"}, {"from": "human", "value": "What is on the table?"}, {"from": "gpt", "value": "Mug"}, {"from": "human", "value": "What is the bottle on?"}, {"from": "gpt", "value": "Desk"}, {"from": "human", "value": "What is the device to the right of the brown bottle?"}, {"from": "gpt", "value": "Computer"}, {"from": "human", "value": "Are there toys or boys?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2324885, "image": "gqa/images/2324885.jpg", "conversations": [{"from": "human", "value": "<image>\nIs there either an elephant or a dog that is walking?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What's the fence made of?"}, {"from": "gpt", "value": "Wood"}, {"from": "human", "value": "Is there a fence in the scene that is metallic?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are these giraffes or elephants?"}, {"from": "gpt", "value": "Elephants"}, {"from": "human", "value": "Are there any dogs or snails?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "On which side of the picture is the fence?"}, {"from": "gpt", "value": "Left"}]}, {"id": 2359802, "image": "gqa/images/2359802.jpg", "conversations": [{"from": "human", "value": "<image>\nDo you see either large window or door?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How big are the windows?"}, {"from": "gpt", "value": "Small"}, {"from": "human", "value": "Which place is it?"}, {"from": "gpt", "value": "Runway"}, {"from": "human", "value": "What place is it?"}, {"from": "gpt", "value": "Runway"}]}, {"id": 2366871, "image": "gqa/images/2366871.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich side is the person on?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Does the table have a different color than the cell phone?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the picture on the right?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is located on top of the table that looks white?"}, {"from": "gpt", "value": "Cell phone"}, {"from": "human", "value": "What is located on top of the table?"}, {"from": "gpt", "value": "Cell phone"}, {"from": "human", "value": "Which kind of device is on top of the table?"}, {"from": "gpt", "value": "Cell phone"}, {"from": "human", "value": "Are there any glasses or napkins in the picture?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is that mobile phone on top of a bed?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "On which side of the picture is the person?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Do you think the person to the right of the other person is talking or cooking?"}, {"from": "gpt", "value": "Talking"}, {"from": "human", "value": "Does the wall have a different color than the table?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Does the rectangular device look black?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the person that is to the left of the other person doing, talking or playing?"}, {"from": "gpt", "value": "Talking"}, {"from": "human", "value": "On which side is the charger?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is there either a bag or an umbrella in the picture?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What device is right of the charger?"}, {"from": "gpt", "value": "Screen"}]}, {"id": 2408362, "image": "gqa/images/2408362.jpg", "conversations": [{"from": "human", "value": "<image>\nWhere are the tents?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Snow"}, {"from": "human", "value": "What color are the trousers?"}, {"from": "gpt", "value": "Dark"}, {"from": "human", "value": "What is the person with the backpack doing?"}, {"from": "gpt", "value": "Skiing"}, {"from": "human", "value": "Is the backpack small?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Does the person with the backpack wear goggles?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is covered in snow?"}, {"from": "gpt", "value": "Mountain"}, {"from": "human", "value": "Are the tents on the left side of the image?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the person that is skiing wearing a jacket?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the mountain covered in?"}, {"from": "gpt", "value": "Snow"}, {"from": "human", "value": "What is the person with the backpack holding?"}, {"from": "gpt", "value": "Pole"}]}, {"id": 2369167, "image": "gqa/images/2369167.jpg", "conversations": [{"from": "human", "value": "<image>\nAre there any cows near the black pole?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are the animals near the pole walking or standing?"}, {"from": "gpt", "value": "Standing"}, {"from": "human", "value": "What animals are eating?"}, {"from": "gpt", "value": "Zebras"}, {"from": "human", "value": "What animals are standing?"}, {"from": "gpt", "value": "Zebras"}, {"from": "human", "value": "What animals are brown?"}, {"from": "gpt", "value": "Zebras"}, {"from": "human", "value": "Which kind of animal is fenced?"}, {"from": "gpt", "value": "Zebras"}, {"from": "human", "value": "Is there a goat or a zebra that is walking?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Do the zebras have brown color?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are the animals near the pole striped and white?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which kind of animal is striped?"}, {"from": "gpt", "value": "Zebras"}, {"from": "human", "value": "What type of animal is striped?"}, {"from": "gpt", "value": "Zebras"}, {"from": "human", "value": "What do both the pole and the post have in common?"}, {"from": "gpt", "value": "Color"}, {"from": "human", "value": "What animals are it?"}, {"from": "gpt", "value": "Zebras"}, {"from": "human", "value": "What animals are in the picture?"}, {"from": "gpt", "value": "Zebras"}]}, {"id": 2339497, "image": "gqa/images/2339497.jpg", "conversations": [{"from": "human", "value": "<image>\nIs it an indoors or outdoors scene?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Outdoors"}, {"from": "human", "value": "How is the weather?"}, {"from": "gpt", "value": "Clear"}, {"from": "human", "value": "Which side is the catcher on, the right or the left?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is the player to the right of the umpire holding a bat?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "On which side is the umpire?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "On which side is the man, the right or the left?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Is the fence in front or behind the trees?"}, {"from": "gpt", "value": "Front"}, {"from": "human", "value": "What place is it?"}, {"from": "gpt", "value": "Field"}, {"from": "human", "value": "Which place is it?"}, {"from": "gpt", "value": "Field"}, {"from": "human", "value": "Where is the man standing on?"}, {"from": "gpt", "value": "Dirt"}, {"from": "human", "value": "Where is the person to the right of the baseball standing on?"}, {"from": "gpt", "value": "Dirt"}, {"from": "human", "value": "Is the umpire to the left or to the right of the catcher on the left of the photo?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Which color is the shirt?"}, {"from": "gpt", "value": "Yellow"}, {"from": "human", "value": "What is this fence in front of?"}, {"from": "gpt", "value": "Trees"}, {"from": "human", "value": "What is the fence in front of?"}, {"from": "gpt", "value": "Trees"}, {"from": "human", "value": "What is in front of the trees on the hill?"}, {"from": "gpt", "value": "Fence"}, {"from": "human", "value": "Are there chandeliers or grinders?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Where are the trees?"}, {"from": "gpt", "value": "Hill"}, {"from": "human", "value": "Are the trees behind the fence?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2397885, "image": "gqa/images/2397885.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat kind of animal is standing?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Elephant"}, {"from": "human", "value": "What color is the fence the elephant is behind of?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "Are there any benches behind the fence near the bush?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is there any fence or ball in this picture?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Do you see a fence in front of the elephant in the zoo?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is in front of the elephant in the zoo?"}, {"from": "gpt", "value": "Fence"}, {"from": "human", "value": "Which place is it?"}, {"from": "gpt", "value": "Zoo"}, {"from": "human", "value": "Which kind of animal is large?"}, {"from": "gpt", "value": "Elephant"}, {"from": "human", "value": "Is there an elephant in this picture?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is there an elephant in the zoo?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Does the blue fence look metallic?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 1159644, "image": "gqa/images/1159644.jpg", "conversations": [{"from": "human", "value": "<image>\nOn which side of the image is the white car?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Does the car to the left of the other car look red?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the SUV to the right or to the left of the truck?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Is there a bus on the road?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "On which side of the picture is the silver car?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What vehicle is to the left of the white car?"}, {"from": "gpt", "value": "Suv"}, {"from": "human", "value": "What vehicle do you think is parked alongside the road that the tree is on?"}, {"from": "gpt", "value": "Suv"}, {"from": "human", "value": "What vehicle is parked alongside the road?"}, {"from": "gpt", "value": "Suv"}, {"from": "human", "value": "Does the car which is to the right of the other car look black?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the vehicle to the right of the vehicle that looks blue and orange?"}, {"from": "gpt", "value": "Suv"}, {"from": "human", "value": "Is there an airplane to the right of the vehicle that is orange and blue?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the vehicle to the left of the vehicle that is parked alongside the road?"}, {"from": "gpt", "value": "Truck"}, {"from": "human", "value": "What is the name of the vehicle that is orange?"}, {"from": "gpt", "value": "Truck"}, {"from": "human", "value": "What kind of vehicle is orange?"}, {"from": "gpt", "value": "Truck"}, {"from": "human", "value": "Which place is it?"}, {"from": "gpt", "value": "Road"}, {"from": "human", "value": "Is there any truck on the road?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What vehicle is on the road?"}, {"from": "gpt", "value": "Suv"}, {"from": "human", "value": "What is the vehicle that is on the road?"}, {"from": "gpt", "value": "Suv"}, {"from": "human", "value": "Are both the barrier and the hedge the same color?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the truck to the left or to the right of the vehicle that is parked alongside the road?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is the white car to the right of the SUV that is parked alongside the road?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2385393, "image": "gqa/images/2385393.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is this pine tree?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Brown"}, {"from": "human", "value": "Which kind of animal is it?"}, {"from": "gpt", "value": "Giraffe"}, {"from": "human", "value": "Is the baby on the left or on the right?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "How fat is the tail?"}, {"from": "gpt", "value": "Thin"}, {"from": "human", "value": "Are there pine trees by the giraffe?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Which color is the giraffe's mane?"}, {"from": "gpt", "value": "Brown"}, {"from": "human", "value": "What animal is this?"}, {"from": "gpt", "value": "Giraffe"}, {"from": "human", "value": "Is the brown ground sandy or bare?"}, {"from": "gpt", "value": "Sandy"}, {"from": "human", "value": "Is the pine by the giraffe brown and tall?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the tall giraffe on the left side or on the right?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Which side of the photo is the tall tree on?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Are there giraffes by the baby?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What animal is above the ground?"}, {"from": "gpt", "value": "Giraffe"}, {"from": "human", "value": "Does the sky look dark?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What animal is walking?"}, {"from": "gpt", "value": "Giraffe"}, {"from": "human", "value": "Are there any giraffes near the baby on the left side?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2414916, "image": "gqa/images/2414916.jpg", "conversations": [{"from": "human", "value": "<image>\nAre there any women in this photo that are standing?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the man in the top part or in the bottom of the image?"}, {"from": "gpt", "value": "Bottom"}, {"from": "human", "value": "Is the woman's shirt black?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which side of the photo is the woman on?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "The woman's pants have what color?"}, {"from": "gpt", "value": "Blue"}]}, {"id": 2333305, "image": "gqa/images/2333305.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich kind of device is the man holding?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Cell phone"}, {"from": "human", "value": "Who is sitting on the bench?"}, {"from": "gpt", "value": "Man"}, {"from": "human", "value": "Is there any black briefcase or backpack?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the name of the device that the person behind the backpack is holding?"}, {"from": "gpt", "value": "Cell phone"}, {"from": "human", "value": "What is he holding?"}, {"from": "gpt", "value": "Cell phone"}, {"from": "human", "value": "Is the bench below the man made of wood or metal?"}, {"from": "gpt", "value": "Wood"}, {"from": "human", "value": "Do the stones behind the bench look tall or short?"}, {"from": "gpt", "value": "Tall"}, {"from": "human", "value": "Are the stones behind the bench large and tall?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which color is the shirt?"}, {"from": "gpt", "value": "Red"}, {"from": "human", "value": "What color are the shorts that the man is wearing?"}, {"from": "gpt", "value": "Gray"}, {"from": "human", "value": "Are there any horses below the man?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the bench green and wooden?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the man sitting on a bench?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What's the bench in front of?"}, {"from": "gpt", "value": "Stones"}, {"from": "human", "value": "What is the bench in front of?"}, {"from": "gpt", "value": "Stones"}, {"from": "human", "value": "What is in front of the stones?"}, {"from": "gpt", "value": "Bench"}, {"from": "human", "value": "Do the stones look large?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What do both the tree and the bench have in common?"}, {"from": "gpt", "value": "Color"}]}, {"id": 2373200, "image": "gqa/images/2373200.jpg", "conversations": [{"from": "human", "value": "<image>\nAre there any electric toothbrushes or placemats in the picture?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What kind of animal is to the left of the painting?"}, {"from": "gpt", "value": "Elephant"}, {"from": "human", "value": "Are there mannequins or spray cans?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there either mannequins or kites?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is there either a zebra or an elephant in this photo?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What does the elephant eat?"}, {"from": "gpt", "value": "Branch"}, {"from": "human", "value": "Is the painting on the right side of the image?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the painting on?"}, {"from": "gpt", "value": "Barrier"}, {"from": "human", "value": "What does the animal to the left of the painting eat?"}, {"from": "gpt", "value": "Branch"}, {"from": "human", "value": "What is the color of the hair?"}, {"from": "gpt", "value": "Dark"}]}, {"id": 2323488, "image": "gqa/images/2323488.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the shirt black and short sleeved?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Do you see any ties or glasses there?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the color of the shirt the same as the color of the necktie?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What type of clothing is blue?"}, {"from": "gpt", "value": "Jeans"}, {"from": "human", "value": "Do you think the shirt is short sleeved or long sleeved?"}, {"from": "gpt", "value": "Short sleeved"}, {"from": "human", "value": "Which kind of clothing is black?"}, {"from": "gpt", "value": "Shirt"}, {"from": "human", "value": "Which color is the shoe the shoe strings are on?"}, {"from": "gpt", "value": "Black"}, {"from": "human", "value": "The necktie has which color?"}, {"from": "gpt", "value": "Black"}]}, {"id": 2410461, "image": "gqa/images/2410461.jpg", "conversations": [{"from": "human", "value": "<image>\nHow tall is the fence?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Tall"}, {"from": "human", "value": "Is the fence in the bottom part or in the top of the image?"}, {"from": "gpt", "value": "Top"}, {"from": "human", "value": "Who is wearing the shoe?"}, {"from": "gpt", "value": "Player"}, {"from": "human", "value": "Who is wearing a shoe?"}, {"from": "gpt", "value": "Player"}, {"from": "human", "value": "Who is playing?"}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "Does the woman to the right of the player appear to be talking?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the woman that is to the left of the tennis ball holding?"}, {"from": "gpt", "value": "Racket"}, {"from": "human", "value": "What is the player to the right of the racket doing, posing or playing?"}, {"from": "gpt", "value": "Playing"}, {"from": "human", "value": "What do the skirt and the shoe have in common?"}, {"from": "gpt", "value": "Color"}, {"from": "human", "value": "Is the fence gray?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which color is the player that is wearing a shoe?"}, {"from": "gpt", "value": "Blond"}, {"from": "human", "value": "What is the woman that is playing holding?"}, {"from": "gpt", "value": "Racket"}, {"from": "human", "value": "Are there rackets to the left of the player on the right?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Does the shoe look white?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What color is the skirt?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "In which part is the vehicle, the top or the bottom?"}, {"from": "gpt", "value": "Top"}, {"from": "human", "value": "Is the wire fence dark and short?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there both a fence and a racket in the image?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Which material makes up the fence, wire or brick?"}, {"from": "gpt", "value": "Wire"}]}, {"id": 2321990, "image": "gqa/images/2321990.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the device that is not black?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Screen"}, {"from": "human", "value": "Is the cellphone in the top part of the picture?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Does the coffee cup look tan?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there silver laptops or DVD players?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "On which side of the image is the screen?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "What is the device to the left of the cat?"}, {"from": "gpt", "value": "Screen"}, {"from": "human", "value": "Is the woman to the left or to the right of the screen?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Are there any chairs?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the orange chair to the left or to the right of the screen on the left?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Are there screens to the left of the chair?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the clothing item that is not orange?"}, {"from": "gpt", "value": "Hat"}, {"from": "human", "value": "Is the shirt orange and short sleeved?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Does the long sleeved shirt have orange color?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the orange chair to the left of the screen on the left?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the shirt long sleeved?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is there a computer mouse to the right of the black device?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the screen to the right or to the left of the cat that looks black?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "On which side is the black device?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Do you see either a keyboard or a lamp there?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the laptop to the right or to the left of her?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "What type of device has the same color as the cat?"}, {"from": "gpt", "value": "Laptop"}, {"from": "human", "value": "Is the black animal to the right or to the left of the screen?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What kind of device is to the left of the woman?"}, {"from": "gpt", "value": "Screen"}, {"from": "human", "value": "What article of clothing is not long sleeved?"}, {"from": "gpt", "value": "Hat"}, {"from": "human", "value": "Are there either white chairs or desks?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which kind of device is to the left of the chair?"}, {"from": "gpt", "value": "Screen"}, {"from": "human", "value": "Which kind of animal is to the right of the screen?"}, {"from": "gpt", "value": "Cat"}]}, {"id": 2318768, "image": "gqa/images/2318768.jpg", "conversations": [{"from": "human", "value": "<image>\nDoes the long hair look brown and straight?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "On which side of the photo is the red drum?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Is this man to the left of a piano?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is there a drum in the image that is not red?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the flag in the top or in the bottom of the photo?"}, {"from": "gpt", "value": "Bottom"}, {"from": "human", "value": "Are both the blouse and the drum the same color?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Do the blouse and the bus have the same color?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Does the flag look rainbow colored and tiny?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the blue vehicle to the right of the man?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "On which side is the lady?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is the woman on the left part?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the vehicle that is blue?"}, {"from": "gpt", "value": "Bus"}, {"from": "human", "value": "How large is the flag that looks yellow?"}, {"from": "gpt", "value": "Tiny"}, {"from": "human", "value": "Are there both ties and glasses in the photo?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What type of vehicle is to the right of the man that is to the right of the lady?"}, {"from": "gpt", "value": "Bus"}, {"from": "human", "value": "Is the man to the left or to the right of the person on the right?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Does the blouse look white?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Of what color is the bus?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "Which side of the photo is the bus on?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Is the tiny flag yellow or red?"}, {"from": "gpt", "value": "Yellow"}]}, {"id": 2374425, "image": "gqa/images/2374425.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the flag to the left of a boat?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the flag to the right of a horse?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the orange flag in the top of the photo?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Do you see any blue balloon or flag?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the girl to the right of a person?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the girl to the right of a cup?"}, {"from": "gpt", "value": "No"}]}, {"id": 2387931, "image": "gqa/images/2387931.jpg", "conversations": [{"from": "human", "value": "<image>\nIs it indoors or outdoors?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Outdoors"}, {"from": "human", "value": "Which place is it?"}, {"from": "gpt", "value": "Beach"}, {"from": "human", "value": "What is the fruit that is on the beach near the water?"}, {"from": "gpt", "value": "Orange"}, {"from": "human", "value": "Of what color do you think is the water the sky is above?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "Are there any oranges on the beach?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What fruit is on the beach?"}, {"from": "gpt", "value": "Orange"}, {"from": "human", "value": "Where is the orange?"}, {"from": "gpt", "value": "Beach"}, {"from": "human", "value": "The orange is where?"}, {"from": "gpt", "value": "Beach"}, {"from": "human", "value": "Is it a garden?"}, {"from": "gpt", "value": "No"}]}, {"id": 2374654, "image": "gqa/images/2374654.jpg", "conversations": [{"from": "human", "value": "<image>\nIs there any white cow or lamb?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Do you see either any tall grass or snow?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How tall is the brown grass?"}, {"from": "gpt", "value": "Short"}, {"from": "human", "value": "What animal is grazing on the grass?"}, {"from": "gpt", "value": "Cow"}, {"from": "human", "value": "The animal that is tan and brown is standing in what?"}, {"from": "gpt", "value": "Grass"}, {"from": "human", "value": "Are there sheep in the grass that is not tall?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the grass tall and brown?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Of which color is the grass?"}, {"from": "gpt", "value": "Brown"}, {"from": "human", "value": "Is the brown cow in the bottom part or in the top of the photo?"}, {"from": "gpt", "value": "Bottom"}, {"from": "human", "value": "What is the animal that is in the short grass?"}, {"from": "gpt", "value": "Calf"}, {"from": "human", "value": "What is the animal that is eating the grass called?"}, {"from": "gpt", "value": "Calf"}, {"from": "human", "value": "What is the calf that is light brown and brown eating?"}, {"from": "gpt", "value": "Grass"}, {"from": "human", "value": "What kind of animal is in the grass?"}, {"from": "gpt", "value": "Calf"}, {"from": "human", "value": "Do you see fences or zebras in the image?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What animal is in the grass?"}, {"from": "gpt", "value": "Cow"}, {"from": "human", "value": "Is there any fence or cow in the image?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2384511, "image": "gqa/images/2384511.jpg", "conversations": [{"from": "human", "value": "<image>\nAre there any yellow balloons or flags?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the American flag on the left side of the photo?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What size do you think is the clock that is on the building?"}, {"from": "gpt", "value": "Huge"}, {"from": "human", "value": "Are there any small clocks in this photo?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Do you see any clocks?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Do the clock and the American flag have a different colors?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the blue flag on the right part or on the left?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is the color of the flag the same as the sky?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2384304, "image": "gqa/images/2384304.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is wearing a shirt?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Man"}, {"from": "human", "value": "What is the person who is to the right of the instrument wearing?"}, {"from": "gpt", "value": "Shorts"}, {"from": "human", "value": "What is the animal to the right of the towel that is in the bottom?"}, {"from": "gpt", "value": "Horse"}, {"from": "human", "value": "Is the man to the left or to the right of the horse that is to the right of the umbrellas?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Is the walking man to the right of the horse wearing jeans?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are the blankets to the right of a pillow?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is there a blanket to the left of the man?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How large is the animal to the right of the towel?"}, {"from": "gpt", "value": "Small"}, {"from": "human", "value": "On which side of the image is the man?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "On which side of the photo is the towel?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Are there dining tables or drawers?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there any people to the left of the umbrellas on the left side?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Who is wearing the shirt?"}, {"from": "gpt", "value": "Man"}, {"from": "human", "value": "Is the small animal to the left or to the right of the person that is wearing shorts?"}, {"from": "gpt", "value": "Left"}]}, {"id": 2381868, "image": "gqa/images/2381868.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the plate on a tablecloth?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the chair to the left of the other chair wooden and full?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the empty chair in the top or in the bottom part of the image?"}, {"from": "gpt", "value": "Top"}, {"from": "human", "value": "What is the chair to the left of the person made of?"}, {"from": "gpt", "value": "Wood"}, {"from": "human", "value": "Is the person in the bottom or in the top part?"}, {"from": "gpt", "value": "Top"}, {"from": "human", "value": "Are there any sugar packets or tennis rackets?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "In which part of the picture is the brown chair, the top or the bottom?"}, {"from": "gpt", "value": "Top"}, {"from": "human", "value": "Is there cheese on the cooked food?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the person to the right or to the left of the chair made of wood?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Which side is the white plate on?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What kind of meat is on the pizza?"}, {"from": "gpt", "value": "Pepperoni"}, {"from": "human", "value": "Is the pepperoni in the bottom part or in the top of the image?"}, {"from": "gpt", "value": "Top"}, {"from": "human", "value": "What is on the cooked food above the glass?"}, {"from": "gpt", "value": "Pepperoni"}, {"from": "human", "value": "What is on the pizza?"}, {"from": "gpt", "value": "Pepperoni"}, {"from": "human", "value": "What food is crusty?"}, {"from": "gpt", "value": "Pizza"}, {"from": "human", "value": "Does the plate to the right of the fork have white color?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the empty chair to the left or to the right of the person in the top part of the image?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is there a cup or a plate?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 1591823, "image": "gqa/images/1591823.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the umbrella to the right or to the left of the person on the left side?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Are there both windows and doors in this picture?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there any motorcycles to the left of the person on the right side?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Do you see any motorcycle there?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there either trays or motorcycles?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2362762, "image": "gqa/images/2362762.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the table made of?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Glass"}, {"from": "human", "value": "Is the photographer in the top part or in the bottom of the image?"}, {"from": "gpt", "value": "Bottom"}, {"from": "human", "value": "Do the red roses look beautiful?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What are the vases filled with?"}, {"from": "gpt", "value": "Water"}, {"from": "human", "value": "Are the vases filled with water?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are the vases holding the red roses?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What do you think is on the table?"}, {"from": "gpt", "value": "Vases"}, {"from": "human", "value": "The vases are on what?"}, {"from": "gpt", "value": "Table"}, {"from": "human", "value": "What are the vases holding?"}, {"from": "gpt", "value": "Roses"}, {"from": "human", "value": "What is filled with the water?"}, {"from": "gpt", "value": "Vases"}, {"from": "human", "value": "What is filled with water?"}, {"from": "gpt", "value": "Vases"}, {"from": "human", "value": "What is holding the roses that look red?"}, {"from": "gpt", "value": "Vases"}, {"from": "human", "value": "The leaves are on what?"}, {"from": "gpt", "value": "Rose"}, {"from": "human", "value": "What are the leaves on?"}, {"from": "gpt", "value": "Rose"}, {"from": "human", "value": "Are the green leaves on a rose?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is there a helmet or a photographer in the photo?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How big is the table made of glass?"}, {"from": "gpt", "value": "Large"}]}, {"id": 2323990, "image": "gqa/images/2323990.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the red ball on the right?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there fences in front of the green bushes?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Does the ball near the bear look red or silver?"}, {"from": "gpt", "value": "Red"}, {"from": "human", "value": "What is the animal that the bushes are behind of?"}, {"from": "gpt", "value": "Bear"}, {"from": "human", "value": "What is the bear in front of?"}, {"from": "gpt", "value": "Bushes"}, {"from": "human", "value": "What's the bear in?"}, {"from": "gpt", "value": "Basket"}, {"from": "human", "value": "What animal is in front of the bushes?"}, {"from": "gpt", "value": "Bear"}, {"from": "human", "value": "What animal is it?"}, {"from": "gpt", "value": "Bear"}, {"from": "human", "value": "What is the color of the fur?"}, {"from": "gpt", "value": "Dark"}, {"from": "human", "value": "What is the bear in?"}, {"from": "gpt", "value": "Basket"}, {"from": "human", "value": "What color is the basket?"}, {"from": "gpt", "value": "Brown"}]}, {"id": 713699, "image": "gqa/images/713699.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat kind of instrument is to the left of the man?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Drum"}, {"from": "human", "value": "Is the person to the left of the glasses wearing a cap?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "On which side is the metal instrument, the right or the left?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "What color is the shirt the person is wearing?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "What color is the necktie the man wears?"}, {"from": "gpt", "value": "Gray"}, {"from": "human", "value": "Are there trains to the left of the person that is wearing a suit?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there men to the left of the instrument made of metal?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are the jeans black?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there any helmets to the left of the person that wears trousers?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is there a tie in the image that is gray?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the person to the right of the person holding?"}, {"from": "gpt", "value": "Jacket"}, {"from": "human", "value": "What is the man holding?"}, {"from": "gpt", "value": "Jacket"}, {"from": "human", "value": "Is the instrument to the left of the person orange and metallic?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What color is the drum?"}, {"from": "gpt", "value": "Orange"}]}, {"id": 2324172, "image": "gqa/images/2324172.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is wearing the helmet?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Catcher"}, {"from": "human", "value": "Is it outdoors or indoors?"}, {"from": "gpt", "value": "Outdoors"}, {"from": "human", "value": "What's the catcher wearing?"}, {"from": "gpt", "value": "Helmet"}, {"from": "human", "value": "Which side of the photo is the batter on?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Is the umpire on the right of the picture?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color does the glove that the batter is wearing have?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "Is there a helmet to the left of the umpire?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the batter wearing?"}, {"from": "gpt", "value": "Glove"}, {"from": "human", "value": "Who do you think is wearing a glove?"}, {"from": "gpt", "value": "Batter"}, {"from": "human", "value": "Do you see any umpires to the right of the batter that is wearing a glove?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there any umpires to the right of the person that is wearing a helmet?"}, {"from": "gpt", "value": "No"}]}, {"id": 2360043, "image": "gqa/images/2360043.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the lamp on the right?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What item of furniture is black?"}, {"from": "gpt", "value": "Desk"}, {"from": "human", "value": "What is the device to the right of the glass vase called?"}, {"from": "gpt", "value": "Keyboard"}, {"from": "human", "value": "What is the keyboard on?"}, {"from": "gpt", "value": "Desk"}, {"from": "human", "value": "Does the container to the left of the vase look black?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there either radios or papers in the image?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the water in a bowl?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the computer monitor on the right side?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the water in?"}, {"from": "gpt", "value": "Vase"}, {"from": "human", "value": "What color is the lamp?"}, {"from": "gpt", "value": "Gold"}, {"from": "human", "value": "Are the flowers in a pot?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the keyboard on the left?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What device is black?"}, {"from": "gpt", "value": "Computer monitor"}, {"from": "human", "value": "Do the box and the computer monitor have the same color?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is there either a black desk or chair?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Do you see any speaker in this image?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How is the black piece of furniture called?"}, {"from": "gpt", "value": "Desk"}, {"from": "human", "value": "In which part of the image is the vase, the bottom or the top?"}, {"from": "gpt", "value": "Bottom"}, {"from": "human", "value": "What device isn't black?"}, {"from": "gpt", "value": "Keyboard"}, {"from": "human", "value": "Which device is not black, the computer monitor or the keyboard?"}, {"from": "gpt", "value": "Keyboard"}]}, {"id": 2323794, "image": "gqa/images/2323794.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the carpet below the desk short and brown?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the cooking utensil to the left of the metal plate?"}, {"from": "gpt", "value": "Cutting board"}, {"from": "human", "value": "What cooking utensil in the picture is red?"}, {"from": "gpt", "value": "Cutting board"}, {"from": "human", "value": "What kind is the cooking utensil?"}, {"from": "gpt", "value": "Cutting board"}, {"from": "human", "value": "Is the round container red and small?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What piece of furniture is above the carpet?"}, {"from": "gpt", "value": "Desk"}, {"from": "human", "value": "Are there any chairs?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is that piece of furniture called?"}, {"from": "gpt", "value": "Desk"}, {"from": "human", "value": "Which kind of furniture is it?"}, {"from": "gpt", "value": "Desk"}, {"from": "human", "value": "What is the item of furniture that is above the box the container is in?"}, {"from": "gpt", "value": "Desk"}, {"from": "human", "value": "What is beneath the desk?"}, {"from": "gpt", "value": "Carpet"}, {"from": "human", "value": "Is the small instrument to the right of the container in the box?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the instrument to the right of the container large or small?"}, {"from": "gpt", "value": "Small"}, {"from": "human", "value": "On which side of the picture is the metal plate?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What is in the box that is under the desk?"}, {"from": "gpt", "value": "Container"}, {"from": "human", "value": "Is the white box to the left or to the right of the container that is not big?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Is the small container to the right or to the left of the white box?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Does the box below the desk look open?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What item of furniture is above the carpet?"}, {"from": "gpt", "value": "Desk"}, {"from": "human", "value": "The container of the paper is what pattern?"}, {"from": "gpt", "value": "Striped"}, {"from": "human", "value": "What is the plate made of?"}, {"from": "gpt", "value": "Metal"}]}, {"id": 2360075, "image": "gqa/images/2360075.jpg", "conversations": [{"from": "human", "value": "<image>\nOf which color is the ceiling?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Beige"}, {"from": "human", "value": "Is the tap in the bottom or in the top?"}, {"from": "gpt", "value": "Bottom"}, {"from": "human", "value": "Is it outdoors?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the color of the sink different than her shirt?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which kind of clothing is white?"}, {"from": "gpt", "value": "Shirt"}]}, {"id": 2396148, "image": "gqa/images/2396148.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich color is the shirt the person wears?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Green"}, {"from": "human", "value": "Which side of the image are the people on?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Is there a cow or a fence in the image?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the color of the sky the same as the shirt?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the vehicle on the road?"}, {"from": "gpt", "value": "Bus"}, {"from": "human", "value": "Where is the luggage?"}, {"from": "gpt", "value": "Ground"}, {"from": "human", "value": "What is the color of the sky?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "What is the color of the vehicle near the road?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "Do you see people to the left of the blue bus?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there any people next to the blue vehicle?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Who is standing next to the blue vehicle?"}, {"from": "gpt", "value": "People"}, {"from": "human", "value": "Are there any buses near the road?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Do you see a red bus or train?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which side of the image is the person on?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What type of vehicle do you think is this, a bus or a truck?"}, {"from": "gpt", "value": "Bus"}]}, {"id": 2352725, "image": "gqa/images/2352725.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is wearing a shirt?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Man"}, {"from": "human", "value": "Does the man that to the left of the people wear a hat?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Do you see umbrellas or canes?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is there an umbrella in this picture that is blue?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the woman to the right or to the left of the man that wears a tank top?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What is the man that is to the left of the people leaning on?"}, {"from": "gpt", "value": "Wall"}, {"from": "human", "value": "What color is the shirt the girl wears?"}, {"from": "gpt", "value": "Yellow"}, {"from": "human", "value": "What is the man that is to the right of the athlete wearing?"}, {"from": "gpt", "value": "Cap"}, {"from": "human", "value": "What is that woman wearing?"}, {"from": "gpt", "value": "T-shirt"}, {"from": "human", "value": "Who is wearing the t-shirt?"}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "Who is wearing a tshirt?"}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "What is the woman wearing?"}, {"from": "gpt", "value": "T-shirt"}, {"from": "human", "value": "The shirt the man is wearing is what color?"}, {"from": "gpt", "value": "Red"}, {"from": "human", "value": "On which side is the girl?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Who wears a shirt?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "Are there umbrellas at the cafe?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Who is wearing the tank top?"}, {"from": "gpt", "value": "Man"}, {"from": "human", "value": "The man that is to the left of the athlete is wearing what?"}, {"from": "gpt", "value": "Tank top"}]}, {"id": 2326006, "image": "gqa/images/2326006.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat piece of furniture is the bird sitting on top of?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Chair"}, {"from": "human", "value": "What's the bird sitting on top of?"}, {"from": "gpt", "value": "Chair"}, {"from": "human", "value": "The bird is sitting on top of what?"}, {"from": "gpt", "value": "Chair"}, {"from": "human", "value": "Is the cup on the left side or on the right of the picture?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Are there both a chair and a lamp in the photo?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What piece of furniture is made of wood?"}, {"from": "gpt", "value": "Chair"}, {"from": "human", "value": "On which side of the image is the person?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is there a chair at the table?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What type of furniture is to the right of the device in the top part of the photo?"}, {"from": "gpt", "value": "Chair"}, {"from": "human", "value": "What type of furniture is the bird sitting on?"}, {"from": "gpt", "value": "Chair"}, {"from": "human", "value": "Is there any lamp or table in this photo?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there any bottles or cups that are not brown?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the bird sitting on?"}, {"from": "gpt", "value": "Chair"}, {"from": "human", "value": "The bird is sitting on what?"}, {"from": "gpt", "value": "Chair"}, {"from": "human", "value": "Which item of furniture is made of wood?"}, {"from": "gpt", "value": "Chair"}, {"from": "human", "value": "What color is the jacket?"}, {"from": "gpt", "value": "Red"}, {"from": "human", "value": "Does the cup have white color?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Do the tiles seem to be black and white or colorful?"}, {"from": "gpt", "value": "Black and white"}, {"from": "human", "value": "The tiles are where?"}, {"from": "gpt", "value": "Floor"}]}, {"id": 2339765, "image": "gqa/images/2339765.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat does the polar bear sit on?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Rock"}, {"from": "human", "value": "What is the polar bear sitting on?"}, {"from": "gpt", "value": "Rock"}, {"from": "human", "value": "Which color do you think the water the window is standing in is?"}, {"from": "gpt", "value": "Gray"}, {"from": "human", "value": "Do you see either any animals or polar bears there?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What animal sits next to the gray water?"}, {"from": "gpt", "value": "Polar bear"}, {"from": "human", "value": "What is standing in the gray water?"}, {"from": "gpt", "value": "Window"}, {"from": "human", "value": "What is the window standing in?"}, {"from": "gpt", "value": "Water"}, {"from": "human", "value": "The polar bear lies on what?"}, {"from": "gpt", "value": "Rock"}, {"from": "human", "value": "Are there either any tools or chimneys in this photo?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the animal that sits next to the gray water called?"}, {"from": "gpt", "value": "Polar bear"}]}, {"id": 2388473, "image": "gqa/images/2388473.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is holding the paper?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "What clothing item is black?"}, {"from": "gpt", "value": "Raincoat"}, {"from": "human", "value": "Is the woman wearing a raincoat?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Where is it, a restaurant or a market?"}, {"from": "gpt", "value": "Restaurant"}, {"from": "human", "value": "Is the woman's umbrella both black and large?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What color is her umbrella?"}, {"from": "gpt", "value": "Black"}, {"from": "human", "value": "Are both the umbrella and the jeep the same color?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the sidewalk made of?"}, {"from": "gpt", "value": "Brick"}, {"from": "human", "value": "Who is holding the umbrella?"}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "What vehicle is to the left of the umbrella?"}, {"from": "gpt", "value": "Jeep"}, {"from": "human", "value": "Are there any bags to the left of the umbrella that she is holding?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the vehicle to the left of the umbrella the woman is holding?"}, {"from": "gpt", "value": "Jeep"}, {"from": "human", "value": "Which kind of clothing is not black?"}, {"from": "gpt", "value": "Sock"}, {"from": "human", "value": "Which type of clothing is black, the sock or the raincoat?"}, {"from": "gpt", "value": "Raincoat"}, {"from": "human", "value": "What is the name of the black piece of clothing?"}, {"from": "gpt", "value": "Raincoat"}, {"from": "human", "value": "Is the black vehicle on the left side of the image?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Which place is it?"}, {"from": "gpt", "value": "Restaurant"}, {"from": "human", "value": "Are there umbrellas or chairs?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2351383, "image": "gqa/images/2351383.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich room is it?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Bathroom"}, {"from": "human", "value": "Are there both a window and a door in the photograph?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is on the seat?"}, {"from": "gpt", "value": "Dirt"}, {"from": "human", "value": "Is this a cabinet or a mirror?"}, {"from": "gpt", "value": "Cabinet"}, {"from": "human", "value": "What piece of furniture is to the right of the toilet?"}, {"from": "gpt", "value": "Cabinet"}, {"from": "human", "value": "What kind of furniture is shown in the image?"}, {"from": "gpt", "value": "Cabinet"}, {"from": "human", "value": "Is it outdoors?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What's the dirt on?"}, {"from": "gpt", "value": "Seat"}, {"from": "human", "value": "What is the dirt on?"}, {"from": "gpt", "value": "Seat"}, {"from": "human", "value": "Is the toilet to the left of a desk?"}, {"from": "gpt", "value": "No"}]}, {"id": 2317897, "image": "gqa/images/2317897.jpg", "conversations": [{"from": "human", "value": "<image>\nIs it outdoors?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Which color is the vest that the man is wearing?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "Is the man in the park flying a flag?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Who is wearing a shirt?"}, {"from": "gpt", "value": "Man"}, {"from": "human", "value": "Who is wearing the shirt?"}, {"from": "gpt", "value": "Man"}, {"from": "human", "value": "Which place is it?"}, {"from": "gpt", "value": "Park"}, {"from": "human", "value": "Are both the kite and the vest the same color?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the color of the kite?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "That kite is where?"}, {"from": "gpt", "value": "Sky"}, {"from": "human", "value": "That jacket has which color?"}, {"from": "gpt", "value": "Dark blue"}, {"from": "human", "value": "Do the trees look green and short?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Who is flying the kite?"}, {"from": "gpt", "value": "Man"}, {"from": "human", "value": "Does the man in the park wear a helmet?"}, {"from": "gpt", "value": "No"}]}, {"id": 2412763, "image": "gqa/images/2412763.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the pattern of the shirt?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Striped"}, {"from": "human", "value": "Is the shirt striped and white?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is there a red train or door?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Does the thick rope seem to be brown or blue?"}, {"from": "gpt", "value": "Brown"}, {"from": "human", "value": "Are there doors in this photo?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "The door has which color?"}, {"from": "gpt", "value": "Red"}, {"from": "human", "value": "What device is the man using?"}, {"from": "gpt", "value": "Cell phone"}, {"from": "human", "value": "On which side is the cell phone?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What is the piece of furniture to the right of the rope that is not thin?"}, {"from": "gpt", "value": "Chair"}, {"from": "human", "value": "What color is the hat?"}, {"from": "gpt", "value": "Dark"}, {"from": "human", "value": "What is tied to the pole?"}, {"from": "gpt", "value": "Rope"}, {"from": "human", "value": "In which part is the phone, the top or the bottom?"}, {"from": "gpt", "value": "Top"}, {"from": "human", "value": "How heavy is the rope that is not thin?"}, {"from": "gpt", "value": "Heavy"}, {"from": "human", "value": "How big is the rope that is not thin?"}, {"from": "gpt", "value": "Large"}, {"from": "human", "value": "Is the man wearing a hat?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What's the man doing?"}, {"from": "gpt", "value": "Talking"}, {"from": "human", "value": "What is the person with the hat using?"}, {"from": "gpt", "value": "Cell phone"}, {"from": "human", "value": "Do you see toys or scooters there?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How thick is the rope that is not little?"}, {"from": "gpt", "value": "Thick"}, {"from": "human", "value": "What is the person with the hat doing, talking or staring?"}, {"from": "gpt", "value": "Talking"}, {"from": "human", "value": "What piece of furniture is to the left of the can?"}, {"from": "gpt", "value": "Chair"}, {"from": "human", "value": "Who is sitting?"}, {"from": "gpt", "value": "Man"}, {"from": "human", "value": "What clothing item isn't orange?"}, {"from": "gpt", "value": "Hat"}, {"from": "human", "value": "What kind of clothing is not striped?"}, {"from": "gpt", "value": "Hat"}, {"from": "human", "value": "Which side of the picture is the can on?"}, {"from": "gpt", "value": "Right"}]}, {"id": 2386758, "image": "gqa/images/2386758.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is wearing a shirt?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "Who is wearing the shirt?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "Is the girl on the right?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is there a dog that is not running?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the girl doing?"}, {"from": "gpt", "value": "Playing"}, {"from": "human", "value": "What kind of animal is on the grass?"}, {"from": "gpt", "value": "Dog"}, {"from": "human", "value": "Is the dog chasing a frisbee?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Which place is it?"}, {"from": "gpt", "value": "Field"}, {"from": "human", "value": "Is it outdoors?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the person that is standing throwing the frisbee?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the black animal doing?"}, {"from": "gpt", "value": "Running"}, {"from": "human", "value": "Where is the dog?"}, {"from": "gpt", "value": "Grass"}, {"from": "human", "value": "Who is throwing the frisbee?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "Who do you think is throwing the frisbee the dog is chasing?"}, {"from": "gpt", "value": "Girl"}]}, {"id": 2410367, "image": "gqa/images/2410367.jpg", "conversations": [{"from": "human", "value": "<image>\nDoes that tap look clean or dirty?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Clean"}, {"from": "human", "value": "Are there dream catchers or skateboards?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is reflected in the clean mirror?"}, {"from": "gpt", "value": "Hose"}, {"from": "human", "value": "What is reflected in the mirror?"}, {"from": "gpt", "value": "Hose"}, {"from": "human", "value": "What is the metal hose reflected in?"}, {"from": "gpt", "value": "Mirror"}, {"from": "human", "value": "Is it indoors or outdoors?"}, {"from": "gpt", "value": "Indoors"}, {"from": "human", "value": "What do the hose and the tap have in common?"}, {"from": "gpt", "value": "Material"}, {"from": "human", "value": "Which part of the image is the faucet in, the top or the bottom?"}, {"from": "gpt", "value": "Bottom"}, {"from": "human", "value": "How clean is the sink that looks white?"}, {"from": "gpt", "value": "Clean"}, {"from": "human", "value": "Is there either any snow or sand that is not white?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the sand white?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Which side of the image is the shelf on?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "On which side is the hose?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Are there chairs in the image?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What's on the wall?"}, {"from": "gpt", "value": "Outlet"}, {"from": "human", "value": "What do you think is on the wall?"}, {"from": "gpt", "value": "Outlet"}]}, {"id": 2373348, "image": "gqa/images/2373348.jpg", "conversations": [{"from": "human", "value": "<image>\nDoes the window that looks black look metallic?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there both a window and a door?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is there either a star or a clock in the picture?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Where are the flags, in the bottom or in the top of the image?"}, {"from": "gpt", "value": "Bottom"}, {"from": "human", "value": "Does the window that is made of metal look black?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2405445, "image": "gqa/images/2405445.jpg", "conversations": [{"from": "human", "value": "<image>\nDo the leggings and the shorts have the same color?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What does the boy hold?"}, {"from": "gpt", "value": "Frisbee"}, {"from": "human", "value": "Is the boy in the top part or in the bottom of the picture?"}, {"from": "gpt", "value": "Top"}, {"from": "human", "value": "Does the boy hold a frisbee?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there any frisbees or parachutes in the picture?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Who is wearing the leggings?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "Who is wearing leggings?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "Who wears shoes?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "Who wears the shoes?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "Is the boy wearing glasses?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the frisbee orange?"}, {"from": "gpt", "value": "No"}]}, {"id": 2388560, "image": "gqa/images/2388560.jpg", "conversations": [{"from": "human", "value": "<image>\nIs she holding a racket?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the woman holding?"}, {"from": "gpt", "value": "Umbrella"}, {"from": "human", "value": "Is she wearing a scarf?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Do you think the ground is wet?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "The umbrella is in front of what?"}, {"from": "gpt", "value": "Pole"}, {"from": "human", "value": "What's the umbrella in front of?"}, {"from": "gpt", "value": "Pole"}, {"from": "human", "value": "Is the lamp to the right or to the left of the tower that is not large?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Which color is the shirt she is wearing?"}, {"from": "gpt", "value": "Black"}, {"from": "human", "value": "What is the color of the scarf the woman is wearing?"}, {"from": "gpt", "value": "Pink"}, {"from": "human", "value": "Are there black umbrellas or objects?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Which color is the umbrella?"}, {"from": "gpt", "value": "Black"}, {"from": "human", "value": "Is the umbrella black and striped?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the pole behind an umbrella?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the color of the hair?"}, {"from": "gpt", "value": "Dark"}, {"from": "human", "value": "Who is holding the black umbrella?"}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "Is this a striped umbrella?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Does the tower that is to the left of the other tower appear to be huge?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is in front of the pole?"}, {"from": "gpt", "value": "Umbrella"}, {"from": "human", "value": "Does the tower to the right of the lamp have large size?"}, {"from": "gpt", "value": "No"}]}, {"id": 2409500, "image": "gqa/images/2409500.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich kind of animal is standing on the hay?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Cow"}, {"from": "human", "value": "Is the weather clear?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there lambs in this image?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color is the cow that is in front of the fence?"}, {"from": "gpt", "value": "Brown"}, {"from": "human", "value": "Is the hay brown and wet?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What kind of animal is standing on the ground?"}, {"from": "gpt", "value": "Cow"}, {"from": "human", "value": "What is under the baby cow?"}, {"from": "gpt", "value": "Hay"}, {"from": "human", "value": "What is the animal that the fence is behind of?"}, {"from": "gpt", "value": "Cow"}, {"from": "human", "value": "What animal is the post in front of?"}, {"from": "gpt", "value": "Cow"}, {"from": "human", "value": "What is in front of the small bush?"}, {"from": "gpt", "value": "Fence"}, {"from": "human", "value": "What's in front of the bush?"}, {"from": "gpt", "value": "Fence"}, {"from": "human", "value": "What is the ground covered by?"}, {"from": "gpt", "value": "Hay"}, {"from": "human", "value": "What is that ground covered by?"}, {"from": "gpt", "value": "Hay"}, {"from": "human", "value": "What is covering the ground?"}, {"from": "gpt", "value": "Hay"}, {"from": "human", "value": "What color is the bare forest?"}, {"from": "gpt", "value": "Brown"}, {"from": "human", "value": "What is in front of the pine tree on the right of the picture?"}, {"from": "gpt", "value": "Fence"}, {"from": "human", "value": "What is the animal behind the wood post?"}, {"from": "gpt", "value": "Cow"}, {"from": "human", "value": "Is the cow above the hay both brown and adult?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What's covered by the hay?"}, {"from": "gpt", "value": "Ground"}]}, {"id": 2401687, "image": "gqa/images/2401687.jpg", "conversations": [{"from": "human", "value": "<image>\nOn which side of the picture is the cup?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What is the cup made of?"}, {"from": "gpt", "value": "Plastic"}, {"from": "human", "value": "Does the cup look full?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the mozzarella cheese in the bottom?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Which kind of fast food is presented in the image?"}, {"from": "gpt", "value": "Pizza"}, {"from": "human", "value": "Are there either any pizzas or forks?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2347339, "image": "gqa/images/2347339.jpg", "conversations": [{"from": "human", "value": "<image>\nAre there candles or umbrellas?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are the trees behind a fence?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What kind of vehicle is in front of the trees?"}, {"from": "gpt", "value": "Car"}, {"from": "human", "value": "What type of vehicle is in front of the trees?"}, {"from": "gpt", "value": "Car"}, {"from": "human", "value": "What is the car in front of?"}, {"from": "gpt", "value": "Trees"}, {"from": "human", "value": "That car is in front of what?"}, {"from": "gpt", "value": "Trees"}, {"from": "human", "value": "Is the purse on the right side?"}, {"from": "gpt", "value": "No"}]}, {"id": 1056, "image": "gqa/images/1056.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the tank top brown?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "On which side of the image is the person?"}, {"from": "gpt", "value": "Right"}]}, {"id": 2353713, "image": "gqa/images/2353713.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the bowl to the right or to the left of the cup in the bottom part?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Is the girl to the right or to the left of the bowl?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Where is the boy standing?"}, {"from": "gpt", "value": "Doorway"}, {"from": "human", "value": "Does the person to the left of the soup hold an umbrella?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there any utensils or cups in the picture?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Who is standing in the doorway?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "Is the boy on the right or on the left?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is the cup in the top of the image?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Do you see any soup in this photograph?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the boy to the right or to the left of the person who is to the left of the bowl?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is the cup to the right or to the left of the round plate?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "What color is the soup?"}, {"from": "gpt", "value": "Yellow"}, {"from": "human", "value": "Who holds the bowl?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "What does the person to the left of the soup hold?"}, {"from": "gpt", "value": "Bowl"}, {"from": "human", "value": "What does the girl hold?"}, {"from": "gpt", "value": "Bowl"}, {"from": "human", "value": "What kind of appliance is to the right of the girl?"}, {"from": "gpt", "value": "Stove"}]}, {"id": 2333193, "image": "gqa/images/2333193.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is the sheep in the top of the photo?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Tan"}, {"from": "human", "value": "Is there a fence or a sheep in this photograph?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2413479, "image": "gqa/images/2413479.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is this mozzarella cheese on?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Pizza"}, {"from": "human", "value": "Is the white paper under the pizza with the tomato sauce?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is under the cheese pizza?"}, {"from": "gpt", "value": "Paper"}, {"from": "human", "value": "Is the person eating a hot dog?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What type of fast food do you think is the person in front of?"}, {"from": "gpt", "value": "Pizza"}, {"from": "human", "value": "What is under the pizza behind the person?"}, {"from": "gpt", "value": "Paper"}, {"from": "human", "value": "In which part of the photo is the white food, the top or the bottom?"}, {"from": "gpt", "value": "Bottom"}, {"from": "human", "value": "What is on the table made of wood?"}, {"from": "gpt", "value": "Pizza"}, {"from": "human", "value": "What is on the white paper?"}, {"from": "gpt", "value": "Pizza"}, {"from": "human", "value": "Is there any chair in the image?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the knife in the bottom part of the picture?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What food is on the table?"}, {"from": "gpt", "value": "Pizza"}, {"from": "human", "value": "Is the brown table metallic or wooden?"}, {"from": "gpt", "value": "Wooden"}, {"from": "human", "value": "Are there any cups in the image?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the person in front of a bus?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the person eating?"}, {"from": "gpt", "value": "Pizza"}, {"from": "human", "value": "Which kind of sauce is it?"}, {"from": "gpt", "value": "Tomato sauce"}, {"from": "human", "value": "What is the sauce that is shown?"}, {"from": "gpt", "value": "Tomato sauce"}, {"from": "human", "value": "Which color does the tee shirt have?"}, {"from": "gpt", "value": "Black"}, {"from": "human", "value": "In which part is the fork, the bottom or the top?"}, {"from": "gpt", "value": "Top"}]}, {"id": 2373995, "image": "gqa/images/2373995.jpg", "conversations": [{"from": "human", "value": "<image>\nWho rides a horse?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Men"}, {"from": "human", "value": "Who is riding a horse?"}, {"from": "gpt", "value": "Men"}, {"from": "human", "value": "Is there a horse to the left of the man that is wearing a hat?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "On which side of the image is the horse?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "On which side of the picture is the horse?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is there a pillow or a bench in the image?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the man who is to the right of the horse wearing?"}, {"from": "gpt", "value": "Hat"}]}, {"id": 2344262, "image": "gqa/images/2344262.jpg", "conversations": [{"from": "human", "value": "<image>\nDoes the gray sky look clear?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the color of the SUV that is to the left of the boat?"}, {"from": "gpt", "value": "Green"}, {"from": "human", "value": "How big is the gray building?"}, {"from": "gpt", "value": "Large"}, {"from": "human", "value": "How is the vehicle on the dirt called?"}, {"from": "gpt", "value": "Car"}, {"from": "human", "value": "Is the tower small and gray?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which kind of vehicle is parked on the street?"}, {"from": "gpt", "value": "Suv"}, {"from": "human", "value": "What is the vehicle that is parked on the street?"}, {"from": "gpt", "value": "Suv"}]}, {"id": 2386108, "image": "gqa/images/2386108.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the woman on the left side?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}]}, {"id": 2338188, "image": "gqa/images/2338188.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is this fork, red or white?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Red"}, {"from": "human", "value": "The fork is on what?"}, {"from": "gpt", "value": "Plate"}, {"from": "human", "value": "What is on the plate?"}, {"from": "gpt", "value": "Fork"}, {"from": "human", "value": "Are there forks on the plate?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is there any silver fork or spoon?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Where in this picture is the red fork, in the bottom or in the top?"}, {"from": "gpt", "value": "Top"}]}, {"id": 2398868, "image": "gqa/images/2398868.jpg", "conversations": [{"from": "human", "value": "<image>\nHow large is the bear?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Small"}, {"from": "human", "value": "Is there a bear in the blue water?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Does the bear have small size and brown color?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Which kind of animal is walking?"}, {"from": "gpt", "value": "Bear"}, {"from": "human", "value": "What is the young animal?"}, {"from": "gpt", "value": "Bear"}, {"from": "human", "value": "Where is that bear?"}, {"from": "gpt", "value": "Water"}]}, {"id": 2342956, "image": "gqa/images/2342956.jpg", "conversations": [{"from": "human", "value": "<image>\nWho holds the racket that to the left of the ball?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Man"}, {"from": "human", "value": "Are there either any tables or drawers?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Does the man to the left of the bag wear a coat?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Does the man to the left of the ball hold a racket?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 1160245, "image": "gqa/images/1160245.jpg", "conversations": [{"from": "human", "value": "<image>\nAre there women or men?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What color is the logo?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "What is the woman holding?"}, {"from": "gpt", "value": "Camera"}, {"from": "human", "value": "What is the device that the woman is holding?"}, {"from": "gpt", "value": "Camera"}, {"from": "human", "value": "What device is the woman holding?"}, {"from": "gpt", "value": "Camera"}, {"from": "human", "value": "Is the woman to the right of the train holding a camera?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there both doors and windows in the photo?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the man that is to the left of the train doing?"}, {"from": "gpt", "value": "Bending"}, {"from": "human", "value": "What color is the skirt, blue or black?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "On which side of the picture is the woman?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Is the woman to the right of the train the person is watching?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "The woman to the right of the man is holding what?"}, {"from": "gpt", "value": "Camera"}, {"from": "human", "value": "How is the vehicle to the left of the man that wears a shirt called?"}, {"from": "gpt", "value": "Train"}, {"from": "human", "value": "What type of vehicle is to the left of the person that holds the camera?"}, {"from": "gpt", "value": "Train"}, {"from": "human", "value": "Which color is the shirt that the man is wearing?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "Is there a chair to the left of the person that is to the left of the man?"}, {"from": "gpt", "value": "No"}]}, {"id": 2325826, "image": "gqa/images/2325826.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich side of the image is the fence on?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What is the fence made of?"}, {"from": "gpt", "value": "Metal"}, {"from": "human", "value": "What type of vehicle is this, a truck or a train?"}, {"from": "gpt", "value": "Train"}, {"from": "human", "value": "Are there either any black doors or windows in this photo?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the train to the left of the fence?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Do the fence and the train door have the same color?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which material is the fence made of, metal or mesh?"}, {"from": "gpt", "value": "Metal"}]}, {"id": 2402697, "image": "gqa/images/2402697.jpg", "conversations": [{"from": "human", "value": "<image>\nHow's the weather?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Sunny"}, {"from": "human", "value": "What color does the airplane in the middle have?"}, {"from": "gpt", "value": "Yellow"}]}, {"id": 2402244, "image": "gqa/images/2402244.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the aircraft that is parked at the terminal?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Jet"}, {"from": "human", "value": "Are there any jets at the airport?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Which place is it?"}, {"from": "gpt", "value": "Airport"}, {"from": "human", "value": "Is it an indoors or outdoors scene?"}, {"from": "gpt", "value": "Outdoors"}, {"from": "human", "value": "Do you see jets on the terminal?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Where is the jet?"}, {"from": "gpt", "value": "Terminal"}, {"from": "human", "value": "How is the aircraft that is on the terminal called?"}, {"from": "gpt", "value": "Jet"}, {"from": "human", "value": "What kind of aircraft is on the terminal?"}, {"from": "gpt", "value": "Jet"}, {"from": "human", "value": "Which kind of aircraft is parked at the terminal?"}, {"from": "gpt", "value": "Jet"}, {"from": "human", "value": "What is on the terminal?"}, {"from": "gpt", "value": "Jet"}, {"from": "human", "value": "What kind of aircraft is white?"}, {"from": "gpt", "value": "Jet"}, {"from": "human", "value": "What kind of aircraft is white?"}, {"from": "gpt", "value": "Jet"}, {"from": "human", "value": "What kind of aircraft is that?"}, {"from": "gpt", "value": "Jet"}]}, {"id": 2383544, "image": "gqa/images/2383544.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the man in front of?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Door"}, {"from": "human", "value": "Which kind of furniture is made of wood?"}, {"from": "gpt", "value": "Chair"}, {"from": "human", "value": "Which kind of furniture is it?"}, {"from": "gpt", "value": "Chair"}, {"from": "human", "value": "What is the name of the item of furniture that is made of wood?"}, {"from": "gpt", "value": "Chair"}, {"from": "human", "value": "Is the man to the left of the person that wears a necktie?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there red ties in the photo?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Who in the image is posing?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "Does the happy person appear to be posing?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Do you see either any glasses or ties there?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Do you think the shirt is long sleeved or short sleeved?"}, {"from": "gpt", "value": "Long sleeved"}, {"from": "human", "value": "Does the red hair seem to be curled or straight?"}, {"from": "gpt", "value": "Curled"}, {"from": "human", "value": "Does the shirt look white and long sleeved?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the color of the shirt?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "Are there chairs or tables that are made of metal?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What's the boy holding onto?"}, {"from": "gpt", "value": "Chair"}, {"from": "human", "value": "Is the boy wearing a hat?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is this boy holding onto?"}, {"from": "gpt", "value": "Chair"}, {"from": "human", "value": "Who is holding onto the chair that is made of wood?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "Who is wearing the shirt?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "Who is wearing the tie?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "Who is wearing a tie?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "Is the happy person wearing a cap?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the door made of metal?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Does the boy's hair appear to be curled and red?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Who is sitting in the chair made out of wood?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "What's the boy doing?"}, {"from": "gpt", "value": "Posing"}, {"from": "human", "value": "Is the chair made of the same material as the door?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What kind of furniture is made of the same material as the door?"}, {"from": "gpt", "value": "Chair"}, {"from": "human", "value": "Is the man eating food?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Does the hair look gray?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is that man in front of?"}, {"from": "gpt", "value": "Door"}, {"from": "human", "value": "Who is wearing a shirt?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "What piece of furniture is the boy holding onto?"}, {"from": "gpt", "value": "Chair"}, {"from": "human", "value": "Who is sitting in the chair?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "On which side of the photo is the food?"}, {"from": "gpt", "value": "Right"}]}, {"id": 2368187, "image": "gqa/images/2368187.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color do you think the shirt that the man is wearing is?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "What is the man doing?"}, {"from": "gpt", "value": "Playing"}, {"from": "human", "value": "Is the person to the left of the ball swinging a bat?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "On which side of the photo is the man racket?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is the person to the right of the racket about to hit a ball?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the man about to hit?"}, {"from": "gpt", "value": "Ball"}, {"from": "human", "value": "The man to the right of the racket is about to hit what?"}, {"from": "gpt", "value": "Ball"}, {"from": "human", "value": "Who is about to hit the ball?"}, {"from": "gpt", "value": "Man"}, {"from": "human", "value": "Do you see any rackets that are red?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there both skateboards and rackets in this image?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color does the fence have?"}, {"from": "gpt", "value": "Green"}, {"from": "human", "value": "Does the pole have the same color as the fence?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Does the shoe have white color?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the man on the left or on the right side of the picture?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Are there fathers or players?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Do the shirt and the net have the same color?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the color of the shorts?"}, {"from": "gpt", "value": "Gray"}, {"from": "human", "value": "What is the man to the left of the ball holding?"}, {"from": "gpt", "value": "Racket"}, {"from": "human", "value": "Who is wearing a shirt?"}, {"from": "gpt", "value": "Man"}]}, {"id": 2417981, "image": "gqa/images/2417981.jpg", "conversations": [{"from": "human", "value": "<image>\nOn which side of the photo is the white airplane?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Right"}]}, {"id": 2405975, "image": "gqa/images/2405975.jpg", "conversations": [{"from": "human", "value": "<image>\nAre the railroad tracks silver and curved?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is that train large and blue?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there any letters that are black?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the color of the vehicle in the center?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "What vehicle is it?"}, {"from": "gpt", "value": "Train"}, {"from": "human", "value": "Which place is it?"}, {"from": "gpt", "value": "Tunnel"}, {"from": "human", "value": "What is the picture showing?"}, {"from": "gpt", "value": "Tunnel"}, {"from": "human", "value": "Is the color of the tracks different than the letters?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Do the letters appear to be red?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there both numbers and letters in the picture?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How large is the train?"}, {"from": "gpt", "value": "Large"}, {"from": "human", "value": "What do you think is this, a bus or a train?"}, {"from": "gpt", "value": "Train"}]}, {"id": 2339078, "image": "gqa/images/2339078.jpg", "conversations": [{"from": "human", "value": "<image>\nWhere is it?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Walkway"}, {"from": "human", "value": "Which place is it?"}, {"from": "gpt", "value": "Walkway"}]}, {"id": 713212, "image": "gqa/images/713212.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat's the woman wearing?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Hat"}, {"from": "human", "value": "Is there a flag or an umbrella in this picture?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the woman wearing?"}, {"from": "gpt", "value": "Hat"}, {"from": "human", "value": "The woman is holding what?"}, {"from": "gpt", "value": "Umbrella"}, {"from": "human", "value": "Is that woman holding a racket?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Who is wearing the hat?"}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "Is she wearing a hat?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2341975, "image": "gqa/images/2341975.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat animal is on the shelf?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Cat"}, {"from": "human", "value": "Which kind of furniture is the cat on?"}, {"from": "gpt", "value": "Shelf"}, {"from": "human", "value": "What is the cat on?"}, {"from": "gpt", "value": "Shelf"}, {"from": "human", "value": "Which kind of animal is on the shelf?"}, {"from": "gpt", "value": "Cat"}, {"from": "human", "value": "What is the name of this piece of furniture?"}, {"from": "gpt", "value": "Shelf"}, {"from": "human", "value": "Do you see a bottle or a cabinet?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there either any cows or wolves in the picture?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What animal is it?"}, {"from": "gpt", "value": "Cat"}, {"from": "human", "value": "What animal is presented in the image?"}, {"from": "gpt", "value": "Cat"}, {"from": "human", "value": "What is this cat on, a chair or a shelf?"}, {"from": "gpt", "value": "Shelf"}]}, {"id": 2410536, "image": "gqa/images/2410536.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is wearing a glove?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Player"}, {"from": "human", "value": "Which color is the shirt?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "Who is on the dirt?"}, {"from": "gpt", "value": "Child"}, {"from": "human", "value": "What is the baseball player throwing?"}, {"from": "gpt", "value": "Baseball"}, {"from": "human", "value": "Who is throwing the baseball?"}, {"from": "gpt", "value": "Player"}, {"from": "human", "value": "Who is throwing the white baseball?"}, {"from": "gpt", "value": "Player"}, {"from": "human", "value": "Is the baseball player wearing a cap?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is it outdoors?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Which side of the image is the kid on?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is the cap blue?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the baseball player holding?"}, {"from": "gpt", "value": "Baseball"}, {"from": "human", "value": "Is the player holding a baseball?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the baseball player wearing a glove?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Who is holding the white baseball?"}, {"from": "gpt", "value": "Player"}, {"from": "human", "value": "Who is wearing a cap?"}, {"from": "gpt", "value": "Player"}, {"from": "human", "value": "Who is wearing the cap?"}, {"from": "gpt", "value": "Player"}]}, {"id": 2412507, "image": "gqa/images/2412507.jpg", "conversations": [{"from": "human", "value": "<image>\nDo you see either any cars or trains?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is that vehicle called?"}, {"from": "gpt", "value": "Train"}, {"from": "human", "value": "What is in front of the tunnel?"}, {"from": "gpt", "value": "Train"}, {"from": "human", "value": "What is the vehicle in front of the tunnel?"}, {"from": "gpt", "value": "Train"}, {"from": "human", "value": "Which color does the vehicle in front of the tunnel have?"}, {"from": "gpt", "value": "Gray"}, {"from": "human", "value": "What is the train in front of?"}, {"from": "gpt", "value": "Tunnel"}, {"from": "human", "value": "The train is in front of what?"}, {"from": "gpt", "value": "Tunnel"}, {"from": "human", "value": "Are there both a window and a door in the picture?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2333736, "image": "gqa/images/2333736.jpg", "conversations": [{"from": "human", "value": "<image>\nAre there cages or tents in this image?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Do the socks look black?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there either any skateboards or boys in the image?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Where is the traffic light, on the left or on the right side of the image?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Are the shoes different in color than the shorts?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are the shorts black?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Which color is the traffic light, red or black?"}, {"from": "gpt", "value": "Red"}, {"from": "human", "value": "Is there either a yellow hydrant or traffic light?"}, {"from": "gpt", "value": "No"}]}, {"id": 2396360, "image": "gqa/images/2396360.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the sky clear or cloudy?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Cloudy"}, {"from": "human", "value": "Are there zebras in the image?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What are the weather conditions today?"}, {"from": "gpt", "value": "Cloudy"}, {"from": "human", "value": "How is the weather?"}, {"from": "gpt", "value": "Cloudy"}, {"from": "human", "value": "What is the color of the field?"}, {"from": "gpt", "value": "Green"}, {"from": "human", "value": "Does the sky have blue color?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the sky cloudy and white?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the vehicle on the right or on the left side of the image?"}, {"from": "gpt", "value": "Right"}]}, {"id": 2359745, "image": "gqa/images/2359745.jpg", "conversations": [{"from": "human", "value": "<image>\nAre there either cars or buses?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "The grass on the cake has what color?"}, {"from": "gpt", "value": "Green"}, {"from": "human", "value": "Which kind of vehicle is on the table?"}, {"from": "gpt", "value": "Bus"}, {"from": "human", "value": "What is on the table?"}, {"from": "gpt", "value": "Bus"}]}, {"id": 2413617, "image": "gqa/images/2413617.jpg", "conversations": [{"from": "human", "value": "<image>\nAre there any cans that are black in the image?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Do you think the can is yellow?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "The floor has what color?"}, {"from": "gpt", "value": "Black"}, {"from": "human", "value": "Are there bottles or boxes in the picture?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Do the wall and the towel have the same color?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the can on the left side or on the right of the picture?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Are there blue towels or blankets?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the curtain on the right?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the tap to the left or to the right of the towel?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Is the curtain to the right or to the left of the white towel?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Is the yellow curtain to the left or to the right of the mirror?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Do the sink and the can have the same color?"}, {"from": "gpt", "value": "No"}]}, {"id": 2324577, "image": "gqa/images/2324577.jpg", "conversations": [{"from": "human", "value": "<image>\nAre there rackets in this photograph?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Does the tank top look black or blue?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "Is the cap black or green?"}, {"from": "gpt", "value": "Black"}, {"from": "human", "value": "What is the woman wearing?"}, {"from": "gpt", "value": "Cap"}, {"from": "human", "value": "What is the person that is to the right of the racket wearing?"}, {"from": "gpt", "value": "Cap"}, {"from": "human", "value": "Who is wearing a cap?"}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "Is the racket on the right side or on the left of the photo?"}, {"from": "gpt", "value": "Left"}]}, {"id": 2359952, "image": "gqa/images/2359952.jpg", "conversations": [{"from": "human", "value": "<image>\nThis boy is wearing what?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Hat"}, {"from": "human", "value": "Is the boy wearing a glove?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Of what color are the ducks?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "What color is the sand?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "Do you see either any brown sand or mud?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there fences or frisbees?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "In which part of the photo are the white ducks, the bottom or the top?"}, {"from": "gpt", "value": "Top"}, {"from": "human", "value": "Does the shirt look black or blue?"}, {"from": "gpt", "value": "Blue"}, {"from": "human", "value": "In which part of the picture are the birds, the bottom or the top?"}, {"from": "gpt", "value": "Top"}, {"from": "human", "value": "Who is wearing a hat?"}, {"from": "gpt", "value": "Boy"}, {"from": "human", "value": "What is the boy wearing?"}, {"from": "gpt", "value": "Hat"}, {"from": "human", "value": "Which place is it?"}, {"from": "gpt", "value": "Park"}, {"from": "human", "value": "Are these animals all of the same type?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the color of the hat that the boy is wearing?"}, {"from": "gpt", "value": "Beige"}]}, {"id": 2317211, "image": "gqa/images/2317211.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the table behind or in front of the person that is wearing a bandana?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Behind"}, {"from": "human", "value": "On which side of the picture is the mat?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Are the scissors in the bottom of the image?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Which kind of furniture is the person in front of?"}, {"from": "gpt", "value": "Table"}, {"from": "human", "value": "Is the person wearing a glove?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What's the person in front of?"}, {"from": "gpt", "value": "Table"}, {"from": "human", "value": "Is the bandana purple or black?"}, {"from": "gpt", "value": "Purple"}, {"from": "human", "value": "Is the flower yellow or purple?"}, {"from": "gpt", "value": "Purple"}, {"from": "human", "value": "Does the belt look beige?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the person wearing?"}, {"from": "gpt", "value": "Bandana"}, {"from": "human", "value": "What is this person wearing?"}, {"from": "gpt", "value": "Bandana"}]}, {"id": 2393686, "image": "gqa/images/2393686.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat vehicle are the trees behind of?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Truck"}, {"from": "human", "value": "What is common to the sky and the stroller?"}, {"from": "gpt", "value": "Color"}, {"from": "human", "value": "What is stuck in the grass?"}, {"from": "gpt", "value": "Post"}, {"from": "human", "value": "Is there either a bus or a mirror in the photo?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is in front of the green trees?"}, {"from": "gpt", "value": "Truck"}, {"from": "human", "value": "Are there vans or trucks in this image?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "On which side of the picture is the girl?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What is the vehicle to the left of the girl?"}, {"from": "gpt", "value": "Truck"}, {"from": "human", "value": "Which side of the image is the stroller on?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What is stuck in the green grass?"}, {"from": "gpt", "value": "Post"}, {"from": "human", "value": "Are the trees behind the vehicle near the tents?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Do you see tents to the right of the truck?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are the tents on the left or on the right of the picture?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Which side of the image are the vendors on?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Does that truck look small and red?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Who is standing?"}, {"from": "gpt", "value": "Girl"}, {"from": "human", "value": "What type of vehicle is in front of the green trees?"}, {"from": "gpt", "value": "Truck"}, {"from": "human", "value": "Which kind of vehicle is in front of the trees?"}, {"from": "gpt", "value": "Truck"}]}, {"id": 2346280, "image": "gqa/images/2346280.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the marker on?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Figure"}, {"from": "human", "value": "Is the clock in the top or in the bottom?"}, {"from": "gpt", "value": "Top"}, {"from": "human", "value": "What's on the figure?"}, {"from": "gpt", "value": "Marker"}]}, {"id": 2328409, "image": "gqa/images/2328409.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat's the pillow on?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Bed"}, {"from": "human", "value": "Is the white pillow on the right or on the left?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Is the white sheet covering a couch?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the bed covered by?"}, {"from": "gpt", "value": "Sheet"}, {"from": "human", "value": "The bed is covered by what?"}, {"from": "gpt", "value": "Sheet"}, {"from": "human", "value": "Is there a blue towel or pillow?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "How large is the window?"}, {"from": "gpt", "value": "Large"}]}, {"id": 2347358, "image": "gqa/images/2347358.jpg", "conversations": [{"from": "human", "value": "<image>\nAre the flowers in a vase?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is in the planter?"}, {"from": "gpt", "value": "Flowers"}, {"from": "human", "value": "Does the racket seem to be red or black?"}, {"from": "gpt", "value": "Red"}, {"from": "human", "value": "Is this man wearing jeans?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there either boys or carts in this photo?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is that shirt red or gray?"}, {"from": "gpt", "value": "Gray"}]}, {"id": 1592531, "image": "gqa/images/1592531.jpg", "conversations": [{"from": "human", "value": "<image>\nHow is the clothing item that is gray called?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Suit"}, {"from": "human", "value": "What color are the eyes?"}, {"from": "gpt", "value": "Gray"}]}, {"id": 2329122, "image": "gqa/images/2329122.jpg", "conversations": [{"from": "human", "value": "<image>\nIs there any food to the right of the man?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the man in front of?"}, {"from": "gpt", "value": "Kiosk"}, {"from": "human", "value": "What place was the photo taken at?"}, {"from": "gpt", "value": "Kiosk"}, {"from": "human", "value": "Is the road tan?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the color of the shirt the man wears?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "Is there any food on the kiosk?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Which place is it?"}, {"from": "gpt", "value": "Kiosk"}, {"from": "human", "value": "What do you think is on the post?"}, {"from": "gpt", "value": "Banana bunch"}, {"from": "human", "value": "What is on the post?"}, {"from": "gpt", "value": "Banana bunch"}, {"from": "human", "value": "What are the bottles made of?"}, {"from": "gpt", "value": "Plastic"}, {"from": "human", "value": "Are the bottles that are not short made of plastic?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2343934, "image": "gqa/images/2343934.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wears a shoe?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "People"}, {"from": "human", "value": "Who is wearing a jacket?"}, {"from": "gpt", "value": "People"}, {"from": "human", "value": "Who is wearing the jacket?"}, {"from": "gpt", "value": "People"}, {"from": "human", "value": "What is the color of the bridge?"}, {"from": "gpt", "value": "Black"}, {"from": "human", "value": "Are there either any bridges or rackets that are black?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Who is wearing a shoe?"}, {"from": "gpt", "value": "People"}]}, {"id": 2414004, "image": "gqa/images/2414004.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is the train?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Green"}]}, {"id": 2325261, "image": "gqa/images/2325261.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is sitting at the table?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "People"}, {"from": "human", "value": "Are there both a table and a plate in the photo?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there guys at the table?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is there a chair at the table?"}, {"from": "gpt", "value": "No"}]}, {"id": 2385171, "image": "gqa/images/2385171.jpg", "conversations": [{"from": "human", "value": "<image>\nAre there traffic lights or skis?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there either traffic lights or trucks in the image?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 3029, "image": "gqa/images/3029.jpg", "conversations": [{"from": "human", "value": "<image>\nDoes the yellow vehicle look old?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color is the license plate?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "What color does the car have?"}, {"from": "gpt", "value": "Yellow"}]}, {"id": 2389359, "image": "gqa/images/2389359.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the telephone in the bottom part or in the top of the image?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Top"}, {"from": "human", "value": "Are there faucets in the bathroom?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is it an indoors scene?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "On which side is the white toilet?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Are there bottles?"}, {"from": "gpt", "value": "No"}]}, {"id": 2368134, "image": "gqa/images/2368134.jpg", "conversations": [{"from": "human", "value": "<image>\nDo you think the tennis racket is black and white?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the tennis player to the right of a racket?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Who is wearing a hat?"}, {"from": "gpt", "value": "Player"}, {"from": "human", "value": "Who is wearing the hat?"}, {"from": "gpt", "value": "Player"}, {"from": "human", "value": "Who is wearing the skirt?"}, {"from": "gpt", "value": "Player"}, {"from": "human", "value": "Is the person to the right of the racket wearing a skirt?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the tennis player to the right or to the left of the racket on the left?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Who holds the racket?"}, {"from": "gpt", "value": "Player"}, {"from": "human", "value": "Who is wearing a skirt?"}, {"from": "gpt", "value": "Player"}, {"from": "human", "value": "Are there breads or plates?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is the racket on the right side?"}, {"from": "gpt", "value": "No"}]}, {"id": 2346464, "image": "gqa/images/2346464.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the blue plate made of steel or glass?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Steel"}, {"from": "human", "value": "Are there any clocks or helmets?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there either any wallets or clocks that are black?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the blue plate in the bottom or in the top of the photo?"}, {"from": "gpt", "value": "Top"}]}, {"id": 2337024, "image": "gqa/images/2337024.jpg", "conversations": [{"from": "human", "value": "<image>\nWho stands under the umbrella?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "Are there any fences or dogs in this photo?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Do you see either any women or boys in the photograph?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What color is the coat that the woman is wearing?"}, {"from": "gpt", "value": "Red"}, {"from": "human", "value": "What type of vehicle is the same color as the coat that the woman is wearing?"}, {"from": "gpt", "value": "Car"}, {"from": "human", "value": "What do the car and the coat have in common?"}, {"from": "gpt", "value": "Color"}, {"from": "human", "value": "On which side of the photo is the red car?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Which kind of clothing is red?"}, {"from": "gpt", "value": "Coat"}, {"from": "human", "value": "Who is wearing the coat?"}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "Who is wearing a coat?"}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "What is she holding?"}, {"from": "gpt", "value": "Umbrella"}, {"from": "human", "value": "What is the woman holding?"}, {"from": "gpt", "value": "Umbrella"}, {"from": "human", "value": "Are there cones or books?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What color is the vehicle to the right of the woman?"}, {"from": "gpt", "value": "Red"}]}, {"id": 2390175, "image": "gqa/images/2390175.jpg", "conversations": [{"from": "human", "value": "<image>\nDoes the bird that is not little seem to be sleeping?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is the bird that is sleeping small and gray?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the bird doing?"}, {"from": "gpt", "value": "Sleeping"}, {"from": "human", "value": "What color do you think the large bird is?"}, {"from": "gpt", "value": "Gray"}]}, {"id": 2382585, "image": "gqa/images/2382585.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat kind of clothing isn't blue?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Socks"}, {"from": "human", "value": "Is the man to the right or to the left of the woman?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "What kind of clothing is blue, the socks or the jeans?"}, {"from": "gpt", "value": "Jeans"}, {"from": "human", "value": "Which side is the woman on?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "What clothing items are blue?"}, {"from": "gpt", "value": "Jeans"}]}, {"id": 2388617, "image": "gqa/images/2388617.jpg", "conversations": [{"from": "human", "value": "<image>\nHow do the pants look, brown or khaki?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Brown"}, {"from": "human", "value": "What kind of furniture is it?"}, {"from": "gpt", "value": "Bed"}, {"from": "human", "value": "Is the hair brown and short?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "How long is the brown hair?"}, {"from": "gpt", "value": "Short"}, {"from": "human", "value": "How is this animal called?"}, {"from": "gpt", "value": "Bear"}]}, {"id": 2321473, "image": "gqa/images/2321473.jpg", "conversations": [{"from": "human", "value": "<image>\nAre the trousers purple?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is the name of the green item of clothing?"}, {"from": "gpt", "value": "Dress"}, {"from": "human", "value": "Which kind of clothing is green?"}, {"from": "gpt", "value": "Dress"}, {"from": "human", "value": "Who is wearing a scarf?"}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "Is the color of the scarf purple?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Does the dress look white?"}, {"from": "gpt", "value": "No"}]}, {"id": 2340920, "image": "gqa/images/2340920.jpg", "conversations": [{"from": "human", "value": "<image>\nHow clean is the vase that is in front of the wall?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Tinted"}, {"from": "human", "value": "Is the brown wall behind a vase?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What's the plant in front of?"}, {"from": "gpt", "value": "Wall"}, {"from": "human", "value": "Is the plant in the vase that looks tinted?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "What is in the vase?"}, {"from": "gpt", "value": "Plant"}, {"from": "human", "value": "The plant is in what?"}, {"from": "gpt", "value": "Vase"}, {"from": "human", "value": "What is the plant in?"}, {"from": "gpt", "value": "Vase"}, {"from": "human", "value": "Is the vase tinted and blue?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this vase brown or blue?"}, {"from": "gpt", "value": "Blue"}]}, {"id": 2329165, "image": "gqa/images/2329165.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat vehicles are to the left of the fire hydrant?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Cars"}, {"from": "human", "value": "Are there either cones or helmets?"}, {"from": "gpt", "value": "No"}]}, {"id": 2320510, "image": "gqa/images/2320510.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich side of the photo is the lamp on?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "What kind of furniture is to the right of the lamp?"}, {"from": "gpt", "value": "Shelf"}, {"from": "human", "value": "What is the item of furniture to the right of the lamp?"}, {"from": "gpt", "value": "Shelf"}, {"from": "human", "value": "Does the lamp shade look round or rectangular?"}, {"from": "gpt", "value": "Rectangular"}, {"from": "human", "value": "Is the shelf in the bottom or in the top?"}, {"from": "gpt", "value": "Bottom"}, {"from": "human", "value": "Does the remote look black?"}, {"from": "gpt", "value": "No"}]}, {"id": 2332088, "image": "gqa/images/2332088.jpg", "conversations": [{"from": "human", "value": "<image>\nIs the cup to the right or to the left of the book in this photo?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "On which side of the picture is the bottle?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Does the counter have white color?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there pepper shakers or pots?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "On which side of the photo is the cup?"}, {"from": "gpt", "value": "Right"}]}, {"id": 713750, "image": "gqa/images/713750.jpg", "conversations": [{"from": "human", "value": "<image>\nAre there any chairs?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the round food?"}, {"from": "gpt", "value": "Pie"}, {"from": "human", "value": "Is the hair long?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which food do you see?"}, {"from": "gpt", "value": "Pie"}, {"from": "human", "value": "What food is it?"}, {"from": "gpt", "value": "Pie"}, {"from": "human", "value": "Is there a knife in the image?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "On which side is the cup?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Are there both a cup and a plate in the scene?"}, {"from": "gpt", "value": "No"}]}, {"id": 2360112, "image": "gqa/images/2360112.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is the plane on the ground?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "Is there a bag on the ground?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which color is the fence?"}, {"from": "gpt", "value": "White"}, {"from": "human", "value": "Is the white fence in the top or in the bottom part of the photo?"}, {"from": "gpt", "value": "Bottom"}]}, {"id": 2331142, "image": "gqa/images/2331142.jpg", "conversations": [{"from": "human", "value": "<image>\nOn which side are the people?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Are there either bags or umbrellas in the image?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Is there any food or meat in the image?"}, {"from": "gpt", "value": "No"}]}, {"id": 2415701, "image": "gqa/images/2415701.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is standing on the grass?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Woman"}, {"from": "human", "value": "Are there any men or women?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a truck or a bus?"}, {"from": "gpt", "value": "Bus"}, {"from": "human", "value": "What is the woman wearing?"}, {"from": "gpt", "value": "Jeans"}, {"from": "human", "value": "Is the woman on the left side or on the right of the image?"}, {"from": "gpt", "value": "Right"}, {"from": "human", "value": "Which place is it?"}, {"from": "gpt", "value": "Road"}, {"from": "human", "value": "Is the woman wearing goggles?"}, {"from": "gpt", "value": "No"}]}, {"id": 2416792, "image": "gqa/images/2416792.jpg", "conversations": [{"from": "human", "value": "<image>\nAre there any men to the left of the wine that is on the wall?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there men to the left of the wine on the left?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there glasses to the left of the bottle that is to the right of the wine?"}, {"from": "gpt", "value": "No"}]}, {"id": 2371117, "image": "gqa/images/2371117.jpg", "conversations": [{"from": "human", "value": "<image>\nDo you see either clock towers or clocks?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there any gold clocks or numbers?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Are there elephants or animals?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2333451, "image": "gqa/images/2333451.jpg", "conversations": [{"from": "human", "value": "<image>\nWhere is the man?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Sand"}, {"from": "human", "value": "What is the color of the umbrella on the left?"}, {"from": "gpt", "value": "Red"}, {"from": "human", "value": "Do you see both glasses and ties?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there both glasses and ties in the photo?"}, {"from": "gpt", "value": "No"}]}, {"id": 2385650, "image": "gqa/images/2385650.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich place is it?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Field"}, {"from": "human", "value": "Is it indoors or outdoors?"}, {"from": "gpt", "value": "Outdoors"}, {"from": "human", "value": "How tall is the grass?"}, {"from": "gpt", "value": "Tall"}, {"from": "human", "value": "Is there any tall grass in this photo?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 2373318, "image": "gqa/images/2373318.jpg", "conversations": [{"from": "human", "value": "<image>\nHow large is the gray house?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Little"}, {"from": "human", "value": "Is the house little and yellow?"}, {"from": "gpt", "value": "No"}]}, {"id": 2406568, "image": "gqa/images/2406568.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat are the gloves made of?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Leather"}, {"from": "human", "value": "What type of material are the gloves made of?"}, {"from": "gpt", "value": "Leather"}, {"from": "human", "value": "Are there hats or gloves that are made of plastic?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Are there both helmets and napkins in this picture?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which side is the camera on?"}, {"from": "gpt", "value": "Left"}, {"from": "human", "value": "Who is wearing a knee pad?"}, {"from": "gpt", "value": "Man"}, {"from": "human", "value": "Who is wearing a shoe?"}, {"from": "gpt", "value": "Man"}]}, {"id": 3047, "image": "gqa/images/3047.jpg", "conversations": [{"from": "human", "value": "<image>\nWhich place is it?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "City"}]}, {"id": 2395569, "image": "gqa/images/2395569.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is the road?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Brown"}, {"from": "human", "value": "Are there either any oranges or plates in this image?"}, {"from": "gpt", "value": "Yes"}]}, {"id": 188, "image": "gqa/images/188.jpg", "conversations": [{"from": "human", "value": "<image>\nHow is the weather?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Sunny"}, {"from": "human", "value": "What is the weather like in this picture, sunny or rainy?"}, {"from": "gpt", "value": "Sunny"}]}, {"id": 666, "image": "gqa/images/666.jpg", "conversations": [{"from": "human", "value": "<image>\nAre there either any helmets or bridges in this scene?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}]}, {"id": 2343660, "image": "gqa/images/2343660.jpg", "conversations": [{"from": "human", "value": "<image>\nDo you see both a fence and a lamb?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}]}, {"id": 2721, "image": "gqa/images/2721.jpg", "conversations": [{"from": "human", "value": "<image>\nDoes the sky that looks blue look cloudy?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}]}, {"id": 2333123, "image": "gqa/images/2333123.jpg", "conversations": [{"from": "human", "value": "<image>\nAre there people to the right of the man?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yes"}]}, {"id": 1160097, "image": "gqa/images/1160097.jpg", "conversations": [{"from": "human", "value": "<image>\nOn which side of the image is the woman?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Left"}]}, {"id": 2367947, "image": "gqa/images/2367947.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is that ground?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Tan"}, {"from": "human", "value": "Is the nose yellow or red?"}, {"from": "gpt", "value": "Red"}]}, {"id": 2386089, "image": "gqa/images/2386089.jpg", "conversations": [{"from": "human", "value": "<image>\nIs there any kitten or helmet in this image?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "No"}]}, {"id": 2329650, "image": "gqa/images/2329650.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat color is the sky?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Blue"}]}, {"id": "073821115X", "image": "ocr_vqa/images/073821115X.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Richard H. Blau"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Too Young to Feel Old: The Arthritis Doctor's 28-Day Formula for Pain-Free Living"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Health, Fitness & Dieting"}, {"from": "human", "value": "Is this a fitness book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a crafts or hobbies related book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1783980621", "image": "ocr_vqa/images/1783980621.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Jaime Pillora"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Getting Started with Grunt: The JavaScript Task Runner"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Computers & Technology"}, {"from": "human", "value": "Is this book related to Computers & Technology?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Mystery, Thriller & Suspense?"}, {"from": "gpt", "value": "No"}]}, {"id": "789480239", "image": "ocr_vqa/images/789480239.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Marilyn Wood"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Eyewitness Travel Guide to New Orleans (Eyewitness Travel Guides)"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Travel"}, {"from": "human", "value": "Is this a journey related book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a life story book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1592335241", "image": "ocr_vqa/images/1592335241.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Gretchen Brown"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Fast and Simple Gluten-Free: 30 Minutes or Less to Fresh and Classic Favorites"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Cookbooks, Food & Wine"}, {"from": "human", "value": "Is this book related to Cookbooks, Food & Wine?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Education & Teaching?"}, {"from": "gpt", "value": "No"}]}, {"id": "1432992996", "image": "ocr_vqa/images/1432992996.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Nel Yomtov"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "The Attack on Pearl Harbor: December 7, 1941 (24-Hour History)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Children's Books"}, {"from": "human", "value": "Is this a kids book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a homosexuality book?"}, {"from": "gpt", "value": "No"}]}, {"id": "3010142366", "image": "ocr_vqa/images/3010142366.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Word Music"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Celebration Hymnal: Songs and Hymns for Worship"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Christian Books & Bibles"}, {"from": "human", "value": "Is this christianity book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a crafts or hobbies related book?"}, {"from": "gpt", "value": "No"}]}, {"id": "882407562", "image": "ocr_vqa/images/882407562.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the title of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Native Cultures in Alaska: Looking Forward, Looking Back (Alaska Geographic)"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Travel"}, {"from": "human", "value": "Is this a journey related book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a comedy book?"}, {"from": "gpt", "value": "No"}]}, {"id": "486491374", "image": "ocr_vqa/images/486491374.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Marty Noble"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Creative Haven Nature Mandalas Coloring Book (Creative Haven Coloring Books)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Crafts, Hobbies & Home"}, {"from": "human", "value": "Is this book related to Crafts, Hobbies & Home?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to History?"}, {"from": "gpt", "value": "No"}]}, {"id": "299087204", "image": "ocr_vqa/images/299087204.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "W. B. Willers"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Trout Biology, an Angler's Guide"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Sports & Outdoors"}, {"from": "human", "value": "Is this a games related book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a financial book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1940636094", "image": "ocr_vqa/images/1940636094.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Delaney Diamond"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Perfect (Johnson Family) (Volume 2)"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Romance"}, {"from": "human", "value": "Is this a romantic book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this an exam preparation book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1502380862", "image": "ocr_vqa/images/1502380862.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Frances P Robinson"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Wedding Planning Guide: Wedding Budget Planner and More"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Crafts, Hobbies & Home"}, {"from": "human", "value": "Is this book related to Crafts, Hobbies & Home?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Crafts, Hobbies & Home?"}, {"from": "gpt", "value": "No"}]}, {"id": "1741045045", "image": "ocr_vqa/images/1741045045.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Lonely Planet"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Lonely Planet Czech & Slovak Republics (Travel Guide)"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Travel"}, {"from": "human", "value": "Is this book related to Travel?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Christian Books & Bibles?"}, {"from": "gpt", "value": "No"}]}, {"id": "875525105", "image": "ocr_vqa/images/875525105.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Michael D. Williams"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Far as the Curse Is Found: The Covenant Story of Redemption"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Christian Books & Bibles"}, {"from": "human", "value": "Is this book related to Christian Books & Bibles?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Engineering & Transportation?"}, {"from": "gpt", "value": "No"}]}, {"id": "814649661", "image": "ocr_vqa/images/814649661.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Alison M. Benders"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Just Prayer: A Book of Hours for Peacemakers and Justice Seekers"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Christian Books & Bibles"}, {"from": "human", "value": "Is this christianity book?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "1505604028", "image": "ocr_vqa/images/1505604028.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Denora M Boone"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Confessions of a First Lady"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Literature & Fiction"}, {"from": "human", "value": "Is this book related to Literature & Fiction?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Crafts, Hobbies & Home?"}, {"from": "gpt", "value": "No"}]}, {"id": "1591431786", "image": "ocr_vqa/images/1591431786.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Robert Bauval"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "The Vatican Heresy: Bernini and the Building of the Hermetic Temple of the Sun"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Religion & Spirituality"}, {"from": "human", "value": "Is this book related to Religion & Spirituality?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Test Preparation?"}, {"from": "gpt", "value": "No"}]}, {"id": "764349252", "image": "ocr_vqa/images/764349252.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "E. Ashley Rooney"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "LEEDING the Way: Domestic Architecture for the Future: LEED Certified, Green, Passive & Natural"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Arts & Photography"}, {"from": "human", "value": "Is this an art related book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a reference book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1451638493", "image": "ocr_vqa/images/1451638493.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Catherine Asaro"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Carnelians (The Saga of the Skolian Empire)"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Science Fiction & Fantasy"}, {"from": "human", "value": "Is this a sci-fi book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a religious book?"}, {"from": "gpt", "value": "No"}]}, {"id": "198726384", "image": "ocr_vqa/images/198726384.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Graham Virgo"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Principles of the Law of Restitution"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Law"}, {"from": "human", "value": "Is this book related to Law?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Gay & Lesbian?"}, {"from": "gpt", "value": "No"}]}, {"id": "193543926X", "image": "ocr_vqa/images/193543926X.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Edward Bernays"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Crystallizing Public Opinion"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Business & Money"}, {"from": "human", "value": "Is this a financial book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a historical book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1601625219", "image": "ocr_vqa/images/1601625219.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Ashley"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "The Cartel (Urban Books)"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Literature & Fiction"}, {"from": "human", "value": "Is this book related to Literature & Fiction?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Comics & Graphic Novels?"}, {"from": "gpt", "value": "No"}]}, {"id": "199535868", "image": "ocr_vqa/images/199535868.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "William Shakespeare"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "A Midsummer Night's Dream: The Oxford Shakespeare"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Literature & Fiction"}, {"from": "human", "value": "Is this book related to Literature & Fiction?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Self-Help?"}, {"from": "gpt", "value": "No"}]}, {"id": "142438006", "image": "ocr_vqa/images/142438006.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Graham Greene"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Our Man in Havana (Penguin Classics)"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Mystery, Thriller & Suspense"}, {"from": "human", "value": "Is this book related to Mystery, Thriller & Suspense?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to History?"}, {"from": "gpt", "value": "No"}]}, {"id": "399243860", "image": "ocr_vqa/images/399243860.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Eric Carle"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "My Very First Book of Colors"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Children's Books"}, {"from": "human", "value": "Is this book related to Children's Books?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Health, Fitness & Dieting?"}, {"from": "gpt", "value": "No"}]}, {"id": "1583551727", "image": "ocr_vqa/images/1583551727.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "James Kavanagh"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "New England Birds: A Folding Pocket Guide to Familiar Species (Pocket Naturalist Guide Series)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Travel"}, {"from": "human", "value": "Is this book related to Travel?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Parenting & Relationships?"}, {"from": "gpt", "value": "No"}]}, {"id": "1508525110", "image": "ocr_vqa/images/1508525110.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Steve Becker LCSW"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "The Inner World of the Psychopath: A definitive primer on the psychopathic personality"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Health, Fitness & Dieting"}, {"from": "human", "value": "Is this book related to Health, Fitness & Dieting?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Cookbooks, Food & Wine?"}, {"from": "gpt", "value": "No"}]}, {"id": "188463303X", "image": "ocr_vqa/images/188463303X.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Pippa Sales"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Improve Your Squash Game: 101 Drills, Coaching Tips and Resources"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Sports & Outdoors"}, {"from": "human", "value": "Is this a games related book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a homosexuality book?"}, {"from": "gpt", "value": "No"}]}, {"id": "226620883", "image": "ocr_vqa/images/226620883.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Brian W. Ogilvie"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "The Science of Describing: Natural History in Renaissance Europe"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Science & Math"}, {"from": "human", "value": "Is this a digital technology book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1570251460", "image": "ocr_vqa/images/1570251460.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Bob Cary"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Born to Pull"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Sports & Outdoors"}, {"from": "human", "value": "Is this a games related book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a transportation engineering book?"}, {"from": "gpt", "value": "No"}]}, {"id": "674032349", "image": "ocr_vqa/images/674032349.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "John Kelsay"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Arguing the Just War in Islam"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Religion & Spirituality"}, {"from": "human", "value": "Is this a religious book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a digital technology book?"}, {"from": "gpt", "value": "No"}]}, {"id": "160078903X", "image": "ocr_vqa/images/160078903X.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Jason Butt"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "100 Things Ravens Fans Should Know & Do Before They Die (100 Things... Fans Should Know & Do Before They Die)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Travel"}, {"from": "human", "value": "Is this book related to Travel?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Business & Money?"}, {"from": "gpt", "value": "No"}]}, {"id": "1887089160", "image": "ocr_vqa/images/1887089160.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Dr. Jialiu Liu"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Jiaogulan: China's \"Immortality Herb\"--Unlocking the Secrets of Nature's Powerful Adaptogen and Antioxidant"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Health, Fitness & Dieting"}, {"from": "human", "value": "Is this book related to Health, Fitness & Dieting?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Crafts, Hobbies & Home?"}, {"from": "gpt", "value": "No"}]}, {"id": "822330628", "image": "ocr_vqa/images/822330628.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Ellen Schattschneider"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Immortal Wishes: Labor and Transcendence on a Japanese Sacred Mountain"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Religion & Spirituality"}, {"from": "human", "value": "Is this a religious book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a child-care book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1476739544", "image": "ocr_vqa/images/1476739544.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Emma Jenner"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Keep Calm and Parent On: A Guilt-Free Approach to Raising Children by Asking More from Them and Doing Less"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Parenting & Relationships"}, {"from": "human", "value": "Is this book related to Parenting & Relationships?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Teen & Young Adult?"}, {"from": "gpt", "value": "No"}]}, {"id": "312384173", "image": "ocr_vqa/images/312384173.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Victoria Holt"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Lord of the Far Island"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Literature & Fiction"}, {"from": "human", "value": "Is this book related to Literature & Fiction?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Parenting & Relationships?"}, {"from": "gpt", "value": "No"}]}, {"id": "811727769", "image": "ocr_vqa/images/811727769.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Mark Freeman"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Gardening in Your Greenhouse (Greenhouse Basics)"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Crafts, Hobbies & Home"}, {"from": "human", "value": "Is this a crafts or hobbies related book?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "146504499X", "image": "ocr_vqa/images/146504499X.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Browntrout Publishers"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Mustangs, Wild Horses of the West 2016 Square 12x12"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Calendars"}, {"from": "human", "value": "Is this a sociopolitical book?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which year's calendar is this?"}, {"from": "gpt", "value": "2016"}]}, {"id": "1583419381", "image": "ocr_vqa/images/1583419381.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Gordon Pueschner"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "The Story of the Charlotte Bobcats (The NBA: a History of Hoops)"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Teen & Young Adult"}, {"from": "human", "value": "Is this a youngster related book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a motivational book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1476707391", "image": "ocr_vqa/images/1476707391.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Karen Kingsbury"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "The Friends of Jesus (Life-Changing Bible Study Series)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Christian Books & Bibles"}, {"from": "human", "value": "Is this book related to Christian Books & Bibles?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Law?"}, {"from": "gpt", "value": "No"}]}, {"id": "160901278X", "image": "ocr_vqa/images/160901278X.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the title of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Meanings of Dress,  The"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Business & Money"}, {"from": "human", "value": "Is this a financial book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a youngster related book?"}, {"from": "gpt", "value": "No"}]}, {"id": "847830411", "image": "ocr_vqa/images/847830411.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Nancy Ellison"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "In Classic Style: The Splendor of American Ballet Theatre"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Humor & Entertainment"}, {"from": "human", "value": "Is this a comedy book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a life story book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1565040767", "image": "ocr_vqa/images/1565040767.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Harry Heckel"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Umbra: The Velvet Shadow (Werewolf - the Apocalypse)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Science Fiction & Fantasy"}, {"from": "human", "value": "Is this book related to Science Fiction & Fantasy?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Science & Math?"}, {"from": "gpt", "value": "No"}]}, {"id": "838316387", "image": "ocr_vqa/images/838316387.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Georges Jean-Aubry"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Joseph Conrad in the Congo"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Travel"}, {"from": "human", "value": "Is this book related to Travel?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Travel?"}, {"from": "gpt", "value": "No"}]}, {"id": "688097375", "image": "ocr_vqa/images/688097375.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Victoria Magazine Editors"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Victoria: The Heart of Christmas"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Politics & Social Sciences"}, {"from": "human", "value": "Is this book related to Politics & Social Sciences?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Parenting & Relationships?"}, {"from": "gpt", "value": "No"}]}, {"id": "830831096", "image": "ocr_vqa/images/830831096.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Dale Larsen"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Ruth: Rescued by the Redeemer (Lifeguide Bible Studies)"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Christian Books & Bibles"}, {"from": "human", "value": "Is this christianity book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a romantic book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1566563593", "image": "ocr_vqa/images/1566563593.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Charles Arthur"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "In Focus Haiti: A Guide to the People, Politics and Culture"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Travel"}, {"from": "human", "value": "Is this a journey related book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a historical book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1590790154", "image": "ocr_vqa/images/1590790154.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Verne Harnish"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Mastering the Rockefeller Habits: What You Must Do to Increase the Value of Your Growing Firm"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Business & Money"}, {"from": "human", "value": "Is this book related to Business & Money?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Business & Money?"}, {"from": "gpt", "value": "No"}]}, {"id": "972120203", "image": "ocr_vqa/images/972120203.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Dennis Andres"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "What Is a Vortex? A Practical Guide to Sedona's Vortex Sites"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Religion & Spirituality"}, {"from": "human", "value": "Is this book related to Religion & Spirituality?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Mystery, Thriller & Suspense?"}, {"from": "gpt", "value": "No"}]}, {"id": "692272585", "image": "ocr_vqa/images/692272585.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Jessica A Smock"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "My Other Ex: Women's True Stories of Losing and Leaving Friends"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Self-Help"}, {"from": "human", "value": "Is this book related to Self-Help?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Sports & Outdoors?"}, {"from": "gpt", "value": "No"}]}, {"id": "323297420", "image": "ocr_vqa/images/323297420.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Joen Iannucci DDS  MS"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Dental Radiography: Principles and Techniques, 5e"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Medical Books"}, {"from": "human", "value": "Is this a pharmaceutical book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a reference book?"}, {"from": "gpt", "value": "No"}]}, {"id": "307408973", "image": "ocr_vqa/images/307408973.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Scott Sigler"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Pandemic: A Novel"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Literature & Fiction"}, {"from": "human", "value": "Is this book related to Literature & Fiction?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Reference?"}, {"from": "gpt", "value": "No"}]}, {"id": "190218894", "image": "ocr_vqa/images/190218894.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Charles D. Ellis"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Falling Short: The Coming Retirement Crisis and What to Do About It"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Business & Money"}, {"from": "human", "value": "Is this book related to Business & Money?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Reference?"}, {"from": "gpt", "value": "No"}]}, {"id": "1250060419", "image": "ocr_vqa/images/1250060419.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "David Crystal"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Making a Point: The Persnickety Story of English Punctuation"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Politics & Social Sciences"}, {"from": "human", "value": "Is this book related to Politics & Social Sciences?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Reference?"}, {"from": "gpt", "value": "No"}]}, {"id": "157805141X", "image": "ocr_vqa/images/157805141X.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Jim Malusa"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Into Thick Air: Biking to the Bellybutton of Six Continents"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Travel"}, {"from": "human", "value": "Is this a journey related book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a pharmaceutical book?"}, {"from": "gpt", "value": "No"}]}, {"id": "037582264X", "image": "ocr_vqa/images/037582264X.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Lois Lenski"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "The Little Train (Lois Lenski Books)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Children's Books"}, {"from": "human", "value": "Is this book related to Children's Books?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Science Fiction & Fantasy?"}, {"from": "gpt", "value": "No"}]}, {"id": "374300224", "image": "ocr_vqa/images/374300224.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Phillip Hoose"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "The Boys Who Challenged Hitler: Knud Pedersen and the Churchill Club"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Teen & Young Adult"}, {"from": "human", "value": "Is this book related to Teen & Young Adult?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Teen & Young Adult?"}, {"from": "gpt", "value": "No"}]}, {"id": "960646612", "image": "ocr_vqa/images/960646612.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "George L. Frow"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Edison Cylinder Phonograph Companion"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Crafts, Hobbies & Home"}, {"from": "human", "value": "Is this a crafts or hobbies related book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a comedy book?"}, {"from": "gpt", "value": "No"}]}, {"id": "764526324", "image": "ocr_vqa/images/764526324.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Eve Zibart"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "The Unofficial Guide to New Orleans (Unofficial Guides)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Travel"}, {"from": "human", "value": "Is this a journey related book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a judicial book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1558689885", "image": "ocr_vqa/images/1558689885.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the title of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Michigan: Portrait of a State (Portrait of a Place)"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Travel"}, {"from": "human", "value": "Is this a journey related book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a pedagogy book?"}, {"from": "gpt", "value": "No"}]}, {"id": "760345457", "image": "ocr_vqa/images/760345457.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Ian Falloon"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "The Complete Book of Classic and Modern Triumph Motorcycles 1937-Today (Complete Book Series)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Engineering & Transportation"}, {"from": "human", "value": "Is this book related to Engineering & Transportation?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Christian Books & Bibles?"}, {"from": "gpt", "value": "No"}]}, {"id": "142246329X", "image": "ocr_vqa/images/142246329X.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "James Bonta"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "The Psychology of Criminal Conduct"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Medical Books"}, {"from": "human", "value": "Is this book related to Medical Books?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Mystery, Thriller & Suspense?"}, {"from": "gpt", "value": "No"}]}, {"id": "3642553141", "image": "ocr_vqa/images/3642553141.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the title of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Synchrotron Radiation: Basics, Methods and Applications"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Science & Math"}, {"from": "human", "value": "Is this book related to Science & Math?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Health, Fitness & Dieting?"}, {"from": "gpt", "value": "No"}]}, {"id": "1608193322", "image": "ocr_vqa/images/1608193322.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "William Stolzenburg"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Rat Island: Predators in Paradise and the World's Greatest Wildlife Rescue"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Science & Math"}, {"from": "human", "value": "Is this a pedagogy book?"}, {"from": "gpt", "value": "No"}]}, {"id": "763641979", "image": "ocr_vqa/images/763641979.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Anton Powell"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "History News: The Greek News"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Children's Books"}, {"from": "human", "value": "Is this a kids book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a comedy book?"}, {"from": "gpt", "value": "No"}]}, {"id": "826480330", "image": "ocr_vqa/images/826480330.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Roger Scruton"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Gentle Regrets: Thoughts from a Life"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Biographies & Memoirs"}, {"from": "human", "value": "Is this a life story book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a games related book?"}, {"from": "gpt", "value": "No"}]}, {"id": "990748901", "image": "ocr_vqa/images/990748901.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Sarah E. Olson"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Becoming One: A Story of Triumph Over Dissociative Identity Disorder"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Health, Fitness & Dieting"}, {"from": "human", "value": "Is this book related to Health, Fitness & Dieting?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Reference?"}, {"from": "gpt", "value": "No"}]}, {"id": "307742814", "image": "ocr_vqa/images/307742814.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Peggielene Bartels"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "King Peggy: An American Secretary, Her Royal Destiny, and the Inspiring Story of How She Changed an African Village"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Biographies & Memoirs"}, {"from": "human", "value": "Is this a life story book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a homosexuality book?"}, {"from": "gpt", "value": "No"}]}, {"id": "032190673X", "image": "ocr_vqa/images/032190673X.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "John D. Ramage"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Writing Arguments: A Rhetoric with Readings (10th Edition)"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Reference"}, {"from": "human", "value": "Is this a reference book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a motivational book?"}, {"from": "gpt", "value": "No"}]}, {"id": "393242277", "image": "ocr_vqa/images/393242277.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Gary Gutting"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "What Philosophy Can Do"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Politics & Social Sciences"}, {"from": "human", "value": "Is this book related to Politics & Social Sciences?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Travel?"}, {"from": "gpt", "value": "No"}]}, {"id": "184603275X", "image": "ocr_vqa/images/184603275X.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Ed Gilbert"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Frontier Militiaman in the War of 1812: Southwestern Frontier (Warrior)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "History"}, {"from": "human", "value": "Is this book related to History?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Law?"}, {"from": "gpt", "value": "No"}]}, {"id": "1618930559", "image": "ocr_vqa/images/1618930559.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Editors of Sports Illustrated"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Sports Illustrated Baseball's Greatest"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Arts & Photography"}, {"from": "human", "value": "Is this an art related book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a games related book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1617012998", "image": "ocr_vqa/images/1617012998.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Eminem"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Eminem 2015 Calendar"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Calendars"}, {"from": "human", "value": "Is this book related to Calendars?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Comics & Graphic Novels?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which year's calendar is this?"}, {"from": "gpt", "value": "2015"}]}, {"id": "1868725022", "image": "ocr_vqa/images/1868725022.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the title of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Images from a Timeless Wilderness"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Travel"}, {"from": "human", "value": "Is this book related to Travel?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Crafts, Hobbies & Home?"}, {"from": "gpt", "value": "No"}]}, {"id": "866360352", "image": "ocr_vqa/images/866360352.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "George S Lewbel"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Diving and snorkeling guide to Bonaire and Curacao including information on Aruba"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Travel"}, {"from": "human", "value": "Is this book related to Travel?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Teen & Young Adult?"}, {"from": "gpt", "value": "No"}]}, {"id": "883448432", "image": "ocr_vqa/images/883448432.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "James H. Cone"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "The Spirituals and the Blues: An Interpretation"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Christian Books & Bibles"}, {"from": "human", "value": "Is this book related to Christian Books & Bibles?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Calendars?"}, {"from": "gpt", "value": "No"}]}, {"id": "486243915", "image": "ocr_vqa/images/486243915.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Karl Fulves"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Self-Working Number Magic: 101 Foolproof Tricks (Dover Magic Books)"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Humor & Entertainment"}, {"from": "human", "value": "Is this book related to Humor & Entertainment?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Crafts, Hobbies & Home?"}, {"from": "gpt", "value": "No"}]}, {"id": "345339010", "image": "ocr_vqa/images/345339010.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Daniel J. Levinson"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "The Seasons of a Man's Life"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Health, Fitness & Dieting"}, {"from": "human", "value": "Is this a fitness book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a motivational book?"}, {"from": "gpt", "value": "No"}]}, {"id": "149428197X", "image": "ocr_vqa/images/149428197X.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Maroun Mourad"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "The Insurance Management Playbook: A Leader's Guide"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Business & Money"}, {"from": "human", "value": "Is this book related to Business & Money?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Science Fiction & Fantasy?"}, {"from": "gpt", "value": "No"}]}, {"id": "1469326825", "image": "ocr_vqa/images/1469326825.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the title of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Colorado Rockies"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Calendars"}, {"from": "human", "value": "Is this a comedy book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1596439734", "image": "ocr_vqa/images/1596439734.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Andrea Davis Pinkney"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Rhythm Ride: A Road Trip Through the Motown Sound"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Children's Books"}, {"from": "human", "value": "Is this book related to Children's Books?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Reference?"}, {"from": "gpt", "value": "No"}]}, {"id": "312641370", "image": "ocr_vqa/images/312641370.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Jennifer Crusie"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Welcome to Temptation"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Humor & Entertainment"}, {"from": "human", "value": "Is this book related to Humor & Entertainment?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Education & Teaching?"}, {"from": "gpt", "value": "No"}]}, {"id": "801986621", "image": "ocr_vqa/images/801986621.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Chilton"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Chrysler Full-Size Trucks, 1967-88 (Chilton Total Car Care Series Manuals)"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Engineering & Transportation"}, {"from": "human", "value": "Is this book related to Engineering & Transportation?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Calendars?"}, {"from": "gpt", "value": "No"}]}, {"id": "1565123395", "image": "ocr_vqa/images/1565123395.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Diana Hollingsworth Gessler"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Very Charleston: A Celebration of History, Culture, and Lowcountry Charm"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Travel"}, {"from": "human", "value": "Is this book related to Travel?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Children's Books?"}, {"from": "gpt", "value": "No"}]}, {"id": "875961827", "image": "ocr_vqa/images/875961827.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Prevention Magazine Health Book Staff"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Gu\u00eda m\u00e9dica de remedios caseros"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Health, Fitness & Dieting"}, {"from": "human", "value": "Is this a fitness book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a religious book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1404219986", "image": "ocr_vqa/images/1404219986.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Stephanie Watson"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Binge Eating (Danger Zone: Dieting and Eating Disorders)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Health, Fitness & Dieting"}, {"from": "human", "value": "Is this a fitness book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this an exam preparation book?"}, {"from": "gpt", "value": "No"}]}, {"id": "801477891", "image": "ocr_vqa/images/801477891.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Ilana Gershon"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "The Breakup 2.0: Disconnecting over New Media"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Computers & Technology"}, {"from": "human", "value": "Is this a digital technology book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this christianity book?"}, {"from": "gpt", "value": "No"}]}, {"id": "321822455", "image": "ocr_vqa/images/321822455.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Adobe Creative Team"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Adobe Dreamweaver CS6 Classroom in a Book"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Computers & Technology"}, {"from": "human", "value": "Is this a digital technology book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a recipe book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1878424785", "image": "ocr_vqa/images/1878424785.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "M.D. Deepak Chopra"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Sacred Verses, Healing Sounds, Volumes I and II: The Bhagavad Gita, Hymns of the Rig Veda (Chopra, Deepak)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Religion & Spirituality"}, {"from": "human", "value": "Is this a religious book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a financial book?"}, {"from": "gpt", "value": "No"}]}, {"id": "113318863X", "image": "ocr_vqa/images/113318863X.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Richard A. Mann"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Essentials of Business Law and the Legal Environment"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Law"}, {"from": "human", "value": "Is this a judicial book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a recipe book?"}, {"from": "gpt", "value": "No"}]}, {"id": "71795375", "image": "ocr_vqa/images/71795375.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Seymour Lipschutz"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Schaum's Outline of Mathematical Handbook of Formulas and Tables, 4th Edition: 2,400 Formulas + Tables (Schaum's Outlines)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Test Preparation"}, {"from": "human", "value": "Is this an exam preparation book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a reference book?"}, {"from": "gpt", "value": "No"}]}, {"id": "764145061", "image": "ocr_vqa/images/764145061.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Veiko Kespersaks"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Calligraphy in 24 Hours"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Arts & Photography"}, {"from": "human", "value": "Is this an art related book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a comedy book?"}, {"from": "gpt", "value": "No"}]}, {"id": "632044489", "image": "ocr_vqa/images/632044489.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Nancy Jo Trun"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Fundamental Bacterial Genetics"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Medical Books"}, {"from": "human", "value": "Is this a pharmaceutical book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this christianity book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1559635053", "image": "ocr_vqa/images/1559635053.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Frank Ackerman"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Why Do We Recycle?: Markets, Values, and Public Policy"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Science & Math"}, {"from": "human", "value": "Is this christianity book?"}, {"from": "gpt", "value": "No"}]}, {"id": "691119422", "image": "ocr_vqa/images/691119422.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Mircea Eliade"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Shamanism: Archaic Techniques of Ecstasy (Bollingen Series (General))"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Religion & Spirituality"}, {"from": "human", "value": "Is this a religious book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a judicial book?"}, {"from": "gpt", "value": "No"}]}, {"id": "837111447", "image": "ocr_vqa/images/837111447.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Martha Warren Beckwith"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Black Roadways: A Study of Jamaican Folk Life"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Travel"}, {"from": "human", "value": "Is this book related to Travel?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Humor & Entertainment?"}, {"from": "gpt", "value": "No"}]}, {"id": "1500762709", "image": "ocr_vqa/images/1500762709.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Mr. James J. Rigos"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Rigos Primer Series Uniform Bar Exam (UBE) Review Series Multistate Bar Exam (MBE) Volume 1"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Test Preparation"}, {"from": "human", "value": "Is this book related to Test Preparation?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to History?"}, {"from": "gpt", "value": "No"}]}, {"id": "573702713", "image": "ocr_vqa/images/573702713.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Chad Beguelin"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Harbor"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Literature & Fiction"}, {"from": "human", "value": "Is this book related to Literature & Fiction?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Crafts, Hobbies & Home?"}, {"from": "gpt", "value": "No"}]}, {"id": "495811696", "image": "ocr_vqa/images/495811696.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Michael G. Maxfield"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Research Methods for Criminal Justice and Criminology, 6th Edition"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Law"}, {"from": "human", "value": "Is this book related to Law?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Computers & Technology?"}, {"from": "gpt", "value": "No"}]}, {"id": "393321185", "image": "ocr_vqa/images/393321185.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the title of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "The Haiku Anthology (Third Edition)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Literature & Fiction"}, {"from": "human", "value": "Is this a motivational book?"}, {"from": "gpt", "value": "No"}]}, {"id": "764966340", "image": "ocr_vqa/images/764966340.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the title of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "William Morris 2015 Calendar: Arts & Crafts Designs"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Calendars"}, {"from": "human", "value": "Is this book related to Calendars?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Parenting & Relationships?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the year printed on this calendar?"}, {"from": "gpt", "value": "2015"}]}, {"id": "231149190", "image": "ocr_vqa/images/231149190.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Lynne Huffer"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Mad for Foucault: Rethinking the Foundations of Queer Theory (Gender and Culture)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Gay & Lesbian"}, {"from": "human", "value": "Is this book related to Gay & Lesbian?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Law?"}, {"from": "gpt", "value": "No"}]}, {"id": "1599799820", "image": "ocr_vqa/images/1599799820.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Joseph Christiano"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Joseph Christiano's Bloodtype Diet AB: A Custom Eating Plan for Losing Weight, Fighting Disease & Staying Healthy for People with Type AB Blood"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Health, Fitness & Dieting"}, {"from": "human", "value": "Is this book related to Health, Fitness & Dieting?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Sports & Outdoors?"}, {"from": "gpt", "value": "No"}]}, {"id": "1857599713", "image": "ocr_vqa/images/1857599713.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Virginia Museum of Fine Arts"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Virginia Museum of Fine Arts: Visitor Guide"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Travel"}, {"from": "human", "value": "Is this book related to Travel?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Test Preparation?"}, {"from": "gpt", "value": "No"}]}, {"id": "1885670281", "image": "ocr_vqa/images/1885670281.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Jack Ritchason N.D."}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Little Herb Encyclopedia: The Handbook of Natures Remedies for a Healthier Life"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Health, Fitness & Dieting"}, {"from": "human", "value": "Is this a fitness book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a reference book?"}, {"from": "gpt", "value": "No"}]}, {"id": "425193942", "image": "ocr_vqa/images/425193942.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Dorothea Benton Frank"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Sullivan's Island (Lowcountry Tales)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Literature & Fiction"}, {"from": "human", "value": "Is this book related to Literature & Fiction?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Humor & Entertainment?"}, {"from": "gpt", "value": "No"}]}, {"id": "1883378680", "image": "ocr_vqa/images/1883378680.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Robert Colyer"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Swim Better: A Guide to Greater Efficiency for Swimmers and Instructors"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Health, Fitness & Dieting"}, {"from": "human", "value": "Is this book related to Health, Fitness & Dieting?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Travel?"}, {"from": "gpt", "value": "No"}]}, {"id": "1452131074", "image": "ocr_vqa/images/1452131074.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Christine Barrely"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "The Little Book of Mary"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Christian Books & Bibles"}, {"from": "human", "value": "Is this book related to Christian Books & Bibles?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Teen & Young Adult?"}, {"from": "gpt", "value": "No"}]}, {"id": "393938883", "image": "ocr_vqa/images/393938883.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Jennifer Popiel"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Rousseau, Burke, and Revolution in France, 1791 (Second Edition)  (Reacting to the Past)"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "History"}, {"from": "human", "value": "Is this book related to History?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Medical Books?"}, {"from": "gpt", "value": "No"}]}, {"id": "1449368425", "image": "ocr_vqa/images/1449368425.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Jez Humble"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Lean Enterprise: How High Performance Organizations Innovate at Scale (Lean (O'Reilly))"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Computers & Technology"}, {"from": "human", "value": "Is this book related to Computers & Technology?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Reference?"}, {"from": "gpt", "value": "No"}]}, {"id": "140190713X", "image": "ocr_vqa/images/140190713X.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Doreen Virtue"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "The Best of Doreen Virtue 4-CD"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Religion & Spirituality"}, {"from": "human", "value": "Is this a religious book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this an exam preparation book?"}, {"from": "gpt", "value": "No"}]}, {"id": "756608465", "image": "ocr_vqa/images/756608465.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Peter Ackroyd"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Kingdom of the Dead (Voyages Through Time)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Religion & Spirituality"}, {"from": "human", "value": "Is this a religious book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a digital technology book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1400045371", "image": "ocr_vqa/images/1400045371.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Byron Katie"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Loving What Is: Four Questions That Can Change Your Life"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Self-Help"}, {"from": "human", "value": "Is this a motivational book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a digital technology book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1416297502", "image": "ocr_vqa/images/1416297502.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "bCreative"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Kickin It: Women's Soccer 2016 Wall Calendar"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Calendars"}, {"from": "human", "value": "Is this book related to Calendars?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Computers & Technology?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which year's calendar is this?"}, {"from": "gpt", "value": "2016"}]}, {"id": "133908712", "image": "ocr_vqa/images/133908712.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Shelley Gaskin"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "GO! With Microsoft Access 2013 Comprehensive, MyITLab with eText and Access Card for GO! with Office 2013"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Computers & Technology"}, {"from": "human", "value": "Is this a digital technology book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this an art related book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1249222834", "image": "ocr_vqa/images/1249222834.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Renee Browning"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Turkmenistan: Including its History, The T\u00fcrkmenbasy Palace, The Ertugrul Gazi Mosque, and More"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Travel"}, {"from": "human", "value": "Is this a journey related book?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "1558322434", "image": "ocr_vqa/images/1558322434.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Sally Sampson"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Party Nuts!: 50 Recipes for Spicy, Sweet, Savory, and Simply Sensational Nuts That Will Be the Hit of Any Gathering (50 Series)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Cookbooks, Food & Wine"}, {"from": "human", "value": "Is this book related to Cookbooks, Food & Wine?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Biographies & Memoirs?"}, {"from": "gpt", "value": "No"}]}, {"id": "B007K56H3C", "image": "ocr_vqa/images/B007K56H3C.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Julian Hawthorne (editor)"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Library of the World's Best Mystery and Detective Stories"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Law"}, {"from": "human", "value": "Is this book related to Law?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Health, Fitness & Dieting?"}, {"from": "gpt", "value": "No"}]}, {"id": "881773840", "image": "ocr_vqa/images/881773840.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Jack Gilbert"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Go Preach!: A Primer for Beginning Preachers"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Christian Books & Bibles"}, {"from": "human", "value": "Is this book related to Christian Books & Bibles?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Calendars?"}, {"from": "gpt", "value": "No"}]}, {"id": "323222358", "image": "ocr_vqa/images/323222358.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Donna D. Ignatavicius MS  RN  ANEF"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Clinical Companion for Medical-Surgical Nursing: Patient-Centered Collaborative Care, 8e"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Medical Books"}, {"from": "human", "value": "Is this book related to Medical Books?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Science Fiction & Fantasy?"}, {"from": "gpt", "value": "No"}]}, {"id": "1508456992", "image": "ocr_vqa/images/1508456992.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Editors Space"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Harbor's Armor: Commentary on Creed of Ibn `Asakir (1155-1223; 550-620 AH)"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Religion & Spirituality"}, {"from": "human", "value": "Is this a religious book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a romantic book?"}, {"from": "gpt", "value": "No"}]}, {"id": "385062680", "image": "ocr_vqa/images/385062680.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Lida Mayo"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Bloody Buna"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "History"}, {"from": "human", "value": "Is this a historical book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a comics book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1481937235", "image": "ocr_vqa/images/1481937235.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Kelly Wallace"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "How To Cure Candida: Yeast Infection Causes, Symptoms, Diet & Natural Remedies"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Health, Fitness & Dieting"}, {"from": "human", "value": "Is this a fitness book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a pharmaceutical book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1577941322", "image": "ocr_vqa/images/1577941322.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Charles Capps"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Faith and Confession"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Christian Books & Bibles"}, {"from": "human", "value": "Is this christianity book?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "1681448599", "image": "ocr_vqa/images/1681448599.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Fleur De Force"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "The Glam Guide"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Crafts, Hobbies & Home"}, {"from": "human", "value": "Is this a crafts or hobbies related book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this christianity book?"}, {"from": "gpt", "value": "No"}]}, {"id": "763785598", "image": "ocr_vqa/images/763785598.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Michael H. Merson"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Global Health: Diseases, Programs, Systems, and Policies"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Medical Books"}, {"from": "human", "value": "Is this a pharmaceutical book?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "807835064", "image": "ocr_vqa/images/807835064.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Nortin M. Hadler"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Rethinking Aging: Growing Old and Living Well in an Overtreated Society"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Health, Fitness & Dieting"}, {"from": "human", "value": "Is this a fitness book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a historical book?"}, {"from": "gpt", "value": "No"}]}, {"id": "756690773", "image": "ocr_vqa/images/756690773.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "William Lindsay"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "DK Eyewitness Books: Prehistoric Life"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Children's Books"}, {"from": "human", "value": "Is this a kids book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a digital technology book?"}, {"from": "gpt", "value": "No"}]}, {"id": "794431550", "image": "ocr_vqa/images/794431550.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Dreamworks How to Train Your Dragon"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "DreamWorks How to Train Your Dragon 2: Draw-It Dragons (LOVE TO DRAW)"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Children's Books"}, {"from": "human", "value": "Is this book related to Children's Books?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Romance?"}, {"from": "gpt", "value": "No"}]}, {"id": "1484211774", "image": "ocr_vqa/images/1484211774.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Edmund Weitz"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Common Lisp Recipes: A Problem-Solution Approach"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Computers & Technology"}, {"from": "human", "value": "Is this book related to Computers & Technology?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Romance?"}, {"from": "gpt", "value": "No"}]}, {"id": "2852581604", "image": "ocr_vqa/images/2852581604.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Richard Touboul"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Les Seychelles aujourd'hui (French Edition)"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Travel"}, {"from": "human", "value": "Is this book related to Travel?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Cookbooks, Food & Wine?"}, {"from": "gpt", "value": "No"}]}, {"id": "1416909559", "image": "ocr_vqa/images/1416909559.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Joan Holub"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Good Luck!: A St. Patrick's Day Story (Ant Hill)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Children's Books"}, {"from": "human", "value": "Is this book related to Children's Books?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Religion & Spirituality?"}, {"from": "gpt", "value": "No"}]}, {"id": "111742829X", "image": "ocr_vqa/images/111742829X.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "D.C De Waal"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "With Rhodes in Mashonaland"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Travel"}, {"from": "human", "value": "Is this a journey related book?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "712358501", "image": "ocr_vqa/images/712358501.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Eleanor Farjeon"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Kings and Queens"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Children's Books"}, {"from": "human", "value": "Is this book related to Children's Books?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Science & Math?"}, {"from": "gpt", "value": "No"}]}, {"id": "2012627900", "image": "ocr_vqa/images/2012627900.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Vatsyayana"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Theologie Hindoue: Le Kama Soutra, Regles de L'Amour de Vatsyayana (Ed.1891) (Religion) (French Edition)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Religion & Spirituality"}, {"from": "human", "value": "Is this a religious book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a crafts or hobbies related book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1610396200", "image": "ocr_vqa/images/1610396200.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Garry Kasparov"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Winter Is Coming: Why Vladimir Putin and the Enemies of the Free World Must Be Stopped"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "History"}, {"from": "human", "value": "Is this book related to History?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Computers & Technology?"}, {"from": "gpt", "value": "No"}]}, {"id": "161434504X", "image": "ocr_vqa/images/161434504X.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Jayanta K. Das Purkayastha"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "PMP\u00ae/CAPM\u00ae EXAM PREP: A Basic Guide to Activity-On-Node and Critical Path Method"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Test Preparation"}, {"from": "human", "value": "Is this an exam preparation book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a journey related book?"}, {"from": "gpt", "value": "No"}]}, {"id": "879611227", "image": "ocr_vqa/images/879611227.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "David Villasenor"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Indian Designs (Native American)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Crafts, Hobbies & Home"}, {"from": "human", "value": "Is this book related to Crafts, Hobbies & Home?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Crafts, Hobbies & Home?"}, {"from": "gpt", "value": "No"}]}, {"id": "1627732608", "image": "ocr_vqa/images/1627732608.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the title of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Code of Federal Regulations Title 9, Animals and Animal Products, Parts 200-end, 2014"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Law"}, {"from": "human", "value": "Is this a judicial book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a pedagogy book?"}, {"from": "gpt", "value": "No"}]}, {"id": "982354207", "image": "ocr_vqa/images/982354207.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Chuck Rosenthal"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Are We Not There Yet?: Travels in Nepal, North India, and Bhutan"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Travel"}, {"from": "human", "value": "Is this book related to Travel?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Politics & Social Sciences?"}, {"from": "gpt", "value": "No"}]}, {"id": "079109796X", "image": "ocr_vqa/images/079109796X.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Alan Marzilli"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Capital Punishment (Point/Counterpoint)"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Teen & Young Adult"}, {"from": "human", "value": "Is this a youngster related book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a youngster related book?"}, {"from": "gpt", "value": "No"}]}, {"id": "877458340", "image": "ocr_vqa/images/877458340.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Michael P. Harker"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Harker's Barns: Visions of an American Icon (Bur Oak Book)"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Travel"}, {"from": "human", "value": "Is this book related to Travel?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Test Preparation?"}, {"from": "gpt", "value": "No"}]}, {"id": "470665769", "image": "ocr_vqa/images/470665769.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Yvonne Rogers"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Interaction Design: Beyond Human - Computer Interaction"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Computers & Technology"}, {"from": "human", "value": "Is this book related to Computers & Technology?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Test Preparation?"}, {"from": "gpt", "value": "No"}]}, {"id": "944119093", "image": "ocr_vqa/images/944119093.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Richard Kunz"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Chicago's Commuter Railroads: A Guide to the Metra System"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Travel"}, {"from": "human", "value": "Is this book related to Travel?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Biographies & Memoirs?"}, {"from": "gpt", "value": "No"}]}, {"id": "876044011", "image": "ocr_vqa/images/876044011.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Kevin J. Todeschi"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Edgar Cayce on the Akashic Records: The Book of Life"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Religion & Spirituality"}, {"from": "human", "value": "Is this book related to Religion & Spirituality?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Business & Money?"}, {"from": "gpt", "value": "No"}]}, {"id": "007176822X", "image": "ocr_vqa/images/007176822X.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "John Jagerson"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "All About Forex Trading (All About Series)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Business & Money"}, {"from": "human", "value": "Is this a financial book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a youngster related book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1569242658", "image": "ocr_vqa/images/1569242658.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Gretchen Becker"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "The First Year: Type 2 Diabetes: An Essential Guide for the Newly Diagnosed"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Health, Fitness & Dieting"}, {"from": "human", "value": "Is this a fitness book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a crafts or hobbies related book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1111830991", "image": "ocr_vqa/images/1111830991.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Frederick J Gravetter"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Statistics for the Behavioral Sciences, 9th Edition"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Science & Math"}, {"from": "human", "value": "Is this a crafts or hobbies related book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1400033411", "image": "ocr_vqa/images/1400033411.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Toni Morrison"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Beloved"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Literature & Fiction"}, {"from": "human", "value": "Is this a pharmaceutical book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1583948414", "image": "ocr_vqa/images/1583948414.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Gustl Marlock"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "The Handbook of Body Psychotherapy and Somatic Psychology"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Health, Fitness & Dieting"}, {"from": "human", "value": "Is this a fitness book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this an exam preparation book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1845270150", "image": "ocr_vqa/images/1845270150.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Elin Meek"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Dathlu Gwyl Ddewi (Hwyl Gwyl)"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Children's Books"}, {"from": "human", "value": "Is this a kids book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this an art related book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1594711453", "image": "ocr_vqa/images/1594711453.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Michael Amodei"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Catholic Essentials: An Overview of the Faith"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Christian Books & Bibles"}, {"from": "human", "value": "Is this christianity book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a kids book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1505630843", "image": "ocr_vqa/images/1505630843.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Tim C. Taylor"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Indigo Squad (The Human Legion) (Volume 2)"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Science Fiction & Fantasy"}, {"from": "human", "value": "Is this a sci-fi book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a journey related book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1558689117", "image": "ocr_vqa/images/1558689117.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Brian Patrick O'Donoghue"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Iditarod Glory"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Sports & Outdoors"}, {"from": "human", "value": "Is this a games related book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a motivational book?"}, {"from": "gpt", "value": "No"}]}, {"id": "081181498X", "image": "ocr_vqa/images/081181498X.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Deborah Fine"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Star Wars Chronicles"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Humor & Entertainment"}, {"from": "human", "value": "Is this book related to Humor & Entertainment?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Medical Books?"}, {"from": "gpt", "value": "No"}]}, {"id": "312430078", "image": "ocr_vqa/images/312430078.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Augusten Burroughs"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Sellevision: A Novel"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Literature & Fiction"}, {"from": "human", "value": "Is this book related to Literature & Fiction?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Mystery, Thriller & Suspense?"}, {"from": "gpt", "value": "No"}]}, {"id": "300109865", "image": "ocr_vqa/images/300109865.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the title of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Psychoanalytic Terms and Concepts"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Medical Books"}, {"from": "human", "value": "Is this book related to Medical Books?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Gay & Lesbian?"}, {"from": "gpt", "value": "No"}]}, {"id": "1119083125", "image": "ocr_vqa/images/1119083125.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Peter Weverka"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Office 2016 All-In-One For Dummies (Office All-in-One for Dummies)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Computers & Technology"}, {"from": "human", "value": "Is this book related to Computers & Technology?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Test Preparation?"}, {"from": "gpt", "value": "No"}]}, {"id": "1625231547", "image": "ocr_vqa/images/1625231547.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Kaplan"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Kaplan New SAT 2016 Strategies, Practice and Review with 3 Practice Tests: Book + Online (Kaplan Test Prep)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Test Preparation"}, {"from": "human", "value": "Is this an exam preparation book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a crafts or hobbies related book?"}, {"from": "gpt", "value": "No"}]}, {"id": "982655908", "image": "ocr_vqa/images/982655908.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Abbie Davies"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "My First Yoga: Animal Poses"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Health, Fitness & Dieting"}, {"from": "human", "value": "Is this book related to Health, Fitness & Dieting?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Travel?"}, {"from": "gpt", "value": "No"}]}, {"id": "198254180", "image": "ocr_vqa/images/198254180.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "P. J. Kelly"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Utilitarianism and Distributive Justice: Jeremy Bentham and the Civil Law"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Science & Math"}, {"from": "human", "value": "Is this book related to Science & Math?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Literature & Fiction?"}, {"from": "gpt", "value": "No"}]}, {"id": "B005DID8H6", "image": "ocr_vqa/images/B005DID8H6.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Derek C. Hutchinson"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "The Complete Book of Sea Kayaking, 5th (How to Paddle Series)"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Sports & Outdoors"}, {"from": "human", "value": "Is this book related to Sports & Outdoors?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Sports & Outdoors?"}, {"from": "gpt", "value": "No"}]}, {"id": "823016293", "image": "ocr_vqa/images/823016293.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Carol Sampson"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Estimating for Interior Designers"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Arts & Photography"}, {"from": "human", "value": "Is this an art related book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a journey related book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1592535690", "image": "ocr_vqa/images/1592535690.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the title of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "The Art of Distilling Whiskey and Other Spirits: An Enthusiast's Guide to the Artisan Distilling of Potent Potables"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Cookbooks, Food & Wine"}, {"from": "human", "value": "Is this a recipe book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a sci-fi book?"}, {"from": "gpt", "value": "No"}]}, {"id": "307409155", "image": "ocr_vqa/images/307409155.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Jan Garavaglia M.D."}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "How Not to Die: Surprising Lessons from America's Favorite Medical Examiner"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Health, Fitness & Dieting"}, {"from": "human", "value": "Is this a fitness book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a romantic book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1305269217", "image": "ocr_vqa/images/1305269217.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Michael D. Spiegler"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Contemporary Behavior Therapy"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Science & Math"}, {"from": "human", "value": "Is this book related to Science & Math?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Romance?"}, {"from": "gpt", "value": "No"}]}, {"id": "1402765363", "image": "ocr_vqa/images/1402765363.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Brenda Rosen"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "The Mythical Creatures Bible: The Definitive Guide to Legendary Beings"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Politics & Social Sciences"}, {"from": "human", "value": "Is this a sociopolitical book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a financial book?"}, {"from": "gpt", "value": "No"}]}, {"id": "882407333", "image": "ocr_vqa/images/882407333.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the title of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Minneapolis/St. Paul: Portrait of the Twin Cities (Portrait of a Place)"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Travel"}, {"from": "human", "value": "Is this a journey related book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this christianity book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1250018684", "image": "ocr_vqa/images/1250018684.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Karen Katz"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "My First Chinese New Year (My First Holiday)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Children's Books"}, {"from": "human", "value": "Is this a kids book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a pedagogy book?"}, {"from": "gpt", "value": "No"}]}, {"id": "486414272", "image": "ocr_vqa/images/486414272.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the title of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Wit and Wisdom of the American Presidents: A Book of Quotations (Dover Thrift Editions,)"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Reference"}, {"from": "human", "value": "Is this a reference book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a homosexuality book?"}, {"from": "gpt", "value": "No"}]}, {"id": "982723911", "image": "ocr_vqa/images/982723911.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the title of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Cryptozoology Anthology: Strange and Mysterious Creatures in Men's Adventure Magazines"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Literature & Fiction"}, {"from": "human", "value": "Is this an exam preparation book?"}, {"from": "gpt", "value": "No"}]}, {"id": "073975856X", "image": "ocr_vqa/images/073975856X.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the title of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Libya Investment and Business Guide"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Travel"}, {"from": "human", "value": "Is this book related to Travel?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Cookbooks, Food & Wine?"}, {"from": "gpt", "value": "No"}]}, {"id": "226142698", "image": "ocr_vqa/images/226142698.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "John D'Emilio"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Lost Prophet: The Life and Times of Bayard Rustin"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Gay & Lesbian"}, {"from": "human", "value": "Is this a homosexuality book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a sci-fi book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1906780234", "image": "ocr_vqa/images/1906780234.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Lawson Wood"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "The World's Best Tropical Dive Destinations"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Travel"}, {"from": "human", "value": "Is this book related to Travel?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Cookbooks, Food & Wine?"}, {"from": "gpt", "value": "No"}]}, {"id": "827208448", "image": "ocr_vqa/images/827208448.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Nathan C. Walker"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Exorcising Preaching: Crafting Intellectually Honest Worship"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Religion & Spirituality"}, {"from": "human", "value": "Is this a religious book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a youngster related book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1517501571", "image": "ocr_vqa/images/1517501571.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Lisa Brian"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "My Lodge Cast Iron Skillet Cookbook: 101 Popular & Delicious Cast Iron Skillet Recipes (Cast Iron Recipes) (Volume 1)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Cookbooks, Food & Wine"}, {"from": "human", "value": "Is this a recipe book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this an art related book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1780547838", "image": "ocr_vqa/images/1780547838.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the title of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "The Official Little Mix 2016 A3 Calendar"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Calendars"}, {"from": "human", "value": "Is this book related to Calendars?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Education & Teaching?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which year's calendar is this?"}, {"from": "gpt", "value": "2016"}]}, {"id": "1454917091", "image": "ocr_vqa/images/1454917091.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Johnny Morgan"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "The Beach Boys: America's Band"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Humor & Entertainment"}, {"from": "human", "value": "Is this a comedy book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a crafts or hobbies related book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1477003797", "image": "ocr_vqa/images/1477003797.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the title of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Womens Wit 2015 Calendar: A Year of Wise and Witty Quotations on Women"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Calendars"}, {"from": "human", "value": "Is this a youngster related book?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "What is the year printed on this calendar?"}, {"from": "gpt", "value": "2015"}]}, {"id": "385736002", "image": "ocr_vqa/images/385736002.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Michael Scott"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "The Alchemyst: The Secrets of the Immortal Nicholas Flamel"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Teen & Young Adult"}, {"from": "human", "value": "Is this a youngster related book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a journey related book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1403986622", "image": "ocr_vqa/images/1403986622.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Michel Foucault"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "On The Government of the Living: Lectures at the Coll\u00e8ge de France, 1979-1980 (Michel Foucault: Lectures at the Coll\u00e8ge de France)"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Politics & Social Sciences"}, {"from": "human", "value": "Is this book related to Politics & Social Sciences?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Test Preparation?"}, {"from": "gpt", "value": "No"}]}, {"id": "B00DU7YCTK", "image": "ocr_vqa/images/B00DU7YCTK.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the title of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Antitrust Law And Economics In A Nutshell [Nutshell Series] by Ernest Gellhorn, William E. Kovacic, Stephen Calkins [West Group,2004] [Paperback] 5TH EDITION"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Law"}, {"from": "human", "value": "Is this a judicial book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a games related book?"}, {"from": "gpt", "value": "No"}]}, {"id": "226470784", "image": "ocr_vqa/images/226470784.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "K. Maria D. Lane"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Geographies of Mars: Seeing and Knowing the Red Planet"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Science & Math"}, {"from": "human", "value": "Is this book related to Science & Math?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Politics & Social Sciences?"}, {"from": "gpt", "value": "No"}]}, {"id": "791096947", "image": "ocr_vqa/images/791096947.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Sharon Giddings"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Cystic Fibrosis (Genes and Disease)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Health, Fitness & Dieting"}, {"from": "human", "value": "Is this a fitness book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this an art related book?"}, {"from": "gpt", "value": "No"}]}, {"id": "880104279", "image": "ocr_vqa/images/880104279.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Rudolf Steiner"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Anthroposophy in Everyday Life"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Religion & Spirituality"}, {"from": "human", "value": "Is this book related to Religion & Spirituality?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Engineering & Transportation?"}, {"from": "gpt", "value": "No"}]}, {"id": "415858941", "image": "ocr_vqa/images/415858941.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Jason M Dougherty"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Claims, Disputes and Litigation Involving BIM"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Law"}, {"from": "human", "value": "Is this a judicial book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a life story book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1402208286", "image": "ocr_vqa/images/1402208286.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Willam Hartston"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "The Encyclopedia of Useless Information"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Reference"}, {"from": "human", "value": "Is this a reference book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this an art related book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1583335234", "image": "ocr_vqa/images/1583335234.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Edward Humes"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Garbology: Our Dirty Love Affair with Trash"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Science & Math"}, {"from": "human", "value": "Is this a sociopolitical book?"}, {"from": "gpt", "value": "No"}]}, {"id": "674018524", "image": "ocr_vqa/images/674018524.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Judith Richardson"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Possessions: The History and Uses of Haunting in the Hudson Valley"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Mystery, Thriller & Suspense"}, {"from": "human", "value": "Is this book related to Mystery, Thriller & Suspense?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Children's Books?"}, {"from": "gpt", "value": "No"}]}, {"id": "199605890", "image": "ocr_vqa/images/199605890.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Geoffrey Hill"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Broken Hierarchies: Poems 1952-2012"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Literature & Fiction"}, {"from": "human", "value": "Is this book related to Literature & Fiction?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Children's Books?"}, {"from": "gpt", "value": "No"}]}, {"id": "1449081541", "image": "ocr_vqa/images/1449081541.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Rachel C.J. Massaquoi"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Foods of Sierra Leone and Other West African Countries: A Cookbook"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Cookbooks, Food & Wine"}, {"from": "human", "value": "Is this book related to Cookbooks, Food & Wine?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Computers & Technology?"}, {"from": "gpt", "value": "No"}]}, {"id": "316097705", "image": "ocr_vqa/images/316097705.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Meg Mitchell Moore"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "So Far Away: A Novel"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Literature & Fiction"}, {"from": "human", "value": "Is this a life story book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1847740308", "image": "ocr_vqa/images/1847740308.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Edoardo Albert"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Imam al-Ghazali: A Concise Life"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Teen & Young Adult"}, {"from": "human", "value": "Is this book related to Teen & Young Adult?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Christian Books & Bibles?"}, {"from": "gpt", "value": "No"}]}, {"id": "691129665", "image": "ocr_vqa/images/691129665.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "George L. Armistead"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Better Birding: Tips, Tools, and Concepts for the Field"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Science & Math"}, {"from": "human", "value": "Is this a crafts or hobbies related book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1476747415", "image": "ocr_vqa/images/1476747415.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Edward O. Wilson"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "A Window on Eternity: A Biologist's Walk Through Gorongosa National Park"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Science & Math"}, {"from": "human", "value": "Is this book related to Science & Math?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Self-Help?"}, {"from": "gpt", "value": "No"}]}, {"id": "967132304", "image": "ocr_vqa/images/967132304.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Wendy Moro"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "The Funny Bride Guide"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Crafts, Hobbies & Home"}, {"from": "human", "value": "Is this book related to Crafts, Hobbies & Home?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Business & Money?"}, {"from": "gpt", "value": "No"}]}, {"id": "1111129037", "image": "ocr_vqa/images/1111129037.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Cengage Learning Delmar"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "ASE Test Preparation - T7 Heating, Ventilation, and Air Conditioning (Delmar Learning's Ase Test Prep Series)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Test Preparation"}, {"from": "human", "value": "Is this book related to Test Preparation?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Test Preparation?"}, {"from": "gpt", "value": "No"}]}, {"id": "087910967X", "image": "ocr_vqa/images/087910967X.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Robert Blumenfeld"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Accents: A Manual for Actors- Revised and Expanded Edition"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Humor & Entertainment"}, {"from": "human", "value": "Is this a comedy book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a child-care book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1607559536", "image": "ocr_vqa/images/1607559536.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Willow Creek Press"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Waterfowl 2014 Wall Calendar"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Calendars"}, {"from": "human", "value": "Is this book related to Calendars?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Law?"}, {"from": "gpt", "value": "No"}, {"from": "human", "value": "Which year's calendar is this?"}, {"from": "gpt", "value": "2014"}]}, {"id": "1439190275", "image": "ocr_vqa/images/1439190275.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Eric C. Westman"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "New Atkins for a New You: The Ultimate Diet for Shedding Weight and Feeling Great."}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Cookbooks, Food & Wine"}, {"from": "human", "value": "Is this book related to Cookbooks, Food & Wine?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to History?"}, {"from": "gpt", "value": "No"}]}, {"id": "873414829", "image": "ocr_vqa/images/873414829.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Eugene Shadley"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "How to Make Multi-Blade Folding Knives"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Crafts, Hobbies & Home"}, {"from": "human", "value": "Is this book related to Crafts, Hobbies & Home?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Biographies & Memoirs?"}, {"from": "gpt", "value": "No"}]}, {"id": "809235668", "image": "ocr_vqa/images/809235668.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Andrea McNichol"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Handwriting Analysis : Putting It to Work for You"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Self-Help"}, {"from": "human", "value": "Is this a motivational book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a financial book?"}, {"from": "gpt", "value": "No"}]}, {"id": "486415910", "image": "ocr_vqa/images/486415910.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Mark Twain"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "A Connecticut Yankee in King Arthur's Court (Dover Thrift Editions)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Literature & Fiction"}, {"from": "human", "value": "Is this book related to Literature & Fiction?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Arts & Photography?"}, {"from": "gpt", "value": "No"}]}, {"id": "1285093135", "image": "ocr_vqa/images/1285093135.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Jennifer Duffy"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Microsoft Word 2013: Illustrated Brief"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Computers & Technology"}, {"from": "human", "value": "Is this a digital technology book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a pedagogy book?"}, {"from": "gpt", "value": "No"}]}, {"id": "982760884", "image": "ocr_vqa/images/982760884.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Andy Crowe PMP  PgMP"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Conversations on the PMP Exam: How to Pass on Your First Try: Fifth Edition"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Test Preparation"}, {"from": "human", "value": "Is this book related to Test Preparation?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Business & Money?"}, {"from": "gpt", "value": "No"}]}, {"id": "1845692160", "image": "ocr_vqa/images/1845692160.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "P J Fellows"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Food Processing Technology: Principles and Practice (Woodhead Publishing in Food Science, Technology and Nutrition)"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Cookbooks, Food & Wine"}, {"from": "human", "value": "Is this a recipe book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a historical book?"}, {"from": "gpt", "value": "No"}]}, {"id": "470409568", "image": "ocr_vqa/images/470409568.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Randy Vance"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Power Boating For Dummies"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Sports & Outdoors"}, {"from": "human", "value": "Is this book related to Sports & Outdoors?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to History?"}, {"from": "gpt", "value": "No"}]}, {"id": "1137279176", "image": "ocr_vqa/images/1137279176.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Deborah Perry Piscione"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Secrets of Silicon Valley: What Everyone Else Can Learn from the Innovation Capital of the World"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Business & Money"}, {"from": "human", "value": "Is this a financial book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a crafts or hobbies related book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1612431631", "image": "ocr_vqa/images/1612431631.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Julie Languille"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Meals in a Jar: Quick and Easy, Just-Add-Water, Homemade Recipes"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Cookbooks, Food & Wine"}, {"from": "human", "value": "Is this book related to Cookbooks, Food & Wine?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Humor & Entertainment?"}, {"from": "gpt", "value": "No"}]}, {"id": "752405322", "image": "ocr_vqa/images/752405322.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Rob Lewis"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Aquidneck Island (Images of America Series: New England)"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Travel"}, {"from": "human", "value": "Is this book related to Travel?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Sports & Outdoors?"}, {"from": "gpt", "value": "No"}]}, {"id": "801621860", "image": "ocr_vqa/images/801621860.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Edward Copas Hinds"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Surgical Treatment of Developmental Jaw Deformities"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Medical Books"}, {"from": "human", "value": "Is this a pharmaceutical book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a journey related book?"}, {"from": "gpt", "value": "No"}]}, {"id": "691167850", "image": "ocr_vqa/images/691167850.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Benjamin J. Cohen"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Currency Power: Understanding Monetary Rivalry"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Business & Money"}, {"from": "human", "value": "Is this book related to Business & Money?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Science & Math?"}, {"from": "gpt", "value": "No"}]}, {"id": "013608592X", "image": "ocr_vqa/images/013608592X.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "David A. Forsyth"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Computer Vision: A Modern Approach (2nd Edition)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Computers & Technology"}, {"from": "human", "value": "Is this book related to Computers & Technology?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Science & Math?"}, {"from": "gpt", "value": "No"}]}, {"id": "1601405308", "image": "ocr_vqa/images/1601405308.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Kooler Design Studio"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Needle Felting Artful Fashion  (Leisure Arts #4296)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Crafts, Hobbies & Home"}, {"from": "human", "value": "Is this book related to Crafts, Hobbies & Home?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Crafts, Hobbies & Home?"}, {"from": "gpt", "value": "No"}]}, {"id": "827608241", "image": "ocr_vqa/images/827608241.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Devra Newberger Speregen"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Albert Einstein: The Jewish Man Behind the Theory"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Teen & Young Adult"}, {"from": "human", "value": "Is this book related to Teen & Young Adult?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Mystery, Thriller & Suspense?"}, {"from": "gpt", "value": "No"}]}, {"id": "760759456", "image": "ocr_vqa/images/760759456.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Charlie Carlson"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Weird Florida"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Travel"}, {"from": "human", "value": "Is this a journey related book?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "941152154", "image": "ocr_vqa/images/941152154.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Roger M. Maiers"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Bringing Home the Belle"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Travel"}, {"from": "human", "value": "Is this a journey related book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this christianity book?"}, {"from": "gpt", "value": "No"}]}, {"id": "B00WKMGRBC", "image": "ocr_vqa/images/B00WKMGRBC.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Monica A. Coleman"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Making a Way Out of No way: A Womanist Theology (Innovations: African American Religious Thought)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Christian Books & Bibles"}, {"from": "human", "value": "Is this christianity book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this christianity book?"}, {"from": "gpt", "value": "No"}]}, {"id": "918860520", "image": "ocr_vqa/images/918860520.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "George Ohsawa"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Philosophy of Oriental Medicine: Key to Your Personal Judging Ability"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Health, Fitness & Dieting"}, {"from": "human", "value": "Is this a fitness book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a transportation engineering book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1601254369", "image": "ocr_vqa/images/1601254369.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "James Jacobs"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Pathfinder Adventure Path: Rise of the Runelords Anniversary Edition"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Science Fiction & Fantasy"}, {"from": "human", "value": "Is this a sci-fi book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a judicial book?"}, {"from": "gpt", "value": "No"}]}, {"id": "1565500539", "image": "ocr_vqa/images/1565500539.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Todd Ray"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Ultimate Skating Guide to the San Francisco Bay Area: 55 Great Places to In-Line Skate in the San Francisco Bay Area"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Sports & Outdoors"}, {"from": "human", "value": "Is this a games related book?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "486235807", "image": "ocr_vqa/images/486235807.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Erte"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Erte Graphics: Five Complete Suites (50 Prints) Reproduced in Full Color"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Arts & Photography"}, {"from": "human", "value": "Is this book related to Arts & Photography?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Computers & Technology?"}, {"from": "gpt", "value": "No"}]}, {"id": "3836526298", "image": "ocr_vqa/images/3836526298.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Stefan Fischer"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Hieronymus Bosch: Complete Works"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Arts & Photography"}, {"from": "human", "value": "Is this an art related book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this a fitness book?"}, {"from": "gpt", "value": "No"}]}, {"id": "761139796", "image": "ocr_vqa/images/761139796.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Suzy Becker"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "I Had Brain Surgery, What's Your Excuse?"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Humor & Entertainment"}, {"from": "human", "value": "Is this book related to Humor & Entertainment?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Biographies & Memoirs?"}, {"from": "gpt", "value": "No"}]}, {"id": "8497592360", "image": "ocr_vqa/images/8497592360.jpg", "conversations": [{"from": "human", "value": "<image>\nWho is the author of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "MARQUEZ GABRIEL GARC"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "LA INCREIBLE Y TRISTE HISTORIA"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Health, Fitness & Dieting"}, {"from": "human", "value": "Is this book related to Health, Fitness & Dieting?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Crafts, Hobbies & Home?"}, {"from": "gpt", "value": "No"}]}, {"id": "940322889", "image": "ocr_vqa/images/940322889.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Tete-Michel Kpomassie"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "An African in Greenland (New York Review Books Classics)"}, {"from": "human", "value": "What type of book is this?"}, {"from": "gpt", "value": "Travel"}, {"from": "human", "value": "Is this a journey related book?"}, {"from": "gpt", "value": "Yes"}]}, {"id": "1429648775", "image": "ocr_vqa/images/1429648775.jpg", "conversations": [{"from": "human", "value": "<image>\nWho wrote this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "Emily Sohn"}, {"from": "human", "value": "What is the title of this book?"}, {"from": "gpt", "value": "Skateboarding: How It Works (The Science of Sports (Sports Illustrated for Kids))"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Children's Books"}, {"from": "human", "value": "Is this a kids book?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this an exam preparation book?"}, {"from": "gpt", "value": "No"}]}, {"id": "310421403", "image": "ocr_vqa/images/310421403.jpg", "conversations": [{"from": "human", "value": "<image>\nWhat is the title of this book?\nAnswer the question using a single word or phrase."}, {"from": "gpt", "value": "The Book of Revelation"}, {"from": "human", "value": "What is the genre of this book?"}, {"from": "gpt", "value": "Comics & Graphic Novels"}, {"from": "human", "value": "Is this book related to Comics & Graphic Novels?"}, {"from": "gpt", "value": "Yes"}, {"from": "human", "value": "Is this book related to Engineering & Transportation?"}, {"from": "gpt", "value": "No"}]}, {"id": "b687414cac351b9b", "image": "textvqa/train_images/b687414cac351b9b.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: STOP, TO, STO, ILDRE"}, {"from": "gpt", "value": "THREE ROUND STOP SIGNS WITH FIGURES OF CHILDREN."}]}, {"id": "14f6ef3da70c7e15", "image": "textvqa/train_images/14f6ef3da70c7e15.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: THOMPSON, ST, STOP, Go"}, {"from": "gpt", "value": "a red stop sign with the street signs on top."}]}, {"id": "ac3e797f958b8a4d", "image": "textvqa/train_images/ac3e797f958b8a4d.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: ALCOHOL, KILLS, TAKE, PELSA, L.S."}, {"from": "gpt", "value": "The graphiti says alcohol kills and to instead take LSD."}]}, {"id": "eabd8e99a4f17bfe", "image": "textvqa/train_images/eabd8e99a4f17bfe.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: ASILANS, 1983"}, {"from": "gpt", "value": "A table at a restaurant, showing a beer, a person pointing at a menu and a coaster that says Ashley's since 1983."}]}, {"id": "c38a0522d2c0783b", "image": "textvqa/train_images/c38a0522d2c0783b.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: AMILLA, AMILLA, AMILLA"}, {"from": "gpt", "value": "Some old books with the title Camilla on it."}]}, {"id": "2d048d23b2e30f48", "image": "textvqa/train_images/2d048d23b2e30f48.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: E0, sdival, Smoked, ack, IPA, asdeaia, www.brouwerijdemolen.al, valer.pils, munchener, moked.checolale, barley, adsmanll, andboltled, emde, lemperalur, phorcyele, E, EMOLE"}, {"from": "gpt", "value": "Some wine with the title Festival Smoked on the label."}]}, {"id": "57b8464cb126b103", "image": "textvqa/train_images/57b8464cb126b103.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: ARDAHL, COMMY, ETN, WOR, 23, DNOW"}, {"from": "gpt", "value": "a group of players with Bardahl on a banner on the sidelines."}]}, {"id": "519e117f699c63b8", "image": "textvqa/train_images/519e117f699c63b8.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: 11, 12, 10, NEWATE, ATE, NE, 2, 9, 3, 8, 4, 7, 6, 5"}, {"from": "gpt", "value": "A glass analog wall clock with both hour and minute hands pointing at the 12."}]}, {"id": "2928b1a1cf22f030", "image": "textvqa/train_images/2928b1a1cf22f030.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: m, Bests, GREAT, WESTERN, 1006, SAUVIGNON, CABER"}, {"from": "gpt", "value": "A bottle of Great Western wine with a wooden backdrop."}]}, {"id": "bb99d21e36296270", "image": "textvqa/train_images/bb99d21e36296270.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: 11"}, {"from": "gpt", "value": "A youth athlete wearing number 11 holding Nesquik and a bottle of beer."}]}, {"id": "0b844bd4dae5e9c8", "image": "textvqa/train_images/0b844bd4dae5e9c8.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: H05, RUS, S"}, {"from": "gpt", "value": "A real Russian license plate with the following numbers: XH05."}]}, {"id": "afff532573f28738", "image": "textvqa/train_images/afff532573f28738.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: "}, {"from": "gpt", "value": "A dime from 2000 that says Liberty on a red table."}]}, {"id": "05ed96977cb9395b", "image": "textvqa/train_images/05ed96977cb9395b.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: NEYMAR, JR, 10"}, {"from": "gpt", "value": "Player number 10 walks across the grassy field."}]}, {"id": "9a50a18ba6e263e2", "image": "textvqa/train_images/9a50a18ba6e263e2.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: COUL-JABEA, 33, PALDING"}, {"from": "gpt", "value": "A basketball member wearing a yellow jersey that says Abdul-Jabbar 33 on the back standing with a basketball in his left hand and his right hand on his hip."}]}, {"id": "4067a102acf00436", "image": "textvqa/train_images/4067a102acf00436.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: ChocoVine, hetaste, of, dutch, chocolse, and, fine, red, vine"}, {"from": "gpt", "value": "A bottle of ChocoVine is displayed with the words \"The Taste of dutch chocolate and fine red wine\" on the label."}]}, {"id": "9de3c99bb7aed570", "image": "textvqa/train_images/9de3c99bb7aed570.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: 14, Specsavers, ng, in, en, do, S, DO, NG."}, {"from": "gpt", "value": "A player with number 14 holds up his right hand."}]}, {"id": "9ce6b248910e4fda", "image": "textvqa/train_images/9ce6b248910e4fda.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: DAVISE"}, {"from": "gpt", "value": "a man is on a boat, taking a photo, and there is a Davis mechanism on the boat."}]}, {"id": "01b238510d6b482b", "image": "textvqa/train_images/01b238510d6b482b.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: SCHOOL, BUS, 143A, 1680, A314-BA"}, {"from": "gpt", "value": "Numbered yellow school buses are parked side by side, with 1680 a neighbor to 1434."}]}, {"id": "f94f66af2ad88d21", "image": "textvqa/train_images/f94f66af2ad88d21.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: bagaimana, dalamhalini, disampaika, lembaga, dengan, tingkat, Pengawas, kepercayaan, sabilitas, Sumber, rendah?, menyetujui, aktivis, integritasnya, orang, bidang, intelijen,, serta, kemampuan, baik, terkait, Pancasila,, itmen, asasi, manusia., Ika,, NKRI, RICARDO, PASARIBU, Surabaya, pada, Sepatu, Merek, Palsu, ESDM, tempat, Nike, menjadi, rogram, adalah, dengan, 35.000, yang, 363398412, dikirim, barang, Ternyata, pemasuka, palsu, pinggir, tertipu, unit, pembangkit, gas, PLTG, dimaksud, leng-, ada, Lazada, menjual, negeri,, mengirim, layak,, menelepon, besertifika, pabrik,, mampu, perproduksi, Atakkae, India,, Sulawesi, eperti, beberapa, telanjur, dibangun,, beroperasi, karena"}, {"from": "gpt", "value": "A Swiss Army is placed on top of a newspaper."}]}, {"id": "00e89628f7bf6d68", "image": "textvqa/train_images/00e89628f7bf6d68.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: XH, Haus, der, 000, Uhren, Hou.., of, IA, Clocks, BLOWED"}, {"from": "gpt", "value": "A building with a huge clock on it has the number 1000 on its sign."}]}, {"id": "fc10fa122eff47a9", "image": "textvqa/train_images/fc10fa122eff47a9.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: rowed, DA, BLG, BREW, Alebrewed, with, honey, and, gesho, 1.Pint, 9.4.fl.oz"}, {"from": "gpt", "value": "A bottle with Miles Davis Bitches Brew on the label with an seascape illustration of a person looking out towards sea."}]}, {"id": "f482df6868034fd8", "image": "textvqa/train_images/f482df6868034fd8.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: Ballantine, 31571, $3.95, Over, 3, months, on, G, the, New, York, Times, Bestseller, List, SAACASIMOV, THE, ROBOTS, OF, DAWN, ALije, Baley, &R., Daneel, Olivaw, Novel"}, {"from": "gpt", "value": "A book that was on the New York Times bestseller list for over 3 months."}]}, {"id": "a08ef37b75b6366a", "image": "textvqa/train_images/a08ef37b75b6366a.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: VODKA, BAC, ARDI, ONOPOLOWA, BACZEWSI, KNOB, Maker's, Mark, CREEK, WISKY, USSELLS"}, {"from": "gpt", "value": "A bottle of Maker's Mark whiskey sits in the middle of other bottles on a shelf."}]}, {"id": "aeabcb1edf39fed6", "image": "textvqa/train_images/aeabcb1edf39fed6.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: <), I"}, {"from": "gpt", "value": "Two boxes with the letter p and one box open with a watch inside."}]}, {"id": "fde8f46ece935093", "image": "textvqa/train_images/fde8f46ece935093.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: H, TEELHO, Mets, 47"}, {"from": "gpt", "value": "A Mets player #47 bobble head figure is shown with his hands up and mouth open."}]}, {"id": "0220a53c342555f2", "image": "textvqa/train_images/0220a53c342555f2.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: Creation:, Brickworld, Creator:, Dolphin, Firocopte, HH-65, MareusSchultz, Marcus, Schultz"}, {"from": "gpt", "value": "The helicopter model is a Eurocopter HH-65 Dolphin, which was created by Marcus Schultz of Brickworld."}]}, {"id": "5c21b48aba7574d2", "image": "textvqa/train_images/5c21b48aba7574d2.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: Are, you, checking, out, my, back, side?"}, {"from": "gpt", "value": "A placard that says \"Are you checking out my back side?\" is sitting on a table."}]}, {"id": "112cfdfdeeea5d2f", "image": "textvqa/train_images/112cfdfdeeea5d2f.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: TIME, TEMP, 0557, LOW, SLOW, COOK, ROWN/SAUTE, STEAM, START/STOP"}, {"from": "gpt", "value": "A cookware display shows that it is cooking at low temperature."}]}, {"id": "417814b32ecd63c7", "image": "textvqa/train_images/417814b32ecd63c7.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: GRAMB, powde, HAERINDA"}, {"from": "gpt", "value": "Baby powder and some spray bottles sit on a shelf in a barbershop."}]}, {"id": "57e60e7639b3d40d", "image": "textvqa/train_images/57e60e7639b3d40d.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: QQ, MONOLULU'S, ESPIN, RADIO1420AM, 106.5F, GP, Solutions, ihe, PETERSON, HPU, monanch, zar, ESERVI, HIGH, SCHOOL, ISAA, sportshin, ETIC, ASSOCIATION"}, {"from": "gpt", "value": "A group of cheerleaders from HPU are doing a routine."}]}, {"id": "14e8193b1faa4a99", "image": "textvqa/train_images/14e8193b1faa4a99.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: Nery, Very, Old, YEARSOL, OLD, BONDED, TWEIVE, Straight, Boutbon, Whsky, Dal, Fitzgerald, 100, PROOF, EXPRESSL, 50%, LCIVOL, CONN, CONNDISSEURS, (100, PROOF), FOR"}, {"from": "gpt", "value": "A large bottle of old Fitzgerald sits in a dark setting."}]}, {"id": "82fa6e0beae8efed", "image": "textvqa/train_images/82fa6e0beae8efed.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: TL, WONDA, x-3*#, 20b18, 24418, 20608, 00299, AICHITOKE"}, {"from": "gpt", "value": "A couple of Wonda cans atop an Aichi Tokei electrical box."}]}, {"id": "1f719862d906942a", "image": "textvqa/train_images/1f719862d906942a.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: YOHN, GIA, NTS"}, {"from": "gpt", "value": "Red and yellow Giants jersey placed on a blue background."}]}, {"id": "1cf0775524f0994b", "image": "textvqa/train_images/1cf0775524f0994b.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: FIDELITY, COLEMBI, WINE, STAR, TER, STEREO, DAVIS, Kind, SYSTEM, MILES, 6, Bottle, Kit, Cabernet, Sauvignon, ApproxABV12%, IANES, BREWING, step-by, tom, STNN, HESTIRY, ALE"}, {"from": "gpt", "value": "Wine Starter System book next to a Brewing book as well."}]}, {"id": "fdb7ef71e98277cd", "image": "textvqa/train_images/fdb7ef71e98277cd.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: ONE, WAY, DO, NOT, ENTER, STOP"}, {"from": "gpt", "value": "A sign behind a stop sign indicates a one way direction."}]}, {"id": "01335761c3a1a042", "image": "textvqa/train_images/01335761c3a1a042.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: R0S0COP, 019.1967, PIC, TU:ES, ROGOCOR, SIETH, AIRGIN, VISION, NOUO, ocean, ZX, Spectrum"}, {"from": "gpt", "value": "An old PC with an LG monitor dispalying RoboCop."}]}, {"id": "35c4873861d8be88", "image": "textvqa/train_images/35c4873861d8be88.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: "}, {"from": "gpt", "value": "The baseball player about to throw the ball is from a team that is the national champions."}]}, {"id": "5a9be206764084b0", "image": "textvqa/train_images/5a9be206764084b0.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: CAPTAN, RUM, BACARD, SELEC, MOUNTGAYRU, bancour, SPICEDRLV, 21R0S0"}, {"from": "gpt", "value": "Bottle of Mount Gay Rum and A bottle of Bacardi Select."}]}, {"id": "e91c8fab0704e571", "image": "textvqa/train_images/e91c8fab0704e571.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: Compie, type:, Dome, Shof, N=25, filename, 328, 9687, Phobucken, cken, 17.50, dash, Min, 14, undassove, 960, Max-, 76, 95, 00/, un, /test, pragam, Arg-, 43.32, 54-15/, ype, C52510, 003-fallo4, bun, handin, out, B8, hobucken, S2510, S2510-003_fallo4, 003., fallo4, Prog.cc"}, {"from": "gpt", "value": "A chalk board displays instructions to compile a computer program."}]}, {"id": "093257282acf0d13", "image": "textvqa/train_images/093257282acf0d13.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: htc"}, {"from": "gpt", "value": "the back of an HTC silver phone on a wooden surface."}]}, {"id": "f4f8867db042c10b", "image": "textvqa/train_images/f4f8867db042c10b.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: BOHEMIA"}, {"from": "gpt", "value": "A black box saying BOHEMIA VALUE FOR A LIFETIME sits inside an open cardboard shipping box."}]}, {"id": "6b0b6abee21e4baa", "image": "textvqa/train_images/6b0b6abee21e4baa.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: BRADBURY, STORIES, ONIAINO, LI3HN3UI, 1, EBRADBUR, NIT, 1S7, LI3HN38HV3, EORIES, OF, EERADBURY, 5"}, {"from": "gpt", "value": "Several books are lined neatly on a shelf, including Fahrenheit 451."}]}, {"id": "9d420bb636b64ed1", "image": "textvqa/train_images/9d420bb636b64ed1.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: alty, Premium, Specialty, Premium, Premium, ID, KIRIN, RAND, KIRIN, AROMA, AROMA, BREWING, THE, AROMA, AROMA, BREWING, KIRIN, KIRIN"}, {"from": "gpt", "value": "small beer bottles that say grand kirin the aroma on them."}]}, {"id": "bc151c20f55a4a26", "image": "textvqa/train_images/bc151c20f55a4a26.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: O, 20"}, {"from": "gpt", "value": "An old plane with 120 on the side flies in the sky."}]}, {"id": "56b9de7912bac7b0", "image": "textvqa/train_images/56b9de7912bac7b0.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: clarion, WILSON, WRITERS, WORKSHOP, FEATURING, CRITICISM, \"SCIENCE, FICTION, SAMUEL, DELANY, FREDERIK, APPROACHED, HARLAN, ELLISON, JOANNA, includingthe, FROM, MANY, NEW, ONE, WILHELM, MOST, EXCITING\", SAMUEL, DELANY, FRITZ, THURSTON, GERARDF, CONWAY, Until, STEVE, HERBST, fiction, condemne, purgatory, decade, radically, Science, literary, Bradbury, Vonnegu, rthur, Tolkien, allelped, recognition, Along, resurgence, popularity, critica, raditional, science, exclusively, most, fthese, Clarion., Writers', atmany, oiceswill, influence, irectiono, science, fictioninthe"}, {"from": "gpt", "value": "The front and back of a book called clarion."}]}, {"id": "82604e9e5a85b6ab", "image": "textvqa/train_images/82604e9e5a85b6ab.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: t, ROCK, BRIDGE, BREWINGCO, RL, RIVE, PINE, Ta, S"}, {"from": "gpt", "value": "A man with a plate of food stands in front of a framed sign for Rock Bridge Brewing company."}]}, {"id": "b282212613b75986", "image": "textvqa/train_images/b282212613b75986.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: 5, RIDGEPER, 208, ISRO, 37V, ZO, PALE, TH, BREWING"}, {"from": "gpt", "value": "A bottle of Bridegport Blue Pale Ale beer being held in a man's hand."}]}, {"id": "1ab3c55cbac00995", "image": "textvqa/train_images/1ab3c55cbac00995.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: .ull, AT&T, 6, 11:05, PM, Schmap!!, Stockholm, Stockholm, Old, Town, Photo:, Lana, Macko, Photo:, Marco, Raaphorst, Photo:, Giorgio, Marziani, Photo:, Nevill, Info, Review, Review, Photos, 7"}, {"from": "gpt", "value": "an iphone with the screen on and time reading 11:05 pm."}]}, {"id": "86c69c39525a24e4", "image": "textvqa/train_images/86c69c39525a24e4.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: 4.0, C, 1, DEETTLY, REEITD, DEEITIH"}, {"from": "gpt", "value": "A man is giving a presentation with a screen showing someone holding phone with the time of 10:20 AM."}]}, {"id": "c06900b3b6c5ddb5", "image": "textvqa/train_images/c06900b3b6c5ddb5.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: UNDERWOOD"}, {"from": "gpt", "value": "a black and white photo of an underwood typewriter."}]}, {"id": "024a8c17281ef932", "image": "textvqa/train_images/024a8c17281ef932.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: POLOBERG, 27"}, {"from": "gpt", "value": "Baseball player wearing number 27 talking to some children."}]}, {"id": "4053d0ebd0afaa36", "image": "textvqa/train_images/4053d0ebd0afaa36.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: SPORT, PRAROHN, Iou, TRONER, 3, 4ovend, 50"}, {"from": "gpt", "value": "a few players with Japanese language on their jerseys with one man wearing 50."}]}, {"id": "5095124725543461", "image": "textvqa/train_images/5095124725543461.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: 20"}, {"from": "gpt", "value": "A black man with Heward on the back of his jersey holds a baseball bat on the field."}]}, {"id": "c08c72c65de834e3", "image": "textvqa/train_images/c08c72c65de834e3.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: STRIKE, OUT, Field, RETSCHMAN, USA, LOWE, 12, 12, 2, 26"}, {"from": "gpt", "value": "a few girls that are wearing jerseys that say USA."}]}, {"id": "fa338073bc8979da", "image": "textvqa/train_images/fa338073bc8979da.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: POLEn, PER., 16, 19, W, Major"}, {"from": "gpt", "value": "Female soccer players wearing numbers such as 16 and 19 jostling for the soccer ball."}]}, {"id": "f92ac1e52d5f4f25", "image": "textvqa/train_images/f92ac1e52d5f4f25.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: aA, AUO, Laa, S, 4azy"}, {"from": "gpt", "value": "A wrestler wearing a Cee Bees uniform is competing against a wrestler wearing red, white and blue."}]}, {"id": "58ba95a1f717233f", "image": "textvqa/train_images/58ba95a1f717233f.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: GIFls, IO, LUGGAGE, SPORTS, SOUVENLERS, S, AY, 71517, LOGIC, RD, THIS, BUS, !!!!, TrutyThaLgclExpert!, Expert!, TheLoca, 0COD, f, Broin, Jull"}, {"from": "gpt", "value": "A large, red bus that says Truly The Local Export on the front is in the furthest lane of a road full of Taxi cab's."}]}, {"id": "0b7fce3bf0471d14", "image": "textvqa/train_images/0b7fce3bf0471d14.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: THE, ARTWORK, FORGE, WELCOME, ARTWO, STOP!, 40, RETE, EXACT, STEPTNO, BOUDDBLANV"}, {"from": "gpt", "value": "The Artwork Forge that is located outside in daytime."}]}, {"id": "6c46d6d2d46ba54b", "image": "textvqa/train_images/6c46d6d2d46ba54b.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: 8"}, {"from": "gpt", "value": "Brown garbage can which says I Love Dogs on it."}]}, {"id": "3b56e9a68452e5ac", "image": "textvqa/train_images/3b56e9a68452e5ac.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: Ths, skelenom, of, Spiedood, s, simier, the, arce, iane, eatre, Smosaurs, discowered, JS00, this, CUENY"}, {"from": "gpt", "value": "A dinosaur skeleton is shown along with text that says this dinosaur is similar to the large plant-eating dinosaurs."}]}, {"id": "23f7f64619b325d9", "image": "textvqa/train_images/23f7f64619b325d9.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: DOMAINE, CHANGARNIER, MEURSAULT, PPELLATION.MEURSAULIT.CONTROLE, CONTROLEE, 2006, BoL\u00ae"}, {"from": "gpt", "value": "A bottle of Domaine Changarnier Meursault from 2006."}]}, {"id": "002d7d220a042075", "image": "textvqa/train_images/002d7d220a042075.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: ne, to, Thorns, Showcase, Lounge, Home, of, the, World, Renown, Bucket, of, Butt, Halibut, er., that, Come, join, us, for, NE, Excellent, Lunch, &, Dinner, GENUI, 11am, 11pm, ERED\", Gourmet, Steaks, &, Seafood, Lite, Responsibly"}, {"from": "gpt", "value": "An advertisement for Thorns Showcase Lounge to join them for lunch and dinner."}]}, {"id": "01e82d950d72633f", "image": "textvqa/train_images/01e82d950d72633f.jpg", "conversations": [{"from": "human", "value": "<image>\nProvide a one-sentence caption for the provided image.\nReference OCR token: 18, Nottingham, Staple, 18, FOYT"}, {"from": "gpt", "value": "A blue single decker bus with the number 18 on the front."}]}]